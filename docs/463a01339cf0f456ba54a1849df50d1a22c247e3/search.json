[
  {
    "objectID": "cheatsheet-math.html",
    "href": "cheatsheet-math.html",
    "title": "DSAN 5100 Math Cheatsheet",
    "section": "",
    "text": "Proposition \\(p\\): A true-false statement like “1 + 1 = 2” or “\\(x\\) is greater than 5”. The latter would be written as \\(p(x)\\), since its true/false value depends on a given value of \\(x\\).\n\\(\\wedge\\): Logical “and”. \\(p \\wedge q\\) is true only if both \\(p\\) and \\(q\\) are true.\n\\(\\vee\\): Logical “or”. \\(p \\vee q\\) is true if \\(p\\) is true or \\(q\\) is true, or both are true.\n\\(\\neg\\): Logical negation: If \\(p\\) is true, \\(\\neg p\\) is false. If \\(p\\) is false, \\(\\neg p\\) is true.\nDeMorgan’s Laws: Logical identities which illustrate how the negation operator gets “distributed” in a logical statement, allowing conversion of “or” statements into “and” statements, and vice-versa: \\(\\neg(p \\wedge q) = \\neg(\\neg p \\vee \\neg q)\\)\n\\(\\implies\\): “Implies”. \\(a \\implies b\\) is true if, whenever \\(a\\) is true, \\(b\\) is also true.\n\\(\\iff\\): “If and only if”. \\(a \\iff b\\) is true if, \\(a\\) is only true when \\(b\\) is true, and \\(a\\) is only false when \\(b\\) is false.\n\\(\\exists\\): “There exists”. In the course this will be written as \\(\\exists x \\in S [p(x)]\\), which means that there exists some element \\(x\\) in the set \\(S\\) such that \\(p(x)\\) is true. Also called the “existential quantifier”.\n\\(\\forall\\): “For all”. In the course this will be written as \\(\\forall x \\in S [p(x)]\\), which means that for every element in a set \\(S\\) (with \\(x\\) representing some element arbitrarily taken from \\(S\\)), the proposition \\(p(x)\\) is true. Also called the “universal quantifier”.\n\nNote that the universal and existential quantifiers are closely related by a negation law (just like \\(\\wedge\\) and \\(\\vee\\) and their connection via DeMorgan’s Laws): \\(\\neg \\left( \\forall x \\in S[p(x)] \\right) \\iff \\exists x \\in S [\\neg p(x)]\\). The negation on the outside of the quantified proposition has moved inside of it, with the quantifier flipped.\nThe same holds true in reverse: \\(\\neg \\left( \\exists x \\in S [p(x)] \\right) \\iff \\forall x \\in S [\\neg p(x)]\\)\n\n\n\n\n\n\nA set \\(S\\) (denoted by a capital letter when possible) is a collection of elements (denoted by a lowercase letter when possible).\n\nFor example, if \\(S = \\{0,1,2,3\\}\\), then \\(0\\) is an element of \\(S\\).\n\n\\(a \\in S\\): The proposition that \\(a\\) is an element of the set \\(S\\).\n\nIf \\(S = \\{0,1,2,3\\}\\), then \\(2 \\in S\\) but \\(5 \\notin S\\).\n\n\\(A \\subseteq S\\): The proposition that \\(A\\) is a subset of the set \\(S\\).\n\nIf \\(S = \\{0, 1, 2, 3\\}\\), then \\(\\{1,3\\} \\subseteq S\\) but \\(\\{1,4\\} \\not\\subseteq S\\). Note that sets are defined to be subsets of themselves, so that \\(S \\subseteq S\\).\n\n\\(A \\subset S\\): The proposition that \\(A\\) is a proper subset of \\(S\\), meaning that \\(A \\subseteq S\\) but \\(A \\neq S\\).\n\nWhile sets are subsets of themselves, sets are not proper subsets of themselves, so that if \\(S = \\{0, 1, 2, 3\\}\\), then \\(\\{1,2,3\\} \\subset S\\) but \\(\\{0, 1, 2, 3\\} \\not\\subset S\\).\n\n\\(|S|\\): The cardinality of, or number of elements in, a set \\(S\\).\n\nIf \\(S = \\{1, 2, 3\\}\\), \\(|S| = 3\\).\nIf the set \\(S\\) has infinite cardinality, we can distinguish between two cases:\n\nIf elements of \\(S\\) can be put into one-to-one correspondence with the natural numbers \\(\\mathbb{N}\\), we say that \\(S\\) is countably infinite and has cardinality \\(\\aleph_0\\) (pronounced “aleph-null”): \\(|S| = \\aleph_0\\).\nIf elements of \\(S\\) cannot be put into one-to-one correspondence with the natural numbers \\(\\mathbb{N}\\), we say that \\(S\\) is uncountably infinite and has cardinality greater than \\(\\aleph_0\\): \\(|S| &gt; \\aleph_0\\).\n\n\n\\(\\mathcal{P}(S)\\): The power set of a set \\(S\\), which is the set of all possible subsets of \\(S\\).\n\nFor example, if \\(S = \\{1, 2, 3\\}\\), \\(\\mathcal{P}(S) = \\{\\varnothing, \\{1\\}, \\{2\\}, \\{3\\}, \\{1,2\\}, \\{1,3\\}, \\{2,3\\}, \\{1,2,3\\}\\}\\). Notice that \\(|\\mathcal{P}(S)| = 2^{|S|}\\), which is always true of the power set.\n\n\n\n\n\n\n\\(\\mathbb{N}\\): The set of all natural numbers, sometimes called the “counting numbers”: \\(\\{0, 1, 2, 3, \\ldots \\}\\) (This set is countably infinite).\n\\(\\mathbb{Z}\\): The set of all integers, which includes all of the natural numbers along with their negatives: \\(\\{\\ldots, -2, -1, 0, 1, 2, \\ldots\\}\\) (This set is also countably infinite)\n\\(\\mathbb{Q}\\): The set of all rational numbers, i.e., well-defined ratios of two integers. \\(x \\in \\mathbb{Q} \\iff x = \\frac{p}{q}\\) for two integers \\(p\\) and \\(q\\), and \\(q \\neq 0\\). (This set is, surprisingly, also countably infinite)\n\\(\\mathbb{R}\\): The set of all real numbers, which includes all integers as well as numbers such as \\(\\pi\\), \\(2.356\\), or \\(\\sqrt{2}\\) (This set is uncountably infinite).\nScalar: A single number from some set of numbers, like \\(-2.1 \\in \\mathbb{R}\\)\nVector: A \\(d\\)-dimensional vector \\(\\mathbf{v}\\) is a collection of \\(d\\) scalars in \\(\\mathbb{R}\\), \\(\\mathbf{v} = (v_1, v_2, \\ldots, v_d)^\\top\\), which we can interpret as an arrow pointing \\(v_i\\) units in each dimension \\(i\\). For example, if \\(\\mathbf{v} = (3,5)\\), we can interpret \\(\\mathbf{v}\\) as representing an arrow pointing \\(3\\) units in the \\(x\\) direction and \\(5\\) units in the \\(y\\) direction.\n\nAs indicated above, however, we will assume that vectors are column vectors unless otherwise specified, though they will be written row-wise with a transpose symbol at the end. This means that, although it will be written like \\(\\mathbf{v} = (v_1, v_2, \\ldots, v_n)^\\top\\), you should apply the transpose in your head: \\[\n\\mathbf{v} = (v_1, v_2, \\ldots, v_n)^\\top = \\begin{bmatrix}v_1 \\\\ v_2 \\\\ \\vdots \\\\ v_n\\end{bmatrix}\n\\]\n\nMatrix: An \\(m \\times n\\) matrix \\(\\mathbf{M}_{[m \\times n]}\\) is an \\(m\\)-by-\\(n\\) grid of scalars, where the scalar in the \\(i\\)th row and \\(j\\)th column is denoted \\(m_{i,j}\\). In the class, we will be careful to add a subscript like \\(\\mathbf{M}_{[m \\times n]}\\) to indicate the number of rows (\\(m\\)) and columns (\\(n\\)) in the matrix, since operations like multiplication are only defined for matrices with particular dimensions.\nMatrix multiplication: For two matrices \\(\\mathbf{X}_{[a \\times b]}\\) and \\(\\mathbf{Y}_{[c \\times d]}\\), matrix multiplication is defined if \\(b = c\\), and produces the following \\(a \\times d\\) matrix \\(\\mathbf{XY}_{[a \\times d]}\\):\n\\[\n  \\mathbf{XY}_{[a \\times d]} = \\begin{bmatrix}\n  x_{1,1}y_{1,1} & \\cdots & x_{m,1}y_{1,n} \\\\\n  \\vdots & \\ddots & \\vdots \\\\\n  x_{1,n}y_{m,1} & \\cdots & x_{m,n}y_{m,n}\n  \\end{bmatrix}\n  \\]\n\\(\\sum_{i=1}^n f(i)\\): \\(\\Sigma\\) is the capitalized Greek letter “Sigma”, and stands for “Sum” in this case. This notation means: “the sum of \\(f(i)\\) from \\(i = 1\\) to \\(i = n\\)”. For example, \\(\\sum_{i=1}^3 i^2 = 1^2 + 2^2 + 3^2 = 14\\).\n\\(\\prod_{i=1}^n f(i)\\): \\(\\Pi\\) is the capitalized Greek letter “Pi”, and stands for “Product” in this case. This notation means: “the product of \\(f(i)\\) from \\(i = 1\\) to \\(i = n\\)”. For example, \\(\\prod_{i=1}^3 i^2 = 1^2 \\cdot 2^2 \\cdot 3^2 = 36\\).\n\n\n\n\n\n\\([a,b] \\in \\mathbb{R}\\): The closed interval between \\(a\\) and \\(b\\). That is, the subset of \\(\\mathbb{R}\\) containing all numbers between \\(a\\) and \\(b\\), including \\(a\\) and \\(b\\) themselves.\n\\((a,b) \\in \\mathbb{R}\\): The open interval between \\(a\\) and \\(b\\). That is, the subset of \\(\\mathbb{R}\\) containing all numbers between \\(a\\) and \\(b\\), excluding \\(a\\) and \\(b\\) themselves.\n\\([a, b)\\), \\((a, b]\\): The half-open interval between \\(a\\) and \\(b\\). In the first case, we include \\(a\\) but exclude \\(b\\), while in the second we exclude \\(a\\) but include \\(b\\).\n\\(\\int_{a}^b f(x)dx\\): The integral of the function \\(f(x)\\) between points \\(a\\) and \\(b\\). In this course, you just need to remember that this produces the area under the curve of \\(f(x)\\) between these points.\n\\(\\frac{d}{dx} \\left[ f(x) \\right]\\): The derivative of the function \\(f(x)\\). For this class, you just need to remember that the derivative is what transforms a Cumulative Density Function (CDF) into a Probability Density Function (PDF): if \\(F_X(v)\\) is the CDF of a random variable \\(X\\), then \\(\\frac{d}{dx}\\left[ F_X(v) \\right] = f_X(v)\\), the PDF of \\(X\\).\n\nFor functions of multiple variables, like the joint pdf \\(f_{X,Y}(v_X, v_Y)\\), we use the \\(\\partial\\) symbol instead of \\(d\\) to denote partial derivatives: for example, the change in \\(F_{X,Y}(v_X, v_Y)\\) as \\(v_X\\) changes is denoted \\(\\frac{\\partial}{\\partial v_X}\\left[ F_{X,Y}(v_X, v_Y) \\right]\\), while the change in \\(F_{X,Y}(v_X, v_Y)\\) as \\(v_Y\\) changes is denoted \\(\\frac{\\partial}{\\partial v_Y}\\left[ F_{X,Y}(v_X, v_Y) \\right]\\)."
  },
  {
    "objectID": "cheatsheet-math.html#math-preliminaries",
    "href": "cheatsheet-math.html#math-preliminaries",
    "title": "DSAN 5100 Math Cheatsheet",
    "section": "",
    "text": "Proposition \\(p\\): A true-false statement like “1 + 1 = 2” or “\\(x\\) is greater than 5”. The latter would be written as \\(p(x)\\), since its true/false value depends on a given value of \\(x\\).\n\\(\\wedge\\): Logical “and”. \\(p \\wedge q\\) is true only if both \\(p\\) and \\(q\\) are true.\n\\(\\vee\\): Logical “or”. \\(p \\vee q\\) is true if \\(p\\) is true or \\(q\\) is true, or both are true.\n\\(\\neg\\): Logical negation: If \\(p\\) is true, \\(\\neg p\\) is false. If \\(p\\) is false, \\(\\neg p\\) is true.\nDeMorgan’s Laws: Logical identities which illustrate how the negation operator gets “distributed” in a logical statement, allowing conversion of “or” statements into “and” statements, and vice-versa: \\(\\neg(p \\wedge q) = \\neg(\\neg p \\vee \\neg q)\\)\n\\(\\implies\\): “Implies”. \\(a \\implies b\\) is true if, whenever \\(a\\) is true, \\(b\\) is also true.\n\\(\\iff\\): “If and only if”. \\(a \\iff b\\) is true if, \\(a\\) is only true when \\(b\\) is true, and \\(a\\) is only false when \\(b\\) is false.\n\\(\\exists\\): “There exists”. In the course this will be written as \\(\\exists x \\in S [p(x)]\\), which means that there exists some element \\(x\\) in the set \\(S\\) such that \\(p(x)\\) is true. Also called the “existential quantifier”.\n\\(\\forall\\): “For all”. In the course this will be written as \\(\\forall x \\in S [p(x)]\\), which means that for every element in a set \\(S\\) (with \\(x\\) representing some element arbitrarily taken from \\(S\\)), the proposition \\(p(x)\\) is true. Also called the “universal quantifier”.\n\nNote that the universal and existential quantifiers are closely related by a negation law (just like \\(\\wedge\\) and \\(\\vee\\) and their connection via DeMorgan’s Laws): \\(\\neg \\left( \\forall x \\in S[p(x)] \\right) \\iff \\exists x \\in S [\\neg p(x)]\\). The negation on the outside of the quantified proposition has moved inside of it, with the quantifier flipped.\nThe same holds true in reverse: \\(\\neg \\left( \\exists x \\in S [p(x)] \\right) \\iff \\forall x \\in S [\\neg p(x)]\\)\n\n\n\n\n\n\nA set \\(S\\) (denoted by a capital letter when possible) is a collection of elements (denoted by a lowercase letter when possible).\n\nFor example, if \\(S = \\{0,1,2,3\\}\\), then \\(0\\) is an element of \\(S\\).\n\n\\(a \\in S\\): The proposition that \\(a\\) is an element of the set \\(S\\).\n\nIf \\(S = \\{0,1,2,3\\}\\), then \\(2 \\in S\\) but \\(5 \\notin S\\).\n\n\\(A \\subseteq S\\): The proposition that \\(A\\) is a subset of the set \\(S\\).\n\nIf \\(S = \\{0, 1, 2, 3\\}\\), then \\(\\{1,3\\} \\subseteq S\\) but \\(\\{1,4\\} \\not\\subseteq S\\). Note that sets are defined to be subsets of themselves, so that \\(S \\subseteq S\\).\n\n\\(A \\subset S\\): The proposition that \\(A\\) is a proper subset of \\(S\\), meaning that \\(A \\subseteq S\\) but \\(A \\neq S\\).\n\nWhile sets are subsets of themselves, sets are not proper subsets of themselves, so that if \\(S = \\{0, 1, 2, 3\\}\\), then \\(\\{1,2,3\\} \\subset S\\) but \\(\\{0, 1, 2, 3\\} \\not\\subset S\\).\n\n\\(|S|\\): The cardinality of, or number of elements in, a set \\(S\\).\n\nIf \\(S = \\{1, 2, 3\\}\\), \\(|S| = 3\\).\nIf the set \\(S\\) has infinite cardinality, we can distinguish between two cases:\n\nIf elements of \\(S\\) can be put into one-to-one correspondence with the natural numbers \\(\\mathbb{N}\\), we say that \\(S\\) is countably infinite and has cardinality \\(\\aleph_0\\) (pronounced “aleph-null”): \\(|S| = \\aleph_0\\).\nIf elements of \\(S\\) cannot be put into one-to-one correspondence with the natural numbers \\(\\mathbb{N}\\), we say that \\(S\\) is uncountably infinite and has cardinality greater than \\(\\aleph_0\\): \\(|S| &gt; \\aleph_0\\).\n\n\n\\(\\mathcal{P}(S)\\): The power set of a set \\(S\\), which is the set of all possible subsets of \\(S\\).\n\nFor example, if \\(S = \\{1, 2, 3\\}\\), \\(\\mathcal{P}(S) = \\{\\varnothing, \\{1\\}, \\{2\\}, \\{3\\}, \\{1,2\\}, \\{1,3\\}, \\{2,3\\}, \\{1,2,3\\}\\}\\). Notice that \\(|\\mathcal{P}(S)| = 2^{|S|}\\), which is always true of the power set.\n\n\n\n\n\n\n\\(\\mathbb{N}\\): The set of all natural numbers, sometimes called the “counting numbers”: \\(\\{0, 1, 2, 3, \\ldots \\}\\) (This set is countably infinite).\n\\(\\mathbb{Z}\\): The set of all integers, which includes all of the natural numbers along with their negatives: \\(\\{\\ldots, -2, -1, 0, 1, 2, \\ldots\\}\\) (This set is also countably infinite)\n\\(\\mathbb{Q}\\): The set of all rational numbers, i.e., well-defined ratios of two integers. \\(x \\in \\mathbb{Q} \\iff x = \\frac{p}{q}\\) for two integers \\(p\\) and \\(q\\), and \\(q \\neq 0\\). (This set is, surprisingly, also countably infinite)\n\\(\\mathbb{R}\\): The set of all real numbers, which includes all integers as well as numbers such as \\(\\pi\\), \\(2.356\\), or \\(\\sqrt{2}\\) (This set is uncountably infinite).\nScalar: A single number from some set of numbers, like \\(-2.1 \\in \\mathbb{R}\\)\nVector: A \\(d\\)-dimensional vector \\(\\mathbf{v}\\) is a collection of \\(d\\) scalars in \\(\\mathbb{R}\\), \\(\\mathbf{v} = (v_1, v_2, \\ldots, v_d)^\\top\\), which we can interpret as an arrow pointing \\(v_i\\) units in each dimension \\(i\\). For example, if \\(\\mathbf{v} = (3,5)\\), we can interpret \\(\\mathbf{v}\\) as representing an arrow pointing \\(3\\) units in the \\(x\\) direction and \\(5\\) units in the \\(y\\) direction.\n\nAs indicated above, however, we will assume that vectors are column vectors unless otherwise specified, though they will be written row-wise with a transpose symbol at the end. This means that, although it will be written like \\(\\mathbf{v} = (v_1, v_2, \\ldots, v_n)^\\top\\), you should apply the transpose in your head: \\[\n\\mathbf{v} = (v_1, v_2, \\ldots, v_n)^\\top = \\begin{bmatrix}v_1 \\\\ v_2 \\\\ \\vdots \\\\ v_n\\end{bmatrix}\n\\]\n\nMatrix: An \\(m \\times n\\) matrix \\(\\mathbf{M}_{[m \\times n]}\\) is an \\(m\\)-by-\\(n\\) grid of scalars, where the scalar in the \\(i\\)th row and \\(j\\)th column is denoted \\(m_{i,j}\\). In the class, we will be careful to add a subscript like \\(\\mathbf{M}_{[m \\times n]}\\) to indicate the number of rows (\\(m\\)) and columns (\\(n\\)) in the matrix, since operations like multiplication are only defined for matrices with particular dimensions.\nMatrix multiplication: For two matrices \\(\\mathbf{X}_{[a \\times b]}\\) and \\(\\mathbf{Y}_{[c \\times d]}\\), matrix multiplication is defined if \\(b = c\\), and produces the following \\(a \\times d\\) matrix \\(\\mathbf{XY}_{[a \\times d]}\\):\n\\[\n  \\mathbf{XY}_{[a \\times d]} = \\begin{bmatrix}\n  x_{1,1}y_{1,1} & \\cdots & x_{m,1}y_{1,n} \\\\\n  \\vdots & \\ddots & \\vdots \\\\\n  x_{1,n}y_{m,1} & \\cdots & x_{m,n}y_{m,n}\n  \\end{bmatrix}\n  \\]\n\\(\\sum_{i=1}^n f(i)\\): \\(\\Sigma\\) is the capitalized Greek letter “Sigma”, and stands for “Sum” in this case. This notation means: “the sum of \\(f(i)\\) from \\(i = 1\\) to \\(i = n\\)”. For example, \\(\\sum_{i=1}^3 i^2 = 1^2 + 2^2 + 3^2 = 14\\).\n\\(\\prod_{i=1}^n f(i)\\): \\(\\Pi\\) is the capitalized Greek letter “Pi”, and stands for “Product” in this case. This notation means: “the product of \\(f(i)\\) from \\(i = 1\\) to \\(i = n\\)”. For example, \\(\\prod_{i=1}^3 i^2 = 1^2 \\cdot 2^2 \\cdot 3^2 = 36\\).\n\n\n\n\n\n\\([a,b] \\in \\mathbb{R}\\): The closed interval between \\(a\\) and \\(b\\). That is, the subset of \\(\\mathbb{R}\\) containing all numbers between \\(a\\) and \\(b\\), including \\(a\\) and \\(b\\) themselves.\n\\((a,b) \\in \\mathbb{R}\\): The open interval between \\(a\\) and \\(b\\). That is, the subset of \\(\\mathbb{R}\\) containing all numbers between \\(a\\) and \\(b\\), excluding \\(a\\) and \\(b\\) themselves.\n\\([a, b)\\), \\((a, b]\\): The half-open interval between \\(a\\) and \\(b\\). In the first case, we include \\(a\\) but exclude \\(b\\), while in the second we exclude \\(a\\) but include \\(b\\).\n\\(\\int_{a}^b f(x)dx\\): The integral of the function \\(f(x)\\) between points \\(a\\) and \\(b\\). In this course, you just need to remember that this produces the area under the curve of \\(f(x)\\) between these points.\n\\(\\frac{d}{dx} \\left[ f(x) \\right]\\): The derivative of the function \\(f(x)\\). For this class, you just need to remember that the derivative is what transforms a Cumulative Density Function (CDF) into a Probability Density Function (PDF): if \\(F_X(v)\\) is the CDF of a random variable \\(X\\), then \\(\\frac{d}{dx}\\left[ F_X(v) \\right] = f_X(v)\\), the PDF of \\(X\\).\n\nFor functions of multiple variables, like the joint pdf \\(f_{X,Y}(v_X, v_Y)\\), we use the \\(\\partial\\) symbol instead of \\(d\\) to denote partial derivatives: for example, the change in \\(F_{X,Y}(v_X, v_Y)\\) as \\(v_X\\) changes is denoted \\(\\frac{\\partial}{\\partial v_X}\\left[ F_{X,Y}(v_X, v_Y) \\right]\\), while the change in \\(F_{X,Y}(v_X, v_Y)\\) as \\(v_Y\\) changes is denoted \\(\\frac{\\partial}{\\partial v_Y}\\left[ F_{X,Y}(v_X, v_Y) \\right]\\)."
  },
  {
    "objectID": "cheatsheet-math.html#conditional-probability",
    "href": "cheatsheet-math.html#conditional-probability",
    "title": "DSAN 5100 Math Cheatsheet",
    "section": "Conditional Probability",
    "text": "Conditional Probability\n\nProbability Fundamentals\n\n\\(\\Omega\\): The set of all possible outcomes in a probability setting\n\\(\\mathcal{P}(\\Omega) = \\{ e \\mid e \\subseteq \\Omega\\}\\): The set of all subsets of \\(\\Omega\\), each of which is an event\n\n\n\nRandom Variables\n\n\\(X\\) is a random variable if it maps each element of \\(\\Omega\\) to a real number \\(o \\in \\mathbb{R}\\).\n\nFor example, if we’re rolling a die, we can create a random variable \\(X\\) which maps \\(\\text{roll a one}\\) to \\(1\\), \\(\\text{roll a two}\\) to \\(2\\), and so on. (Allows us to do math with probability spaces!)\n\n\\(X\\) is a discrete random variable if it maps outcomes to countable set of numbers, whether this means a finite set like \\(\\{1,2,3\\}\\) or a countably infinite set like \\(\\mathbb{N}\\).\n\\(X\\) is a continuous random variable if it maps outcomes to a non-countable set of numbers, typically \\(\\mathbb{R}\\).\n\\(\\mathcal{R}_X\\), the support of a random variable \\(X\\), is the set of all possible values that the random variable can map onto. For example, if \\(X\\) represents a dice roll, then \\(\\mathcal{R}_X = \\{1, 2, 3, 4, 5, 6\\}\\).\nCumulative Density Function (CDF): Given a random variable \\(X\\) (whether discrete or continuous), \\(F_X(v) = P(X \\leq v)\\) is its cumulative density function, which tells us the probability that \\(X\\) is realized as a number less than or equal to some value \\(v\\).\nProbability Mass Function (PMF): Given a discrete random variable \\(X\\), \\(p_X(v) = P(X = v)\\) is its probability mass function, which tells us the probability that \\(X\\) is realized as the value \\(v\\).\nProbability Density Function (PDF): Given a continuous random variable \\(X\\), \\(f_X(v)\\) is the unique function which allows us to determine, using integration, the probability that \\(X\\) is in some range \\([a,b]\\). That is, it is the unique function satisfying \\(P(X \\in [a,b]) = \\int_a^b f_X(x)dx\\).\n\nRemember: unlike in the discrete case where \\(p_X(v) = P(X = v)\\), \\(f_X(v)\\) is not the probability that \\(X\\) is realized as the value \\(v\\). \\(f_X(v) \\neq P(X = v)\\)."
  },
  {
    "objectID": "cheatsheet-math.html#expectation-variance-moments",
    "href": "cheatsheet-math.html#expectation-variance-moments",
    "title": "DSAN 5100 Math Cheatsheet",
    "section": "Expectation, Variance, Moments",
    "text": "Expectation, Variance, Moments\n\n\\(M_1(V)\\): The (“regular”) arithmetic mean of a set of values \\(V = \\{v_1, v_2, \\ldots, v_n\\}\\): \\(M_1(V) = (v_1 + v_2 + \\cdots + v_n)\\frac{1}{n} = \\left( \\sum_{i=1}^n v_i \\right)\\frac{1}{n}\\).\n\\(M_0(V)\\): The geometric mean of a set of values \\(V = \\{v_1, v_2, \\ldots, v_n\\}\\): \\(M_0(V) = (v_1\\cdot v_2 \\cdot \\cdots \\cdot v_n)^{\\frac{1}{n}} = \\left( \\prod_{i=1}^n v_i \\right)^{\\frac{1}{n}}\\)\n\\(M_{-1}(V)\\): The harmonic mean of a set of values \\(V = \\{v_1, v_2, \\ldots, v_n\\}\\): \\(M_{-1}(V) = \\frac{n}{\\frac{1}{v_1} + \\frac{1}{v_2} + \\cdots + \\frac{1}{v_n}} = \\left( \\frac{\\sum_{i=1}^n v_i^{-1}}{n} \\right)^{-1}\\)\n\\(\\odot\\): The Hadamard product of matrices. For two matrices \\(\\mathbf{X}_{[m \\times n]}\\) and \\(\\mathbf{Y}_{[m \\times n]}\\) with equal dimensions:\n\\[\n  X_{[m \\times n]} = \\begin{bmatrix}\n      x_{1,1} & \\cdots & x_{1,n} \\\\\n      \\vdots & \\ddots & \\vdots \\\\\n      x_{m,1} & \\cdots & x_{m,n}\n  \\end{bmatrix}, Y_{[m \\times n]} = \\begin{bmatrix}\n      y_{1,1} & \\cdots & y_{1,n} \\\\\n      \\vdots & \\ddots & \\vdots \\\\\n      y_{m,1} & \\cdots & y_{m,n}\n  \\end{bmatrix}\n  \\]\nTheir Hadamard product \\(\\mathbf{X} \\odot \\mathbf{Y}\\) is another \\(m \\times n\\) matrix\n\\[\n  (\\mathbf{X} \\odot \\mathbf{Y})_{[m \\times n]} = \\begin{bmatrix}\n      x_{1,1}y_{1,1} & \\cdots & x_{1,n}y_{1,n} \\\\\n      \\vdots & \\ddots & \\vdots \\\\\n      x_{m,1}y_{m,1} & \\cdots & x_{m,n}y_{m,n}\n  \\end{bmatrix}\n  \\]"
  },
  {
    "objectID": "w01/index.html",
    "href": "w01/index.html",
    "title": "Week 1: Welcome to DSAN 5100!",
    "section": "",
    "text": "(Week 1 of DSAN 5100 was a joint session across all individual sections, taught on Zoom.)\n\n\n\n\n\n\nToday’s Links\n\n\n\n\nWeek 1 Lecture Notes\nWeek 1 Lecture Recording"
  },
  {
    "objectID": "extra-videos/index.html",
    "href": "extra-videos/index.html",
    "title": "Extra Videos",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Last Updated - Oldest\n        \n         \n          Last Updated - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nTitle\n\n\nLast Updated\n\n\n\n\n\n\nCorrected Bayes’ Theorem Example (W03.1)\n\n\nFriday Sep 8, 2023\n\n\n\n\nStatistics Fundamentals (W02.5)\n\n\nTuesday Sep 5, 2023\n\n\n\n\nProbability Fundamentals (W02.4)\n\n\nMonday Sep 4, 2023\n\n\n\n\nCombinatorics (W02.3)\n\n\nSunday Sep 3, 2023\n\n\n\n\nReview (W02.2)\n\n\nSaturday Sep 2, 2023\n\n\n\n\nAbout Me (W02.1)\n\n\nFriday Sep 1, 2023\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DSAN 5100, Section 03 (Thursdays)",
    "section": "",
    "text": "This is a “hub” collecting relevant links for each week, for students in Prof. Jeff’s Thursday section (Section 03) of DSAN 5100: Probabilistic Modeling and Statistical Computing, Fall 2023 at Georgetown University. Sections take place in Car Barn room 201 on Thursdays from 12:30pm to 3:30pm.\nThis page is not a replacement for the Main Course Page or the course’s Canvas Page, which are shared across all sections!\nUse the menu on the left, or the table below, to view the resources for a specific week.\n\n\n\n\n\n\n\n\n\n\nTitle\n\n\nDate\n\n\n\n\n\n\nWeek 1: Welcome to DSAN 5100!\n\n\nThursday, August 24, 2023\n\n\n\n\nWeek 2: Introduction to Probabilistic Modeling\n\n\nWednesday, September 6, 2023\n\n\n\n\nWeek 3: Conditional Probability\n\n\nThursday, September 7, 2023\n\n\n\n\nWeek 4: Discrete Probability Distributions\n\n\nThursday, September 14, 2023\n\n\n\n\nWeek 5: Continuous Probability Distributions\n\n\nThursday, September 21, 2023\n\n\n\n\nWeek 6: Continuous Distributions, Moments, Covariance\n\n\nThursday, September 28, 2023\n\n\n\n\nWeek 7: Joint, Marginal, and Conditional Distributions\n\n\nThursday, October 5, 2023\n\n\n\n\nWeek 8: Markov Models\n\n\nThursday, October 5, 2023\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "writeups/sampling-from-df/index.html",
    "href": "writeups/sampling-from-df/index.html",
    "title": "Two Ways of Sampling from a Data Frame",
    "section": "",
    "text": "A few students have run into issues when trying to use the sample() function, from base-R, to sample from a full data.frame or tibble. In this writeup I’ll argue that this is a case where using a function from the tidyverse called slice_sample() will make your life much easier, but I will also show how to do this sampling using only base-R functions.\nBefore we start, we make sure to use set.seed(5000) at the beginning, so that your grader gets the same results as you do even when working with random processes!\nset.seed(5000)"
  },
  {
    "objectID": "writeups/sampling-from-df/index.html#creating-a-deck-of-cards-using-expand.grid",
    "href": "writeups/sampling-from-df/index.html#creating-a-deck-of-cards-using-expand.grid",
    "title": "Two Ways of Sampling from a Data Frame",
    "section": "Creating a Deck of Cards Using expand.grid()",
    "text": "Creating a Deck of Cards Using expand.grid()\nThis is done as was introduced in the Bootcamp:\n\n\nCode\nranks &lt;- c(\"Ace\", \"Two\", \"Three\", \"Four\", \"Five\", \"Six\", \"Seven\", \"Eight\",\n           \"Nine\", \"Ten\", \"Jack\", \"Queen\", \"King\")\nsuits &lt;- c(\"Hearts\", \"Diamonds\", \"Clubs\", \"Spades\")\ndeck_df &lt;- expand.grid(ranks, suits)\ncolnames(deck_df) &lt;- c(\"Rank\", \"Suit\")\nhead(deck_df)\n\n\n\n\n\n\nRank\nSuit\n\n\n\n\nAce\nHearts\n\n\nTwo\nHearts\n\n\nThree\nHearts\n\n\nFour\nHearts\n\n\nFive\nHearts\n\n\nSix\nHearts\n\n\n\n\n\n\nAnd we can check the dimensions of deck_df just to make sure it created the right number of cards:\n\ndim(deck_df)\n\n[1] 52  2\n\n\nNow, since sampling without replacement is the default case for both sample functions, to illustrate how to use parameters to these functions I will be sampling with replacement."
  },
  {
    "objectID": "writeups/sampling-from-df/index.html#using-tidyverse-to-sample-with-replacement",
    "href": "writeups/sampling-from-df/index.html#using-tidyverse-to-sample-with-replacement",
    "title": "Two Ways of Sampling from a Data Frame",
    "section": "Using tidyverse to Sample WITH Replacement",
    "text": "Using tidyverse to Sample WITH Replacement\nThe following code uses the pipe operator %&gt;% to take the data.frame, deck_df, and “pipe it into” the slice_sample() function from the tidyverse. We have to provide two arguments:\n\nn: The number of samples we’d like to take, and\nreplace: If set to TRUE, the sampling is performed with replacement. Otherwise (the default), the sampling is performed without replacement.\n\n\n\nCode\nlibrary(tidyverse)\n# Using the \"fancier\" pipe operator (%&gt;%)\ndeck_sample_df &lt;- deck_df %&gt;% slice_sample(n = 12, replace = TRUE)\ndeck_sample_df\n\n\n\n\n\n\nRank\nSuit\n\n\n\n\nAce\nSpades\n\n\nFive\nHearts\n\n\nFour\nSpades\n\n\nJack\nSpades\n\n\nNine\nClubs\n\n\nSeven\nClubs\n\n\nTen\nClubs\n\n\nQueen\nClubs\n\n\nKing\nSpades\n\n\nTwo\nSpades\n\n\nThree\nSpades\n\n\nJack\nSpades\n\n\n\n\n\n\nHere we can confirm that it sampled with replacement since we see that it selected the Jack of Spades twice (once in slot 4 and once in slot 12).\nNote that, although using the pipe operator %&gt;% is the “standard” way to use tidyverse functions, you can still use the functions without using the pipe operator (long story short, the pipe operator just takes whatever comes before the %&gt;% and “plugs it in” as the first argument to the function that comes after the %&gt;%), by specifying the first argument to the slice_sample() function explicitly:\n\ndeck_sample_df &lt;- slice_sample(deck_df, n = 12, replace = TRUE)\ndeck_sample_df\n\n\n\n\n\nRank\nSuit\n\n\n\n\nFour\nHearts\n\n\nFive\nClubs\n\n\nFour\nClubs\n\n\nFive\nDiamonds\n\n\nKing\nSpades\n\n\nKing\nDiamonds\n\n\nFive\nSpades\n\n\nTwo\nClubs\n\n\nQueen\nHearts\n\n\nEight\nClubs\n\n\nJack\nSpades\n\n\nEight\nClubs\n\n\n\n\n\n\nTo me, one nice aspect of slice_sample() over other base-R functions is (among other things) it ensures that the column names are maintained when you sample, which is not always true for the base-R functions. It’s also possible to do in base-R (without using tidyverse libraries/functions), though, just less straightforwardly."
  },
  {
    "objectID": "writeups/sampling-from-df/index.html#using-base-r-to-sample-with-replacement",
    "href": "writeups/sampling-from-df/index.html#using-base-r-to-sample-with-replacement",
    "title": "Two Ways of Sampling from a Data Frame",
    "section": "Using Base-R to Sample WITH Replacement",
    "text": "Using Base-R to Sample WITH Replacement\nFirst off, note that just applying sample() to the deck will not produce the outcome we expect, or want, which probably unfortunately goes against our intuitions for how this function should work:\n\nsample(deck_df, 5, replace = TRUE)\n\n\n\n\n\nSuit\nRank\nSuit.1\nRank.1\nRank.2\n\n\n\n\nHearts\nAce\nHearts\nAce\nAce\n\n\nHearts\nTwo\nHearts\nTwo\nTwo\n\n\nHearts\nThree\nHearts\nThree\nThree\n\n\nHearts\nFour\nHearts\nFour\nFour\n\n\nHearts\nFive\nHearts\nFive\nFive\n\n\nHearts\nSix\nHearts\nSix\nSix\n\n\nHearts\nSeven\nHearts\nSeven\nSeven\n\n\nHearts\nEight\nHearts\nEight\nEight\n\n\nHearts\nNine\nHearts\nNine\nNine\n\n\nHearts\nTen\nHearts\nTen\nTen\n\n\nHearts\nJack\nHearts\nJack\nJack\n\n\nHearts\nQueen\nHearts\nQueen\nQueen\n\n\nHearts\nKing\nHearts\nKing\nKing\n\n\nDiamonds\nAce\nDiamonds\nAce\nAce\n\n\nDiamonds\nTwo\nDiamonds\nTwo\nTwo\n\n\nDiamonds\nThree\nDiamonds\nThree\nThree\n\n\nDiamonds\nFour\nDiamonds\nFour\nFour\n\n\nDiamonds\nFive\nDiamonds\nFive\nFive\n\n\nDiamonds\nSix\nDiamonds\nSix\nSix\n\n\nDiamonds\nSeven\nDiamonds\nSeven\nSeven\n\n\nDiamonds\nEight\nDiamonds\nEight\nEight\n\n\nDiamonds\nNine\nDiamonds\nNine\nNine\n\n\nDiamonds\nTen\nDiamonds\nTen\nTen\n\n\nDiamonds\nJack\nDiamonds\nJack\nJack\n\n\nDiamonds\nQueen\nDiamonds\nQueen\nQueen\n\n\nDiamonds\nKing\nDiamonds\nKing\nKing\n\n\nClubs\nAce\nClubs\nAce\nAce\n\n\nClubs\nTwo\nClubs\nTwo\nTwo\n\n\nClubs\nThree\nClubs\nThree\nThree\n\n\nClubs\nFour\nClubs\nFour\nFour\n\n\nClubs\nFive\nClubs\nFive\nFive\n\n\nClubs\nSix\nClubs\nSix\nSix\n\n\nClubs\nSeven\nClubs\nSeven\nSeven\n\n\nClubs\nEight\nClubs\nEight\nEight\n\n\nClubs\nNine\nClubs\nNine\nNine\n\n\nClubs\nTen\nClubs\nTen\nTen\n\n\nClubs\nJack\nClubs\nJack\nJack\n\n\nClubs\nQueen\nClubs\nQueen\nQueen\n\n\nClubs\nKing\nClubs\nKing\nKing\n\n\nSpades\nAce\nSpades\nAce\nAce\n\n\nSpades\nTwo\nSpades\nTwo\nTwo\n\n\nSpades\nThree\nSpades\nThree\nThree\n\n\nSpades\nFour\nSpades\nFour\nFour\n\n\nSpades\nFive\nSpades\nFive\nFive\n\n\nSpades\nSix\nSpades\nSix\nSix\n\n\nSpades\nSeven\nSpades\nSeven\nSeven\n\n\nSpades\nEight\nSpades\nEight\nEight\n\n\nSpades\nNine\nSpades\nNine\nNine\n\n\nSpades\nTen\nSpades\nTen\nTen\n\n\nSpades\nJack\nSpades\nJack\nJack\n\n\nSpades\nQueen\nSpades\nQueen\nQueen\n\n\nSpades\nKing\nSpades\nKing\nKing\n\n\n\n\n\n\nA way to avoid this is to make sure that you are using the sample() function NOT on the entire data.frame object, but just to select a subset of the rows of the data.frame, like the following:\n\ndeck_df[sample(nrow(deck_df), 15, replace = TRUE),]\n\n\n\n\n\n\nRank\nSuit\n\n\n\n\n24\nJack\nDiamonds\n\n\n19\nSix\nDiamonds\n\n\n25\nQueen\nDiamonds\n\n\n19.1\nSix\nDiamonds\n\n\n3\nThree\nHearts\n\n\n10\nTen\nHearts\n\n\n31\nFive\nClubs\n\n\n11\nJack\nHearts\n\n\n47\nEight\nSpades\n\n\n39\nKing\nClubs\n\n\n39.1\nKing\nClubs\n\n\n43\nFour\nSpades\n\n\n22\nNine\nDiamonds\n\n\n9\nNine\nHearts\n\n\n27\nAce\nClubs\n\n\n\n\n\n\nFirst off, notice how here we can again confirm that it sampled with replacement since it had to create additional ids like 34.1 and 34.2 to represent the fact that card #34 (the Eight of Clubs) ended up in our sample 3 times.\nAlso note how, rather than sampling from the data.frame, which may be intuitively/linguistically how we would describe what we want, we are actually sampling from the set of indices of the data.frame, then asking R to give us the rows corresponding to those sampled indices. Concretely, to see what’s going on, let’s just look at the row filter we’ve provided (the portion of the full code that is within the square brackets [], before the comma):\n\nsample(nrow(deck_df), 15, replace = TRUE)\n\n [1] 30 32 30 46  7 30 46 27 21 42 25 26 17 35  4\n\n\nWe see that, in fact, we are not really sampling from the data.frame itself, so much as sampling from a list of its indices (from 1 to 52), and then after performing this sample we are going and asking R to give us the rows at the indices that ended up in this sample. Keeping this distinction in mind (between the rows themselves and their indices) can be helpful for debugging code like this."
  },
  {
    "objectID": "writeups/sample-space-tibbles/index.html",
    "href": "writeups/sample-space-tibbles/index.html",
    "title": "Simulating Sample Spaces With Tibbles",
    "section": "",
    "text": "After working with a good number of students trying to set up a tibble (and/or data.frame) in R to represent the sample space of phone users given at the beginning of Quiz 1, and sort of winging it with a bunch of different approaches each time it came up, I decided to try and figure out some “standardized” way to generate a tibble which will represent a given sample space, with minimal headaches, that will work every time! This is the result."
  },
  {
    "objectID": "writeups/sample-space-tibbles/index.html#step-0-what-do-i-mean-by-simulating-a-sample-space",
    "href": "writeups/sample-space-tibbles/index.html#step-0-what-do-i-mean-by-simulating-a-sample-space",
    "title": "Simulating Sample Spaces With Tibbles",
    "section": "Step 0: What Do I Mean By “Simulating” a Sample Space?",
    "text": "Step 0: What Do I Mean By “Simulating” a Sample Space?\nWhat I’m referring to here is, for example, the information you are given at the top of Quiz 1, stating that a random sample contained:\n\n340 people currently using an iPhone,\n185 people using a different phone who don’t want to switch phones ever, and\n232 people using a different phone but hoping to switch to an iPhone in the future.\n\nThe idea is that we can generate a tibble which “encodes” this information in its rows, by allowing us to use the naïve definition of probability to compute probabilities of particular types of people: for example, say we are interested in the probability that a person in our sample uses an iPhone. Mathematically (by the naïve definition), if we construct a random variable \\(F\\) (for iFone, of course) representing the outcome of a randomly-selected person’s phone type (so that \\(F = 1\\) if the person we ask ends up being an iPhone user, and \\(F = 0\\) otherwise), then we can use the information from our sample to compute \\(\\Pr(F = 1)\\) as\n\\[\n\\Pr(F = 1) = \\frac{\\#\\text{ iPhone users in sample}}{\\#\\text{ People in sample}}\n\\tag{1}\\]\nThis means, therefore, that if we had a tibble called df where each row contained information on one particular person from our sample, then we could “translate” this naive definition formula into code as something like\nprob_F &lt;- nrow(df[df$iphone == 1,]) / nrow(df)\nSince here df[df$iphone == 1,] would subset the full df to keep only those rows corresponding to people with iPhones, while df itself (without any filters applied) would contain a row for each person. Literally, we are applying the following “translation” of the naïve definition-based formula (Equation 1) into code:\n\\[\n\\Pr(F = 1) = \\frac{\\overbrace{\\#}^{\\texttt{nrow}}\\overbrace{\\text{ iPhone users in sample}}^{\\texttt{df[df\\$iphone == 1]}}}{\\underbrace{\\#}_{\\texttt{nrow}}\\underbrace{\\text{ People in sample}}_{\\texttt{df}}}\n\\tag{2}\\]\nSimilarly, say we wanted to compute a conditional probability on the basis of our sample, like the probability of a person liking the feature (the feature mentioned in the quiz) given that they are an iPhone user. In this case, let \\(L\\) be an RV such that \\(L = 1\\) if the person likes the feature and \\(L = 0\\) otherwise. Then we can represent the probability we want in this case mathematically using the definition of conditional probability:\n\\[\n\\Pr(L = 1 \\mid F = 1) = \\frac{\\Pr(L = 1 \\cap F = 1)}{\\Pr(F = 1)}\n\\tag{3}\\]\nAnd then we can interpret this ratio (of \\(\\Pr(L = 1 \\cap F = 1)\\) to \\(\\Pr(F = 1)\\) using the naïve definition of probability to derive a new “naïve definition-based equation for the same conditional probability” written mathematically in Equation 3:\n\\[\n\\Pr(L = 1 \\mid F = 1) = \\frac{\\#\\text{ iPhone users in sample who like feature}}{\\#\\text{ iPhone users in sample}}\n\\tag{4}\\]\nIn this case, since both the numerator and denominator are restricted to only those people in our sample who are iPhone users, we can make our lives easy by creating a new “only iPhone users” tibble, using code like\niphone_df &lt;- df[df$iphone == 1,]\nAnd, with this iPhone-users-only tibble now available to us, Equation 4 can be translated into code similarly to how we translated Equation 1 into code, as\nprob_L_given_F &lt;- nrow(iphone_df[iphone_df$like_feature == 1]) / nrow(iphone_df)\nWhere once again we have just applied the following set of “translations” to the naïve definition (this time the “conditional naïve definition”):\n\\[\n\\Pr(L = 1 \\mid F = 1) = \\frac{\\overbrace{\\#}^{\\texttt{nrow}}\\overbrace{\\text{ iPhone users in sample who like feature}}^{\\texttt{iphone\\_df[iphone\\_df\\$likes\\_feature == 1]}}}{\\underbrace{\\#}_{\\texttt{nrow}}\\underbrace{\\text{ iPhone users in sample}}_{\\texttt{iphone\\_df}}}\n\\tag{5}\\]\nSo, all of the above shows you how to work with a sample-space-simulating tibble, once you have created it. The following steps will show you how to create such a sample-space-simulating tibble using functions from the tidyverse."
  },
  {
    "objectID": "writeups/sample-space-tibbles/index.html#step-1-identifying-types-of-people-in-the-sample",
    "href": "writeups/sample-space-tibbles/index.html#step-1-identifying-types-of-people-in-the-sample",
    "title": "Simulating Sample Spaces With Tibbles",
    "section": "Step 1: Identifying “Types” of People in the Sample",
    "text": "Step 1: Identifying “Types” of People in the Sample\nIn the case of the quiz, since each person in our sample is characterized by their values for 3 binary variables (\\(F\\) for iPhone, \\(W\\) for wants-to-switch, and \\(L\\) for likes-feature), we know that there are \\(2^3 = 8\\) possible types of people that could appear in the dataset:\n\n\nTable 1: The 8 possible types of people in our sample, sorted in terms of their binary representations (so that 000 corresponds to the non-iPhone, doesn’t-want-to-switch, and doesn’t-like-the-feature type; 001 corresponds to the non-iPhone, doesn’t-want-to-switch, and does-like-the-feature type; and so on.)\n\n\n\n\n\n\n\n\nType\n\\(F\\)(iPhone)\n\\(W\\)(Wants to switch)\n\\(L\\)(Likes feature)\n\n\n\n\n1\n0\n0\n0\n\n\n2\n0\n0\n1\n\n\n3\n0\n1\n0\n\n\n4\n0\n1\n1\n\n\n5\n1\n0\n0\n\n\n6\n1\n0\n1\n\n\n7\n1\n1\n0\n\n\n8\n1\n1\n1\n\n\n\n\nWe’ll see why we are splitting people into these types in the next section, but here our next task is to fill out the missing “number in sample” column with the number of people who have each of these combinations of properties, using the information given in the problem.\nFor example, since we know that there are 340 iPhone users in the sample, and we know that the probability of an iPhone user liking the feature is \\(0.8\\), we can compute the number of iPhone users who like the feature as\n\\[\n\\begin{align*}\n\\#\\text{ iPhone users who like feature} &= \\#\\text{ iPhone users} \\cdot 0.8 \\\\\n&= 340 \\cdot 0.8 = 272.\n\\end{align*}\n\\]\nWorking out the numbers for all the other types in a similar way (rounding to the nearest integer in cases where we don’t get integers, and also assuming that all iPhone users just have a \\(W\\) value of \\(0\\), since they don’t want to switch to an iPhone because they already have an iPhone), we arrive at the following counts [see the Appendix below for full details of the computations]:\n\n\nTable 2: The same list of types as in Table 1, now with an additional column where we’ve computed the number of times that each type appears in our sample (on the basis of the info given in the assignment)\n\n\n\n\n\n\n\n\n\nType\n\\(F\\)(iPhone)\n\\(W\\)(Wants to switch)\n\\(L\\)(Likes feature)\nNumber in Sample\n\n\n\n\n1\n0\n0\n0\n89\n\n\n2\n0\n0\n1\n96\n\n\n3\n0\n1\n0\n121\n\n\n4\n0\n1\n1\n111\n\n\n5\n1\n0\n0\n68\n\n\n6\n1\n0\n1\n272\n\n\n7\n1\n1\n0\n0\n\n\n8\n1\n1\n1\n0"
  },
  {
    "objectID": "writeups/sample-space-tibbles/index.html#step-2-encoding-each-type-as-a-tibble_row",
    "href": "writeups/sample-space-tibbles/index.html#step-2-encoding-each-type-as-a-tibble_row",
    "title": "Simulating Sample Spaces With Tibbles",
    "section": "Step 2: Encoding Each Type as a tibble_row",
    "text": "Step 2: Encoding Each Type as a tibble_row\nOne nice thing about the tibble library is it explicitly provides a function just for creating individual rows of a full tibble, called tibble_row(). It has the same syntax as the more general tibble() function, but in this case you can just provide a set of key=value pairs as arguments, so that (for example) to create a row representing the first “type” in our dataset \\((F = 0, W = 0, L = 0)\\), we can run\n\nlibrary(tibble)\ntype1 &lt;- tibble_row(iphone=0, wants_switch=0, likes_feature=0)\ntype1\n\n\n\n\n\niphone\nwants_switch\nlikes_feature\n\n\n\n\n0\n0\n0\n\n\n\n\n\n\nNow we can do the same thing for the other 5 non-zero types (we don’t have to explicitly make row objects for the \\((F = 0, W = 1, L = 0)\\) or \\((F = 0, W = 1, L = 1)\\) types, since we’re not going to need any of these in our sample-space-simulating tibble, though we could make these tibble_row objects if we really wanted to for some reason):\n\ntype2 &lt;- tibble_row(iphone=0, wants_switch=0, likes_feature=1)\ntype3 &lt;- tibble_row(iphone=0, wants_switch=1, likes_feature=0)\ntype4 &lt;- tibble_row(iphone=0, wants_switch=1, likes_feature=1)\ntype5 &lt;- tibble_row(iphone=1, wants_switch=0, likes_feature=0)\ntype6 &lt;- tibble_row(iphone=1, wants_switch=0, likes_feature=1)\n\nWith these “types” set up as rows, all that’s left to do is to duplicate these rows however many times we need to in order to reflect the number of each type in our sample (Step 3), and then combine these duplicated rows together into one big tibble (Step 4)!"
  },
  {
    "objectID": "writeups/sample-space-tibbles/index.html#step-3-replicating-types-to-form-subsets-of-the-sample-space",
    "href": "writeups/sample-space-tibbles/index.html#step-3-replicating-types-to-form-subsets-of-the-sample-space",
    "title": "Simulating Sample Spaces With Tibbles",
    "section": "Step 3: Replicating Types To Form Subsets of the Sample Space",
    "text": "Step 3: Replicating Types To Form Subsets of the Sample Space\nThis is the part that I found most difficult—honestly, unless there’s some secret easy way that I don’t know about (please tell me if there is!), the best method I could find for duplicating a given tibble_row object k times was to utilize the following code snippet (which uses the slice() function from the dplyr library) as a template:\ntype |&gt; slice(rep(1:n(), k))\nfor taking the individual tibble_row variable type and repeating it k times.\nSo, using this to make 89 “copies” of the type encoded as the tibble_row called type_1, to represent the 89 people in our sample who are of this type, I used:\n\nlibrary(dplyr) # So we can use slice()\ntype1_rows &lt;- type1 |&gt; slice(rep(1:n(), 89))\n\nWhich produces output that looks as follows (I’m using head() to avoid printing out rows with the exact same values 89 times, but you can see that it worked by glancing at the result of head() that follows along with the result of dim() below that)\n\ntype1_rows |&gt; head()\n\n\n\n\n\niphone\nwants_switch\nlikes_feature\n\n\n\n\n0\n0\n0\n\n\n0\n0\n0\n\n\n0\n0\n0\n\n\n0\n0\n0\n\n\n0\n0\n0\n\n\n0\n0\n0\n\n\n\n\n\n\n\ndim(type1_rows)\n\n[1] 89  3\n\n\nGiven that this approach worked to make 89 copies of the first type, I just use the same approach 5 more times, to make the appropriate number of copies of each type based on the “Number in Sample” column from Table 2:\n\ntype2_rows &lt;- type2 |&gt; slice(rep(1:n(), 96))\ntype3_rows &lt;- type3 |&gt; slice(rep(1:n(), 121))\ntype4_rows &lt;- type4 |&gt; slice(rep(1:n(), 111))\ntype5_rows &lt;- type5 |&gt; slice(rep(1:n(), 68))\ntype6_rows &lt;- type6 |&gt; slice(rep(1:n(), 272))\n\nThis leaves only one remaining step of combining these individual collections of rows into a giant tibble."
  },
  {
    "objectID": "writeups/sample-space-tibbles/index.html#step-4-combining-the-type-rows",
    "href": "writeups/sample-space-tibbles/index.html#step-4-combining-the-type-rows",
    "title": "Simulating Sample Spaces With Tibbles",
    "section": "Step 4: Combining the Type-Rows",
    "text": "Step 4: Combining the Type-Rows\nNow that we have these six objects, each representing a particular type of person that could be in our sample, replicated the correct number of times based on our calculations from the information given in the problem, we can combine them to form a single, combined tibble by using the bind_rows() function from dplyr as follows (sorry this line looks so packed/scary: we could have done all this in a loop or something that looks a bit “nicer”, but here I thought writing it all out could help with understanding, especially since there are only 6, rather than 8, possible types):\n\nsample_df &lt;- bind_rows(\n    type1_rows, type2_rows, type3_rows,\n    type4_rows, type5_rows, type6_rows\n)\n\nEven though printing the head() or tail() of this dataset will not be that helpful for ensuring that we created everything correctly, we can at least check that the dimensions are correct, as we’re expecting the sample to contain 757 people (rows) in total, with 3 pieces of information (columns) for each person:\n\ndim(sample_df)\n\n[1] 757   3\n\n\nWe could also check, as a way of starting the type of computations mentioned in Step 0, the number of people within the full sample_df dataset who match some filter—in this case, for example, the number of people who are iPhone users:\n\niphone_df &lt;- sample_df[sample_df$iphone == 1,]\ndim(iphone_df)\n\n[1] 340   3\n\n\nAnd this tells us that again, the number of rows in this subset matches what we expected—more evidence that we’ve constructed things correctly.\nNow that we’ve created the iphone_df that was mentioned as part of Step 0, we can carry out the one final step of computing a conditional probability using this iphone_df object, in precisely the way described in Step 0: to get the conditional probability that someone in the sample likes the feature given that they are an iPhone user, \\(\\Pr(L = 1 \\mid F = 1)\\), we just compute\n\nnrow(iphone_df[iphone_df$likes_feature == 1,]) / nrow(iphone_df)\n\n[1] 0.8\n\n\nwhich once again matches the information given in the problem. To compute the quantities the problem asks you to compute, you can use a similar pattern to this example."
  },
  {
    "objectID": "writeups/sample-space-tibbles/index.html#optional-step-5-wrapping-the-row-duplication-in-a-function",
    "href": "writeups/sample-space-tibbles/index.html#optional-step-5-wrapping-the-row-duplication-in-a-function",
    "title": "Simulating Sample Spaces With Tibbles",
    "section": "(Optional) Step 5: Wrapping the Row Duplication in a Function",
    "text": "(Optional) Step 5: Wrapping the Row Duplication in a Function\nIf you’re like me, and you find that typing slice(rep(1:n(), k)) over and over again is scary and could easily lead to mistakes, you can wrap this whole process in a function to make your life easier. For example, we can define a function called duplicate_row which takes an argument tr representing a tibble_row object and another argument num_reps specifying how many times that tibble_row should be repeated:\n\nduplicate_row &lt;- function(tr, num_reps) {\n    return(tr |&gt; slice(rep(1:n(), num_reps)))\n}\n\nAnd now rather than writing the whole operation over and over again, we can just call duplicate_row as often as needed. If you wanted a tibble which contained the numbers 1 through 5 repeated that many times, for example (that is, the number 1 repeated 1 time, the number 2 repeated 2 times, and so on), this could be done in a loop using our duplicate_row function as follows:\n\n# Create a single row containing the number 1\nfull_tibble &lt;- tibble_row(n = 1)\n# Create 2 rows containing the number 2 and add\n# those 2 rows to full_tibble, then create 3 rows\n# containing the number 3 and add those 3 rows\n# to full_tibble, and so on\nfor (i in 2:5) {\n    row_containing_i &lt;- tibble_row(n = i)\n    repeated_rows &lt;- duplicate_row(row_containing_i, i)\n    full_tibble &lt;- bind_rows(full_tibble, repeated_rows)\n}\ndim(full_tibble)\n\n[1] 15  1\n\nfull_tibble\n\n\n\n\n\nn\n\n\n\n\n1\n\n\n2\n\n\n2\n\n\n3\n\n\n3\n\n\n3\n\n\n4\n\n\n4\n\n\n4\n\n\n4\n\n\n5\n\n\n5\n\n\n5\n\n\n5\n\n\n5\n\n\n\n\n\n\nI hope that helps a bit, in case this scenario ever comes up again on a homework or quiz, or it comes up on your project or at some point in your future data science career!"
  },
  {
    "objectID": "writeups/sample-space-tibbles/index.html#appendix-computing-counts-for-each-type",
    "href": "writeups/sample-space-tibbles/index.html#appendix-computing-counts-for-each-type",
    "title": "Simulating Sample Spaces With Tibbles",
    "section": "Appendix: Computing Counts For Each Type",
    "text": "Appendix: Computing Counts For Each Type\nWe already computed the number of iPhone users who like the feature as 272: \\(\\#(F = 1, W = 0, L = 1) = 272\\). This lets us compute, using the complement rule, that there are\n\\[\n340 - 272 = 68\n\\]\nremaining iPhone users, who do not like the feature: \\(\\#(F = 1, W = 0, L = 0) = 68\\). The counts for the final two rows, \\(\\#(F = 1, W = 1, L = 0)\\) and \\(\\#(F = 1, W = 1, L = 1)\\) are both zero, since we defined \\(W\\) for iPhone users to always be \\(0\\), since they already have the iPhone so cannot want to switch to the iPhone. This gives us the bottom half of the count column.\nFor the top half, we compute as follows: the top half (first four rows) represent all of the non-iPhone users. Since there are\n\\[\n340 + 185 + 232 = 757\n\\]\npeople in total, and 340 are iPhone users, this means that\n\\[\n757 - 340 = 417\n\\]\nmust be non-iPhone users (which we also could have computed by adding the 185 and 232 given in the problem): \\(\\#(F = 0) = 417\\).\nOf these 417, we are also given that 185 don’t want to switch, while 232 do want to switch, so\n\n\\(\\#(F = 0, W = 0) = 185\\) and\n\\(\\#(F = 0, W = 1) = 232\\).\n\nThe final piece of info we need is the info given in the problem that 52% of the no-switch people like the feature, while only 48% of the hope-to-switch people like the feature.\nSince “no-switch people” are people with the properties \\((F = 0, W = 0)\\), and “hope-to-switch people” are people with the properties \\((F = 0, W = 1)\\), we can use these given conditional probabilities to compute the remaining counts in our table as follows:\nNo-switch people who like the feature:\nWe are given the info that, among no-switch people, 52% like the feature. So,\n\\[\n\\begin{align}\n\\#(F = 0, W = 0, L = 1) &= 0.52 \\cdot \\#(F = 0, W = 0) \\\\\n&= 0.52 \\cdot 185 = 96.2,\n\\end{align}\n\\]\nwhich we round to 96 to get an integer number of people.\nNo-switch people who don’t like the feature:\nSince 52% of no-switch people like the feature, this must mean that (100% - 52% = 48%) of no-switch people must not like the feature:\n\\[\n\\begin{align}\n\\#(F = 0, W = 0, L = 0) &= (1 - 0.52) \\cdot \\#(F = 0, W = 0) \\\\\n&= 0.48 \\cdot 185 = 88.8,\n\\end{align}\n\\]\nwhich we round to 89 to get an integer number of people.\nHope-to-switch people who like the feature:\nWe are given the info that, among hope-to-switch people, 48% like the feature. So,\n\\[\n\\begin{align}\n\\#(F = 0, W = 1, L = 1) &= 0.48 \\cdot \\#(F = 0, W = 1) \\\\\n&= 0.48 \\cdot 232 = 111.36,\n\\end{align}\n\\]\nwhich we round to 111 to get an integer number of people.\nHope-to-switch people who don’t like the feature\nSince we are given that 48% of hope-to-switch people like the feature, this must mean that (100% - 48% = 52%) of hope-to-switch people do not like the feature. So,\n\\[\n\\begin{align}\n\\#(F = 0, W = 1, L = 0) &= 0.52 \\cdot \\#(F = 0, W = 1) \\\\\n&= 0.52 \\cdot 232 = 120.64,\n\\end{align}\n\\]\nwhich we round to 121 to get an integer number of people.\nI may have made a mistake in one or more of those calculations, so please let me know if you find one. As a sanity check, however, I did sum the numbers in the “number in sample” column, and the sum does come out to 757 as expected."
  },
  {
    "objectID": "writeups/order-of-integration/index.html",
    "href": "writeups/order-of-integration/index.html",
    "title": "Continuous Probability and the Order of Integration",
    "section": "",
    "text": "Code\nsource(\"../../_globals.r\")\nProblem 2e on your Lab 5 Assignment, which asks you to:\nis trickier than most of the other parts/problems, in the sense that it really requires us to think carefully about what exactly we’re doing when we take integrals to obtain probabilities from probability density functions. So, in this writeup, I want to walk through that problem step-by-step, showing where the “trickiness” enters into the problem."
  },
  {
    "objectID": "writeups/order-of-integration/index.html#using-our-intuition-without-geometry",
    "href": "writeups/order-of-integration/index.html#using-our-intuition-without-geometry",
    "title": "Continuous Probability and the Order of Integration",
    "section": "Using Our Intuition (Without Geometry)",
    "text": "Using Our Intuition (Without Geometry)\nIn this part I’m going to show how, if we ignore some of the details of the problem, we might think of the two following ways to go about obtaining the answer, which on the surface seem like equally “good” ways to go about it:\n\nApproach 1: Inner integral over \\(Y\\), outer integral over \\(X\\)\n\nIntegrate the joint pdf \\(f_{X,Y}(x,y)\\) from \\(y = x\\) to the maximum value that \\(y\\) can take on, that is, from \\(y = x\\) to \\(y = 3\\), then\nIntegrate the result from (1) over the full range of values \\(x\\) can take on, that is, from \\(x = 0\\) to \\(x = 2\\).\n\nApproach 2: Inner integral over \\(X\\), outer integral over \\(Y\\)\n\nIntegrate the joint pdf \\(f_{X,Y}(x,y)\\) from \\(x = 0\\) to \\(x = y\\), then\nIntegrate the result from (1) over the full range of values \\(y\\) can take on, that is, from \\(y = 0\\) to \\(y = 3\\)\n\n\nUsing the joint pdf \\(f_{X,Y}(x,y)\\) that we obtained in earlier parts of the problem,\n\\[\nf_{X,Y}(x,y) = 3C(x^2 + 2xy^2) = \\frac{1}{44}(x^2 + 2xy^2),\n\\]\ncarrying out the math for Approach 1 gives us the following result (skipping many many steps):\n\\[\n\\begin{align*}\n\\Pr(X \\leq Y) &= \\int_{0}^{2}\\int_{x}^{3}f_{X,Y}(x,y)~dy~dx \\\\\n&= \\frac{1}{132} \\int_0^2 (9x^2 + 54x - 3x^3 - 2x^4)~dx \\\\\n&= \\frac{1}{132}\\cdot \\frac{536}{5} \\approx 0.812~✅\n\\end{align*}\n\\]\nSo far, we can at least be a bit assured by the fact that we’ve obtained a value between 0 and 1, hence a valid probability value1.\nCarrying out the math for Approach 2 in the same way, however, gives us something strange:\n\\[\n\\begin{align*}\n\\Pr(X \\leq Y) &= \\int_{0}^{3}\\int_{0}^{y}f_{X,Y}(x,y)~dx~dy \\\\\n&= \\frac{1}{132}\\int_{0}^{3} y^3 + 3y^4 \\\\\n&= \\frac{1}{132}\\cdot \\frac{3321}{20} \\approx 1.258~😳\n\\end{align*}\n\\]\nSo what happened?"
  },
  {
    "objectID": "writeups/order-of-integration/index.html#finding-the-issue-by-thinking-geometrically",
    "href": "writeups/order-of-integration/index.html#finding-the-issue-by-thinking-geometrically",
    "title": "Continuous Probability and the Order of Integration",
    "section": "Finding The Issue By Thinking Geometrically",
    "text": "Finding The Issue By Thinking Geometrically\nThere are a lot of ways we could stop and try to diagnose what’s going on here, but the approach that helped me most in thinking through this problem was to plot out the space over which we’re integrating the joint pdf, geometrically:\nHere I create what is sometimes called a “mesh grid”, by running the expand_grid() function (from tidyverse, which replaces the base-R expand.grid() function you have already seen, but isn’t very different) to create a grid of points, where these points’ \\(x\\) values are drawn from x and their \\(y\\) values are drawn from y:\n\n\nCode\nlibrary(tidyverse)\nx &lt;- seq(from = 0, to = 2, by = 0.01)\ny &lt;- seq(from = 0, to = 3, by = 0.01)\nxy_df &lt;- expand_grid(x, y)\n# Display the first and last 6 rows\nxy_df |&gt; head(); xy_df |&gt; tail()\n\n\n\n\n\n\nx\ny\n\n\n\n\n0\n0.00\n\n\n0\n0.01\n\n\n0\n0.02\n\n\n0\n0.03\n\n\n0\n0.04\n\n\n0\n0.05\n\n\n\n\n\n\n\n\n\n\nx\ny\n\n\n\n\n2\n2.95\n\n\n2\n2.96\n\n\n2\n2.97\n\n\n2\n2.98\n\n\n2\n2.99\n\n\n2\n3.00\n\n\n\n\n\n\nNext I use the mutate() function to create a new variable, x_leq_y, on the basis of this grid, and look at the count of the number of points in my grid which do and do not satisfy the boolean expression x &lt;= y:\n\n\nCode\nxy_df &lt;- xy_df |&gt; mutate(\n  x_leq_y = as.numeric(x &lt;= y)\n)\nxy_df |&gt; group_by(x_leq_y) |&gt; count(.drop=FALSE)\n\n\n\n\n\n\nx_leq_y\nn\n\n\n\n\n0\n20100\n\n\n1\n40401\n\n\n\n\n\n\nFinally, I use ggplot with the geom_tile() geometry to create a simple but helpful visualization of the subset of \\([0,2] \\times [0,3]\\) within which the boolean condition is true (and where I have explicitly drawn lines showing the boundaries within which the point \\((x,y)\\) has a non-zero probability density, as well as the function \\(f(x) = x\\), which will both come in handy later):\n\n\nCode\nlibrary(latex2exp)\nggplot(xy_df, aes(x=x, y=y)) +\n  geom_tile(aes(fill=factor(x_leq_y))) +\n  geom_segment(x=0, y=0, xend=0, yend=3) +\n  geom_segment(x=0, y=0, xend=2, yend=0) +\n  geom_segment(x=0, y=3, xend=2, yend=3) +\n  geom_segment(x=2, y=0, xend=2, yend=3) +\n  stat_function(fun = function(x) x) +\n  coord_fixed() +\n  dsan_theme() +\n  labs(\n    fill = TeX(\"$X \\\\leq Y$\"),\n    title = \"The Integration Space, in 2D\"\n  ) +\n  scale_fill_discrete(labels=c(\"False\",\"True\"))\n\n\n\n\n\n\n\n\n\nAnd now let’s use this plot to think about what we’re doing in both Approach 1 and Approach 2.\n\nApproach 1\nTo think through the double integral in this case, visually, I like to imagine “sweeping” over the space across one dimension when computing the inner integral, then “sweeping” over the space across the other dimension when computing the outer integral.\nRemember that the double integral in Approach 1 was set up as follows:\n\\[\n\\begin{align*}\n\\Pr(X \\leq Y) &= \\int_{0}^{2}\\int_{x}^{3}f_{X,Y}(x,y)~dy~dx\n\\end{align*}\n\\]\nSo, in this case, we can add some arrows to our plot to show the “sweeping” which is occurring when we compute the inner integral. Since the inner integral is from \\(y = x\\) to \\(y = 3\\), I think of arrows sweeping upwards from the line \\(y = x\\) to the (horizontal) line \\(y = 3\\).\nSo, to make the diagram on the left side of the figure below, which represents the inner integral, I use:\n\nDashed yellow lines to represent the bounds between which we’re “sweeping”, and\nDashed arrows to represent the direction of the sweeping\n\nThen to make the diagram on the right, which represents the outer integral, I use:\n\nSolid yellow lines to represent the bounds between which we’re sweeping, and\nSolid arrows to represent the direction of the sweeping\n\nWhich means that ultimately, after computing the two integrals, we have integrated over the region of the \\(xy\\)-plane bounded by the dashed and solid yellow lines.\n\n\nCode\nlibrary(patchwork)\nlibrary(latex2exp)\n# blw = Boundary line width\nblw &lt;- 1\n# blc = Boundary line color\nblc &lt;- 'yellow'\na1_inner_xvals &lt;- c(0.05, 0.5, 1, 1.5, 1.95)\na1_inner_df &lt;- tibble(x=a1_inner_xvals)\na1_inner_df &lt;- a1_inner_df |&gt; mutate(\n    xend = x,\n    y = x,\n    yend = 3\n)\na1_inner_plot &lt;- ggplot(xy_df, aes(x=x, y=y)) +\n  geom_tile(aes(fill=factor(x_leq_y))) +\n  geom_segment(x=0, y=0, xend=0, yend=3) +\n  geom_segment(x=0, y=0, xend=2, yend=0) +\n  geom_segment(x=0, y=3, xend=2, yend=3) +\n  geom_segment(x=2, y=0, xend=2, yend=3) +\n  stat_function(fun = function(x) x) +\n  geom_segment(data=a1_inner_df, aes(x=x, y=y, xend=xend, yend=yend), linetype='dashed', arrow = arrow(length = unit(0.5, \"cm\"))) +\n  # Inner integral, lower bound\n  geom_segment(x=0, y=0, xend=2, yend=2, color=blc, linewidth=blw, linetype='dashed') +\n  # Inner integral, upper bound\n  geom_segment(x=0, y=3, xend=2, yend=3, color=blc, linewidth=blw, linetype='dashed') +\n  coord_fixed() +\n  dsan_theme() +\n  labs(\n    title = \"A1.1: Inner Integral\"\n  ) +\n  remove_legend()\n\na1_outer_yvals &lt;- c(0.05, 0.5, 1, 1.5, 2, 2.5, 2.95)\na1_outer_df &lt;- tibble(y=a1_outer_yvals)\na1_outer_df &lt;- a1_outer_df |&gt; mutate(\n    yend = y,\n    x = 0,\n    xend = 2\n)\n\na1_outer_plot &lt;- ggplot(xy_df, aes(x=x, y=y)) +\n  geom_tile(aes(fill=factor(x_leq_y))) +\n  geom_segment(data=a1_inner_df, aes(x=x, y=y, xend=xend, yend=yend), linetype='dashed', arrow = arrow(length = unit(0.5, \"cm\"))) +\n  geom_segment(data=a1_outer_df, aes(x=x, y=y, xend=xend, yend=yend), linetype='solid', arrow = arrow(length = unit(0.5, \"cm\"))) +\n  geom_segment(x=0, y=0, xend=0, yend=3) +\n  geom_segment(x=0, y=0, xend=2, yend=0) +\n  geom_segment(x=0, y=3, xend=2, yend=3) +\n  geom_segment(x=2, y=0, xend=2, yend=3) +\n  stat_function(fun = function(x) x) +\n  # Inner integral, lower bound\n  geom_segment(x=0, y=0, xend=2, yend=2, color=blc, linewidth=blw, linetype='dashed') +\n  # Inner integral, upper bound\n  geom_segment(x=0, y=3, xend=2, yend=3, color=blc, linewidth=blw, linetype='dashed') +\n  # Outer integral, lower bound\n  geom_segment(x=0, y=0, xend=0, yend=3, color=blc, linewidth=blw, linetype='solid') +\n  # Outer integral, upper bound\n  geom_segment(x=2, y=0, xend=2, yend=3, color=blc, linewidth=blw, linetype='solid') +\n  coord_fixed() +\n  dsan_theme() +\n  labs(\n    title = \"A1.2: Outer Integral\"\n  ) +\n  remove_legend()\na1_inner_plot + a1_outer_plot\n\n\n\n\n\n\n\n\n\nNote how, since the inner integral in this case already excluded all points lying beneath the line \\(y = x\\) (the dashed yellow diagonal line), it actually didn’t matter that our outer integral went over this “boundary line”: the overall result of the double-integration only sums up the values of the pdf in the range bounded by the yellow lines. In other words, even though the outer integral does “sweep” over the dashed yellow diagonal \\(y = x\\) line, thus sweeping outside of the range of valid values of \\(x\\), it did not have any density here to sum up, since all of the probability density in this red triangle had been left out of the inner integral.\n(If that last paragraph didn’t make sense to you, don’t worry about it! Just stick to the pictures for intuition)\n\n\nApproach 2\nOn the other hand, recall that the double integral in Approach 2 was set up as follows:\n\\[\n\\begin{align*}\n\\Pr(X \\leq Y) &= \\int_{0}^{3}\\int_{0}^{y}f_{X,Y}(x,y)~dx~dy\n\\end{align*}\n\\]\nGiven this double integral setup, we can employ this same way of thinking about integration (as “sweeping” across a dimension) to obtain the following diagram, which helps illustrate why we obtain a value greater than 1 in this case:\n\n\nCode\na2_inner_yvals &lt;- c(0.5, 1, 1.5, 2, 2.5, 2.95)\na2_inner_df &lt;- tibble(y=a2_inner_yvals)\na2_inner_df &lt;- a2_inner_df |&gt; mutate(\n    yend = y,\n    x = 0.05,\n    xend = y\n)\nribbon_xvals &lt;- seq(from = 2, to = 3, by = 0.01)\nribbon_df &lt;- tibble(x=ribbon_xvals, y=ribbon_xvals)\na2_inner_plot &lt;- ggplot(xy_df, aes(x=x, y=y)) +\n  geom_tile(aes(fill=factor(x_leq_y))) +\n  geom_segment(data=a2_inner_df, aes(x=x, y=y, xend=xend, yend=yend), linetype='dashed', arrow = arrow(length = unit(0.5, \"cm\"))) +\n  geom_ribbon(data=ribbon_df, aes(x=x, ymin=y, ymax=3), alpha=0.333) +\n  geom_segment(x=0, y=0, xend=0, yend=3) +\n  geom_segment(x=0, y=0, xend=2, yend=0) +\n  geom_segment(x=0, y=3, xend=2, yend=3) +\n  geom_segment(x=2, y=0, xend=2, yend=3) +\n  stat_function(fun=function(x) x) +\n  # Inner integral, lower bound\n  geom_segment(x=0, y=0, xend=0, yend=3, color=blc, linewidth=blw, linetype='dashed') +\n  # Inner integral, upper bound\n  geom_segment(x=0, y=0, xend=3, yend=3, color=blc, linewidth=blw, linetype='dashed') +\n  coord_fixed() +\n  dsan_theme() +\n  labs(\n    title = \"A2.1: Inner Integral\"\n  ) +\n  remove_legend()\n\na2_outer_xvals &lt;- c(0.05, 0.5, 1, 1.5, 1.95, 2.5, 2.95)\na2_outer_df &lt;- tibble(x=a2_outer_xvals)\na2_outer_df &lt;- a2_outer_df |&gt; mutate(\n    xend = x,\n    y = 0,\n    yend = 2.95\n)\n\na2_outer_plot &lt;- ggplot(xy_df, aes(x=x, y=y)) +\n  geom_tile(aes(fill=factor(x_leq_y))) +\n  geom_segment(data=a2_inner_df, aes(x=x, y=y, xend=xend, yend=yend), linetype='dashed', arrow = arrow(length = unit(0.5, \"cm\"))) +\n  geom_segment(data=a2_outer_df, aes(x=x, y=y, xend=xend, yend=yend), linetype='solid', arrow = arrow(length = unit(0.5, \"cm\"))) +\n  geom_ribbon(data=ribbon_df, aes(x=x, ymin=y, ymax=3), alpha=0.333) +\n  geom_segment(x=0, y=0, xend=0, yend=3) +\n  geom_segment(x=0, y=0, xend=2, yend=0) +\n  geom_segment(x=0, y=3, xend=2, yend=3) +\n  geom_segment(x=2, y=0, xend=2, yend=3) +\n  stat_function(fun=function(x) x) +\n  # Inner integral, lower bound\n  geom_segment(x=0, y=0, xend=0, yend=3, color=blc, linewidth=blw, linetype='dashed') +\n  # Inner integral, upper bound\n  geom_segment(x=0, y=0, xend=3, yend=3, color=blc, linewidth=blw, linetype='dashed') +\n  # Outer integral, lower bound\n  geom_segment(x=0, y=0, xend=3, yend=0, color=blc, linewidth=blw, linetype='solid') +\n  # Outer integral, upper bound\n  geom_segment(x=0, y=3, xend=3, yend=3, color=blc, linewidth=blw, linetype='solid') +\n  coord_fixed() +\n  dsan_theme() +\n  labs(\n    title = \"A2.2: Outer Integral\"\n  ) +\n  remove_legend()\na2_inner_plot + a2_outer_plot\n\n\n\n\n\n\n\n\n\nSo we see that, whereas in Approach 1 everything worked out since the line \\(y = x\\) was suitable as a mathematical representation of the entire lower bound of \\(y\\), here in Approach 2 we cannot use the line \\(y = x\\) on its own to characterize the upper bound on \\(x\\), since this will include the grey triangle in the diagram above as part of the region over which we’re integrating the joint pdf."
  },
  {
    "objectID": "writeups/order-of-integration/index.html#fixing-the-issue",
    "href": "writeups/order-of-integration/index.html#fixing-the-issue",
    "title": "Continuous Probability and the Order of Integration",
    "section": "Fixing The Issue",
    "text": "Fixing The Issue\n\nA Technically-Correct Fix\nThinking through the above statement a bit further: if we want to “integrate out” the \\(x\\) variable, the upper bound on \\(x\\) should instead be \\(\\min(2, y)\\). In other words, by looking at the above diagram, we can see that the following modification to our integral in Approach 2 would technically “work” to fix the problem, if it was easy to compute:\n\\[\n\\begin{align*}\n\\Pr(X \\leq Y) &= \\int_{0}^{3}\\int_{0}^{\\min(2, y)}f_{X,Y}(x,y)~dx~dy\n\\end{align*}\n\\]\nOne way of thinking about this is, if we had set our upper bounds in Approach 2 this way, the diagram showing the “sweeping” over the \\(x\\) dimension would instead look like the following, where the yellow line traces out \\(x = \\min(2,y)\\) instead of \\(x = y\\) (the black line):\n\n\nCode\na2_inner_df_fixed &lt;- a2_inner_df |&gt; mutate(\n  xend = ifelse(xend &gt;= 2, 2, xend)\n)\na2_fixed_inner_plot &lt;- ggplot(xy_df, aes(x=x, y=y)) +\n  geom_tile(aes(fill=factor(x_leq_y))) +\n  geom_segment(data=a2_inner_df_fixed, aes(x=x, y=y, xend=xend, yend=yend), linetype='dashed', arrow = arrow(length = unit(0.5, \"cm\"))) +\n  geom_ribbon(data=ribbon_df, aes(x=x, ymin=y, ymax=3), alpha=0.333) +\n  geom_segment(x=0, y=0, xend=0, yend=3) +\n  geom_segment(x=0, y=0, xend=2, yend=0) +\n  geom_segment(x=0, y=3, xend=2, yend=3) +\n  geom_segment(x=2, y=0, xend=2, yend=3) +\n  stat_function(fun=function(x) x) +\n  # Inner integral, lower bound\n  geom_segment(x=0, y=0, xend=0, yend=3, color=blc, linewidth=blw, linetype='dashed') +\n  # Inner integral, upper bound, segment 1\n  geom_segment(x=2, y=2, xend=2, yend=3, color=blc, linewidth=blw, linetype='dashed') +\n  # Inner integral, upper bound, segment 2\n  geom_segment(x=0, y=0, xend=2, yend=2, color=blc, linewidth=blw, linetype='dashed') +\n  coord_fixed() +\n  dsan_theme() +\n  labs(\n    title = \"A2.1: Inner Integral\"\n  ) +\n  remove_legend()\n\na2_outer_df_fixed &lt;- a2_outer_df |&gt; filter(x &lt;= 2)\n\na2_fixed_outer_plot &lt;- ggplot(xy_df, aes(x=x, y=y)) +\n  geom_tile(aes(fill=factor(x_leq_y))) +\n  geom_segment(data=a2_inner_df_fixed, aes(x=x, y=y, xend=xend, yend=yend), linetype='dashed', arrow = arrow(length = unit(0.5, \"cm\"))) +\n  geom_segment(data=a2_outer_df_fixed, aes(x=x, y=y, xend=xend, yend=yend), linetype='solid', arrow = arrow(length = unit(0.5, \"cm\"))) +\n  geom_ribbon(data=ribbon_df, aes(x=x, ymin=y, ymax=3), alpha=0.333) +\n  geom_segment(x=0, y=0, xend=0, yend=3) +\n  geom_segment(x=0, y=0, xend=2, yend=0) +\n  geom_segment(x=0, y=3, xend=2, yend=3) +\n  geom_segment(x=2, y=0, xend=2, yend=3) +\n  stat_function(fun=function(x) x) +\n  # Inner integral, lower bound\n  geom_segment(x=0, y=0, xend=0, yend=3, color=blc, linewidth=blw, linetype='dashed') +\n  # Inner integral, upper bound, segment 1\n  geom_segment(x=2, y=2, xend=2, yend=3, color=blc, linewidth=blw, linetype='dashed') +\n  # Inner integral, upper bound, segment 2\n  geom_segment(x=0, y=0, xend=2, yend=2, color=blc, linewidth=blw, linetype='dashed') +\n  # Outer integral, lower bound\n  geom_segment(x=0, y=0, xend=2, yend=0, color=blc, linewidth=blw, linetype='solid') +\n  # Outer integral, upper bound\n  geom_segment(x=0, y=3, xend=2, yend=3, color=blc, linewidth=blw, linetype='solid') +\n  coord_fixed() +\n  dsan_theme() +\n  labs(\n    title = \"A2.2: Outer Integral\"\n  ) +\n  remove_legend()\na2_fixed_inner_plot + a2_fixed_outer_plot\n\n\n\n\n\n\n\n\n\n\n\nAvoiding \\(\\min()\\): A Quick Fix\nSince including fancy functions like \\(\\min()\\) and/or \\(\\max()\\) in our integral bounds makes things more complicated (to me, at least), one “quick fix” way to handle this would be to just take the result of the original Approach 2 integral and subtract out the integral of the joint pdf within the grey triangle in the above diagrams.\n\n\nA More Practical/“Correct” Approach\nHowever, the more “correct” way in a sense would be to ensure that we are never integrating over an area that is not in the support of \\((X,Y)\\). To accomplish this, we can observe that our Approach 2 integral would have worked and would have integrated only over the support of \\((X,Y)\\) if we had broken it up as follows:\n\\[\n\\Pr(X \\leq Y) = \\int_{0}^{2}\\int_{0}^{y}f_{X,Y}(x,y)~dx~dy + \\int_{2}^{3}\\int_{0}^{2}f_{X,Y}(x,y)~dx~dy\n\\]\nThus we’ll call this way of integrating Approach 3, which can be visualized as follows:\n\n\nCode\na31_inner_yvals &lt;- c(0.5, 1, 1.5, 1.95)\na31_inner_df &lt;- tibble(y=a31_inner_yvals)\na31_inner_df &lt;- a31_inner_df |&gt; mutate(\n    yend = y,\n    x = 0.05,\n    xend = y\n)\na31_outer_xvals &lt;- c(0.05, 0.5, 1, 1.5, 1.95)\na31_outer_df &lt;- tibble(x=a31_outer_xvals)\na31_outer_df &lt;- a31_outer_df |&gt; mutate(\n    xend = x,\n    y = 0.05,\n    yend = 2\n)\na31_plot &lt;- ggplot(xy_df, aes(x=x, y=y)) +\n  geom_tile(aes(fill=factor(x_leq_y))) +\n  geom_segment(data=a31_inner_df, aes(x=x, y=y, xend=xend, yend=yend), linetype='dashed', arrow = arrow(length = unit(0.5, \"cm\"))) +\n  geom_segment(data=a31_outer_df, aes(x=x, y=y, xend=xend, yend=yend), linetype='solid', arrow = arrow(length = unit(0.5, \"cm\"))) +\n  geom_segment(x=0, y=0, xend=0, yend=3) +\n  geom_segment(x=0, y=0, xend=2, yend=0) +\n  geom_segment(x=0, y=3, xend=2, yend=3) +\n  geom_segment(x=2, y=0, xend=2, yend=3) +\n  stat_function(fun=function(x) x) +\n  # Lower bound, inner integral\n  geom_segment(x=0, y=0, xend=0, yend=2, color=\"yellow\", linewidth=1, linetype='dashed') +\n  # Upper bound, inner integral\n  geom_segment(x=0, y=0, xend=2, yend=2, color=\"yellow\", linewidth=1, linetype='dashed') +\n  # Lower bound, outer integral\n  geom_segment(x=0, y=0, xend=2, yend=0, color=\"yellow\", linewidth=1, linetype='solid') +\n  geom_segment(x=0, y=2, xend=2, yend=2, color=\"yellow\", linewidth=1, linetype='solid') +\n  coord_fixed() +\n  dsan_theme() +\n  labs(\n    title = \"A3.1: First Integral\"\n  ) +\n  remove_legend()\n\na32_inner_yvals &lt;- c(2.05, 2.5, 2.95)\na32_inner_df &lt;- tibble(y=a32_inner_yvals)\na32_inner_df &lt;- a32_inner_df |&gt; mutate(\n    yend = y,\n    x = 0,\n    xend = 1.95\n)\na32_outer_xvals &lt;- c(0.05, 0.5, 1, 1.5, 1.95)\na32_outer_df &lt;- tibble(x=a32_outer_xvals)\na32_outer_df &lt;- a32_outer_df |&gt; mutate(\n    xend = x,\n    y = 2,\n    yend = 2.95\n)\n\na32_plot &lt;- ggplot(xy_df, aes(x=x, y=y)) +\n  geom_tile(aes(fill=factor(x_leq_y))) +\n  geom_segment(data=a32_inner_df, aes(x=x, y=y, xend=xend, yend=yend), linetype='dashed', arrow = arrow(length = unit(0.5, \"cm\"))) +\n  geom_segment(data=a32_outer_df, aes(x=x, y=y, xend=xend, yend=yend), linetype='solid', arrow = arrow(length = unit(0.5, \"cm\"))) +\n  geom_segment(x=0, y=0, xend=0, yend=3) +\n  geom_segment(x=0, y=0, xend=2, yend=0) +\n  geom_segment(x=0, y=3, xend=2, yend=3) +\n  geom_segment(x=2, y=0, xend=2, yend=3) +\n  # Lower bound of inner integral\n  geom_segment(x=0, y=2, xend=0, yend=3, color=\"yellow\", linewidth=1, linetype='dashed') +\n  geom_segment(x=2, y=2, xend=2, yend=3, color=\"yellow\", linewidth=1, linetype='dashed') +\n  geom_segment(x=0, y=3, xend=2, yend=3, color=\"yellow\", linewidth=1, linetype='solid') +\n  geom_segment(x=0, y=2, xend=2, yend=2, color='yellow', linewidth=1, linetype='solid') +\n  stat_function(fun=function(x) x) +\n  coord_fixed() +\n  dsan_theme() +\n  labs(\n    title = \"A3.2: Second Integral\"\n  ) +\n  remove_legend()\na31_plot + a32_plot\n\n\n\n\n\n\n\n\n\nSo we see that the following steps give us the correct result:\n\nWe first integrate the joint pdf over the region displayed on the left: the triangle with vertices at \\((0,0)\\), \\((0,2)\\), and \\((2,2)\\))\nWe then integrate the joint pdf separately over the region displayed on the right: the square with vertices at \\((0,2)\\), \\((0,3)\\), \\((2,2)\\), and \\((2,3)\\)\nAnd then we obtain the total density of the pdf within the admissible (green) region by adding these two results together\n\nMathematically, this gives us (skipping many steps like we did before):\n\\[\n\\begin{align*}\n\\Pr(X \\leq Y) &= \\int_{0}^{2}\\int_{0}^{y}f_{X,Y}(x,y)~dx~dy + \\int_{2}^{3}\\int_{0}^{2}f_{X,Y}(x,y)~dx~dy \\\\\n&= \\frac{29}{165} + \\frac{7}{11} = \\frac{134}{165} \\approx 0.812,\n\\end{align*}\n\\]\nmatching the result from our original integral, performed in the opposite order.\nHopefully this way of breaking down the relationship between integration and probability can help you out: if you find yourself staring at a problem for too long, try breaking your brain out of the rut by seeing if diagrams like the above can help you reason through what the bounds of your integrals should be 😎"
  },
  {
    "objectID": "writeups/order-of-integration/index.html#footnotes",
    "href": "writeups/order-of-integration/index.html#footnotes",
    "title": "Continuous Probability and the Order of Integration",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nNote that this does not mean we are necessarily correct! It just means that our result doesn’t “break” any laws of probability.↩︎"
  },
  {
    "objectID": "writeups/quiz-1-clarifications/index.html",
    "href": "writeups/quiz-1-clarifications/index.html",
    "title": "Quiz 1 Clarifications",
    "section": "",
    "text": "Quiz 1 Links\n\n\n\n\nQuiz 1"
  },
  {
    "objectID": "writeups/quiz-1-clarifications/index.html#starting-off-generating-the-new-york-data",
    "href": "writeups/quiz-1-clarifications/index.html#starting-off-generating-the-new-york-data",
    "title": "Quiz 1 Clarifications",
    "section": "Starting Off: Generating the New York Data",
    "text": "Starting Off: Generating the New York Data"
  },
  {
    "objectID": "writeups/deriving-pdf/index.html",
    "href": "writeups/deriving-pdf/index.html",
    "title": "Deriving a pdf from Scratch",
    "section": "",
    "text": "Setting Random Seed\n\n\n\n(At the beginning of code where you’re dealing with distributions, make sure you set the random seed to 5100, or at least some constant value, to make sure results are reproducible across different computers at different times)\n\nset.seed(5100)\n# This just loads some global ggplot settings, you\n# can uncomment this if trying to run on your own/on Colab\nsource(\"../../_globals.r\")\nOn the Lab 5 Assignment, I think a lot of students might be wrestling with what’s “going on” on Problem 1, so I wanted to make a quick writeup with some intuition around where to start on this problem.\nWhereas in Problem 2 you are given a CDF (there are unknown variables, but you have something concrete to start “doing math” with), in Problem 1 it may seem at first like you don’t have enough information to complete the problem, since you only have information about a constraint on the possible values that \\(X\\) and \\(Y\\) can take on, rather than (e.g.) the actual probability density that the pdf \\(f_{X,Y}(x,y)\\) should take on.\nIn reality, though, that’s part of the difficulty of the problem: namely, how to derive a valid pdf from only these tiny scraps of information!"
  },
  {
    "objectID": "writeups/deriving-pdf/index.html#necessary-vs.-sufficient-conditions",
    "href": "writeups/deriving-pdf/index.html#necessary-vs.-sufficient-conditions",
    "title": "Deriving a pdf from Scratch",
    "section": "Necessary vs. Sufficient Conditions",
    "text": "Necessary vs. Sufficient Conditions\nBefore we start, in case the distinction between necessary and sufficient conditions isn’t something you’ve learned before:\n\nIf [a predicate] \\(p\\) is necessary for [a predicate] \\(q\\), then if we know \\(p\\) is false then \\(q\\) must be false.\n\nFor example, let \\(p = [x &gt; 3]\\) and \\(q = [x &gt; 5]\\).\nThen \\(p\\) is a necessary condition for \\(q\\), because in this case if we know that \\(p\\) is false \\(q\\) must also be false.\nNote that the converse does not hold! That is, knowing that \\(p\\) is true does not tell us that \\(q\\) is true: if we know \\(p\\) (so we know that \\(x &gt; 3\\)), we still don’t know \\(q\\), since we could have e.g. \\(x = 4\\).\n\nIf \\(p\\) is sufficient for \\(q\\), then if we know \\(p\\) is true we also know that \\(q\\) is true.\n\nFor example, let \\(p = [x\\text{ is divisible by }4]\\) and \\(q = [x\\text{ is even}]\\)\nThen \\(p\\) is a sufficient condition for \\(q\\), since all numbers divisible by 4 are also even.\nAgain you have to be careful, because the converse does not hold: knowing that \\(q\\) is false in this example does not tell us that \\(p\\) is false: if we know \\(\\neg q\\), we know \\(x\\) is not divisible by 4, but \\(p\\) can still be true, since e.g. \\(x\\) could be 6 (an even number not divisible by 4).\n\n\nI think keeping this in mind is helpful for this specific problem, because we can think about the following two necessary conditions that must hold for a given function \\(f_Z(v)\\) to represent a valid pdf for the random variable \\(Z\\).\n\n\n\n\n\n\nGoing from Single-Valued to Multi-Valued pdfs\n\n\n\nI use \\(Z\\) to define the pdf \\(f_Z(v)\\) here to emphasize how pdfs are (at their core) defined for single random variables like \\(X\\), \\(Y\\), or \\(Z\\).\nNonetheless, as we enter into multivariable probability world we can consider \\(f_Z(v)\\) as the pdf for a vector-valued random variable \\(Z\\), so that \\(Z\\) can in fact represent a point that is decomposable into an \\(x\\)-coordinate (represented by a random variable \\(X\\)) and a \\(y\\)-coordinate (represented by a random variable \\(Y\\)). In this case, we can rewrite \\(Z\\) as \\((X,Y)\\) and call our pdf \\(f_{(X,Y)}(v_X, x_Y)\\), which for succinctness we usually shorten to just \\(f_{X,Y}(x,y)\\)."
  },
  {
    "objectID": "writeups/deriving-pdf/index.html#two-necessary-conditions-for-a-valid-pdf-which-are-jointly-sufficient",
    "href": "writeups/deriving-pdf/index.html#two-necessary-conditions-for-a-valid-pdf-which-are-jointly-sufficient",
    "title": "Deriving a pdf from Scratch",
    "section": "Two Necessary Conditions for a Valid pdf Which Are Jointly Sufficient",
    "text": "Two Necessary Conditions for a Valid pdf Which Are Jointly Sufficient\nGiven the above definitions+examples of necessary vs. sufficient conditions, here (if we call the first condition \\(NC_1\\) and the second \\(NC_2\\)) they are individually necessary but jointly sufficient: meaning that if we define a new condition \\(B\\) for “both”, such that \\(B = (NC_1 \\wedge NC_2)\\), then \\(B\\) is in fact a sufficient condition for \\(f\\) to be a valid pdf. If we can ensure that both of the necessary conditions given below are true, then we know that our function \\(f_Z\\) defines a valid pdf for a random variable \\(Z\\).\n\nNecessary Condition 1 (\\(NC_1\\), Single-Variable): The integral of the pdf \\(f_Z(v)\\) over \\(\\mathcal{R}_Z\\) (where \\(\\mathcal{R}_Z\\) is the support of \\(Z\\)) must equal 1.\nNecessary Condition 1 (\\(NC_1\\), Multi-Value): The double-integral of the pdf \\(f_{X,Y}(x,y)\\) over \\(\\mathcal{R}_X\\) and \\(\\mathcal{R}_Y\\) must equal 1.\nNecessary Condition 2 (\\(NC_2\\), Single-Value): If \\(Z\\) is defined over a range \\([a, b]\\), then the pdf \\(f_Z\\) must assign nonzero probability density to all non-empty one-dimensional intervals of radius \\(\\varepsilon\\) around \\(v \\in [a,b]\\), and zero probability density to all other intervals.\nNecessary Condition 2 (\\(NC_2\\), Multi-Value): If \\(X\\) is defined over a range \\([a_X, b_X]\\) and \\(Y\\) is defined over a range \\([a_Y, b_Y]\\), then the pdf \\(f_{X,Y}\\) must assign nonzero probability density to all non-empty two-dimensional circles of radius \\(\\varepsilon\\) around points \\(\\{ (x,y) \\mid x \\in [a_X,b_X]\\text{ and }y \\in [a_Y,b_Y]\\}\\).\n\nI know Necessary Condition 2 is extremely scary-looking and confusing, but it is mainly that way to handle extremely “weird” cases where we’d like to define probability distributions over bizarre sets like the Sierpiński triangle.\nSince in Problem 1 on the Lab Assignment we are working with a nicely-behaved set (the set that you plotted in part 1, which is just a triangle taking up the bottom 1/2 of the unit square), we can transform Necessary Condition 2 into a much more intuitive version\n\nNecessary Condition 2 (\\(NC_2\\), RVs Defined over “Well-Behaved” Spaces): If \\(X\\) is defined over a range \\([a_X, b_X]\\) and \\(Y\\) is defined over a range \\([a_Y, b_Y]\\), then the pdf \\(f_{X,Y}\\) must assign nonzero probability density to all points \\(\\{(x,y) \\mid x \\in [a_X,b_X]\\text{ and }y \\in [a_Y,b_Y]\\}\\).\n\nIf the difference between the “well-behaved” case and the general case above is not clear, compare the definitions closely (in the “simplified version” just given, we don’t have to worry about circles around points, just points themselves)."
  },
  {
    "objectID": "writeups/deriving-pdf/index.html#why-are-you-telling-us-all-this-how-does-it-help-solve-problem-1",
    "href": "writeups/deriving-pdf/index.html#why-are-you-telling-us-all-this-how-does-it-help-solve-problem-1",
    "title": "Deriving a pdf from Scratch",
    "section": "Why Are You Telling Us All This? How Does It Help Solve Problem 1?",
    "text": "Why Are You Telling Us All This? How Does It Help Solve Problem 1?\nIf you’ve made it all the way to this point, you may be frustrated that I still haven’t pointed exactly to how these two conditions help us solve Problem 1.\nSince I can’t give away the solution for that particular problem, here I will show the applicability of these two conditions to a similar problem, and then your job is to think about how the way I work through this problem can help you work through problem 1.\nThe example problem: Given two random variables \\(X \\sim \\mathcal{U}[0,1]\\) and \\(Y \\sim \\mathcal{U}[0,1]\\), consider the joint distribution of the vector-valued random variable \\(Z = (X,Y)\\), where the possible realizations of \\(Z\\) are restricted to only those values of \\(X\\) and \\(Y\\) such that they lie within a circle of radius \\(1\\) around the origin: that is, \\(X^2 + Y^2 &lt; 1\\). This means that we could create a plot which “fills in” the possible values of \\(Z\\) more and more as we sample more points, by generating values of \\(X\\) sampled from from \\(\\mathcal{U}[0,1]\\) and values of \\(Y\\) sampled from \\(\\mathcal{U}[0,1]\\), then placing the points on the plot if they are “admissible” (if they form a valid realization of \\(Z\\)) and throwing the points away otherwise:\n\nlibrary(tidyverse)\nN &lt;- 2500\nx_vals &lt;- runif(N, -1, 1)\ny_vals &lt;- runif(N, -1, 1)\nsample_df &lt;- tibble(x=x_vals, y=y_vals)\nsample_df &lt;- sample_df |&gt;\n  mutate(\n    admissible = x^2 + y^2 &lt; 1\n  )\nsample_df |&gt; head()\n\n\n\n\n\nx\ny\nadmissible\n\n\n\n\n0.0853844\n0.4159406\nTRUE\n\n\n-0.4991692\n-0.6671818\nTRUE\n\n\n-0.5449181\n0.9697597\nFALSE\n\n\n-0.2142207\n-0.8855359\nTRUE\n\n\n0.8015973\n0.2324585\nTRUE\n\n\n-0.6283825\n-0.0055527\nTRUE\n\n\n\n\n\n\nWe see that, given how admissible is defined, plotting only the points for which admissible == TRUE will mean that we are “filling out” the subset of all possible values in the square \\([-1,1] \\times [-1,1]\\) that satisfy our contstraint:\n\nadmissible_df &lt;- sample_df |&gt;\n  filter(admissible)\nggplot(admissible_df, aes(x=x, y=y)) +\n  geom_point() +\n  dsan_theme() +\n  # If you were wondering how to make it an actual perfect circle\n  coord_fixed()\n\n\n\n\n\n\n\n\nAnd now we can finally use our two necessary conditions, albeit in reverse order:\n\nApplying Necessary Condition 2 (Simplified Version) To This Case:\nTo satisfy this condition, let’s literally just define a pdf \\(f_{X,Y}\\) that has some non-zero value \\(c\\) for points within the circle in the above plot, and has value \\(0\\) otherwise:\n\\[\nf_{X,Y}(x,y) = \\begin{cases}\nc &\\text{if }x^2 + y^2 &lt; 1, \\\\\n0 &\\text{otherwise.}\n\\end{cases}\n\\]\nSo far, we’ve satisfied Necessary Condition 1 (\\(NC_1\\)) for \\(f_{X,Y}\\) to be a valid pdf. Now if we can figure out how to also make this function satisfy Necessary Condition 2 (\\(NC_2\\)), we’ll know that we have a valid pdf for \\(Z = (X,Y)\\).\n\n\nApplying Necessary Condition 1 To This Case\nGiven that \\(X\\) and \\(Y\\) are both defined (in a nicely-behaved way) over the range \\([-1,1]\\), the remaining condition \\(NC_1\\) is satisfied if the following equality holds:\n\\[\n\\int_{-1}^{1}\\int_{-1}^{1}f_{X,Y}(x,y)dxdy = 1\n\\tag{1}\\]\nIf you calculate these two definite integrals (you could do it using fancy math, like variable substitution, or just using geometry, e.g. by thinking about what the integral would be given what you know about the areas of circles), you will find that this integral-filled equality reduces to the equality\n\\[\nc\\pi = 1\n\\]\nSo that, finally, we can solve for the value of \\(c\\) which now lets us “fill in this detail”: that if we choose \\(c = \\frac{1}{\\pi}\\), so that\n\\[\nf_{X,Y}(x,y) = \\begin{cases}\n\\frac{1}{\\pi} &\\text{if }x^2 + y^2 &lt; 1, \\\\\n0 &\\text{otherwise.}\n\\end{cases}\n\\]\nthen we get a nice chain of realizations:\n\nThe equality Equation 1 holds, so\nWe have satisfied \\(NC_1\\), after already satisfying \\(NC_2\\) above, so\nWe have now satisfied both \\(NC_1\\) and \\(NC_2\\),\nThis means we have satisfied \\(B\\), so that finally\nWe have defined a valid pdf \\(f_{X,Y}(x,y)\\) (since \\(B\\) is a sufficient condition for valid pdfs).\n\nI hope that helps somewhat: I wrote things out in excruciating detail, using necessary and sufficient conditions and etc., to try and show how there is a general logic to these types of problems (or at least, a general logic for how we can use the information we’re given to construct a distribution which encodes this information)."
  },
  {
    "objectID": "w02/slides.html#prof.-jeff-introduction",
    "href": "w02/slides.html#prof.-jeff-introduction",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Prof. Jeff Introduction!",
    "text": "Prof. Jeff Introduction!\n\nBorn and raised in NW DC → high school in Rockville, MD\nUniversity of Maryland: Computer Science, Math, Economics (2008-2012)"
  },
  {
    "objectID": "w02/slides.html#grad-school",
    "href": "w02/slides.html#grad-school",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Grad School",
    "text": "Grad School\n\nStudied abroad in Beijing (Peking University/北大) → internship with Huawei in Hong Kong (HKUST)\n\n\n\n\nStanford for MS in Computer Science (2012-2014)\nResearch Economist at UC Berkeley (2014-2015)\n\n\n\n\n\n\nColumbia (NYC) for PhD[+Postdoc] in Political Science (2015-2023)"
  },
  {
    "objectID": "w02/slides.html#dissertation-political-science-history",
    "href": "w02/slides.html#dissertation-political-science-history",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Dissertation (Political Science + History)",
    "text": "Dissertation (Political Science + History)\n“Our Word is Our Weapon”: Text-Analyzing Wars of Ideas from the French Revolution to the First Intifada"
  },
  {
    "objectID": "w02/slides.html#research-labor-economics",
    "href": "w02/slides.html#research-labor-economics",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Research (Labor Economics)",
    "text": "Research (Labor Economics)\n\n\n\n“Monopsony in Online Labor Markets”: Machine Learning to enhance causal estimates of the effect of job description language on uptake rate\n\n\n\n“Freedom as Non-Domination in the Labor Market”: Game-theoretic models of workers’ rights (monopsony vs. labor discipline)\n\n\n\n\n\n“Unsupervised Extraction of Workplace Rights and Duties from Collective Bargaining Agreements”: Linguistic (dependency) parses of contracts → time series of worker vs. employer rights and responsibilities over time"
  },
  {
    "objectID": "w02/slides.html#deterministic-processes",
    "href": "w02/slides.html#deterministic-processes",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Deterministic Processes",
    "text": "Deterministic Processes\n\nGiven a set of inputs, we can compute the outcome exactly\nExample: Given the radius of a circle, we can compute its area without any uncertainty. \\(r \\mapsto \\pi r^2\\)\n(The fact that we can compute the outcome doesn’t mean that it’s easy to do so! See, e.g., the double pendulum)\n\n\nImage credit: Tenor.com\nThe pendulum example points to the fact that the notion of a chaotic system, one which is “sensitive to initial conditions”, is different from that of a stochastic system."
  },
  {
    "objectID": "w02/slides.html#holy-grail-deterministic-model-newtonian-physics",
    "href": "w02/slides.html#holy-grail-deterministic-model-newtonian-physics",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "“Holy Grail” Deterministic Model: Newtonian Physics",
    "text": "“Holy Grail” Deterministic Model: Newtonian Physics\n\n\n\n\n\n\n\n\n\n\ngrid\n\n \n\ncluster_01\n\n “Nature”  \n\ncluster_02\n\n “Science”   \n\nObs\n\n Thing(s) we can see   \n\nUnd\n\n Underlying processes   \n\nUnd-&gt;Obs\n\n    \n\nModel\n\n Model   \n\nUnd-&gt;Model\n\n    \n\nModel-&gt;Obs\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\ngrid\n\n \n\ncluster_04\n\n  Woolsthorpe Manor    \n\ncluster_03\n\n Isaac Newton   \n\nTree\n\n  Falling Apple     \n\nPhysics\n\n  Particle Interactions     \n\nPhysics-&gt;Tree\n\n    \n\nNewton\n\n Newton’s Laws   \n\nPhysics-&gt;Newton\n\n    \n\nNewton-&gt;Tree\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\[\n\\leadsto F_g = G\\frac{m_1m_2}{r^2}\n\\]\nFigure 1: Newton’s Law of Universal Gravitation← Dr. Zirkel follows Newton’s famous steps. Coloured wood engraving. Wellcome Collection (Public Domain)"
  },
  {
    "objectID": "w02/slides.html#but-what-happens-when",
    "href": "w02/slides.html#but-what-happens-when",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "But What Happens When…",
    "text": "But What Happens When…\n\\[\n\\text{Outcome}\\left(\\text{Dice Roll}\\right) = \\; ?\\frac{?_1?_2}{?^2}\n\\]\n\n\n\nPre-Enlightenment\n\n\n\n\nHans Sebald Beham, Fortuna (1541), CC BY 4.0, via Wikimedia Commons\n\n\n\n\nPost-Enlightenment\n\n\n\n\nBlaise Pascal, Traité du triangle arithmétique (1665). Public Domain, via Internet Archive"
  },
  {
    "objectID": "w02/slides.html#random-processes",
    "href": "w02/slides.html#random-processes",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Random Processes",
    "text": "Random Processes\n\n\n\nCan’t compute the outcome exactly, but can still say something about potential outcomes!\nExample: randomly chosen radius \\(r \\in [0,1]\\), what can we say about \\(A = \\pi r^2\\)?\n\nUnif: \\([0,\\pi]\\) equally likely\nExp: closer to \\(0\\) more likely"
  },
  {
    "objectID": "w02/slides.html#data-ground-truth-noise",
    "href": "w02/slides.html#data-ground-truth-noise",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Data = Ground Truth + Noise",
    "text": "Data = Ground Truth + Noise\n\nDepressing but true origin of statistics (as opposed to probability): the Plague 😷\n\n\n\n\n\n\n\nGround Truth: The Great Plague (Lord Have Mercy on London, Unknown Artist, circa 1665, via Wikimedia Commons)\n\n\n\n\n\n\n\nNoisy Data (Recorded amidst chaos): London Bill of Mortality, 1665 (Public Domain, Wellcome Collection)"
  },
  {
    "objectID": "w02/slides.html#random-variables",
    "href": "w02/slides.html#random-variables",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Random Variables",
    "text": "Random Variables\n\nIn algebra, to solve problems we work with variables\nIn probability theory, to solve problems we work with random variables\nRecall the difference between random and deterministic: \\(A = \\pi r^2\\) tells us that, given a value of \\(r\\), we can solve for the unique value of \\(A\\)\nIn probability theory, however, there is no one “true” value of a random variable \\(X\\).\nLet \\(X = f(N)\\) mean that \\(X\\) is the result of a rolled die, where the die has \\(N\\) sides.\nPlugging in \\(N = 6\\) (standard 6-sided die) still doesn’t mean we know “the” value of \\(X\\). However, (if the die is fair) we do know\n\n\\[\n\\Pr(X = 1) = \\Pr(X = 2) = \\cdots = \\Pr(X = 6) = \\frac{1}{6}\n\\]"
  },
  {
    "objectID": "w02/slides.html#discrete-vs.-continuous",
    "href": "w02/slides.html#discrete-vs.-continuous",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Discrete vs. Continuous",
    "text": "Discrete vs. Continuous\n\nMany complicated definitions, often misleading or unintuitive!\nHow I want you to remember: How many possible values between two known values?\nDiscrete: e.g., number of siblings\n\nI have 2 siblings, you have 3 siblings… How many values (sibling counts) in between?\n\nContinuous: e.g., temperature\n\nIt is 27.0° C in my room, 28.0° C in your room… How many values (temperatures) in between?\n\nSo, if \\(X\\) is the result of a rolled die, is \\(X\\) discrete or continuous? How many values can be rolled between 3 and 4?"
  },
  {
    "objectID": "w02/slides.html#thinking-about-independence",
    "href": "w02/slides.html#thinking-about-independence",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Thinking About Independence",
    "text": "Thinking About Independence\n\nWe’ll define it formally later; for now, this is our working definition:\n\n\n\n\n\n\n\nWorking Definition: Independence\n\n\nTwo random variables \\(X\\) and \\(Y\\) are independent if learning information about \\(X\\) does not give you information about the value of \\(Y\\), or vice-versa."
  },
  {
    "objectID": "w02/slides.html#naïve-definition-of-probability",
    "href": "w02/slides.html#naïve-definition-of-probability",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Naïve Definition of Probability",
    "text": "Naïve Definition of Probability\n\nSample Space: The set of all possible outcomes of an experiment\nEvent: A subset of the sample space\n\n\n\n\n\n\n\nNaïve Definition of Probability\n\n\nGiven a sample space \\(S\\), and an event \\(E \\subset S\\),\n\\[\n\\Pr(\\underbrace{E}_{\\text{event}}) = \\frac{\\text{\\# Favorable Outcomes}}{\\text{\\# Possible Outcomes}} = \\frac{|E|}{|S|}\n\\]"
  },
  {
    "objectID": "w02/slides.html#example-flipping-two-coins",
    "href": "w02/slides.html#example-flipping-two-coins",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Example: Flipping Two Coins",
    "text": "Example: Flipping Two Coins\n\n\n\n\n\n\nNaïve Definition of Probability\n\n\nGiven a sample space \\(S\\), and an event \\(E \\subset S\\),\n\\[\n\\Pr(\\underbrace{E}_{\\text{event}}) = \\frac{\\text{\\# Favorable Outcomes}}{\\text{\\# Possible Outcomes}} = \\frac{|E|}{|S|}\n\\]\n\n\n\n\nFlipping two coins:\n\nSample space \\(S = \\{TT, TH, HT, HH\\}\\)\nEvent \\(E_1\\): Result of first flip is \\(H\\), result of second flip is \\(T\\) \\(\\implies\\) \\(E_1 = \\{HT\\}\\).\nEvent \\(E_2\\): At least one \\(H\\) \\(\\implies\\) \\(E_2 = \\{TH, HT, HH\\}\\).\n\n\n\\[\n\\begin{align*}\n\\Pr(E_1) &= \\frac{|\\{HT\\}|}{|S|} = \\frac{|\\{HT\\}|}{|\\{TT, TH, HT, HH\\}|} = \\frac{1}{4} \\\\\n\\Pr(E_2) &= \\frac{|\\{TH, HT, HH\\}|}{|S|} = \\frac{|\\{TH, HT, HH\\}|}{|\\{TT, TH, HT, HH\\}|} = \\frac{3}{4}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w02/slides.html#events-neq-outcomes",
    "href": "w02/slides.html#events-neq-outcomes",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Events \\(\\neq\\) Outcomes!",
    "text": "Events \\(\\neq\\) Outcomes!\n\nOutcomes are things, events are sets of things\nSubtle but extremely important distinction!\nIn the coin flip example:\n\nThe event \\(E_1 = \\{HT\\}\\) can be confused with the outcome \\(HT\\).\nSo, try to remember instead the event \\(E_2 = \\{TH, HT, HH\\}\\): it is more clear, in this case, how this event does not correspond to any individual outcome"
  },
  {
    "objectID": "w02/slides.html#back-to-the-naïve-definition",
    "href": "w02/slides.html#back-to-the-naïve-definition",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Back to the Naïve Definition",
    "text": "Back to the Naïve Definition\n\n\n\n\n\n\nNaïve Definition of Probability\n\n\nGiven a sample space \\(S\\), and an event \\(E \\subset S\\),\n\\[\n\\Pr(\\underbrace{E}_{\\text{event}}) = \\frac{\\text{\\# Favorable Outcomes}}{\\text{\\# Possible Outcomes}} = \\frac{|E|}{|S|}\n\\]\n\n\n\n\nThe naïve definition tells us that probabilities are just ratios of counts:\n\nCount the number of ways the event \\(E\\) can happen, count the total number of things that can happen, and divide!\n\nThis is why we begin studying probability by studying combinatorics: the mathematics of counting"
  },
  {
    "objectID": "w02/slides.html#combinatorics-ice-cream-possibilities",
    "href": "w02/slides.html#combinatorics-ice-cream-possibilities",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Combinatorics: Ice Cream Possibilities",
    "text": "Combinatorics: Ice Cream Possibilities\n\n\n\n\n\n\n\nThe \\(6 = 2 \\cdot 3\\) possible cone+flavor combinations which can result from choosing a flavor first and a cone type second.\n\n\n\n\n\n\n\nThe \\(6 = 3 \\cdot 2\\) possible cone+flavor combinations which can result from choosing a flavor first and a cone type second."
  },
  {
    "objectID": "w02/slides.html#grouping-vs.-ordering",
    "href": "w02/slides.html#grouping-vs.-ordering",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Grouping vs. Ordering",
    "text": "Grouping vs. Ordering\n\nIn standard statistics/combinatorics introductions you’ll learn different counting formulas for when order matters vs. when order doesn’t matter\nThis is not a mathematical distinction so much as a pragmatic distinction: what are you trying to accomplish by counting?\nProblems with extremely similar descriptions can differ in small detail, so that the units you need to distinguish between in one version differ from the units you need to distinguish between in the other."
  },
  {
    "objectID": "w02/slides.html#does-order-matter",
    "href": "w02/slides.html#does-order-matter",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Does Order Matter?",
    "text": "Does Order Matter?\n\n\n\n\n\n\nExample: Student Government vs. Student Sports\n\n\n\nConsider a school where students can either try out for the swim team or run for a position in the student government\nThe swim team has 4 slots, but slots aren’t differentiated: you’re either on the team (one of the 4 chosen students) or not\nThe student government also has 4 slots, but there is a difference between the slots: first slot is President, second is Vice President, third is Secretary, and fourth is Treasurer.\n\n\n\n\n\nSimple case (for intuition): the school only has 4 students. In this case, how many ways are there to form the swim team? What about the student government?\n\nSwim team: \\(1\\) way. You have only one choice, to let all 4 students onto the team\nStudent government: \\(4 \\cdot 3 \\cdot 2 \\cdot 1 = 24\\) ways. You have to let all 4 students in, but you have a choice of who is President, Vice President, Secretary, and Treasurer\n\nHow did we get \\(4 \\cdot 3 \\cdot 2 \\cdot 1\\)? (Think about the ice cream example…)\n\nStart by choosing the President: 4 choices\nNow choose the Vice President: only 3 students left to choose from\nNow choose the Secretary: only 2 students left to choose from\nNow choose the Treasurer: only 1 student left to choose from"
  },
  {
    "objectID": "w02/slides.html#permutations-vs.-combinations",
    "href": "w02/slides.html#permutations-vs.-combinations",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Permutations vs. Combinations",
    "text": "Permutations vs. Combinations\n\nPermutations: How many ways can I choose groups of size \\(k\\) out of \\(n\\) total objects, where order within groups matters: \\(P_{n,k}\\) (sometimes written \\(_nP_k\\)).\n\nIn this case, we want to count \\((a,b)\\) and \\((b,a)\\) as two separate groups\n\nCombinations: How many ways can I choose groups of size \\(k\\) out of \\(n\\) total objects, where order in the groups doesn’t matter: \\(C_{n,k}\\) (sometimes written \\(_nC_k,\\binom{n}{k}\\)).\n\nIn this case, we don’t want to count \\((a, b)\\) and \\((b, a)\\) as two separate groups…\n\n\n\\[\n\\begin{align*}\nP_{n,k} = \\frac{n!}{(n-k)!}, \\; C_{n,k} = \\frac{n!}{k!(n-k)!}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w02/slides.html#no-need-to-memorize",
    "href": "w02/slides.html#no-need-to-memorize",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "No Need to Memorize!",
    "text": "No Need to Memorize!\n\n\nKey point: you don’t have to remember these as two separate formulas!\nThe number of combinations is based on the number of permutations, but corrected for double counting: e.g., corrected for the fact that \\((a,b) \\neq (b,a)\\) when counting permutations but \\((a,b) = (b,a)\\) when counting combinations.\n\n\\[\nC_{n,k} = \\frac{P_{n,k}}{k!} \\genfrac{}{}{0pt}{}{\\leftarrow \\text{Permutations}}{\\leftarrow \\text{Duplicate groups}}\n\\]\nWhere does \\(k!\\) come from? (How many different orderings can we make of the same group?)\n\n\\(k = 2\\): \\((\\underbrace{\\boxed{\\phantom{a}}}_{\\text{2 choices}},\\underbrace{\\boxed{\\phantom{a}}}_{\\text{1 remaining choice}}) \\implies 2\\)\n\\(k = 3\\): \\((\\underbrace{\\boxed{\\phantom{a}}}_{\\text{3 choices}},\\underbrace{\\boxed{\\phantom{a}}}_{\\text{2 remaining choices}}, \\underbrace{\\boxed{\\phantom{a}}}_{\\text{1 remaining choice}}) \\implies 6\\)\n\\(k = 4\\): \\((\\underbrace{\\boxed{\\phantom{a}}}_{\\text{4 choices}}, \\underbrace{\\boxed{\\phantom{a}}}_{\\text{3 remaining choices}}, \\underbrace{\\boxed{\\phantom{a}}}_{\\text{2 remaining choices}}, \\underbrace{\\boxed{\\phantom{a}}}_{\\text{1 remaining choice}}) \\implies 24\\)"
  },
  {
    "objectID": "w02/slides.html#with-or-without-replacement",
    "href": "w02/slides.html#with-or-without-replacement",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "With or Without Replacement?",
    "text": "With or Without Replacement?\n\nBoils down to: can the same object be included in my sample more than once?\n\n\n\n\nWithout Replacement\nWith Replacement\n\n\n\n\nMost statistical problems: “Check off” objects as you collect data about them, so that each observation in your data is unique\nVery special (but very important!) set of statistical problems: allow objects to appear in your sample multiple times, to “squeeze” more information out of the sample (called Bootstrapping—much more on this later in the course!)"
  },
  {
    "objectID": "w02/slides.html#how-many-possible-samples",
    "href": "w02/slides.html#how-many-possible-samples",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "How Many Possible Samples?",
    "text": "How Many Possible Samples?\n\n\n\n\n\n\nExample: How Many Possible Samples?\n\n\nFrom a population of \\(N = 3\\), how many ways can we take samples of size \\(k = 2\\)?\n\n\n\n\n\n\n\nWithout Replacement\nWith Replacement\n\n\n\n\n\\(3 \\cdot 2 = 6\\) ways (3 objects to choose from for first element of sample, 2 remaining objects to choose from for second element of sample)\n\\(3\\cdot 3 = 3^2 = 9\\) ways (3 objects to choose from for first element of sample, still 3 objects to choose from for second element of sample)\n\n\n\n\n\n\n\n\n\n\n\n\nResult: How Many Possible Samples\n\n\nFrom a population of size \\(N\\), how many ways can we take samples of size \\(k\\)? (Try to extrapolate from above examples before looking at answer!)\n\n\n\n\n\n\n\nWithout Replacement\nWith Replacement\n\n\n\n\n\\(\\displaystyle \\underbrace{N \\cdot (N-1) \\cdot \\cdots \\cdot (N - k + 1)}_{k\\text{ times}} = \\frac{N!}{(N - k )!}\\)(This formula should look somewhat familiar…)\n\\(\\displaystyle \\underbrace{N \\cdot N \\cdot \\cdots \\cdot N}_{k\\text{ times}} = N^k\\)"
  },
  {
    "objectID": "w02/slides.html#logic-sets-and-probability",
    "href": "w02/slides.html#logic-sets-and-probability",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Logic, Sets, and Probability",
    "text": "Logic, Sets, and Probability\n\nThere is a deep connection1 between the objects and operations of logic, set theory, and probability:\n\n\n\n\n\n\n\n\n\n\n\nLogic\nSet Theory\nProbability Theory\n\n\n\n\nObjects\nPredicates\\(p, q \\in \\{T, F\\}\\)\nSets\\(S = \\{a, b, \\ldots\\}\\)\nEvents\\(E = \\{TH, HT, HH\\}\\)\n\n\nConjunction\nAnd (\\(\\wedge\\))\\(p \\wedge q\\)\nIntersection (\\(\\cap\\))\\(A \\cap B\\)\nMultiplication (\\(\\times\\)):\\(\\Pr(E_1 \\cap E_2) = \\Pr(E_1)\\times \\Pr(E_2)\\)\n\n\nDisjunction\nOr (\\(\\vee\\))\\(p \\vee q\\)\nUnion (\\(\\cup\\))\\(A \\cup B\\)\nAddition (\\(+\\)): \\(\\Pr(E_1 \\cup E_2) =\\)\\(\\Pr(E_1) + \\Pr(E_2) - \\Pr(E_1 \\wedge E_2)\\)\n\n\nNegation\nNot (\\(\\neg\\))\\(\\neg p\\)\nComplement (\\(^c\\))\\(S^c\\)\nSubtract from 1\\(\\Pr(A^c) = 1 - \\Pr(A)\\)\n\n\n\nFor math majors, you can think of it as an isomorphism between the objects and operations of the three subjects"
  },
  {
    "objectID": "w02/slides.html#example-flipping-two-coins-1",
    "href": "w02/slides.html#example-flipping-two-coins-1",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Example: Flipping Two Coins",
    "text": "Example: Flipping Two Coins\n\nLogic: We can define 4 predicates:\n\n\\(p_1\\) = “First result is \\(H\\)”, \\(q_1\\) = “First result is \\(T\\)”\n\\(p_2\\) = “Second result is \\(H\\)”, \\(q_2\\) = “Second result is \\(T\\)”\n\nLogical formulas:\n\n\\(f_1 = p_1 \\wedge q_2\\): “First result is \\(H\\) and second result is \\(T\\)”\n\\(f_2 = p_1 \\vee q_2\\): “First result is \\(H\\) or second result is \\(T\\)”\n\\(f_3 = \\neg p_1\\): “First result is not \\(H\\)”\n\nThe issue?: We don’t know, until after the coins have been flipped, whether these are true or false!\nBut, we should still be able to say something about their likelihood, for example, whether \\(f_1\\) or \\(f_2\\) is more likely to happen… Enter probability theory!"
  },
  {
    "objectID": "w02/slides.html#logic-rightarrow-probability",
    "href": "w02/slides.html#logic-rightarrow-probability",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Logic \\(\\rightarrow\\) Probability",
    "text": "Logic \\(\\rightarrow\\) Probability\n\nProbability theory lets us reason about the uncertainty surrounding logical predicates like \\(p\\) and \\(q\\), by:\n\nencoding them as sets of possibilities \\(P\\) and \\(Q\\), and\nrepresenting the uncertainty around any given possibility using a probability measure \\(\\Pr: S \\mapsto [0,1]\\),\n\nthus allowing us to reason about\n\nthe likelihood of these set-encoded predicates on their own: \\(\\Pr(P)\\) and \\(\\Pr(Q)\\), but also\ntheir logical connections: \\(\\Pr(p \\wedge q) = \\Pr(P \\cap Q)\\), \\(\\Pr(\\neg p) = \\Pr(P^c)\\), and so on."
  },
  {
    "objectID": "w02/slides.html#flipping-two-coins-logic-rightarrow-probability",
    "href": "w02/slides.html#flipping-two-coins-logic-rightarrow-probability",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Flipping Two Coins: Logic \\(\\rightarrow\\) Probability",
    "text": "Flipping Two Coins: Logic \\(\\rightarrow\\) Probability\n\nReturning to the two coins example: we can look at the predicates and see that they exhaust all possibilities, so that we can define a sample space \\(S = \\{TT, TH, HT, HH\\}\\) of all possible outcomes of our coin-flipping experiment, noting that \\(|S| = 4\\), so there are 4 possible outcomes.\nThen we can associate each predicate with an event, a subset of the sample space, and use our naïve definition to compute the probability of these events:\n\n\n\n\n\n\n\n\n\nPredicate\nEvent\nProbability\n\n\n\n\n\\(p_1\\) = “First result is \\(H\\)”\n\\(P_1 = \\{HT, HH\\}\\)\n\\(\\Pr(P_1) = \\frac{|P_1|}{|S|} = \\frac{2}{4} = \\frac{1}{2}\\)\n\n\n\\(q_1\\) = “First result is \\(T\\)”\n\\(Q_1 = \\{TT, TH\\}\\)\n\\(\\Pr(Q_1) = \\frac{|Q_1|}{|S|} = \\frac{2}{4} = \\frac{1}{2}\\)\n\n\n\\(p_2\\) = “Second result is \\(H\\)”\n\\(P_2 = \\{TH, HH\\}\\)\n\\(\\Pr(P_2) = \\frac{|P_2|}{|S|} = \\frac{2}{4} = \\frac{1}{2}\\)\n\n\n\\(q_2\\) = “Second result is \\(T\\)”\n\\(Q_2 = \\{TT, HT\\}\\)\n\\(\\Pr(Q_2) = \\frac{|Q_2|}{|S|} = \\frac{2}{4} = \\frac{1}{2}\\)"
  },
  {
    "objectID": "w02/slides.html#moving-from-predicates-to-formulas",
    "href": "w02/slides.html#moving-from-predicates-to-formulas",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Moving from Predicates to Formulas",
    "text": "Moving from Predicates to Formulas\n\nNotice that, in the four rows of the previous table, we were only computing the probabilities of “simple” events: events corresponding to a single predicate\nBut we promised that probability theory lets us compute probabilities for logical formulas as well! …The magic of encoding events as sets becomes clear:\n\n\n\n\n\n\n\n\n\nFormula\nEvent\nProbability\n\n\n\n\n\\(f_1 = p_1 \\wedge q_2\\)\n\\[ \\begin{align*} F_1 &= P_1 \\cap Q_2 \\\\ &= \\{HT, HH\\} \\cap \\{TT, HT\\} \\\\ &= \\{HT\\} \\end{align*} \\]\n\\[\\begin{align*} \\Pr(F_1) &= \\Pr(\\{HT\\}) \\\\ &= \\frac{|\\{HT\\}|}{|S|} = \\frac{1}{4} \\end{align*}\\]\n\n\n\\(f_2 = p_1 \\vee q_2\\)\n\\[\\begin{align*} F_2 &= P_1 \\cup Q_2 \\\\ &= \\{HT, HH\\} \\cup \\{TT, HT\\} \\\\ &= \\{TT, HT, HH\\} \\end{align*}\\]\n\\[\\begin{align*} \\Pr(F_2) &= \\Pr(\\{TT, HT, HH\\}) \\\\ &= \\frac{|\\{TT, HT, HH\\}|}{|S|} = \\frac{3}{4} \\end{align*}\\]\n\n\n\\(f_3 = \\neg p_1\\)\n\\[\\begin{align*} F_3 &= P_1^c \\\\ &= \\{HT, HH\\}^c \\\\ &= \\{TT, TH\\}\\end{align*}\\]\n\\[\\begin{align*} \\Pr(F_3) &= \\Pr(\\{TT, TH\\}) \\\\ &= \\frac{|\\{TT, TH\\}|}{|S|} = \\frac{2}{4} = \\frac{1}{2} \\end{align*}\\]"
  },
  {
    "objectID": "w02/slides.html#using-rules-of-probability",
    "href": "w02/slides.html#using-rules-of-probability",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Using “Rules” of Probability",
    "text": "Using “Rules” of Probability\n\nHopefully, though, you found all this churning through set theory to be a bit tedious…\nThis is where rules of probability come from! They simplify set-theoretic computations into simple multiplications, additions, and subtractions:\n\n\\(\\Pr(A \\cap B) = \\Pr(A) \\times \\Pr(B)\\)\n\\(\\Pr(A \\cup B) = \\Pr(A) + \\Pr(B) - \\Pr(A \\cap B)\\)\n\\(\\Pr(A^c) = 1 - \\Pr(A)\\)\n\nSince we know probabilities of the “simple” events \\(P_1\\), \\(Q_1\\), \\(P_2\\), \\(Q_2\\), we don’t need to “look inside them”! Just take the probabilities and multiply/add/subtract as needed:\n\n\n\n\n\n\n\n\n\nFormula\nEvent\nProbability\n\n\n\n\n\\(f_1 = p_1 \\wedge q_2\\)\n\\(F_1 = P_1 \\cap Q_2\\)\n\\(\\Pr(F_1) = \\Pr(P_1) \\times \\Pr(Q_2) = \\frac{1}{2}\\times \\frac{1}{2} = \\frac{1}{4}\\)\n\n\n\\(f_2 = p_1 \\vee q_2\\)\n\\(F_2 = P_1 \\cup Q_2\\)\n\\[\\textstyle{\\begin{align*} \\textstyle \\Pr(F_2) &= \\Pr(P_1) + \\Pr(Q_2) - \\Pr(P_1 \\cap Q_2) \\\\ \\textstyle &= \\frac{1}{2} + \\frac{1}{2} - \\frac{1}{4} = \\frac{3}{4} \\end{align*}}\\]\n\n\n\\(f_3 = \\neg p_1\\)\n\\(F_3 = P_1^c\\)\n\\(\\Pr(F_3) = 1 - \\Pr(P_1) = 1 - \\frac{1}{2} = \\frac{1}{2}\\)"
  },
  {
    "objectID": "w02/slides.html#importing-results-from-logic",
    "href": "w02/slides.html#importing-results-from-logic",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "“Importing” Results from Logic",
    "text": "“Importing” Results from Logic\n\nThis deep connection between the three fields means that, if we have some useful theorem or formula from one field, we can immediately put it to use in another!\nFor example: DeMorgan’s Laws were developed in logic (DeMorgan was a 19th-century logician), and basically just tell us how to distribute logic operators:\n\n\\[\n\\begin{align*}\n\\underbrace{\\neg(p \\wedge q)}_{\\text{``}p\\text{ and }q\\text{'' is not true}} &\\iff \\underbrace{\\neg p \\vee \\neg q}_{p\\text{ is not true or }q\\text{ is not true}} \\\\\n\\underbrace{\\neg(p \\vee q)}_{\\text{``}p\\text{ or }q\\text{'' is not true}} &\\iff \\underbrace{\\neg p \\wedge \\neg q}_{p\\text{ is not true and }q\\text{ is not true}}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w02/slides.html#converting-to-probability-theory",
    "href": "w02/slides.html#converting-to-probability-theory",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Converting to Probability Theory",
    "text": "Converting to Probability Theory\n\nSo, using the same principles we used in our coin flipping examples, we can consider events \\(P\\) and \\(Q\\), and get the following “translation” of DeMorgan’s Laws:\n\n\n\n\n\n\n\n\n\nLogic\nSet Theory\nProbability Theory\n\n\n\n\n\\(\\neg(p \\wedge q) = \\neg p \\vee \\neg q\\)\n\\((P \\cap Q)^c = P^c \\cup Q^c\\)\n\\(\\Pr((P \\cap Q)^c) = \\Pr(P^c \\cup Q^c)\\)\n\n\n\\(\\neg(p \\vee q) = \\neg p \\wedge \\neg q\\)\n\\((P \\cup Q)^c = P^c \\cap Q^c\\)\n\\(\\Pr((P \\cup Q)^c) = \\Pr(P^c \\cap Q^c)\\)\n\n\n\n\nNote that, since these are isomorphic to one another, we could have derived DeMorgan’s Laws from within probability theory, rather than the other way around:\n\n\\[\n\\begin{align*}\n\\Pr((P \\cap Q)^c) &= 1 - \\Pr(P \\cap Q) = 1 - \\Pr(P)\\Pr(Q) \\\\\n&= 1 - (1-\\Pr(P^c))(1 - \\Pr(Q^c)) \\\\\n&= 1 - [1 - \\Pr(P^c) - \\Pr(Q^c) + \\Pr(P^c)\\Pr(Q^c)] \\\\\n&= \\Pr(P^c) + \\Pr(Q^c) - \\Pr(P^c)\\Pr(Q^c) \\\\\n&= \\Pr(P^c) + \\Pr(Q^c) - \\Pr(P^c \\cap Q^c) \\\\\n&= \\Pr(P^c \\cup Q^c) \\; ✅\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w02/slides.html#random-variables-1",
    "href": "w02/slides.html#random-variables-1",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Random Variables",
    "text": "Random Variables\n\nRecall our discussion of random variables: used by analogy to algebra, since we can do math with them:\nJust as \\(2 \\cdot 3\\) is shorthand for \\(2 + 2 + 2\\), we can define \\(X\\) as shorthand for the possible outcomes of a random process. \\[\n\\begin{align*}\nS = \\{ &\\text{result of dice roll is 1}, \\\\\n&\\text{result of dice roll is 2}, \\\\\n&\\text{result of dice roll is 3}, \\\\\n&\\text{result of dice roll is 4}, \\\\\n&\\text{result of dice roll is 5}, \\\\\n&\\text{result of dice roll is 6}\\} \\rightsquigarrow X \\in \\{1,\\ldots,6\\}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w02/slides.html#random-variables-as-events",
    "href": "w02/slides.html#random-variables-as-events",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Random Variables as Events",
    "text": "Random Variables as Events\n\nEach value \\(v_X\\) that a random variable \\(X\\) can take on gives rise to an event \\(X = v_X\\): the event that the random variable \\(X\\) takes on value \\(v\\).\nSince \\(X = v_X\\) is an event, we can compute its probability \\(\\Pr(X = v_X)\\)!\n\n\n\n\nEvent in words\nEvent in terms of RV\n\n\n\n\nResult of dice roll is 1\n\\(X = 1\\)\n\n\nResult of dice roll is 2\n\\(X = 2\\)\n\n\nResult of dice roll is 3\n\\(X = 3\\)\n\n\nResult of dice roll is 4\n\\(X = 4\\)\n\n\nResult of dice roll is 5\n\\(X = 5\\)\n\n\nResult of dice roll is 6\n\\(X = 6\\)"
  },
  {
    "objectID": "w02/slides.html#doing-math-with-events",
    "href": "w02/slides.html#doing-math-with-events",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Doing Math with Events",
    "text": "Doing Math with Events\n\nWe’ve seen how \\(\\Pr(\\cdot)\\) can “encode” logical expressions involving uncertain outcomes.\nEven more powerful when paired with the notion of random variables: lets us also “encode” mathematical expressions involving uncertain quantities!\nConsider an experiment where we roll two dice. Let \\(X\\) be the RV encoding the outcome of the first roll, and \\(Y\\) be the RV encoding the outcome of the second roll.\nWe can compute probabilities involving \\(X\\) and \\(Y\\) separately, e.g., \\(\\Pr(X = 1) = \\frac{1}{6}\\), but we can also reason probabilistically about mathematical expressions involving \\(X\\) and \\(Y\\)! For example, we can reason about their sum:\n\n\\[\n\\begin{align*}\n\\Pr(\\text{rolls sum to 10}) &= \\Pr(X + Y = 10) \\\\\n&= \\Pr(Y = 10 - X)\n\\end{align*}\n\\]\n\nOr about how the outcome of one roll will relate to the outcome of the other:\n\n\\[\n\\begin{align*}\n\\Pr(\\text{first roll above mean}) &= \\Pr\\left(X &gt; \\frac{X+Y}{2}\\right) \\\\\n&= \\Pr(2X &gt; X+Y) = \\Pr(X &gt; Y)\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w02/slides.html#are-random-variables-all-powerful",
    "href": "w02/slides.html#are-random-variables-all-powerful",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Are Random Variables All-Powerful??",
    "text": "Are Random Variables All-Powerful??\n\nJust remember that probability \\(P(\\cdot)\\) is always probability of an event—random variables are just shorthand for quantifiable events.\nNot all events can be simplified via random variables!\n\n\\(\\text{catch a fish} \\mapsto P(\\text{trout}), P(\\text{bass}), \\ldots\\)\n\nWhat types of events can be quantified like this?\n\n(Hint: It has to do with a key topic in the early weeks of both DSAN 5000 and 5100…)\n\n\n\nThe answer is, broadly, any situation where you’re modeling things, like dice rolls, where mathematical operations like addition, multiplication, etc. make sense. So, if we’re modeling dice, it makes sense to say e.g. “result is 6” + “result is 3” = “total is 9”. More on the next page!"
  },
  {
    "objectID": "w02/slides.html#recall-types-of-variables",
    "href": "w02/slides.html#recall-types-of-variables",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Recall: Types of Variables",
    "text": "Recall: Types of Variables\n\nCategorical\n\nNo meaningful way to order values: \\(\\{\\text{trout}, \\text{bass}, \\ldots \\}\\)\n\nOrdinal\n\nCan place in order (bigger, smaller), though gaps aren’t meaningful: \\(\\{{\\color{orange}\\text{great}},{\\color{orange}\\text{greater}},{\\color{orange}\\text{greatest}}\\}\\)\n\\({\\color{orange}\\text{greater}} \\overset{?}{=} 2\\cdot {\\color{orange}\\text{great}} - 1\\)\n\nCardinal\n\nCan place in order, and gaps are meaningful \\(\\implies\\) can do “standard” math with them! Example: \\(\\{{\\color{blue}1},{\\color{blue}2},\\ldots,{\\color{blue}10}\\}\\)\n\\({\\color{blue}7}\\overset{\\color{green}\\unicode{x2714}}{=} 2 \\cdot {\\color{blue}4} - 1\\)\nIf events have this structure (meaningful way to define multiplication, addition, subtraction), then we can analyze them as random variables"
  },
  {
    "objectID": "w02/slides.html#visualizing-discrete-rvs",
    "href": "w02/slides.html#visualizing-discrete-rvs",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Visualizing Discrete RVs",
    "text": "Visualizing Discrete RVs\n\nUltimate Probability Pro-Tip: When you hear “discrete distribution”, think of a bar graph: \\(x\\)-axis = events, bar height = probability of events\nTwo coins example: \\(X\\) = RV representing number of heads obtained in two coin flips"
  },
  {
    "objectID": "w02/slides.html#preview-visualizing-continuous-rvs",
    "href": "w02/slides.html#preview-visualizing-continuous-rvs",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "(Preview:) Visualizing Continuous RVs",
    "text": "(Preview:) Visualizing Continuous RVs\n\nThis works even for continuous distributions, if you focus on the area under the curve instead of the height:"
  },
  {
    "objectID": "w02/slides.html#probability-theory-gives-us-distributions-for-rvs-not-numbers",
    "href": "w02/slides.html#probability-theory-gives-us-distributions-for-rvs-not-numbers",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Probability Theory Gives Us Distributions for RVs, not Numbers!",
    "text": "Probability Theory Gives Us Distributions for RVs, not Numbers!\n\nWe’re going beyond “base” probability theory if we want to summarize these distributions\nHowever, we can understand a lot about the full distribution by looking at some basic summary statistics. Most common way to summarize:\n\n\n\n\n\n\n\n\n\n\\(\\underbrace{\\text{point estimate}}_{\\text{mean/median}}\\)\n\\(\\pm\\)\n\\(\\underbrace{\\text{uncertainty}}_{\\text{variance/standard deviation}}\\)"
  },
  {
    "objectID": "w02/slides.html#example-game-reviews",
    "href": "w02/slides.html#example-game-reviews",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Example: Game Reviews",
    "text": "Example: Game Reviews\n\n(Data from Metacritic)"
  },
  {
    "objectID": "w02/slides.html#adding-a-single-line",
    "href": "w02/slides.html#adding-a-single-line",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Adding a Single Line",
    "text": "Adding a Single Line\n\n(Data from Metacritic)"
  },
  {
    "objectID": "w02/slides.html#or-a-single-ribbon",
    "href": "w02/slides.html#or-a-single-ribbon",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Or a Single Ribbon",
    "text": "Or a Single Ribbon"
  },
  {
    "objectID": "w02/slides.html#example-the-normal-distribution",
    "href": "w02/slides.html#example-the-normal-distribution",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Example: The Normal Distribution",
    "text": "Example: The Normal Distribution\n\n\n\n(The distribution you saw a few slides ago)\n\n\n\n\n\n\n\n\n“RV \\(X\\) is normally distributed with mean \\({\\color{purple}\\mu}\\) and standard deviation \\({\\color{purple}\\sigma}\\)”\n\nTranslates to \\(X \\sim \\mathcal{N}(\\color{purple}{\\mu},\\color{purple}{\\sigma})\\)1\n\\(\\color{purple}{\\mu}\\) and \\(\\color{purple}{\\sigma}\\) are parameters2: the “knobs” or “sliders” which change the location/shape of the distribution\n\n\n\n\n\nThe parameters in this case give natural summaries of the data:\n\n\\({\\color{\\purple}\\mu}\\) = center (mean), \\({\\color{purple}\\sigma}\\) = [square root of] variance around center\n\nMean can usually be interpreted intuitively; for standard deviation, we usually use the 68-95-99.7 rule, which will make more sense relative to some real-world data…\n\nThroughout the course, this “calligraphic” font \\(\\mathcal{N}\\), \\(\\mathcal{D}\\), etc., will be used to denote distributionsThroughout the course, remember, purrple is for purrameters"
  },
  {
    "objectID": "w02/slides.html#real-data-and-the-68-95-99.7-rule",
    "href": "w02/slides.html#real-data-and-the-68-95-99.7-rule",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Real Data and the 68-95-99.7 Rule",
    "text": "Real Data and the 68-95-99.7 Rule\n\n\n\n\n\n\n\nFigure 2: Heights (cm) for 18K professional athletes\n\n\n\n\n\n\n\nFigure 3: The 68-95-99.7 Rule visualized (Wikimedia Commons)\n\n\n\n\nThe point estimate \\({\\color{purple}\\mu} = 186.48\\) is straightforward: the average height of the athletes is 186.48cm. Using the 68-95-99.7 Rule to interpret the SD, \\({\\color{purple}\\sigma} = 9.7\\), we get:\n\n\n\nAbout 68% of the heights fall between\n\n\n\n\n\n\n\n\n\n[\\({\\color{purple}\\mu} - 1\\cdot {\\color{purple}\\sigma}\\)\nand\n\\({\\color{purple}\\mu} + 1\\cdot {\\color{purple}\\sigma}\\)]\n\n\n[186.48 - 1 · 9.7\nand\n186.48 + 1 · 9.7]\n\n\n[176.78\nand\n196.18]\n\n\n\n\n\nAbout 95% of the heights fall between\n\n\n\n\n\n\n\n\n\n[\\({\\color{purple}\\mu} - 2 \\cdot {\\color{purple}\\sigma}\\)\nand\n\\({\\color{purple}\\mu} + 2 \\cdot {\\color{purple}\\sigma}\\)]\n\n\n[186.48 - 2 · 9.7\nand\n186.48 + 2 · 9.7]\n\n\n[167.08\nand\n205.88]"
  },
  {
    "objectID": "w02/slides.html#boxplots-comparing-multiple-distributions",
    "href": "w02/slides.html#boxplots-comparing-multiple-distributions",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Boxplots: Comparing Multiple Distributions",
    "text": "Boxplots: Comparing Multiple Distributions\n\n\n\n\n\n\nJhguch at en.wikipedia, CC BY-SA 2.5, via Wikimedia Commons\n\n\n\n\n\n\n\nProtonk, CC BY-SA 3.0, via Wikimedia Commons"
  },
  {
    "objectID": "w02/slides.html#another-option-joyplots",
    "href": "w02/slides.html#another-option-joyplots",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Another Option: Joyplots",
    "text": "Another Option: Joyplots\n\n\n\n\n\n\nFigure 4: (Iconic album cover)\n\n\n\n\n\n\nFigure 5: (Tooting my own horn)"
  },
  {
    "objectID": "w02/slides.html#multivariate-distributions-preview",
    "href": "w02/slides.html#multivariate-distributions-preview",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Multivariate Distributions: Preview",
    "text": "Multivariate Distributions: Preview\n\nThe bivariate normal distribution represents the distribution of two normally-distributed RVs \\(\\mathbf{X} = [\\begin{smallmatrix} X_1 & X_2\\end{smallmatrix}]\\), which may or may not be correlated:\n\n\n\\[\n\\mathbf{X} = \\begin{bmatrix}X_1 \\\\ X_2\\end{bmatrix}, \\; \\boldsymbol{\\mu} =\n%\\begin{bmatrix}\\mu_1 \\\\ \\mu_2\\end{bmatrix}\n\\begin{bmatrix}\\smash{\\overbrace{\\mu_1}^{\\mathbb{E}[X_1]}} \\\\ \\smash{\\underbrace{\\mu_2}_{\\mathbb{E}[X_2]}}\\end{bmatrix}\n, \\; \\mathbf{\\Sigma} = \\begin{bmatrix}\\smash{\\overbrace{\\sigma_1^2}^{\\text{Var}[X_1]}} & \\smash{\\overbrace{\\rho\\sigma_1\\sigma_2}^{\\text{Cov}[X_1,X_2]}} \\\\ \\smash{\\underbrace{\\rho\\sigma_2\\sigma_1}_{\\text{Cov}[X_2,X_1]}} & \\smash{\\underbrace{\\sigma_2^2}_{\\text{Var}[X_2]}}\\end{bmatrix}\n% \\begin{bmatrix}\\sigma_1^2 & \\rho\\sigma_1\\sigma_2 \\\\ \\rho\\sigma_2\\sigma_1 & \\sigma_2^2 \\end{bmatrix}\n% = \\begin{bmatrix}\\text{Var}[X_1] & \\text{Cov}[X_1,X_2] \\\\ \\text{Cov}[X_2,X_1] & \\text{Var}[X_2] \\end{bmatrix}\n\\]\n\n\nBy squishing all this information intro matrices, we can specify the parameters of multivariate-normally-distributed vectors of RVs similarly to how we specify single-dimensional normally-distributed RVs:\n\n\n\\[\n\\begin{align*}\n\\overbrace{X}^{\\mathclap{\\text{scalar}}} &\\sim \\mathcal{N}\\phantom{_k}(\\overbrace{\\mu}^{\\text{scalar}}, \\overbrace{\\sigma}^{\\text{scalar}}) \\tag{Univariate} \\\\\n\\underbrace{\\mathbf{X}}_{\\text{vector}} &\\sim \\boldsymbol{\\mathcal{N}}_k(\\smash{\\underbrace{\\boldsymbol{\\mu}}_{\\text{vector}}}, \\underbrace{\\mathbf{\\Sigma}}_{\\text{matrix}}) \\tag{Multivariate}\n\\end{align*}\n\\]\n\n\nNote: In the future I’ll use the notation \\(\\mathbf{X}_{[a \\times b]}\\) to denote the dimensions of the vectors/matrices, like \\(\\mathbf{X}_{[k \\times 1]} \\sim \\boldsymbol{\\mathcal{N}}_k(\\boldsymbol{\\mu}_{[k \\times 1]}, \\mathbf{\\Sigma}_{[k \\times k]})\\)"
  },
  {
    "objectID": "w02/slides.html#visualizing-3d-distributions-projection",
    "href": "w02/slides.html#visualizing-3d-distributions-projection",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Visualizing 3D Distributions: Projection",
    "text": "Visualizing 3D Distributions: Projection\n\nSince most of our intuitions about plots come from 2D plots, it is extremely useful to be able to take a 3D plot like this and imagine “projecting” it down into different 2D plots:\n\n\n(Adapted via LaTeX from StackExchange discussion)"
  },
  {
    "objectID": "w02/slides.html#visualizing-3d-distributions-contours",
    "href": "w02/slides.html#visualizing-3d-distributions-contours",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Visualizing 3D Distributions: Contours",
    "text": "Visualizing 3D Distributions: Contours\n\nFrom Prof. Hickman’s slides!"
  },
  {
    "objectID": "w02/slides.html#visualizing-3d-distributions-contours-1",
    "href": "w02/slides.html#visualizing-3d-distributions-contours-1",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Visualizing 3D Distributions: Contours",
    "text": "Visualizing 3D Distributions: Contours\n\n\n\n\n\nAlso from Prof. Hickman’s slides!"
  },
  {
    "objectID": "w02/index.html",
    "href": "w02/index.html",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "",
    "text": "Open slides in new window →"
  },
  {
    "objectID": "w02/index.html#prof.-jeff-introduction",
    "href": "w02/index.html#prof.-jeff-introduction",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Prof. Jeff Introduction!",
    "text": "Prof. Jeff Introduction!\n\nBorn and raised in NW DC → high school in Rockville, MD\nUniversity of Maryland: Computer Science, Math, Economics (2008-2012)"
  },
  {
    "objectID": "w02/index.html#grad-school",
    "href": "w02/index.html#grad-school",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Grad School",
    "text": "Grad School\n\nStudied abroad in Beijing (Peking University/北大) → internship with Huawei in Hong Kong (HKUST)\n\n\n\n\nStanford for MS in Computer Science (2012-2014)\nResearch Economist at UC Berkeley (2014-2015)\n\n\n\n\n\n\nColumbia (NYC) for PhD[+Postdoc] in Political Science (2015-2023)"
  },
  {
    "objectID": "w02/index.html#dissertation-political-science-history",
    "href": "w02/index.html#dissertation-political-science-history",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Dissertation (Political Science + History)",
    "text": "Dissertation (Political Science + History)\n“Our Word is Our Weapon”: Text-Analyzing Wars of Ideas from the French Revolution to the First Intifada"
  },
  {
    "objectID": "w02/index.html#research-labor-economics",
    "href": "w02/index.html#research-labor-economics",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Research (Labor Economics)",
    "text": "Research (Labor Economics)\n\n\n\n“Monopsony in Online Labor Markets”: Machine Learning to enhance causal estimates of the effect of job description language on uptake rate\n\n\n\n“Freedom as Non-Domination in the Labor Market”: Game-theoretic models of workers’ rights (monopsony vs. labor discipline)\n\n\n\n\n\n“Unsupervised Extraction of Workplace Rights and Duties from Collective Bargaining Agreements”: Linguistic (dependency) parses of contracts → time series of worker vs. employer rights and responsibilities over time"
  },
  {
    "objectID": "w02/index.html#deterministic-processes",
    "href": "w02/index.html#deterministic-processes",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Deterministic Processes",
    "text": "Deterministic Processes\n\nGiven a set of inputs, we can compute the outcome exactly\nExample: Given the radius of a circle, we can compute its area without any uncertainty. \\(r \\mapsto \\pi r^2\\)\n(The fact that we can compute the outcome doesn’t mean that it’s easy to do so! See, e.g., the double pendulum)\n\n\n\n\nImage credit: Tenor.com\n\n\n\nThe pendulum example points to the fact that the notion of a chaotic system, one which is “sensitive to initial conditions”, is different from that of a stochastic system."
  },
  {
    "objectID": "w02/index.html#holy-grail-deterministic-model-newtonian-physics",
    "href": "w02/index.html#holy-grail-deterministic-model-newtonian-physics",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "“Holy Grail” Deterministic Model: Newtonian Physics",
    "text": "“Holy Grail” Deterministic Model: Newtonian Physics\n\n\n\n\n\n\n\n\n\n\ngrid\n\n \n\ncluster_01\n\n “Nature”  \n\ncluster_02\n\n “Science”   \n\nObs\n\n Thing(s) we can see   \n\nUnd\n\n Underlying processes   \n\nUnd-&gt;Obs\n\n    \n\nModel\n\n Model   \n\nUnd-&gt;Model\n\n    \n\nModel-&gt;Obs\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\ngrid\n\n \n\ncluster_03\n\n Isaac Newton  \n\ncluster_04\n\n  Woolsthorpe Manor     \n\nTree\n\n  Falling Apple     \n\nPhysics\n\n  Particle Interactions     \n\nPhysics-&gt;Tree\n\n    \n\nNewton\n\n Newton’s Laws   \n\nPhysics-&gt;Newton\n\n    \n\nNewton-&gt;Tree\n\n   \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\[\n\\leadsto F_g = G\\frac{m_1m_2}{r^2}\n\\]\nFigure 1: Newton’s Law of Universal Gravitation← Dr. Zirkel follows Newton’s famous steps. Coloured wood engraving. Wellcome Collection (Public Domain)"
  },
  {
    "objectID": "w02/index.html#but-what-happens-when",
    "href": "w02/index.html#but-what-happens-when",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "But What Happens When…",
    "text": "But What Happens When…\n\\[\n\\text{Outcome}\\left(\\text{Dice Roll}\\right) = \\; ?\\frac{?_1?_2}{?^2}\n\\]\n\n\n\nPre-Enlightenment\n\n\n\n\nHans Sebald Beham, Fortuna (1541), CC BY 4.0, via Wikimedia Commons\n\n\n\n\nPost-Enlightenment\n\n\n\n\nBlaise Pascal, Traité du triangle arithmétique (1665). Public Domain, via Internet Archive"
  },
  {
    "objectID": "w02/index.html#random-processes",
    "href": "w02/index.html#random-processes",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Random Processes",
    "text": "Random Processes\n\n\n\nCan’t compute the outcome exactly, but can still say something about potential outcomes!\nExample: randomly chosen radius \\(r \\in [0,1]\\), what can we say about \\(A = \\pi r^2\\)?\n\nUnif: \\([0,\\pi]\\) equally likely\nExp: closer to \\(0\\) more likely\n\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(ggplot2)\nN &lt;- 1000\nradii &lt;- rexp(N, 4)\ntitle &lt;- paste0(N, \" Exponentially-Distributed Radii\")\nplot_circ_with_distr(N, radii, title, alpha=0.15)\n\nWarning: Removed 1456 rows containing missing values (`geom_path()`)."
  },
  {
    "objectID": "w02/index.html#data-ground-truth-noise",
    "href": "w02/index.html#data-ground-truth-noise",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Data = Ground Truth + Noise",
    "text": "Data = Ground Truth + Noise\n\nDepressing but true origin of statistics (as opposed to probability): the Plague 😷\n\n\n\n\n\n\n\nGround Truth: The Great Plague (Lord Have Mercy on London, Unknown Artist, circa 1665, via Wikimedia Commons)\n\n\n\n\n\n\n\nNoisy Data (Recorded amidst chaos): London Bill of Mortality, 1665 (Public Domain, Wellcome Collection)"
  },
  {
    "objectID": "w02/index.html#random-variables",
    "href": "w02/index.html#random-variables",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Random Variables",
    "text": "Random Variables\n\nIn algebra, to solve problems we work with variables\nIn probability theory, to solve problems we work with random variables\nRecall the difference between random and deterministic: \\(A = \\pi r^2\\) tells us that, given a value of \\(r\\), we can solve for the unique value of \\(A\\)\nIn probability theory, however, there is no one “true” value of a random variable \\(X\\).\nLet \\(X = f(N)\\) mean that \\(X\\) is the result of a rolled die, where the die has \\(N\\) sides.\nPlugging in \\(N = 6\\) (standard 6-sided die) still doesn’t mean we know “the” value of \\(X\\). However, (if the die is fair) we do know\n\n\\[\n\\Pr(X = 1) = \\Pr(X = 2) = \\cdots = \\Pr(X = 6) = \\frac{1}{6}\n\\]"
  },
  {
    "objectID": "w02/index.html#discrete-vs.-continuous",
    "href": "w02/index.html#discrete-vs.-continuous",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Discrete vs. Continuous",
    "text": "Discrete vs. Continuous\n\nMany complicated definitions, often misleading or unintuitive!\nHow I want you to remember: How many possible values between two known values?\nDiscrete: e.g., number of siblings\n\nI have 2 siblings, you have 3 siblings… How many values (sibling counts) in between?\n\nContinuous: e.g., temperature\n\nIt is 27.0° C in my room, 28.0° C in your room… How many values (temperatures) in between?\n\nSo, if \\(X\\) is the result of a rolled die, is \\(X\\) discrete or continuous? How many values can be rolled between 3 and 4?"
  },
  {
    "objectID": "w02/index.html#thinking-about-independence",
    "href": "w02/index.html#thinking-about-independence",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Thinking About Independence",
    "text": "Thinking About Independence\n\nWe’ll define it formally later; for now, this is our working definition:\n\n\n\n\n\n\n\nWorking Definition: Independence\n\n\n\nTwo random variables \\(X\\) and \\(Y\\) are independent if learning information about \\(X\\) does not give you information about the value of \\(Y\\), or vice-versa."
  },
  {
    "objectID": "w02/index.html#naïve-definition-of-probability",
    "href": "w02/index.html#naïve-definition-of-probability",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Naïve Definition of Probability",
    "text": "Naïve Definition of Probability\n\nSample Space: The set of all possible outcomes of an experiment\nEvent: A subset of the sample space\n\n\n\n\n\n\n\nNaïve Definition of Probability\n\n\n\nGiven a sample space \\(S\\), and an event \\(E \\subset S\\),\n\\[\n\\Pr(\\underbrace{E}_{\\text{event}}) = \\frac{\\text{\\# Favorable Outcomes}}{\\text{\\# Possible Outcomes}} = \\frac{|E|}{|S|}\n\\]"
  },
  {
    "objectID": "w02/index.html#example-flipping-two-coins",
    "href": "w02/index.html#example-flipping-two-coins",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Example: Flipping Two Coins",
    "text": "Example: Flipping Two Coins\n\n\n\n\n\n\nNaïve Definition of Probability\n\n\n\nGiven a sample space \\(S\\), and an event \\(E \\subset S\\),\n\\[\n\\Pr(\\underbrace{E}_{\\text{event}}) = \\frac{\\text{\\# Favorable Outcomes}}{\\text{\\# Possible Outcomes}} = \\frac{|E|}{|S|}\n\\]\n\n\n\nFlipping two coins:\n\nSample space \\(S = \\{TT, TH, HT, HH\\}\\)\nEvent \\(E_1\\): Result of first flip is \\(H\\), result of second flip is \\(T\\) \\(\\implies\\) \\(E_1 = \\{HT\\}\\).\nEvent \\(E_2\\): At least one \\(H\\) \\(\\implies\\) \\(E_2 = \\{TH, HT, HH\\}\\).\n\n\n\\[\n\\begin{align*}\n\\Pr(E_1) &= \\frac{|\\{HT\\}|}{|S|} = \\frac{|\\{HT\\}|}{|\\{TT, TH, HT, HH\\}|} = \\frac{1}{4} \\\\\n\\Pr(E_2) &= \\frac{|\\{TH, HT, HH\\}|}{|S|} = \\frac{|\\{TH, HT, HH\\}|}{|\\{TT, TH, HT, HH\\}|} = \\frac{3}{4}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w02/index.html#events-neq-outcomes",
    "href": "w02/index.html#events-neq-outcomes",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Events \\(\\neq\\) Outcomes!",
    "text": "Events \\(\\neq\\) Outcomes!\n\nOutcomes are things, events are sets of things\nSubtle but extremely important distinction!\nIn the coin flip example:\n\nThe event \\(E_1 = \\{HT\\}\\) can be confused with the outcome \\(HT\\).\nSo, try to remember instead the event \\(E_2 = \\{TH, HT, HH\\}\\): it is more clear, in this case, how this event does not correspond to any individual outcome"
  },
  {
    "objectID": "w02/index.html#back-to-the-naïve-definition",
    "href": "w02/index.html#back-to-the-naïve-definition",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Back to the Naïve Definition",
    "text": "Back to the Naïve Definition\n\n\n\n\n\n\nNaïve Definition of Probability\n\n\n\nGiven a sample space \\(S\\), and an event \\(E \\subset S\\),\n\\[\n\\Pr(\\underbrace{E}_{\\text{event}}) = \\frac{\\text{\\# Favorable Outcomes}}{\\text{\\# Possible Outcomes}} = \\frac{|E|}{|S|}\n\\]\n\n\n\nThe naïve definition tells us that probabilities are just ratios of counts:\n\nCount the number of ways the event \\(E\\) can happen, count the total number of things that can happen, and divide!\n\nThis is why we begin studying probability by studying combinatorics: the mathematics of counting"
  },
  {
    "objectID": "w02/index.html#combinatorics-ice-cream-possibilities",
    "href": "w02/index.html#combinatorics-ice-cream-possibilities",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Combinatorics: Ice Cream Possibilities",
    "text": "Combinatorics: Ice Cream Possibilities\n\n\n\n\n\n\n\nThe \\(6 = 2 \\cdot 3\\) possible cone+flavor combinations which can result from choosing a flavor first and a cone type second.\n\n\n\n\n\n\n\nThe \\(6 = 3 \\cdot 2\\) possible cone+flavor combinations which can result from choosing a flavor first and a cone type second."
  },
  {
    "objectID": "w02/index.html#grouping-vs.-ordering",
    "href": "w02/index.html#grouping-vs.-ordering",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Grouping vs. Ordering",
    "text": "Grouping vs. Ordering\n\nIn standard statistics/combinatorics introductions you’ll learn different counting formulas for when order matters vs. when order doesn’t matter\nThis is not a mathematical distinction so much as a pragmatic distinction: what are you trying to accomplish by counting?\nProblems with extremely similar descriptions can differ in small detail, so that the units you need to distinguish between in one version differ from the units you need to distinguish between in the other."
  },
  {
    "objectID": "w02/index.html#does-order-matter",
    "href": "w02/index.html#does-order-matter",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Does Order Matter?",
    "text": "Does Order Matter?\n\n\n\n\n\n\nExample: Student Government vs. Student Sports\n\n\n\n\nConsider a school where students can either try out for the swim team or run for a position in the student government\nThe swim team has 4 slots, but slots aren’t differentiated: you’re either on the team (one of the 4 chosen students) or not\nThe student government also has 4 slots, but there is a difference between the slots: first slot is President, second is Vice President, third is Secretary, and fourth is Treasurer.\n\n\n\n\nSimple case (for intuition): the school only has 4 students. In this case, how many ways are there to form the swim team? What about the student government?\n\nSwim team: \\(1\\) way. You have only one choice, to let all 4 students onto the team\nStudent government: \\(4 \\cdot 3 \\cdot 2 \\cdot 1 = 24\\) ways. You have to let all 4 students in, but you have a choice of who is President, Vice President, Secretary, and Treasurer\n\nHow did we get \\(4 \\cdot 3 \\cdot 2 \\cdot 1\\)? (Think about the ice cream example…)\n\nStart by choosing the President: 4 choices\nNow choose the Vice President: only 3 students left to choose from\nNow choose the Secretary: only 2 students left to choose from\nNow choose the Treasurer: only 1 student left to choose from"
  },
  {
    "objectID": "w02/index.html#permutations-vs.-combinations",
    "href": "w02/index.html#permutations-vs.-combinations",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Permutations vs. Combinations",
    "text": "Permutations vs. Combinations\n\nPermutations: How many ways can I choose groups of size \\(k\\) out of \\(n\\) total objects, where order within groups matters: \\(P_{n,k}\\) (sometimes written \\(_nP_k\\)).\n\nIn this case, we want to count \\((a,b)\\) and \\((b,a)\\) as two separate groups\n\nCombinations: How many ways can I choose groups of size \\(k\\) out of \\(n\\) total objects, where order in the groups doesn’t matter: \\(C_{n,k}\\) (sometimes written \\(_nC_k,\\binom{n}{k}\\)).\n\nIn this case, we don’t want to count \\((a, b)\\) and \\((b, a)\\) as two separate groups…\n\n\n\\[\n\\begin{align*}\nP_{n,k} = \\frac{n!}{(n-k)!}, \\; C_{n,k} = \\frac{n!}{k!(n-k)!}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w02/index.html#no-need-to-memorize",
    "href": "w02/index.html#no-need-to-memorize",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "No Need to Memorize!",
    "text": "No Need to Memorize!\n\n\nKey point: you don’t have to remember these as two separate formulas!\nThe number of combinations is based on the number of permutations, but corrected for double counting: e.g., corrected for the fact that \\((a,b) \\neq (b,a)\\) when counting permutations but \\((a,b) = (b,a)\\) when counting combinations.\n\n\\[\nC_{n,k} = \\frac{P_{n,k}}{k!} \\genfrac{}{}{0pt}{}{\\leftarrow \\text{Permutations}}{\\leftarrow \\text{Duplicate groups}}\n\\]\nWhere does \\(k!\\) come from? (How many different orderings can we make of the same group?)\n\n\\(k = 2\\): \\((\\underbrace{\\boxed{\\phantom{a}}}_{\\text{2 choices}},\\underbrace{\\boxed{\\phantom{a}}}_{\\text{1 remaining choice}}) \\implies 2\\)\n\\(k = 3\\): \\((\\underbrace{\\boxed{\\phantom{a}}}_{\\text{3 choices}},\\underbrace{\\boxed{\\phantom{a}}}_{\\text{2 remaining choices}}, \\underbrace{\\boxed{\\phantom{a}}}_{\\text{1 remaining choice}}) \\implies 6\\)\n\\(k = 4\\): \\((\\underbrace{\\boxed{\\phantom{a}}}_{\\text{4 choices}}, \\underbrace{\\boxed{\\phantom{a}}}_{\\text{3 remaining choices}}, \\underbrace{\\boxed{\\phantom{a}}}_{\\text{2 remaining choices}}, \\underbrace{\\boxed{\\phantom{a}}}_{\\text{1 remaining choice}}) \\implies 24\\)"
  },
  {
    "objectID": "w02/index.html#with-or-without-replacement",
    "href": "w02/index.html#with-or-without-replacement",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "With or Without Replacement?",
    "text": "With or Without Replacement?\n\nBoils down to: can the same object be included in my sample more than once?\n\n\n\n\nWithout Replacement\nWith Replacement\n\n\n\n\nMost statistical problems: “Check off” objects as you collect data about them, so that each observation in your data is unique\nVery special (but very important!) set of statistical problems: allow objects to appear in your sample multiple times, to “squeeze” more information out of the sample (called Bootstrapping—much more on this later in the course!)"
  },
  {
    "objectID": "w02/index.html#how-many-possible-samples",
    "href": "w02/index.html#how-many-possible-samples",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "How Many Possible Samples?",
    "text": "How Many Possible Samples?\n\n\n\n\n\n\nExample: How Many Possible Samples?\n\n\n\nFrom a population of \\(N = 3\\), how many ways can we take samples of size \\(k = 2\\)?\n\n\n\n\n\n\n\nWithout Replacement\nWith Replacement\n\n\n\n\n\\(3 \\cdot 2 = 6\\) ways (3 objects to choose from for first element of sample, 2 remaining objects to choose from for second element of sample)\n\\(3\\cdot 3 = 3^2 = 9\\) ways (3 objects to choose from for first element of sample, still 3 objects to choose from for second element of sample)\n\n\n\n\n\n\n\n\n\n\n\nResult: How Many Possible Samples\n\n\n\nFrom a population of size \\(N\\), how many ways can we take samples of size \\(k\\)? (Try to extrapolate from above examples before looking at answer!)\n\n\n\n\n\n\n\nWithout Replacement\nWith Replacement\n\n\n\n\n\\(\\displaystyle \\underbrace{N \\cdot (N-1) \\cdot \\cdots \\cdot (N - k + 1)}_{k\\text{ times}} = \\frac{N!}{(N - k )!}\\)(This formula should look somewhat familiar…)\n\\(\\displaystyle \\underbrace{N \\cdot N \\cdot \\cdots \\cdot N}_{k\\text{ times}} = N^k\\)"
  },
  {
    "objectID": "w02/index.html#logic-sets-and-probability",
    "href": "w02/index.html#logic-sets-and-probability",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Logic, Sets, and Probability",
    "text": "Logic, Sets, and Probability\n\nThere is a deep connection1 between the objects and operations of logic, set theory, and probability:\n\n\n\n\n\n\n\n\n\n\n\nLogic\nSet Theory\nProbability Theory\n\n\n\n\nObjects\nPredicates\\(p, q \\in \\{T, F\\}\\)\nSets\\(S = \\{a, b, \\ldots\\}\\)\nEvents\\(E = \\{TH, HT, HH\\}\\)\n\n\nConjunction\nAnd (\\(\\wedge\\))\\(p \\wedge q\\)\nIntersection (\\(\\cap\\))\\(A \\cap B\\)\nMultiplication (\\(\\times\\)):\\(\\Pr(E_1 \\cap E_2) = \\Pr(E_1)\\times \\Pr(E_2)\\)\n\n\nDisjunction\nOr (\\(\\vee\\))\\(p \\vee q\\)\nUnion (\\(\\cup\\))\\(A \\cup B\\)\nAddition (\\(+\\)): \\(\\Pr(E_1 \\cup E_2) =\\)\\(\\Pr(E_1) + \\Pr(E_2) - \\Pr(E_1 \\wedge E_2)\\)\n\n\nNegation\nNot (\\(\\neg\\))\\(\\neg p\\)\nComplement (\\(^c\\))\\(S^c\\)\nSubtract from 1\\(\\Pr(A^c) = 1 - \\Pr(A)\\)"
  },
  {
    "objectID": "w02/index.html#example-flipping-two-coins-1",
    "href": "w02/index.html#example-flipping-two-coins-1",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Example: Flipping Two Coins",
    "text": "Example: Flipping Two Coins\n\nLogic: We can define 4 predicates:\n\n\\(p_1\\) = “First result is \\(H\\)”, \\(q_1\\) = “First result is \\(T\\)”\n\\(p_2\\) = “Second result is \\(H\\)”, \\(q_2\\) = “Second result is \\(T\\)”\n\nLogical formulas:\n\n\\(f_1 = p_1 \\wedge q_2\\): “First result is \\(H\\) and second result is \\(T\\)”\n\\(f_2 = p_1 \\vee q_2\\): “First result is \\(H\\) or second result is \\(T\\)”\n\\(f_3 = \\neg p_1\\): “First result is not \\(H\\)”\n\nThe issue?: We don’t know, until after the coins have been flipped, whether these are true or false!\nBut, we should still be able to say something about their likelihood, for example, whether \\(f_1\\) or \\(f_2\\) is more likely to happen… Enter probability theory!"
  },
  {
    "objectID": "w02/index.html#logic-rightarrow-probability",
    "href": "w02/index.html#logic-rightarrow-probability",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Logic \\(\\rightarrow\\) Probability",
    "text": "Logic \\(\\rightarrow\\) Probability\n\nProbability theory lets us reason about the uncertainty surrounding logical predicates like \\(p\\) and \\(q\\), by:\n\nencoding them as sets of possibilities \\(P\\) and \\(Q\\), and\nrepresenting the uncertainty around any given possibility using a probability measure \\(\\Pr: S \\mapsto [0,1]\\),\n\nthus allowing us to reason about\n\nthe likelihood of these set-encoded predicates on their own: \\(\\Pr(P)\\) and \\(\\Pr(Q)\\), but also\ntheir logical connections: \\(\\Pr(p \\wedge q) = \\Pr(P \\cap Q)\\), \\(\\Pr(\\neg p) = \\Pr(P^c)\\), and so on."
  },
  {
    "objectID": "w02/index.html#flipping-two-coins-logic-rightarrow-probability",
    "href": "w02/index.html#flipping-two-coins-logic-rightarrow-probability",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Flipping Two Coins: Logic \\(\\rightarrow\\) Probability",
    "text": "Flipping Two Coins: Logic \\(\\rightarrow\\) Probability\n\nReturning to the two coins example: we can look at the predicates and see that they exhaust all possibilities, so that we can define a sample space \\(S = \\{TT, TH, HT, HH\\}\\) of all possible outcomes of our coin-flipping experiment, noting that \\(|S| = 4\\), so there are 4 possible outcomes.\nThen we can associate each predicate with an event, a subset of the sample space, and use our naïve definition to compute the probability of these events:\n\n\n\n\n\n\n\n\n\nPredicate\nEvent\nProbability\n\n\n\n\n\\(p_1\\) = “First result is \\(H\\)”\n\\(P_1 = \\{HT, HH\\}\\)\n\\(\\Pr(P_1) = \\frac{|P_1|}{|S|} = \\frac{2}{4} = \\frac{1}{2}\\)\n\n\n\\(q_1\\) = “First result is \\(T\\)”\n\\(Q_1 = \\{TT, TH\\}\\)\n\\(\\Pr(Q_1) = \\frac{|Q_1|}{|S|} = \\frac{2}{4} = \\frac{1}{2}\\)\n\n\n\\(p_2\\) = “Second result is \\(H\\)”\n\\(P_2 = \\{TH, HH\\}\\)\n\\(\\Pr(P_2) = \\frac{|P_2|}{|S|} = \\frac{2}{4} = \\frac{1}{2}\\)\n\n\n\\(q_2\\) = “Second result is \\(T\\)”\n\\(Q_2 = \\{TT, HT\\}\\)\n\\(\\Pr(Q_2) = \\frac{|Q_2|}{|S|} = \\frac{2}{4} = \\frac{1}{2}\\)"
  },
  {
    "objectID": "w02/index.html#moving-from-predicates-to-formulas",
    "href": "w02/index.html#moving-from-predicates-to-formulas",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Moving from Predicates to Formulas",
    "text": "Moving from Predicates to Formulas\n\nNotice that, in the four rows of the previous table, we were only computing the probabilities of “simple” events: events corresponding to a single predicate\nBut we promised that probability theory lets us compute probabilities for logical formulas as well! …The magic of encoding events as sets becomes clear:\n\n\n\n\n\n\n\n\n\nFormula\nEvent\nProbability\n\n\n\n\n\\(f_1 = p_1 \\wedge q_2\\)\n\\[ \\begin{align*} F_1 &= P_1 \\cap Q_2 \\\\ &= \\{HT, HH\\} \\cap \\{TT, HT\\} \\\\ &= \\{HT\\} \\end{align*} \\]\n\\[\\begin{align*} \\Pr(F_1) &= \\Pr(\\{HT\\}) \\\\ &= \\frac{|\\{HT\\}|}{|S|} = \\frac{1}{4} \\end{align*}\\]\n\n\n\\(f_2 = p_1 \\vee q_2\\)\n\\[\\begin{align*} F_2 &= P_1 \\cup Q_2 \\\\ &= \\{HT, HH\\} \\cup \\{TT, HT\\} \\\\ &= \\{TT, HT, HH\\} \\end{align*}\\]\n\\[\\begin{align*} \\Pr(F_2) &= \\Pr(\\{TT, HT, HH\\}) \\\\ &= \\frac{|\\{TT, HT, HH\\}|}{|S|} = \\frac{3}{4} \\end{align*}\\]\n\n\n\\(f_3 = \\neg p_1\\)\n\\[\\begin{align*} F_3 &= P_1^c \\\\ &= \\{HT, HH\\}^c \\\\ &= \\{TT, TH\\}\\end{align*}\\]\n\\[\\begin{align*} \\Pr(F_3) &= \\Pr(\\{TT, TH\\}) \\\\ &= \\frac{|\\{TT, TH\\}|}{|S|} = \\frac{2}{4} = \\frac{1}{2} \\end{align*}\\]"
  },
  {
    "objectID": "w02/index.html#using-rules-of-probability",
    "href": "w02/index.html#using-rules-of-probability",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Using “Rules” of Probability",
    "text": "Using “Rules” of Probability\n\nHopefully, though, you found all this churning through set theory to be a bit tedious…\nThis is where rules of probability come from! They simplify set-theoretic computations into simple multiplications, additions, and subtractions:\n\n\\(\\Pr(A \\cap B) = \\Pr(A) \\times \\Pr(B)\\)\n\\(\\Pr(A \\cup B) = \\Pr(A) + \\Pr(B) - \\Pr(A \\cap B)\\)\n\\(\\Pr(A^c) = 1 - \\Pr(A)\\)\n\nSince we know probabilities of the “simple” events \\(P_1\\), \\(Q_1\\), \\(P_2\\), \\(Q_2\\), we don’t need to “look inside them”! Just take the probabilities and multiply/add/subtract as needed:\n\n\n\n\n\n\n\n\n\nFormula\nEvent\nProbability\n\n\n\n\n\\(f_1 = p_1 \\wedge q_2\\)\n\\(F_1 = P_1 \\cap Q_2\\)\n\\(\\Pr(F_1) = \\Pr(P_1) \\times \\Pr(Q_2) = \\frac{1}{2}\\times \\frac{1}{2} = \\frac{1}{4}\\)\n\n\n\\(f_2 = p_1 \\vee q_2\\)\n\\(F_2 = P_1 \\cup Q_2\\)\n\\[\\textstyle{\\begin{align*} \\textstyle \\Pr(F_2) &= \\Pr(P_1) + \\Pr(Q_2) - \\Pr(P_1 \\cap Q_2) \\\\ \\textstyle &= \\frac{1}{2} + \\frac{1}{2} - \\frac{1}{4} = \\frac{3}{4} \\end{align*}}\\]\n\n\n\\(f_3 = \\neg p_1\\)\n\\(F_3 = P_1^c\\)\n\\(\\Pr(F_3) = 1 - \\Pr(P_1) = 1 - \\frac{1}{2} = \\frac{1}{2}\\)"
  },
  {
    "objectID": "w02/index.html#importing-results-from-logic",
    "href": "w02/index.html#importing-results-from-logic",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "“Importing” Results from Logic",
    "text": "“Importing” Results from Logic\n\nThis deep connection between the three fields means that, if we have some useful theorem or formula from one field, we can immediately put it to use in another!\nFor example: DeMorgan’s Laws were developed in logic (DeMorgan was a 19th-century logician), and basically just tell us how to distribute logic operators:\n\n\\[\n\\begin{align*}\n\\underbrace{\\neg(p \\wedge q)}_{\\text{``}p\\text{ and }q\\text{'' is not true}} &\\iff \\underbrace{\\neg p \\vee \\neg q}_{p\\text{ is not true or }q\\text{ is not true}} \\\\\n\\underbrace{\\neg(p \\vee q)}_{\\text{``}p\\text{ or }q\\text{'' is not true}} &\\iff \\underbrace{\\neg p \\wedge \\neg q}_{p\\text{ is not true and }q\\text{ is not true}}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w02/index.html#converting-to-probability-theory",
    "href": "w02/index.html#converting-to-probability-theory",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Converting to Probability Theory",
    "text": "Converting to Probability Theory\n\nSo, using the same principles we used in our coin flipping examples, we can consider events \\(P\\) and \\(Q\\), and get the following “translation” of DeMorgan’s Laws:\n\n\n\n\n\n\n\n\n\nLogic\nSet Theory\nProbability Theory\n\n\n\n\n\\(\\neg(p \\wedge q) = \\neg p \\vee \\neg q\\)\n\\((P \\cap Q)^c = P^c \\cup Q^c\\)\n\\(\\Pr((P \\cap Q)^c) = \\Pr(P^c \\cup Q^c)\\)\n\n\n\\(\\neg(p \\vee q) = \\neg p \\wedge \\neg q\\)\n\\((P \\cup Q)^c = P^c \\cap Q^c\\)\n\\(\\Pr((P \\cup Q)^c) = \\Pr(P^c \\cap Q^c)\\)\n\n\n\n\nNote that, since these are isomorphic to one another, we could have derived DeMorgan’s Laws from within probability theory, rather than the other way around:\n\n\\[\n\\begin{align*}\n\\Pr((P \\cap Q)^c) &= 1 - \\Pr(P \\cap Q) = 1 - \\Pr(P)\\Pr(Q) \\\\\n&= 1 - (1-\\Pr(P^c))(1 - \\Pr(Q^c)) \\\\\n&= 1 - [1 - \\Pr(P^c) - \\Pr(Q^c) + \\Pr(P^c)\\Pr(Q^c)] \\\\\n&= \\Pr(P^c) + \\Pr(Q^c) - \\Pr(P^c)\\Pr(Q^c) \\\\\n&= \\Pr(P^c) + \\Pr(Q^c) - \\Pr(P^c \\cap Q^c) \\\\\n&= \\Pr(P^c \\cup Q^c) \\; ✅\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w02/index.html#random-variables-1",
    "href": "w02/index.html#random-variables-1",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Random Variables",
    "text": "Random Variables\n\nRecall our discussion of random variables: used by analogy to algebra, since we can do math with them:\nJust as \\(2 \\cdot 3\\) is shorthand for \\(2 + 2 + 2\\), we can define \\(X\\) as shorthand for the possible outcomes of a random process. \\[\n\\begin{align*}\nS = \\{ &\\text{result of dice roll is 1}, \\\\\n&\\text{result of dice roll is 2}, \\\\\n&\\text{result of dice roll is 3}, \\\\\n&\\text{result of dice roll is 4}, \\\\\n&\\text{result of dice roll is 5}, \\\\\n&\\text{result of dice roll is 6}\\} \\rightsquigarrow X \\in \\{1,\\ldots,6\\}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w02/index.html#random-variables-as-events",
    "href": "w02/index.html#random-variables-as-events",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Random Variables as Events",
    "text": "Random Variables as Events\n\nEach value \\(v_X\\) that a random variable \\(X\\) can take on gives rise to an event \\(X = v_X\\): the event that the random variable \\(X\\) takes on value \\(v\\).\nSince \\(X = v_X\\) is an event, we can compute its probability \\(\\Pr(X = v_X)\\)!\n\n\n\n\nEvent in words\nEvent in terms of RV\n\n\n\n\nResult of dice roll is 1\n\\(X = 1\\)\n\n\nResult of dice roll is 2\n\\(X = 2\\)\n\n\nResult of dice roll is 3\n\\(X = 3\\)\n\n\nResult of dice roll is 4\n\\(X = 4\\)\n\n\nResult of dice roll is 5\n\\(X = 5\\)\n\n\nResult of dice roll is 6\n\\(X = 6\\)"
  },
  {
    "objectID": "w02/index.html#doing-math-with-events",
    "href": "w02/index.html#doing-math-with-events",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Doing Math with Events",
    "text": "Doing Math with Events\n\nWe’ve seen how \\(\\Pr(\\cdot)\\) can “encode” logical expressions involving uncertain outcomes.\nEven more powerful when paired with the notion of random variables: lets us also “encode” mathematical expressions involving uncertain quantities!\nConsider an experiment where we roll two dice. Let \\(X\\) be the RV encoding the outcome of the first roll, and \\(Y\\) be the RV encoding the outcome of the second roll.\nWe can compute probabilities involving \\(X\\) and \\(Y\\) separately, e.g., \\(\\Pr(X = 1) = \\frac{1}{6}\\), but we can also reason probabilistically about mathematical expressions involving \\(X\\) and \\(Y\\)! For example, we can reason about their sum:\n\n\\[\n\\begin{align*}\n\\Pr(\\text{rolls sum to 10}) &= \\Pr(X + Y = 10) \\\\\n&= \\Pr(Y = 10 - X)\n\\end{align*}\n\\]\n\nOr about how the outcome of one roll will relate to the outcome of the other:\n\n\\[\n\\begin{align*}\n\\Pr(\\text{first roll above mean}) &= \\Pr\\left(X &gt; \\frac{X+Y}{2}\\right) \\\\\n&= \\Pr(2X &gt; X+Y) = \\Pr(X &gt; Y)\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w02/index.html#are-random-variables-all-powerful",
    "href": "w02/index.html#are-random-variables-all-powerful",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Are Random Variables All-Powerful??",
    "text": "Are Random Variables All-Powerful??\n\nJust remember that probability \\(P(\\cdot)\\) is always probability of an event—random variables are just shorthand for quantifiable events.\nNot all events can be simplified via random variables!\n\n\\(\\text{catch a fish} \\mapsto P(\\text{trout}), P(\\text{bass}), \\ldots\\)\n\nWhat types of events can be quantified like this?\n\n(Hint: It has to do with a key topic in the early weeks of both DSAN 5000 and 5100…)\n\n\n\nThe answer is, broadly, any situation where you’re modeling things, like dice rolls, where mathematical operations like addition, multiplication, etc. make sense. So, if we’re modeling dice, it makes sense to say e.g. “result is 6” + “result is 3” = “total is 9”. More on the next page!"
  },
  {
    "objectID": "w02/index.html#recall-types-of-variables",
    "href": "w02/index.html#recall-types-of-variables",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Recall: Types of Variables",
    "text": "Recall: Types of Variables\n\nCategorical\n\nNo meaningful way to order values: \\(\\{\\text{trout}, \\text{bass}, \\ldots \\}\\)\n\nOrdinal\n\nCan place in order (bigger, smaller), though gaps aren’t meaningful: \\(\\{{\\color{orange}\\text{great}},{\\color{orange}\\text{greater}},{\\color{orange}\\text{greatest}}\\}\\)\n\\({\\color{orange}\\text{greater}} \\overset{?}{=} 2\\cdot {\\color{orange}\\text{great}} - 1\\)\n\nCardinal\n\nCan place in order, and gaps are meaningful \\(\\implies\\) can do “standard” math with them! Example: \\(\\{{\\color{blue}1},{\\color{blue}2},\\ldots,{\\color{blue}10}\\}\\)\n\\({\\color{blue}7}\\overset{\\color{green}\\unicode{x2714}}{=} 2 \\cdot {\\color{blue}4} - 1\\)\nIf events have this structure (meaningful way to define multiplication, addition, subtraction), then we can analyze them as random variables"
  },
  {
    "objectID": "w02/index.html#visualizing-discrete-rvs",
    "href": "w02/index.html#visualizing-discrete-rvs",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Visualizing Discrete RVs",
    "text": "Visualizing Discrete RVs\n\nUltimate Probability Pro-Tip: When you hear “discrete distribution”, think of a bar graph: \\(x\\)-axis = events, bar height = probability of events\nTwo coins example: \\(X\\) = RV representing number of heads obtained in two coin flips\n\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ lubridate 1.9.2     ✔ tibble    3.2.1\n✔ purrr     1.0.2     ✔ tidyr     1.3.0\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors"
  },
  {
    "objectID": "w02/index.html#preview-visualizing-continuous-rvs",
    "href": "w02/index.html#preview-visualizing-continuous-rvs",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "(Preview:) Visualizing Continuous RVs",
    "text": "(Preview:) Visualizing Continuous RVs\n\nThis works even for continuous distributions, if you focus on the area under the curve instead of the height:\n\n\nfuncShaded &lt;- function(x, lower_bound, upper_bound) {\n    y &lt;- dnorm(x)\n    y[x &lt; lower_bound | x &gt; upper_bound] &lt;- NA\n    return(y)\n}\nfuncShadedBound1 &lt;- function(x) funcShaded(x, -Inf, 0)\nfuncShadedBound2 &lt;- function(x) funcShaded(x, 0.2, 1.8)\nfuncShadedBound3 &lt;- function(x) funcShaded(x, 2, Inf)\n\nnorm_plot &lt;- ggplot(data.frame(x=c(-3,3)), aes(x = x)) +\n    stat_function(fun = dnorm) +\n    labs(\n      title=\"Probability Density, X Normally Distributed\",\n      x=\"Possible Values of X\",\n      y=\"Probability Density\"\n    ) +\n    dsan_theme(\"half\") +\n    theme(legend.position = \"none\") +\n    coord_cartesian(clip = \"off\")\nlabel_df &lt;- tribble(\n  ~x, ~y, ~label,\n  -0.8, 0.1, \"Pr(X &lt; 0) = 0.5\",\n  1.0, 0.05, \"Pr(0.2 &lt; X &lt; 1.8)\\n= 0.385\",\n  2.5,0.1,\"Pr(X &gt; 1.96)\\n= 0.025\"\n)\nshaded_plot &lt;- norm_plot +\n  stat_function(fun = funcShadedBound1, geom = \"area\", fill=cbPalette[1], alpha = 0.5) +\n  stat_function(fun = funcShadedBound2, geom = \"area\", fill=cbPalette[2], alpha = 0.5) +\n  stat_function(fun = funcShadedBound3, geom = \"area\", fill=cbPalette[3], alpha = 0.5) +\n  geom_text(label_df, mapping=aes(x = x, y = y, label = label), size=6)\nshaded_plot"
  },
  {
    "objectID": "w02/index.html#probability-theory-gives-us-distributions-for-rvs-not-numbers",
    "href": "w02/index.html#probability-theory-gives-us-distributions-for-rvs-not-numbers",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Probability Theory Gives Us Distributions for RVs, not Numbers!",
    "text": "Probability Theory Gives Us Distributions for RVs, not Numbers!\n\nWe’re going beyond “base” probability theory if we want to summarize these distributions\nHowever, we can understand a lot about the full distribution by looking at some basic summary statistics. Most common way to summarize:\n\n\n\n\n\n\n\n\n\n\\(\\underbrace{\\text{point estimate}}_{\\text{mean/median}}\\)\n\\(\\pm\\)\n\\(\\underbrace{\\text{uncertainty}}_{\\text{variance/standard deviation}}\\)"
  },
  {
    "objectID": "w02/index.html#example-game-reviews",
    "href": "w02/index.html#example-game-reviews",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Example: Game Reviews",
    "text": "Example: Game Reviews\n\nlibrary(readr)\nfig_title &lt;- \"Review for a Popular Nintendo Switch Game\"\nfig_subtitle &lt;- \"(That I definitely didn't play for &gt;400 hours this summer...)\"\n#score_df &lt;- read_csv(\"https://gist.githubusercontent.com/jpowerj/8b2b6a50cef5a682db640e874a14646b/raw/bbe07891a90874d1fe624224c1b82212b1ac8378/totk_scores.csv\")\nscore_df &lt;- read_csv(\"https://gist.githubusercontent.com/jpowerj/8b2b6a50cef5a682db640e874a14646b/raw/e3c2b9d258380e817289fbb64f91ba9ed4357d62/totk_scores.csv\")\n\nRows: 145 Columns: 1\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (1): score\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nmean_score &lt;- mean(score_df$score)\nlibrary(ggplot2)\nggplot(score_df, aes(x=score)) +\n  geom_histogram() +\n  #geom_vline(xintercept=mean_score) +\n  labs(\n    title=fig_title,\n    subtitle=fig_subtitle,\n    x=\"Review Score\",\n    y=\"Number of Reviews\"\n  ) +\n  dsan_theme(\"full\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n(Data from Metacritic)"
  },
  {
    "objectID": "w02/index.html#adding-a-single-line",
    "href": "w02/index.html#adding-a-single-line",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Adding a Single Line",
    "text": "Adding a Single Line\n\nlibrary(readr)\nmean_score &lt;- mean(score_df$score)\nmean_score_label &lt;- sprintf(\"%0.2f\", mean_score)\nlibrary(ggplot2)\nggplot(score_df, aes(x=score)) +\n  geom_histogram() +\n  geom_vline(aes(xintercept=mean_score, linetype=\"dashed\"), color=\"purple\", size=1) +\n  scale_linetype_manual(\"\", values=c(\"dashed\"=\"dashed\"), labels=c(\"dashed\"=\"Mean Score\")) +\n  # Add single additional tick\n  scale_x_continuous(breaks=c(60, 70, 80, 90, mean_score, 100), labels=c(\"60\",\"70\",\"80\",\"90\",mean_score_label,\"100\")) +\n  labs(\n    title=fig_title,\n    subtitle=fig_subtitle,\n    x=\"Review Score\",\n    y=\"Number of Reviews\"\n  ) +\n  dsan_theme(\"full\") +\n  theme(\n    legend.title = element_blank(),\n    legend.spacing.y = unit(0, \"mm\")\n  ) +\n  theme(axis.text.x = element_text(colour = c('black', 'black','black', 'black', 'purple', 'black')))\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nWarning: Vectorized input to `element_text()` is not officially supported.\nℹ Results may be unexpected or may change in future versions of ggplot2.\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n(Data from Metacritic)"
  },
  {
    "objectID": "w02/index.html#or-a-single-ribbon",
    "href": "w02/index.html#or-a-single-ribbon",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Or a Single Ribbon",
    "text": "Or a Single Ribbon\n\n\n\nlibrary(tibble)\nN &lt;- 10\n# Each x value gets 10 y values\nx &lt;- sort(rep(seq(1,10),10))\ny &lt;- x + rnorm(length(x), 0, 5)\ndf &lt;- tibble(x=x,y=y)\ntotal_N &lt;- nrow(df)\nggplot(df, aes(x=x,y=y)) +\n  geom_point(size=g_pointsize) +\n  dsan_theme(\"column\") +\n  labs(\n    title=paste0(\"N=\",total_N,\" Randomly-Generated Points\")\n  )\n\n\n\n\n\n# This time, just the means\nlibrary(dplyr)\nmean_df &lt;- df %&gt;% group_by(x) %&gt;% summarize(mean=mean(y), min=min(y), max=max(y))\nggplot(mean_df, aes(x=x, y=mean)) +\n  geom_ribbon(aes(ymin=min, ymax=max, fill=\"ribbon\"), alpha=0.5) +\n  geom_point(aes(color=\"mean\"), size=g_pointsize) +\n  geom_line(size=g_linesize) +\n  dsan_theme(\"half\") +\n  scale_color_manual(\"\", values=c(\"mean\"=\"black\"), labels=c(\"mean\"=\"Mean\")) +\n  scale_fill_manual(\"\", values=c(\"ribbon\"=cbPalette[1]), labels=c(\"ribbon\"=\"Range\")) +\n  remove_legend_title() +\n  labs(\n    title=paste0(\"Means of N=\",total_N,\" Randomly-Generated Points\")\n  )\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\nlibrary(tibble)\nN &lt;- 100\n# Each x value gets 10 y values\nx &lt;- sort(rep(seq(1,10),10))\ny &lt;- x + rnorm(length(x), 0, 1)\ndf &lt;- tibble(x=x,y=y)\ntotal_N &lt;- nrow(df)\nggplot(df, aes(x=x,y=y)) +\n  geom_point(size=g_pointsize) +\n  dsan_theme(\"column\") +\n  labs(\n    title=paste0(\"N=\",total_N,\" Randomly-Generated Points\")\n  )\n\n\n\n\n\n# This time, just the means\nlibrary(dplyr)\nmean_df &lt;- df %&gt;% group_by(x) %&gt;% summarize(mean=mean(y), min=min(y), max=max(y))\nggplot(mean_df, aes(x=x, y=mean)) +\n  geom_ribbon(aes(ymin=min, ymax=max, fill=\"ribbon\"), alpha=0.5) +\n  geom_point(aes(color=\"mean\"), size=g_pointsize) +\n  geom_line(size=g_linesize) +\n  dsan_theme(\"half\") +\n  scale_color_manual(\"\", values=c(\"mean\"=\"black\"), labels=c(\"mean\"=\"Mean\")) +\n  scale_fill_manual(\"\", values=c(\"ribbon\"=cbPalette[1]), labels=c(\"ribbon\"=\"Range\")) +\n  remove_legend_title() +\n  labs(\n    title=paste0(\"Means of N=\",total_N,\" Randomly-Generated Points\")\n  )"
  },
  {
    "objectID": "w02/index.html#example-the-normal-distribution",
    "href": "w02/index.html#example-the-normal-distribution",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Example: The Normal Distribution",
    "text": "Example: The Normal Distribution\n\n\n\n(The distribution you saw a few slides ago)\n\n\nvlines_std_normal &lt;- tibble::tribble(\n  ~x, ~xend, ~y, ~yend, ~Params,\n  0, 0, 0, dnorm(0), \"Mean\",\n  -2, -2, 0, dnorm(-2), \"SD\",\n  -1, -1, 0, dnorm(-1), \"SD\",\n  1, 1, 0, dnorm(1), \"SD\",\n  2, 2, 0, dnorm(2), \"SD\"\n)\nggplot(data.frame(x = c(-3, 3)), aes(x = x)) +\n    stat_function(fun = dnorm, linewidth = g_linewidth) +\n    geom_segment(data=vlines_std_normal, aes(x=x, xend=xend, y=y, yend=yend, linetype = Params), linewidth = g_linewidth, color=\"purple\") +\n    geom_area(stat = \"function\", fun = dnorm, fill = cbPalette[1], xlim = c(-3, 3), alpha=0.2) +\n    #geom_area(stat = \"function\", fun = dnorm, fill = \"blue\", xlim = c(0, 2))\n    dsan_theme(\"quarter\") +\n    labs(\n      x = \"v\",\n      y = \"Density f(v)\"\n    )\n\n\n\n\n\n\n“RV \\(X\\) is normally distributed with mean \\({\\color{purple}\\mu}\\) and standard deviation \\({\\color{purple}\\sigma}\\)”\n\nTranslates to \\(X \\sim \\mathcal{N}(\\color{purple}{\\mu},\\color{purple}{\\sigma})\\)2\n\\(\\color{purple}{\\mu}\\) and \\(\\color{purple}{\\sigma}\\) are parameters3: the “knobs” or “sliders” which change the location/shape of the distribution\n\n\n\n\n\nThe parameters in this case give natural summaries of the data:\n\n\\({\\color{\\purple}\\mu}\\) = center (mean), \\({\\color{purple}\\sigma}\\) = [square root of] variance around center\n\nMean can usually be interpreted intuitively; for standard deviation, we usually use the 68-95-99.7 rule, which will make more sense relative to some real-world data…"
  },
  {
    "objectID": "w02/index.html#real-data-and-the-68-95-99.7-rule",
    "href": "w02/index.html#real-data-and-the-68-95-99.7-rule",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Real Data and the 68-95-99.7 Rule",
    "text": "Real Data and the 68-95-99.7 Rule\n\n\n\n\n\n\n\nFigure 2: Heights (cm) for 18K professional athletes\n\n\n\n\n\n\n\nFigure 3: The 68-95-99.7 Rule visualized (Wikimedia Commons)\n\n\n\n\nThe point estimate \\({\\color{purple}\\mu} = 186.48\\) is straightforward: the average height of the athletes is 186.48cm. Using the 68-95-99.7 Rule to interpret the SD, \\({\\color{purple}\\sigma} = 9.7\\), we get:\n\n\n\nAbout 68% of the heights fall between\n\n\n\n\n\n\n\n\n\n[\\({\\color{purple}\\mu} - 1\\cdot {\\color{purple}\\sigma}\\)\nand\n\\({\\color{purple}\\mu} + 1\\cdot {\\color{purple}\\sigma}\\)]\n\n\n[186.48 - 1 · 9.7\nand\n186.48 + 1 · 9.7]\n\n\n[176.78\nand\n196.18]\n\n\n\n\n\nAbout 95% of the heights fall between\n\n\n\n\n\n\n\n\n\n[\\({\\color{purple}\\mu} - 2 \\cdot {\\color{purple}\\sigma}\\)\nand\n\\({\\color{purple}\\mu} + 2 \\cdot {\\color{purple}\\sigma}\\)]\n\n\n[186.48 - 2 · 9.7\nand\n186.48 + 2 · 9.7]\n\n\n[167.08\nand\n205.88]"
  },
  {
    "objectID": "w02/index.html#boxplots-comparing-multiple-distributions",
    "href": "w02/index.html#boxplots-comparing-multiple-distributions",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Boxplots: Comparing Multiple Distributions",
    "text": "Boxplots: Comparing Multiple Distributions\n\n\n\n\n\n\nJhguch at en.wikipedia, CC BY-SA 2.5, via Wikimedia Commons\n\n\n\n\n\n\n\nProtonk, CC BY-SA 3.0, via Wikimedia Commons"
  },
  {
    "objectID": "w02/index.html#another-option-joyplots",
    "href": "w02/index.html#another-option-joyplots",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Another Option: Joyplots",
    "text": "Another Option: Joyplots\n\n\n\n\n\n\nFigure 4: (Iconic album cover)\n\n\n\n\n\n\nFigure 5: (Tooting my own horn)"
  },
  {
    "objectID": "w02/index.html#multivariate-distributions-preview",
    "href": "w02/index.html#multivariate-distributions-preview",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Multivariate Distributions: Preview",
    "text": "Multivariate Distributions: Preview\n\nThe bivariate normal distribution represents the distribution of two normally-distributed RVs \\(\\mathbf{X} = [\\begin{smallmatrix} X_1 & X_2\\end{smallmatrix}]\\), which may or may not be correlated:\n\n\n\\[\n\\mathbf{X} = \\begin{bmatrix}X_1 \\\\ X_2\\end{bmatrix}, \\; \\boldsymbol{\\mu} =\n%\\begin{bmatrix}\\mu_1 \\\\ \\mu_2\\end{bmatrix}\n\\begin{bmatrix}\\smash{\\overbrace{\\mu_1}^{\\mathbb{E}[X_1]}} \\\\ \\smash{\\underbrace{\\mu_2}_{\\mathbb{E}[X_2]}}\\end{bmatrix}\n, \\; \\mathbf{\\Sigma} = \\begin{bmatrix}\\smash{\\overbrace{\\sigma_1^2}^{\\text{Var}[X_1]}} & \\smash{\\overbrace{\\rho\\sigma_1\\sigma_2}^{\\text{Cov}[X_1,X_2]}} \\\\ \\smash{\\underbrace{\\rho\\sigma_2\\sigma_1}_{\\text{Cov}[X_2,X_1]}} & \\smash{\\underbrace{\\sigma_2^2}_{\\text{Var}[X_2]}}\\end{bmatrix}\n% \\begin{bmatrix}\\sigma_1^2 & \\rho\\sigma_1\\sigma_2 \\\\ \\rho\\sigma_2\\sigma_1 & \\sigma_2^2 \\end{bmatrix}\n% = \\begin{bmatrix}\\text{Var}[X_1] & \\text{Cov}[X_1,X_2] \\\\ \\text{Cov}[X_2,X_1] & \\text{Var}[X_2] \\end{bmatrix}\n\\]\n\n\nBy squishing all this information intro matrices, we can specify the parameters of multivariate-normally-distributed vectors of RVs similarly to how we specify single-dimensional normally-distributed RVs:\n\n\n\\[\n\\begin{align*}\n\\overbrace{X}^{\\mathclap{\\text{scalar}}} &\\sim \\mathcal{N}\\phantom{_k}(\\overbrace{\\mu}^{\\text{scalar}}, \\overbrace{\\sigma}^{\\text{scalar}}) \\tag{Univariate} \\\\\n\\underbrace{\\mathbf{X}}_{\\text{vector}} &\\sim \\boldsymbol{\\mathcal{N}}_k(\\smash{\\underbrace{\\boldsymbol{\\mu}}_{\\text{vector}}}, \\underbrace{\\mathbf{\\Sigma}}_{\\text{matrix}}) \\tag{Multivariate}\n\\end{align*}\n\\]\n\n\nNote: In the future I’ll use the notation \\(\\mathbf{X}_{[a \\times b]}\\) to denote the dimensions of the vectors/matrices, like \\(\\mathbf{X}_{[k \\times 1]} \\sim \\boldsymbol{\\mathcal{N}}_k(\\boldsymbol{\\mu}_{[k \\times 1]}, \\mathbf{\\Sigma}_{[k \\times k]})\\)"
  },
  {
    "objectID": "w02/index.html#visualizing-3d-distributions-projection",
    "href": "w02/index.html#visualizing-3d-distributions-projection",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Visualizing 3D Distributions: Projection",
    "text": "Visualizing 3D Distributions: Projection\n\nSince most of our intuitions about plots come from 2D plots, it is extremely useful to be able to take a 3D plot like this and imagine “projecting” it down into different 2D plots:\n\n\n\n\n(Adapted via LaTeX from StackExchange discussion)"
  },
  {
    "objectID": "w02/index.html#visualizing-3d-distributions-contours",
    "href": "w02/index.html#visualizing-3d-distributions-contours",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Visualizing 3D Distributions: Contours",
    "text": "Visualizing 3D Distributions: Contours\n\n\n\nFrom Prof. Hickman’s slides!"
  },
  {
    "objectID": "w02/index.html#visualizing-3d-distributions-contours-1",
    "href": "w02/index.html#visualizing-3d-distributions-contours-1",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Visualizing 3D Distributions: Contours",
    "text": "Visualizing 3D Distributions: Contours\n\n\n\nAlso from Prof. Hickman’s slides!"
  },
  {
    "objectID": "w02/index.html#footnotes",
    "href": "w02/index.html#footnotes",
    "title": "Week 2: Introduction to Probabilistic Modeling",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFor math majors, you can think of it as an isomorphism between the objects and operations of the three subjects↩︎\nThroughout the course, this “calligraphic” font \\(\\mathcal{N}\\), \\(\\mathcal{D}\\), etc., will be used to denote distributions↩︎\nThroughout the course, remember, purrple is for purrameters↩︎"
  },
  {
    "objectID": "w04/slides.html#discrete-vs.-continuous",
    "href": "w04/slides.html#discrete-vs.-continuous",
    "title": "Week 4: Discrete Probability Distributions",
    "section": "Discrete vs. Continuous",
    "text": "Discrete vs. Continuous\n\n\n\nDiscrete = “Easy mode”: Based (intuitively) on sets\n\\(\\Pr(A)\\): Four marbles \\(\\{A, B, C, D\\}\\) in box, all equally likely, what is the probability I pull out \\(A\\)?\n\n\n\n\n\n\n\n\n\n\n\\[\n\\Pr(A) = \\underbrace{\\frac{|\\{A\\}|}{|\\Omega|}}_{\\mathclap{\\small \\text{Probability }\\textbf{mass}}} = \\frac{1}{|\\{A,B,C,D\\}|} = \\frac{1}{4}\n\\]\n\n\nContinuous = “Hard mode”: Based (intuitively) on areas\n\\(\\Pr(A)\\): If I throw a dart at this square, what is the probability that I hit region \\(A\\)?\n\n\n\n\n\n\n\n\n\n\n\\[\n\\Pr(A) = \\underbrace{\\frac{\\text{Area}(\\{A\\})}{\\text{Area}(\\Omega)}}_{\\mathclap{\\small \\text{Probability }\\textbf{density}}} = \\frac{\\pi r^2}{s^2} = \\frac{\\pi \\left(\\frac{1}{4}\\right)^2}{4} = \\frac{\\pi}{64}\n\\]"
  },
  {
    "objectID": "w04/slides.html#the-technical-difference-tldr",
    "href": "w04/slides.html#the-technical-difference-tldr",
    "title": "Week 4: Discrete Probability Distributions",
    "section": "The Technical Difference tl;dr",
    "text": "The Technical Difference tl;dr\n\nCountable Sets: Can be put into 1-to-1 correspondence with the natural numbers \\(\\mathbb{N}\\)\n\nWhat are you doing when you’re counting? Saying “first”, “second”, “third”, …\nYou’re pairing each object with a natural number! \\(\\{(\\texttt{a},1),(\\texttt{b},2),\\ldots,(\\texttt{z},26)\\}\\) \n\nUncountable Sets: Cannot be put into 1-to-1 correspondence with the natural numbers.\n\n\\(\\mathbb{R}\\) is uncountable. Intuition: Try counting the real numbers. Proof1 \\[\n\\text{Assume }\\exists (f: \\mathbb{R} \\leftrightarrow \\mathbb{N}) =\n\\begin{array}{|c|c|c|c|c|c|c|}\\hline\n\\mathbb{R} & & & & & & \\Leftrightarrow \\mathbb{N} \\\\ \\hline\n\\color{orange}{3} & . & 1 & 4 & 1 & \\cdots & \\Leftrightarrow 1 \\\\\\hline\n4 & . & \\color{orange}{9} & 9 & 9 & \\cdots & \\Leftrightarrow 2 \\\\\\hline\n0 & . & 1 & \\color{orange}{2} & 3 & \\cdots &\\Leftrightarrow 3 \\\\\\hline\n1 & . & 2 & 3 & \\color{orange}{4} & \\cdots & \\Leftrightarrow 4 \\\\\\hline\n\\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\\hline\n\\end{array} \\overset{\\color{blue}{y_{[i]}} = \\color{orange}{x_{[i]}} \\overset{\\mathbb{Z}_{10}}{+} 1}{\\longrightarrow} \\color{blue}{y = 4.035 \\ldots} \\Leftrightarrow \\; ?\n\\]\n\n\n\n\nFun math challenge: Is \\(\\mathbb{Q}\\) countable? See this appendix slide for why the answer is yes, despite the fact that \\(\\forall x, y \\in \\mathbb{Q} \\left[ \\frac{x+y}{2} \\in \\mathbb{Q} \\right]\\)\nThe method used in this proof, if you haven’t seen it before, is called Cantor diagonalization, and it is extremely fun and applicable to a wide variety of levels-of-infinity proofs"
  },
  {
    "objectID": "w04/slides.html#the-practical-difference",
    "href": "w04/slides.html#the-practical-difference",
    "title": "Week 4: Discrete Probability Distributions",
    "section": "The Practical Difference",
    "text": "The Practical Difference\n\nThis part of the course (discrete probability): \\(\\Pr(X = v), v \\in \\mathcal{R}_X \\subseteq \\mathbb{N}\\)\n\nExample: \\(\\Pr(\\)\\() = \\Pr(X = 3), 3 \\in \\{1,2,3,4,5,6\\} \\subseteq \\mathbb{N}\\)\n\nNext part of the course (continuous probability): \\(\\Pr(X \\in V), v \\subseteq \\mathbb{R}\\)\n\nExample: \\(\\Pr(X \\geq 2\\pi) = \\Pr(X \\in [\\pi,\\infty)), [\\pi,\\infty) \\subseteq \\mathbb{R}\\)\n\nWhy do they have to be in separate parts?\n\n\\[\n\\Pr(X = 2\\pi) = \\frac{\\text{Area}(\\overbrace{2\\pi}^{\\mathclap{\\small \\text{Single point}}})}{\\text{Area}(\\underbrace{\\mathbb{R}}_{\\mathclap{\\small \\text{(Uncountably) Infinite set of points}}})} = 0\n\\]"
  },
  {
    "objectID": "w04/slides.html#probability-mass-vs.-probability-density",
    "href": "w04/slides.html#probability-mass-vs.-probability-density",
    "title": "Week 4: Discrete Probability Distributions",
    "section": "Probability Mass vs. Probability Density",
    "text": "Probability Mass vs. Probability Density\n\nCumulative Distribution Function (CDF): \\(F_X(v) = \\Pr(X \\leq v)\\)\nFor discrete RV \\(X\\), Probability Mass Function (pmf) \\(p_X(v)\\): \\[\n\\begin{align*}\np_X(v) &= \\Pr(X = v) = F_X(v) - F_X(v-1) \\\\\n\\implies F_X(v) &= \\sum_{\\{w \\in \\mathcal{R}_X: \\; w \\leq v\\}}p_X(w)\n\\end{align*}\n\\]\nFor continuous RV \\(X\\) (\\(\\mathcal{R}_X \\subseteq \\mathbb{R}\\)), Probability Density Function (pdf) \\(f_X(v)\\): \\[\n\\begin{align*}\nf_X(v) &= \\frac{d}{dx}F_X(v) \\\\\n\\implies F_X(v) &= \\int_{-\\infty}^v f_X(w)dw\n\\end{align*}\n\\]\n\n\n\nFrustratingly, the CDF/pmf/pdf is usually written using \\(X\\) and \\(x\\), like \\(F_X(x) = \\Pr(X \\leq x)\\). To me this is extremely confusing, since the capitalized \\(X\\) is a random variable (not a number) while the lowercase \\(x\\) is some particular value, like \\(3\\). So, to emphasize this difference, I use \\(X\\) for the RV and \\(v\\) for the value at which we’re checking the CDF/pmf/pdf.\nAlso note the capitalized CDF but lowercase pmf/pdf, matching the mathematical notation where \\(f_X(v)\\) is the derivative of \\(F_X(v)\\)."
  },
  {
    "objectID": "w04/slides.html#probability-density-neq-probability",
    "href": "w04/slides.html#probability-density-neq-probability",
    "title": "Week 4: Discrete Probability Distributions",
    "section": "Probability Density \\(\\neq\\) Probability",
    "text": "Probability Density \\(\\neq\\) Probability\n\nBEWARE: \\(f_X(v) \\neq \\Pr(X = v)\\)!\nLong story short, for continuous variables, \\(\\Pr(X = v) = 0\\)1\nHence, we instead construct a PDF \\(f_X(v)\\) that enables us to calculate \\(\\Pr(X \\in [a,b])\\) by integrating: \\(f_X(v)\\) is whatever function satisfies \\(\\Pr(X \\in [a,b]) = \\int_{a}^bf_X(v)dv\\).\ni.e., instead of \\(p_X(v) = \\Pr(X = v)\\) from discrete world, the relevant function here is \\(f_X(v)\\), the probability density of \\(X\\) at \\(v\\).\nIf we really want to get something like the “probability of a value” in a continuous space 😪, we can get something kind of like this by using fancy limits \\[\nf_X(v) = \\lim_{\\varepsilon \\to 0}\\frac{P(X \\in [v-\\varepsilon, v + \\varepsilon])}{2\\varepsilon} = \\lim_{\\varepsilon \\to 0}\\frac{F(v + \\varepsilon) - F(v - \\varepsilon)}{2\\varepsilon} = \\frac{d}{dx}F_X(v)\n\\]\n\nFor intuition: \\(X \\sim U[0,10] \\implies \\Pr(X = \\pi) = \\frac{|\\{v \\in \\mathbb{R}:\\; v = \\pi\\}|}{|\\mathbb{R}|} = \\frac{1}{2^{\\aleph_0}} \\approx 0\\). That is, finding the \\(\\pi\\) needle in the \\(\\mathbb{R}\\) haystack is a one-in-\\(\\left(\\infty^\\infty\\right)\\) event. A similar issue occurs if \\(S\\) is countably-infinite, like \\(S = \\mathbb{N}\\): \\(\\Pr(X = 3) = \\frac{|\\{x \\in \\mathbb{N} : \\; x = 3\\}|}{|\\mathbb{N}|} = \\frac{1}{\\aleph_0}\\)."
  },
  {
    "objectID": "w04/slides.html#bernoulli-distribution",
    "href": "w04/slides.html#bernoulli-distribution",
    "title": "Week 4: Discrete Probability Distributions",
    "section": "Bernoulli Distribution",
    "text": "Bernoulli Distribution\n\nSingle trial with two outcomes, “success” (1) or “failure” (0): basic model of a coin flip (heads = 1, tails = 0)\n\\(X \\sim \\text{Bern}({\\color{purple} p}) \\implies \\mathcal{R}_X = \\{0,1\\}, \\; \\Pr(X = 1) = {\\color{purple}p}\\)."
  },
  {
    "objectID": "w04/slides.html#binomial-distribution",
    "href": "w04/slides.html#binomial-distribution",
    "title": "Week 4: Discrete Probability Distributions",
    "section": "Binomial Distribution",
    "text": "Binomial Distribution\n\nNumber of successes in \\({\\color{purple}N}\\) Bernoulli trials. \\(X \\sim \\text{Binom}({\\color{purple}N},{\\color{purple}k},{\\color{purple}p}) \\implies \\mathcal{R}_X = \\{0, 1, \\ldots, N\\}\\)\n\n\\(P(X = k) = \\binom{N}{k}p^k(1-p)^{N-k}\\): probability of \\(k\\) successes out of \\(N\\) trials.\n\\(\\binom{N}{k} = \\frac{N!}{k!(N-k)!}\\): “Binomial coefficient”. How many groups of size \\(k\\) can be formed?1\n\n\nA fun way to never have to memorize or compute these: imagine a pyramid like \\(\\genfrac{}{}{0pt}{}{}{\\boxed{\\phantom{1}}}\\genfrac{}{}{0pt}{}{\\boxed{\\phantom{1}}}{}\\genfrac{}{}{0pt}{}{}{\\boxed{\\phantom{1}}}\\), where the boxes are slots for numbers, and put a \\(1\\) in the box at the top. In the bottom row, fill each slot with the sum of the two numbers above-left and above-right of it. Since \\(1 + \\text{(nothing)} = 1\\), this looks like: \\(\\genfrac{}{}{0pt}{}{}{1}\\genfrac{}{}{0pt}{}{1}{}\\genfrac{}{}{0pt}{}{}{1}\\). Continue filling in the pyramid this way, so the next row looks like \\(\\genfrac{}{}{0pt}{}{}{1}\\genfrac{}{}{0pt}{}{1}{}\\genfrac{}{}{0pt}{}{}{2}\\genfrac{}{}{0pt}{}{1}{}\\genfrac{}{}{0pt}{}{}{1}\\), then \\(\\genfrac{}{}{0pt}{}{}{1}\\genfrac{}{}{0pt}{}{1}{}\\genfrac{}{}{0pt}{}{}{3}\\genfrac{}{}{0pt}{}{2}{}\\genfrac{}{}{0pt}{}{}{3}\\genfrac{}{}{0pt}{}{1}{}\\genfrac{}{}{0pt}{}{}{1}\\), and so on. The \\(k\\)th number in the \\(N\\)th row (counting from \\(0\\)) is \\(\\binom{N}{k}\\). For the triangle written out to the 7th row, see Appendix I at end of slideshow."
  },
  {
    "objectID": "w04/slides.html#visualizing-the-binomial",
    "href": "w04/slides.html#visualizing-the-binomial",
    "title": "Week 4: Discrete Probability Distributions",
    "section": "Visualizing the Binomial",
    "text": "Visualizing the Binomial\n\n\nCode\nk &lt;- seq(0, 10)\nprob &lt;- dbinom(k, 10, 0.5)\nbar_data &lt;- tibble(k, prob)\nggplot(bar_data, aes(x=k, y=prob)) +\n  geom_bar(stat=\"identity\", fill=cbPalette[1]) +\n  labs(\n    title=\"Binomial Distribution, N = 10, p = 0.5\",\n    y=\"Probability Mass\"\n  ) +\n  scale_x_continuous(breaks=seq(0,10)) +\n  dsan_theme(\"half\")\n\n\n\n\nSo who can tell me, from this plot, the approximate probability of getting 4 heads when flipping a coin 10 times?"
  },
  {
    "objectID": "w04/slides.html#multiple-classes-multinomial-distribution",
    "href": "w04/slides.html#multiple-classes-multinomial-distribution",
    "title": "Week 4: Discrete Probability Distributions",
    "section": "Multiple Classes: Multinomial Distribution",
    "text": "Multiple Classes: Multinomial Distribution\n\nBernoulli only allows two outcomes: success or failure.\nWhat if we’re predicting soccer match outcomes?\n\n\\(X_i \\in \\{\\text{Win}, \\text{Loss}, \\text{Draw}\\}\\)\n\nCategorical Distribution: Generalization of Bernoulli to \\(k\\) outcomes. \\(X \\sim \\text{Categorical}(\\mathbf{p} = \\{p_1, p_2, \\ldots, p_k\\}), \\sum_{i=1}^kp_i = 1\\).\n\n\\(P(X = k) = p_k\\)\n\nMultinomial Distribution: Generalization of Binomial to \\(k\\) outcomes.\n\\(\\mathbf{X} \\sim \\text{Multinom}(N,k,\\mathbf{p}=\\{p_1,p_2,\\ldots,p_k\\}), \\sum_{i=1}^kp_i=1\\)\n\n\\(P(\\mathbf{X} = \\{x_1,x_2\\ldots,x_k\\}) = \\frac{N!}{x_1!x_2!\\cdots x_k!}p_1^{x_1}p_2^{x_2}\\cdots p_k^{x_k}\\)\n\\(P(\\text{30 wins}, \\text{4 losses}, \\text{4 draws}) = \\frac{38!}{30!4!4!}p_{\\text{win}}^{30}p_{\\text{lose}}^4p_{\\text{draw}}^4\\)."
  },
  {
    "objectID": "w04/slides.html#geometric-distribution",
    "href": "w04/slides.html#geometric-distribution",
    "title": "Week 4: Discrete Probability Distributions",
    "section": "Geometric Distribution",
    "text": "Geometric Distribution\n\nGeometric: Likelihood that we need \\({\\color{purple}k}\\) trials to get our first success. \\(X \\sim \\text{Geom}({\\color{purple}k},{\\color{purple}p}) \\implies \\mathcal{R}_X = \\{0, 1, \\ldots\\}\\)\n\n\\(P(X = k) = \\underbrace{(1-p)^{k-1}}_{\\small k - 1\\text{ failures}}\\cdot \\underbrace{p}_{\\mathclap{\\small \\text{success}}}\\)\nProbability of \\(k-1\\) failures followed by a success"
  },
  {
    "objectID": "w04/slides.html#less-common-but-important-distributions",
    "href": "w04/slides.html#less-common-but-important-distributions",
    "title": "Week 4: Discrete Probability Distributions",
    "section": "Less Common (But Important) Distributions",
    "text": "Less Common (But Important) Distributions\n\nDiscrete Uniform: \\(N\\) equally-likely outcomes\n\n\\(X \\sim U\\{{\\color{purple}a},{\\color{purple}b}\\} \\implies \\mathcal{R}_X = \\{a, a+1, \\ldots, b\\}, P(X = k) = \\frac{1}{{\\color{purple}b} - {\\color{purple}a} + 1}\\)\n\nBeta: \\(X \\sim \\text{Beta}({\\color{purple}\\alpha}, {\\color{purple}\\beta})\\): conjugate prior for Bernoulli, Binomial, and Geometric dists.\n\nIntuition: If we use Beta to encode our prior hypothesis, then observe data drawn from Binomial, distribution of our updated hypothesis is still Beta.\n\\(\\underbrace{\\Pr(\\text{biased}) = \\Pr(\\text{unbiased})}_{\\text{Prior: }\\text{Beta}({\\color{purple}\\alpha}, {\\color{purple}\\beta})} \\rightarrow\\) Observe \\(\\underbrace{\\frac{8}{10}\\text{ heads}}_{\\text{Data}} \\rightarrow \\underbrace{\\Pr(\\text{biased}) = 0.65}_{\\text{Posterior: }\\text{Beta}({\\color{purple}\\alpha + 8}, {\\color{purple}\\beta + 2})}\\)\n\nDirichlet: \\(\\mathbf{X} = (X_1, X_2, \\ldots, X_K) \\sim \\text{Dir}({\\color{purple} \\boldsymbol\\alpha})\\)\n\n\\(K\\)-dimensional extension of Beta (thus, conjugate prior for Multinomial)\n\n\n\n\nWe can now use \\(\\text{Beta}(\\alpha + 8, \\beta + 2)\\) as a prior for our next set of trials (encoding our knowledge up to that point), and update further once we know the results (to yet another Beta distribution)."
  },
  {
    "objectID": "w04/slides.html#interactive-visualizations",
    "href": "w04/slides.html#interactive-visualizations",
    "title": "Week 4: Discrete Probability Distributions",
    "section": "Interactive Visualizations",
    "text": "Interactive Visualizations\n\nSeeing Theory →"
  },
  {
    "objectID": "w04/slides.html#lab-3-demonstration",
    "href": "w04/slides.html#lab-3-demonstration",
    "title": "Week 4: Discrete Probability Distributions",
    "section": "Lab 3 Demonstration",
    "text": "Lab 3 Demonstration\nLab 3 Demo Link"
  },
  {
    "objectID": "w04/slides.html#lab-3-assignment-overview",
    "href": "w04/slides.html#lab-3-assignment-overview",
    "title": "Week 4: Discrete Probability Distributions",
    "section": "Lab 3 Assignment Overview",
    "text": "Lab 3 Assignment Overview\nLab 3 Assignment"
  },
  {
    "objectID": "w04/slides.html#appendix-countability-of-mathbbq",
    "href": "w04/slides.html#appendix-countability-of-mathbbq",
    "title": "Week 4: Discrete Probability Distributions",
    "section": "Appendix: Countability of \\(\\mathbb{Q}\\)",
    "text": "Appendix: Countability of \\(\\mathbb{Q}\\)\n\nBad definition: “\\(\\mathbb{N}\\) is countable because no \\(x \\in \\mathbb{N}\\) between \\(0\\) and \\(1\\). \\(\\mathbb{R}\\) is uncountable because infinitely-many \\(x \\in \\mathbb{R}\\) between \\(0\\) and \\(1\\).” (\\(\\implies \\mathbb{Q}\\) uncountable)\nAnd yet, \\(\\mathbb{Q}\\) is countable…\n\n\n\n\n\n\n\n\n\n\\[\n\\begin{align*}\n\\begin{array}{ll}\ns: \\mathbb{N} \\leftrightarrow \\mathbb{Z} & s(n) = (-1)^n \\left\\lfloor \\frac{n+1}{2} \\right\\rfloor \\\\\nh_+: \\mathbb{Z}^+ \\leftrightarrow \\mathbb{Q}^+ & p_1^{a_1}p_2^{a_2}\\cdots \\mapsto p_1^{s(a_1)}p_2^{s(a_2)}\\cdots \\\\\nh: \\mathbb{Z} \\leftrightarrow \\mathbb{Q} & h(n) = \\begin{cases}h_+(n) &n &gt; 0 \\\\ 0 & n = 0 \\\\\n-h_+(-n) & n &lt; 0\\end{cases} \\\\\n(h \\circ s): \\mathbb{N} \\leftrightarrow \\mathbb{Q} & ✅🤯\n\\end{array}\n\\end{align*}\n\\]\n\n\n\n\n\n\n\n\nImage credit: Rebecca J. Stones, Math StackExchange. Math credit: Thomas Andrews, Math StackExchange"
  },
  {
    "objectID": "w04/index.html",
    "href": "w04/index.html",
    "title": "Week 4: Discrete Probability Distributions",
    "section": "",
    "text": "Open slides in new window →"
  },
  {
    "objectID": "w04/index.html#discrete-vs.-continuous",
    "href": "w04/index.html#discrete-vs.-continuous",
    "title": "Week 4: Discrete Probability Distributions",
    "section": "Discrete vs. Continuous",
    "text": "Discrete vs. Continuous\n\n\n\nDiscrete = “Easy mode”: Based (intuitively) on sets\n\\(\\Pr(A)\\): Four marbles \\(\\{A, B, C, D\\}\\) in box, all equally likely, what is the probability I pull out \\(A\\)?\n\n\nlibrary(tibble)\nlibrary(ggplot2)\ndisc_df &lt;- tribble(\n  ~x, ~y, ~label,\n  0, 0, \"A\",\n  0, 1, \"B\",\n  1, 0, \"C\",\n  1, 1, \"D\"\n)\nggplot(disc_df, aes(x=x, y=y, label=label)) +\n    geom_point(size=g_pointsize) +\n    geom_text(\n      size=g_textsize,\n      hjust=1.5,\n      vjust=-0.5\n    ) +\n    xlim(-0.5,1.5) + ylim(-0.5,1.5) +\n    coord_fixed() +\n    dsan_theme(\"quarter\") +\n    labs(\n      title=\"Discrete Probability Space in N\"\n    )\n\n\n\n\n\\[\n\\Pr(A) = \\underbrace{\\frac{|\\{A\\}|}{|\\Omega|}}_{\\mathclap{\\small \\text{Probability }\\textbf{mass}}} = \\frac{1}{|\\{A,B,C,D\\}|} = \\frac{1}{4}\n\\]\n\n\nContinuous = “Hard mode”: Based (intuitively) on areas\n\\(\\Pr(A)\\): If I throw a dart at this square, what is the probability that I hit region \\(A\\)?\n\n\nlibrary(ggforce)\nggplot(disc_df, aes(x=x, y=y, label=label)) +\n    xlim(-0.5,1.5) + ylim(-0.5,1.5) +\n    geom_rect(aes(xmin = -0.5, xmax = 1.5, ymin = -0.5, ymax = 1.5), fill=cbPalette[1], color=\"black\", alpha=0.3) +\n    geom_circle(aes(x0=x, y0=y, r=0.25), fill=cbPalette[2]) +\n    coord_fixed() +\n    dsan_theme(\"quarter\") +\n    geom_text(\n      size=g_textsize,\n      #hjust=1.75,\n      #vjust=-0.75\n    ) +\n    geom_text(\n      data=data.frame(label=\"Ω\"),\n      aes(x=-0.4,y=1.39),\n      parse=TRUE,\n      size=g_textsize\n    ) +\n    labs(\n      title=expression(\"Continuous Probability Space in \"*R^2)\n    )\n\n\n\n\n\\[\n\\Pr(A) = \\underbrace{\\frac{\\text{Area}(\\{A\\})}{\\text{Area}(\\Omega)}}_{\\mathclap{\\small \\text{Probability }\\textbf{density}}} = \\frac{\\pi r^2}{s^2} = \\frac{\\pi \\left(\\frac{1}{4}\\right)^2}{4} = \\frac{\\pi}{64}\n\\]"
  },
  {
    "objectID": "w04/index.html#the-technical-difference-tldr",
    "href": "w04/index.html#the-technical-difference-tldr",
    "title": "Week 4: Discrete Probability Distributions",
    "section": "The Technical Difference tl;dr",
    "text": "The Technical Difference tl;dr\n\nCountable Sets: Can be put into 1-to-1 correspondence with the natural numbers \\(\\mathbb{N}\\)\n\nWhat are you doing when you’re counting? Saying “first”, “second”, “third”, …\nYou’re pairing each object with a natural number! \\(\\{(\\texttt{a},1),(\\texttt{b},2),\\ldots,(\\texttt{z},26)\\}\\) \n\nUncountable Sets: Cannot be put into 1-to-1 correspondence with the natural numbers.\n\n\\(\\mathbb{R}\\) is uncountable. Intuition: Try counting the real numbers. Proof1 \\[\n\\text{Assume }\\exists (f: \\mathbb{R} \\leftrightarrow \\mathbb{N}) =\n\\begin{array}{|c|c|c|c|c|c|c|}\\hline\n\\mathbb{R} & & & & & & \\Leftrightarrow \\mathbb{N} \\\\ \\hline\n\\color{orange}{3} & . & 1 & 4 & 1 & \\cdots & \\Leftrightarrow 1 \\\\\\hline\n4 & . & \\color{orange}{9} & 9 & 9 & \\cdots & \\Leftrightarrow 2 \\\\\\hline\n0 & . & 1 & \\color{orange}{2} & 3 & \\cdots &\\Leftrightarrow 3 \\\\\\hline\n1 & . & 2 & 3 & \\color{orange}{4} & \\cdots & \\Leftrightarrow 4 \\\\\\hline\n\\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\\hline\n\\end{array} \\overset{\\color{blue}{y_{[i]}} = \\color{orange}{x_{[i]}} \\overset{\\mathbb{Z}_{10}}{+} 1}{\\longrightarrow} \\color{blue}{y = 4.035 \\ldots} \\Leftrightarrow \\; ?\n\\]\n\n\n\n\nFun math challenge: Is \\(\\mathbb{Q}\\) countable? See this appendix slide for why the answer is yes, despite the fact that \\(\\forall x, y \\in \\mathbb{Q} \\left[ \\frac{x+y}{2} \\in \\mathbb{Q} \\right]\\)"
  },
  {
    "objectID": "w04/index.html#the-practical-difference",
    "href": "w04/index.html#the-practical-difference",
    "title": "Week 4: Discrete Probability Distributions",
    "section": "The Practical Difference",
    "text": "The Practical Difference\n\nThis part of the course (discrete probability): \\(\\Pr(X = v), v \\in \\mathcal{R}_X \\subseteq \\mathbb{N}\\)\n\nExample: \\(\\Pr(\\)\\() = \\Pr(X = 3), 3 \\in \\{1,2,3,4,5,6\\} \\subseteq \\mathbb{N}\\)\n\nNext part of the course (continuous probability): \\(\\Pr(X \\in V), v \\subseteq \\mathbb{R}\\)\n\nExample: \\(\\Pr(X \\geq 2\\pi) = \\Pr(X \\in [\\pi,\\infty)), [\\pi,\\infty) \\subseteq \\mathbb{R}\\)\n\nWhy do they have to be in separate parts?\n\n\\[\n\\Pr(X = 2\\pi) = \\frac{\\text{Area}(\\overbrace{2\\pi}^{\\mathclap{\\small \\text{Single point}}})}{\\text{Area}(\\underbrace{\\mathbb{R}}_{\\mathclap{\\small \\text{(Uncountably) Infinite set of points}}})} = 0\n\\]"
  },
  {
    "objectID": "w04/index.html#probability-mass-vs.-probability-density",
    "href": "w04/index.html#probability-mass-vs.-probability-density",
    "title": "Week 4: Discrete Probability Distributions",
    "section": "Probability Mass vs. Probability Density",
    "text": "Probability Mass vs. Probability Density\n\nCumulative Distribution Function (CDF): \\(F_X(v) = \\Pr(X \\leq v)\\)\nFor discrete RV \\(X\\), Probability Mass Function (pmf) \\(p_X(v)\\): \\[\n\\begin{align*}\np_X(v) &= \\Pr(X = v) = F_X(v) - F_X(v-1) \\\\\n\\implies F_X(v) &= \\sum_{\\{w \\in \\mathcal{R}_X: \\; w \\leq v\\}}p_X(w)\n\\end{align*}\n\\]\nFor continuous RV \\(X\\) (\\(\\mathcal{R}_X \\subseteq \\mathbb{R}\\)), Probability Density Function (pdf) \\(f_X(v)\\): \\[\n\\begin{align*}\nf_X(v) &= \\frac{d}{dx}F_X(v) \\\\\n\\implies F_X(v) &= \\int_{-\\infty}^v f_X(w)dw\n\\end{align*}\n\\]\n\n\n\nFrustratingly, the CDF/pmf/pdf is usually written using \\(X\\) and \\(x\\), like \\(F_X(x) = \\Pr(X \\leq x)\\). To me this is extremely confusing, since the capitalized \\(X\\) is a random variable (not a number) while the lowercase \\(x\\) is some particular value, like \\(3\\). So, to emphasize this difference, I use \\(X\\) for the RV and \\(v\\) for the value at which we’re checking the CDF/pmf/pdf.\nAlso note the capitalized CDF but lowercase pmf/pdf, matching the mathematical notation where \\(f_X(v)\\) is the derivative of \\(F_X(v)\\)."
  },
  {
    "objectID": "w04/index.html#probability-density-neq-probability",
    "href": "w04/index.html#probability-density-neq-probability",
    "title": "Week 4: Discrete Probability Distributions",
    "section": "Probability Density \\(\\neq\\) Probability",
    "text": "Probability Density \\(\\neq\\) Probability\n\nBEWARE: \\(f_X(v) \\neq \\Pr(X = v)\\)!\nLong story short, for continuous variables, \\(\\Pr(X = v) = 0\\)2\nHence, we instead construct a PDF \\(f_X(v)\\) that enables us to calculate \\(\\Pr(X \\in [a,b])\\) by integrating: \\(f_X(v)\\) is whatever function satisfies \\(\\Pr(X \\in [a,b]) = \\int_{a}^bf_X(v)dv\\).\ni.e., instead of \\(p_X(v) = \\Pr(X = v)\\) from discrete world, the relevant function here is \\(f_X(v)\\), the probability density of \\(X\\) at \\(v\\).\nIf we really want to get something like the “probability of a value” in a continuous space 😪, we can get something kind of like this by using fancy limits \\[\nf_X(v) = \\lim_{\\varepsilon \\to 0}\\frac{P(X \\in [v-\\varepsilon, v + \\varepsilon])}{2\\varepsilon} = \\lim_{\\varepsilon \\to 0}\\frac{F(v + \\varepsilon) - F(v - \\varepsilon)}{2\\varepsilon} = \\frac{d}{dx}F_X(v)\n\\]"
  },
  {
    "objectID": "w04/index.html#bernoulli-distribution",
    "href": "w04/index.html#bernoulli-distribution",
    "title": "Week 4: Discrete Probability Distributions",
    "section": "Bernoulli Distribution",
    "text": "Bernoulli Distribution\n\nSingle trial with two outcomes, “success” (1) or “failure” (0): basic model of a coin flip (heads = 1, tails = 0)\n\\(X \\sim \\text{Bern}({\\color{purple} p}) \\implies \\mathcal{R}_X = \\{0,1\\}, \\; \\Pr(X = 1) = {\\color{purple}p}\\).\n\n\nlibrary(ggplot2)\nlibrary(tibble)\nbern_tibble &lt;- tribble(\n  ~Outcome, ~Probability, ~Color,\n  \"Failure\", 0.2, cbPalette[1],\n  \"Success\", 0.8, cbPalette[2]\n)\nggplot(data = bern_tibble, aes(x=Outcome, y=Probability)) +\n  geom_bar(aes(fill=Outcome), stat = \"identity\") +\n  dsan_theme(\"half\") +\n  labs(\n    y = \"Probability Mass\"\n  ) +\n  scale_fill_manual(values=c(cbPalette[1], cbPalette[2])) +\n  remove_legend()"
  },
  {
    "objectID": "w04/index.html#binomial-distribution",
    "href": "w04/index.html#binomial-distribution",
    "title": "Week 4: Discrete Probability Distributions",
    "section": "Binomial Distribution",
    "text": "Binomial Distribution\n\nNumber of successes in \\({\\color{purple}N}\\) Bernoulli trials. \\(X \\sim \\text{Binom}({\\color{purple}N},{\\color{purple}k},{\\color{purple}p}) \\implies \\mathcal{R}_X = \\{0, 1, \\ldots, N\\}\\)\n\n\\(P(X = k) = \\binom{N}{k}p^k(1-p)^{N-k}\\): probability of \\(k\\) successes out of \\(N\\) trials.\n\\(\\binom{N}{k} = \\frac{N!}{k!(N-k)!}\\): “Binomial coefficient”. How many groups of size \\(k\\) can be formed?3"
  },
  {
    "objectID": "w04/index.html#visualizing-the-binomial",
    "href": "w04/index.html#visualizing-the-binomial",
    "title": "Week 4: Discrete Probability Distributions",
    "section": "Visualizing the Binomial",
    "text": "Visualizing the Binomial\n\n\nCode\nk &lt;- seq(0, 10)\nprob &lt;- dbinom(k, 10, 0.5)\nbar_data &lt;- tibble(k, prob)\nggplot(bar_data, aes(x=k, y=prob)) +\n  geom_bar(stat=\"identity\", fill=cbPalette[1]) +\n  labs(\n    title=\"Binomial Distribution, N = 10, p = 0.5\",\n    y=\"Probability Mass\"\n  ) +\n  scale_x_continuous(breaks=seq(0,10)) +\n  dsan_theme(\"half\")\n\n\n\n\n\n\n\n\n\n\nSo who can tell me, from this plot, the approximate probability of getting 4 heads when flipping a coin 10 times?"
  },
  {
    "objectID": "w04/index.html#multiple-classes-multinomial-distribution",
    "href": "w04/index.html#multiple-classes-multinomial-distribution",
    "title": "Week 4: Discrete Probability Distributions",
    "section": "Multiple Classes: Multinomial Distribution",
    "text": "Multiple Classes: Multinomial Distribution\n\nBernoulli only allows two outcomes: success or failure.\nWhat if we’re predicting soccer match outcomes?\n\n\\(X_i \\in \\{\\text{Win}, \\text{Loss}, \\text{Draw}\\}\\)\n\nCategorical Distribution: Generalization of Bernoulli to \\(k\\) outcomes. \\(X \\sim \\text{Categorical}(\\mathbf{p} = \\{p_1, p_2, \\ldots, p_k\\}), \\sum_{i=1}^kp_i = 1\\).\n\n\\(P(X = k) = p_k\\)\n\nMultinomial Distribution: Generalization of Binomial to \\(k\\) outcomes.\n\\(\\mathbf{X} \\sim \\text{Multinom}(N,k,\\mathbf{p}=\\{p_1,p_2,\\ldots,p_k\\}), \\sum_{i=1}^kp_i=1\\)\n\n\\(P(\\mathbf{X} = \\{x_1,x_2\\ldots,x_k\\}) = \\frac{N!}{x_1!x_2!\\cdots x_k!}p_1^{x_1}p_2^{x_2}\\cdots p_k^{x_k}\\)\n\\(P(\\text{30 wins}, \\text{4 losses}, \\text{4 draws}) = \\frac{38!}{30!4!4!}p_{\\text{win}}^{30}p_{\\text{lose}}^4p_{\\text{draw}}^4\\)."
  },
  {
    "objectID": "w04/index.html#geometric-distribution",
    "href": "w04/index.html#geometric-distribution",
    "title": "Week 4: Discrete Probability Distributions",
    "section": "Geometric Distribution",
    "text": "Geometric Distribution\n\nGeometric: Likelihood that we need \\({\\color{purple}k}\\) trials to get our first success. \\(X \\sim \\text{Geom}({\\color{purple}k},{\\color{purple}p}) \\implies \\mathcal{R}_X = \\{0, 1, \\ldots\\}\\)\n\n\\(P(X = k) = \\underbrace{(1-p)^{k-1}}_{\\small k - 1\\text{ failures}}\\cdot \\underbrace{p}_{\\mathclap{\\small \\text{success}}}\\)\nProbability of \\(k-1\\) failures followed by a success\n\n\n\nlibrary(ggplot2)\nk &lt;- seq(0, 8)\nprob &lt;- dgeom(k, 0.5)\nbar_data &lt;- tibble(k, prob)\nggplot(bar_data, aes(x = k, y = prob)) +\n    geom_bar(stat = \"identity\", fill = cbPalette[1]) +\n    labs(\n        title = \"Geometric Distribution, p = 0.5\",\n        y = \"Probability Mass\"\n    ) +\n    scale_x_continuous(breaks = seq(0, 8)) +\n    dsan_theme(\"half\")"
  },
  {
    "objectID": "w04/index.html#less-common-but-important-distributions",
    "href": "w04/index.html#less-common-but-important-distributions",
    "title": "Week 4: Discrete Probability Distributions",
    "section": "Less Common (But Important) Distributions",
    "text": "Less Common (But Important) Distributions\n\nDiscrete Uniform: \\(N\\) equally-likely outcomes\n\n\\(X \\sim U\\{{\\color{purple}a},{\\color{purple}b}\\} \\implies \\mathcal{R}_X = \\{a, a+1, \\ldots, b\\}, P(X = k) = \\frac{1}{{\\color{purple}b} - {\\color{purple}a} + 1}\\)\n\nBeta: \\(X \\sim \\text{Beta}({\\color{purple}\\alpha}, {\\color{purple}\\beta})\\): conjugate prior for Bernoulli, Binomial, and Geometric dists.\n\nIntuition: If we use Beta to encode our prior hypothesis, then observe data drawn from Binomial, distribution of our updated hypothesis is still Beta.\n\\(\\underbrace{\\Pr(\\text{biased}) = \\Pr(\\text{unbiased})}_{\\text{Prior: }\\text{Beta}({\\color{purple}\\alpha}, {\\color{purple}\\beta})} \\rightarrow\\) Observe \\(\\underbrace{\\frac{8}{10}\\text{ heads}}_{\\text{Data}} \\rightarrow \\underbrace{\\Pr(\\text{biased}) = 0.65}_{\\text{Posterior: }\\text{Beta}({\\color{purple}\\alpha + 8}, {\\color{purple}\\beta + 2})}\\)\n\nDirichlet: \\(\\mathbf{X} = (X_1, X_2, \\ldots, X_K) \\sim \\text{Dir}({\\color{purple} \\boldsymbol\\alpha})\\)\n\n\\(K\\)-dimensional extension of Beta (thus, conjugate prior for Multinomial)\n\n\n\n\nWe can now use \\(\\text{Beta}(\\alpha + 8, \\beta + 2)\\) as a prior for our next set of trials (encoding our knowledge up to that point), and update further once we know the results (to yet another Beta distribution)."
  },
  {
    "objectID": "w04/index.html#interactive-visualizations",
    "href": "w04/index.html#interactive-visualizations",
    "title": "Week 4: Discrete Probability Distributions",
    "section": "Interactive Visualizations",
    "text": "Interactive Visualizations\n\nSeeing Theory →"
  },
  {
    "objectID": "w04/index.html#lab-3-demonstration",
    "href": "w04/index.html#lab-3-demonstration",
    "title": "Week 4: Discrete Probability Distributions",
    "section": "Lab 3 Demonstration",
    "text": "Lab 3 Demonstration\nLab 3 Demo Link"
  },
  {
    "objectID": "w04/index.html#lab-3-assignment-overview",
    "href": "w04/index.html#lab-3-assignment-overview",
    "title": "Week 4: Discrete Probability Distributions",
    "section": "Lab 3 Assignment Overview",
    "text": "Lab 3 Assignment Overview\nLab 3 Assignment"
  },
  {
    "objectID": "w04/index.html#appendix-countability-of-mathbbq",
    "href": "w04/index.html#appendix-countability-of-mathbbq",
    "title": "Week 4: Discrete Probability Distributions",
    "section": "Appendix: Countability of \\(\\mathbb{Q}\\)",
    "text": "Appendix: Countability of \\(\\mathbb{Q}\\)\n\nBad definition: “\\(\\mathbb{N}\\) is countable because no \\(x \\in \\mathbb{N}\\) between \\(0\\) and \\(1\\). \\(\\mathbb{R}\\) is uncountable because infinitely-many \\(x \\in \\mathbb{R}\\) between \\(0\\) and \\(1\\).” (\\(\\implies \\mathbb{Q}\\) uncountable)\nAnd yet, \\(\\mathbb{Q}\\) is countable…\n\n\n\n\n\n\n\n\n\n\\[\n\\begin{align*}\n\\begin{array}{ll}\ns: \\mathbb{N} \\leftrightarrow \\mathbb{Z} & s(n) = (-1)^n \\left\\lfloor \\frac{n+1}{2} \\right\\rfloor \\\\\nh_+: \\mathbb{Z}^+ \\leftrightarrow \\mathbb{Q}^+ & p_1^{a_1}p_2^{a_2}\\cdots \\mapsto p_1^{s(a_1)}p_2^{s(a_2)}\\cdots \\\\\nh: \\mathbb{Z} \\leftrightarrow \\mathbb{Q} & h(n) = \\begin{cases}h_+(n) &n &gt; 0 \\\\ 0 & n = 0 \\\\\n-h_+(-n) & n &lt; 0\\end{cases} \\\\\n(h \\circ s): \\mathbb{N} \\leftrightarrow \\mathbb{Q} & ✅🤯\n\\end{array}\n\\end{align*}\n\\]\n\n\n\n\n\n\nImage credit: Rebecca J. Stones, Math StackExchange. Math credit: Thomas Andrews, Math StackExchange"
  },
  {
    "objectID": "w04/index.html#footnotes",
    "href": "w04/index.html#footnotes",
    "title": "Week 4: Discrete Probability Distributions",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe method used in this proof, if you haven’t seen it before, is called Cantor diagonalization, and it is extremely fun and applicable to a wide variety of levels-of-infinity proofs↩︎\nFor intuition: \\(X \\sim U[0,10] \\implies \\Pr(X = \\pi) = \\frac{|\\{v \\in \\mathbb{R}:\\; v = \\pi\\}|}{|\\mathbb{R}|} = \\frac{1}{2^{\\aleph_0}} \\approx 0\\). That is, finding the \\(\\pi\\) needle in the \\(\\mathbb{R}\\) haystack is a one-in-\\(\\left(\\infty^\\infty\\right)\\) event. A similar issue occurs if \\(S\\) is countably-infinite, like \\(S = \\mathbb{N}\\): \\(\\Pr(X = 3) = \\frac{|\\{x \\in \\mathbb{N} : \\; x = 3\\}|}{|\\mathbb{N}|} = \\frac{1}{\\aleph_0}\\).↩︎\nA fun way to never have to memorize or compute these: imagine a pyramid like \\(\\genfrac{}{}{0pt}{}{}{\\boxed{\\phantom{1}}}\\genfrac{}{}{0pt}{}{\\boxed{\\phantom{1}}}{}\\genfrac{}{}{0pt}{}{}{\\boxed{\\phantom{1}}}\\), where the boxes are slots for numbers, and put a \\(1\\) in the box at the top. In the bottom row, fill each slot with the sum of the two numbers above-left and above-right of it. Since \\(1 + \\text{(nothing)} = 1\\), this looks like: \\(\\genfrac{}{}{0pt}{}{}{1}\\genfrac{}{}{0pt}{}{1}{}\\genfrac{}{}{0pt}{}{}{1}\\). Continue filling in the pyramid this way, so the next row looks like \\(\\genfrac{}{}{0pt}{}{}{1}\\genfrac{}{}{0pt}{}{1}{}\\genfrac{}{}{0pt}{}{}{2}\\genfrac{}{}{0pt}{}{1}{}\\genfrac{}{}{0pt}{}{}{1}\\), then \\(\\genfrac{}{}{0pt}{}{}{1}\\genfrac{}{}{0pt}{}{1}{}\\genfrac{}{}{0pt}{}{}{3}\\genfrac{}{}{0pt}{}{2}{}\\genfrac{}{}{0pt}{}{}{3}\\genfrac{}{}{0pt}{}{1}{}\\genfrac{}{}{0pt}{}{}{1}\\), and so on. The \\(k\\)th number in the \\(N\\)th row (counting from \\(0\\)) is \\(\\binom{N}{k}\\). For the triangle written out to the 7th row, see Appendix I at end of slideshow.↩︎"
  },
  {
    "objectID": "w03/index.html",
    "href": "w03/index.html",
    "title": "Week 3: Conditional Probability",
    "section": "",
    "text": "Open slides in new window →"
  },
  {
    "objectID": "w03/index.html#recap-1",
    "href": "w03/index.html#recap-1",
    "title": "Week 3: Conditional Probability",
    "section": "Recap",
    "text": "Recap\n\nLogic \\(\\rightarrow\\) Set Theory \\(\\rightarrow\\) Probability Theory\nEntirety of probability theory can be derived from two axioms:\n\n\n\n\n\n\n\nThe Entirety of Probability Theory Follows From…\n\n\n\nAxiom 1 (Unitarity): \\(\\Pr(\\Omega) = 1\\) (The probability that something happens is 1)\nAxiom 2 (\\(\\sigma\\)-additivity): For mutually-exclusive events \\(E_1, E_2, \\ldots\\),\n\\[\n\\underbrace{\\Pr\\left(\\bigcup_{i=1}^{\\infty}E_i\\right)}_{\\Pr(E_1\\text{ occurs }\\vee E_2\\text{ occurs } \\vee \\cdots)} = \\underbrace{\\sum_{i=1}^{\\infty}\\Pr(E_i)}_{\\Pr(E_1\\text{ occurs}) + \\Pr(E_2\\text{ occurs}) + \\cdots}\n\\]\n\n\n\nBut what does “mutually exclusive” mean…?"
  },
  {
    "objectID": "w03/index.html#venn-diagrams-sets",
    "href": "w03/index.html#venn-diagrams-sets",
    "title": "Week 3: Conditional Probability",
    "section": "Venn Diagrams: Sets",
    "text": "Venn Diagrams: Sets\n\n\n\n\n\n\n\n\n\\[\n\\begin{align*}\n&A = \\{0, 1, 2\\}, \\; B = \\{4, 5, 6\\} \\\\\n&\\implies A \\cap B = \\varnothing\n\\end{align*}\n\\]\nFigure 1: Mutually-exclusive (disjoint) sets\n\n\n\n\n\n\n\n\\[\n\\begin{align*}\n&A = \\{1, 2, 3\\}, \\; B = \\{3, 4, 5\\} \\\\\n&\\implies A \\cap B = \\{3\\}\n\\end{align*}\n\\]\nFigure 2: Non-mutually-exclusive sets"
  },
  {
    "objectID": "w03/index.html#venn-diagrams-events-dice",
    "href": "w03/index.html#venn-diagrams-events-dice",
    "title": "Week 3: Conditional Probability",
    "section": "Venn Diagrams: Events (Dice)",
    "text": "Venn Diagrams: Events (Dice)\n\\[\n\\begin{align*}\nA &= \\{\\text{Roll is even}\\} = \\{2, 4, 6\\} \\\\\nB &= \\{\\text{Roll is odd}\\} = \\{1, 3, 5\\} \\\\\nC &= \\{\\text{Roll is in Fibonnaci sequence}\\} = \\{1, 2, 3, 5\\}\n\\end{align*}\n\\]\n\n\n\n\n\n\n\n\n\n\nSet 1\nSet 2\nIntersection\nMutually Exclusive?\nCan Happen Simultaneously?\n\n\n\n\n\\(A\\)\n\\(B\\)\n\\(A \\cap B = \\varnothing\\)\nYes\nNo\n\n\n\\(A\\)\n\\(C\\)\n\\(A \\cap C = \\{2\\}\\)\nNo\nYes\n\n\n\\(B\\)\n\\(C\\)\n\\(B \\cap C = \\{1, 3, 5\\}\\)\nNo\nYes"
  },
  {
    "objectID": "w03/index.html#rules-of-probability",
    "href": "w03/index.html#rules-of-probability",
    "title": "Week 3: Conditional Probability",
    "section": "“Rules” of Probability",
    "text": "“Rules” of Probability\n\n(Remember: not “rules” but “facts resulting from the logic \\(\\leftrightarrow\\) probability connection”)\n\n\n\n\n\n\n\n“Rules” of Probability\n\n\n\nFor logical predicates \\(p, q \\in \\{T, F\\}\\), events \\(P, Q\\) defined so \\(P\\) = event that \\(p\\) becomes true, \\(Q\\) = event that \\(q\\) becomes true,\n\nLogical AND = Probabilistic Multiplication\n\n\\[\n\\Pr(p \\wedge q) = \\Pr(P \\cap Q) = \\Pr(P) \\cdot \\Pr(Q)\n\\]\n\nLogical OR = Probabilistic Addition\n\n\\[\n\\Pr(p \\vee q) = \\Pr(P \\cup Q) = \\Pr(P) + \\Pr(Q) - \\underbrace{\\Pr(P \\cap Q)}_{\\text{(see rule 1)}}\n\\]\n\nLogical NOT = Probabilistic Complement\n\n\\[\n\\Pr(\\neg p) = \\Pr(P^c) = 1 - \\Pr(P)\n\\]"
  },
  {
    "objectID": "w03/index.html#conditional-probability",
    "href": "w03/index.html#conditional-probability",
    "title": "Week 3: Conditional Probability",
    "section": "Conditional Probability",
    "text": "Conditional Probability\n\nUsually if someone asks you probabilistic questions, like\n\n“What is the likelihood that [our team] wins?”\n“Do you think it will rain tomorrow?” and so on\n\nYou don’t guess a random number, you consider and incorporate evidence.\nExample: \\(\\Pr(\\text{rain})\\) on its own, without any other info? A tough question… maybe \\(0.5\\)?\nIn reality, we would think about\n\n\\(\\Pr(\\text{rain} \\mid \\text{month of the year})\\)\n\\(\\Pr(\\text{rain} \\mid \\text{where we live})\\)\n\\(\\Pr(\\text{rain} \\mid \\text{did it rain yesterday?})\\)\n\nPsychologically, breaks down into two steps: (1) Think of a baseline probability, (2) Update baseline probability to incorporate relevant evidence (more on this in a bit…)\nAlso recall from last week: all probability is conditional probability, even if just conditioned on “something happened” (\\(\\Omega\\), the thing defined so \\(\\Pr(\\Omega) = 1\\))"
  },
  {
    "objectID": "w03/index.html#naïve-definition-2.0",
    "href": "w03/index.html#naïve-definition-2.0",
    "title": "Week 3: Conditional Probability",
    "section": "Naïve Definition 2.0",
    "text": "Naïve Definition 2.0\n\n\n\n\n\n\n[Slightly Less] Naïve Definition of Probability\n\n\n\n\\[\n\\Pr(A \\mid B) = \\frac{\\text{\\# of Desired Outcomes in world where }B\\text{ happened}}{\\text{\\# Total outcomes in world where }B\\text{ happened}} = \\frac{|B \\cap A|}{|B|}\n\\]\n\n\n\n\n\n\n\n\n\n\nWorld Name\nWeather in World\nLikelihood of Rain Today\n\n\n\n\n\\(R\\)\nRained for the past 5 days\n\\(\\Pr(\\text{rain} \\mid R) &gt; 0.5\\)\n\n\n\\(M\\)\nMix of rain and non-rain over past 5 days\n\\(\\Pr(\\text{rain} \\mid M) \\approx 0.5\\)\n\n\n\\(S\\)\nSunny for the past 5 days\n\\(\\Pr(\\text{rain} \\mid S) &lt; 0.5\\)"
  },
  {
    "objectID": "w03/index.html#law-of-total-probability",
    "href": "w03/index.html#law-of-total-probability",
    "title": "Week 3: Conditional Probability",
    "section": "Law of Total Probability",
    "text": "Law of Total Probability\n\nSuppose the events \\(B_1, \\ldots, B_k\\) form a partition of the space \\(S\\) and \\(\\Pr(B_j) &gt; 0 \\forall j\\).\nThen, for every event \\(A\\) in \\(S\\),\n\n\\[\n\\Pr(A) = \\sum_{i=1}^k \\Pr(B_j)\\Pr(A \\mid B_j)\n\\]\n\nProbability of an event is the sum of its conditional probabilities across all conditions.\nIn other words: \\(A\\) is some event, \\(B_1, \\ldots, B_n\\) are mutually exclusive events filling entire sample-space, then\n\n\\[\n\\Pr(A) = \\Pr(A \\mid B_1)\\Pr(B_1) + \\Pr(A \\mid B_2)\\Pr(B_2) + \\cdots + \\Pr(A \\mid B_n)\\Pr(B_n)\n\\]\ni.e. Compute the probability by summing over all possible cases."
  },
  {
    "objectID": "w03/index.html#example",
    "href": "w03/index.html#example",
    "title": "Week 3: Conditional Probability",
    "section": "Example",
    "text": "Example\n\nProbabilities of completing a job on time, with and without rain, are 0.42 and 0.90 respectively.\nProbability it will rain is 0.45. What is the probability the job will be completed on time?\n\\(A\\) = job will be completed on time, \\(B\\) = rain\n\n\\[\n\\Pr(B) = 0.45 \\implies \\Pr(B^c) = 1 - \\Pr(B) = 0.55.\n\\]\n\nNote: Events \\(B\\) and \\(B^c\\) are exclusive and form partitions of the sample space \\(S\\)\nWe know \\(\\Pr(A \\mid B) = 0.24\\), \\(\\Pr(A \\mid B^c) = 0.9\\).\nBy the Law of Total Probability, we have\n\n\\[\n\\begin{align*}\n\\Pr(A) &= \\Pr(B)\\Pr(A \\mid B) + \\Pr(B^c)\\Pr(A \\mid B^c) \\\\\n&= 0.45(0.42) + 0.55(0.9) = 0.189 + 0.495 = 0684.\n\\end{align*}\n\\]\nSo, the probability that the job will be completed on time is 0.684. (source)"
  },
  {
    "objectID": "w03/index.html#deriving-bayes-theorem",
    "href": "w03/index.html#deriving-bayes-theorem",
    "title": "Week 3: Conditional Probability",
    "section": "Deriving Bayes’ Theorem",
    "text": "Deriving Bayes’ Theorem\n\nLiterally just a re-writing of the conditional probability definition (don’t be scared)!\n\n\n\n\nFor two events \\(A\\) and \\(B\\), definition of conditional probability says that\n\n\\[\n\\begin{align*}\n\\Pr(A \\mid B) &= \\frac{\\Pr(A \\cap B)}{\\Pr(B)} \\tag{1} \\\\\n\\Pr(B \\mid A) &= \\frac{\\Pr(B \\cap A)}{\\Pr(A)} \\tag{2}\n\\end{align*}\n\\]\n\nMultiply to get rid of fractions\n\n\\[\n\\begin{align*}\n\\Pr(A \\mid B)\\Pr(B) &= \\Pr(A \\cap B) \\tag{1*} \\\\\n\\Pr(B \\mid A)\\Pr(A) &= \\Pr(B \\cap A) \\tag{2*}\n\\end{align*}\n\\]\n\n\nBut set intersection is associative (just like multiplication…), \\(A \\cap B = B \\cap A\\)! So, we know LHS of \\((\\text{1*})\\) = LHS of \\((\\text{2*})\\):\n\n\\[\n\\Pr(A \\mid B)\\Pr(B) = \\Pr(B \\mid A)\\Pr(A)\n\\]\n\nDivide both sides by \\(\\Pr(B)\\) to get a new definition of \\(\\Pr(A \\mid B)\\), Bayes’ Theorem!\n\n\n\n\\[\n\\boxed{\\Pr(A \\mid B) = \\frac{\\Pr(B \\mid A)\\Pr(A)}{\\Pr(B)}}\n\\]\nFigure 3: Bayes’ Theorem"
  },
  {
    "objectID": "w03/index.html#why-is-this-helpful",
    "href": "w03/index.html#why-is-this-helpful",
    "title": "Week 3: Conditional Probability",
    "section": "Why Is This Helpful?",
    "text": "Why Is This Helpful?\n\n\n\n\n\n\nBayes’ Theorem\n\n\n\nFor any two events \\(A\\) and \\(B\\), \\[\n\\Pr(A \\mid B) = \\frac{\\Pr(B \\mid A)\\Pr(A)}{\\Pr(B)}\n\\]\n\n\n\nIn words (as exciting as I can make it, for now): Bayes’ Theorem allows us to take information about \\(B \\mid A\\) and use it to infer information about \\(A \\mid B\\)\nIt isn’t until you work through some examples that this becomes mind-blowing, the most powerful equation we have for inferring unknowns from knowns…\nConsider \\(A = \\{\\text{person has disease}\\}\\), \\(B = \\{\\text{person tests positive for disease}\\}\\)\n\nIs \\(A\\) observable on its own? No, but…\n\nIs \\(B\\) observable on its own? Yes, and\nCan we infer information about \\(A\\) from knowing \\(B\\)? Also Yes, thanks to Bayes!\n\nTherefore, we can use \\(B\\) to infer information about \\(A\\), i.e., calculate \\(\\Pr(A \\mid B)\\)…"
  },
  {
    "objectID": "w03/index.html#why-is-this-helpful-for-data-science",
    "href": "w03/index.html#why-is-this-helpful-for-data-science",
    "title": "Week 3: Conditional Probability",
    "section": "Why Is This Helpful for Data Science?",
    "text": "Why Is This Helpful for Data Science?\n\nIt merges probability theory and hypothesis testing into a single framework:\n\n\\[\n\\Pr(\\text{hypothesis} \\mid \\text{data}) = \\frac{\\Pr(\\text{data} \\mid \\text{hypothesis})\\Pr(\\text{hypothesis})}{\\Pr(\\text{data})}\n\\]"
  },
  {
    "objectID": "w03/index.html#probability-forwards-and-backwards",
    "href": "w03/index.html#probability-forwards-and-backwards",
    "title": "Week 3: Conditional Probability",
    "section": "Probability Forwards and Backwards",
    "text": "Probability Forwards and Backwards\n\nTwo discrete RVs:\n\nWeather on a given day, \\(W \\in \\{\\textsf{Rain},\\textsf{Sun}\\}\\)\nAction that day, \\(A \\in \\{\\textsf{Go}, \\textsf{Stay}\\}\\): go to party or stay in and watch movie\n\nData-generating process: if \\(\\textsf{Sun}\\), rolls a die \\(R\\) and goes out unless \\(R = 6\\). If \\(\\textsf{Rain}\\), flips a coin and goes out if \\(\\textsf{H}\\).\nProbabilistic Graphical Model (PGM):"
  },
  {
    "objectID": "w03/index.html#section",
    "href": "w03/index.html#section",
    "title": "Week 3: Conditional Probability",
    "section": "",
    "text": "So, if we know \\(W = \\textsf{Sun}\\), what is \\(P(A = \\textsf{Go})\\)? \\[\n\\begin{align*}\nP(A = \\textsf{Go} \\mid W) &= 1 - P(R = 6) \\\\\n&= 1 - \\frac{1}{6} = \\frac{5}{6}\n\\end{align*}\n\\]\nConditional probability lets us go forwards (left to right):\n\n\n\n\n\n\n\nBut what if we want to perform inference going backwards?"
  },
  {
    "objectID": "w03/index.html#section-1",
    "href": "w03/index.html#section-1",
    "title": "Week 3: Conditional Probability",
    "section": "",
    "text": "If we see Ana at the party, we know \\(A = \\textsf{Go}\\)\nWhat does this tell us about the weather?\nIntuitively, we should increase our degree of belief that \\(W = \\textsf{Sun}\\). But, by how much?\nWe don’t know \\(P(W \\mid A)\\), only \\(P(A \\mid W)\\)…"
  },
  {
    "objectID": "w03/index.html#section-2",
    "href": "w03/index.html#section-2",
    "title": "Week 3: Conditional Probability",
    "section": "",
    "text": "\\[\nP(W = \\textsf{Sun} \\mid A = \\textsf{Go}) = \\frac{\\overbrace{P(A = \\textsf{Go} \\mid W = \\textsf{Sun})}^{5/6~ ✅}\\overbrace{P(W = \\textsf{Sun})}^{❓}}{\\underbrace{P(A = \\textsf{Go})}_{❓}}\n\\]\n\nWe’ve seen \\(P(W = \\textsf{Sun})\\) before, it’s our prior: the probability without having any additional relevant knowledge. So, let’s say 50/50. \\(P(W = \\textsf{Sun}) = \\frac{1}{2}\\)\nIf we lived in Seattle, we could pick \\(P(W = \\textsf{Sun}) = \\frac{1}{4}\\)"
  },
  {
    "objectID": "w03/index.html#section-3",
    "href": "w03/index.html#section-3",
    "title": "Week 3: Conditional Probability",
    "section": "",
    "text": "\\[\nP(W = \\textsf{Sun} \\mid A = \\textsf{Go}) = \\frac{\\overbrace{P(A = \\textsf{Go} \\mid W = \\textsf{Sunny})}^{5/6~ ✅}\\overbrace{P(W = \\textsf{Sun})}^{1/2~ ✅}}{\\underbrace{P(A = \\textsf{Go})}_{❓}}\n\\]\n\n\\(P(A = \\textsf{Go})\\) is trickier: the probability that Ana goes out regardless of what the weather is. But there are only two possible weather outcomes! So we just compute\n\n\\[\n\\begin{align*}\n&P(A = \\textsf{Go}) = \\sum_{\\omega \\in S(W)}P(A = \\textsf{Go}, \\omega) = \\sum_{\\omega \\in S(W)}P(A = \\textsf{Go} \\mid \\omega)P(\\omega) \\\\\n&= P(A = \\textsf{Go} \\mid W = \\textsf{Rain})P(W = \\textsf{Rain}) + P(A = \\textsf{Go} \\mid W = \\textsf{Sun})P(W = \\textsf{Sun}) \\\\\n&= \\left( \\frac{1}{2} \\right)\\left( \\frac{1}{2} \\right) + \\left( \\frac{5}{6} \\right)\\left( \\frac{1}{2} \\right) = \\frac{1}{4} + \\frac{5}{12} = \\frac{2}{3}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w03/index.html#putting-it-all-together",
    "href": "w03/index.html#putting-it-all-together",
    "title": "Week 3: Conditional Probability",
    "section": "Putting it All Together",
    "text": "Putting it All Together\n\\[\n\\begin{align*}\nP(W = \\textsf{Sun} \\mid A = \\textsf{Go}) &= \\frac{\\overbrace{P(A = \\textsf{Go} \\mid W = \\textsf{Sunny})}^{3/4~ ✅}\\overbrace{P(W = \\textsf{Sun})}^{1/2~ ✅}}{\\underbrace{P(A = \\textsf{Go})}_{1/2~ ✅}} \\\\\n&= \\frac{\\left(\\frac{3}{4}\\right)\\left(\\frac{1}{2}\\right)}{\\frac{1}{2}} = \\frac{\\frac{3}{8}}{\\frac{1}{2}} = \\frac{3}{4}.\n\\end{align*}\n\\]\n\nGiven that we see Ana at the party, we should update our beliefs, so that \\(P(W = \\textsf{Sun}) = \\frac{3}{4}, P(W = \\textsf{Rain}) = \\frac{1}{4}\\)."
  },
  {
    "objectID": "w03/index.html#a-scarier-example",
    "href": "w03/index.html#a-scarier-example",
    "title": "Week 3: Conditional Probability",
    "section": "A Scarier Example",
    "text": "A Scarier Example\n\nBo worries he has a rare disease. He takes a test with 99% accuracy and tests positive. What’s the probability Bo has the disease? (Intuition: 99%? …Let’s do the math!)\n\n\n\n\n\\(H \\in \\{\\textsf{sick}, \\textsf{healthy}\\}, T \\in \\{\\textsf{T}^+, \\textsf{T}^-\\}\\)\nThe test: 99% accurate. \\(\\Pr(T = \\textsf{T}^+ \\mid H = \\textsf{sick}) = 0.99\\), \\(\\Pr(T = \\textsf{T}^- \\mid H = \\textsf{healthy}) = 0.99\\).\nThe disease: 1 in 10K. \\(\\Pr(H = \\textsf{sick}) = \\frac{1}{10000}\\)\nWhat do we want to know? \\(\\Pr(H = \\textsf{sick} \\mid T = \\textsf{T}^+)\\)\nHow do we get there?\n\n\n\n\n\nThis photo, originally thought to be of Thomas Bayes, turns out to be probably someone else… \\(\\Pr(\\textsf{Bayes})\\)?\n\n\n\n\n\n\\(H\\) for health, \\(T\\) for test result\nPhoto credit: https://thedatascientist.com/wp-content/uploads/2019/04/reverend-thomas-bayes.jpg"
  },
  {
    "objectID": "w03/index.html#section-4",
    "href": "w03/index.html#section-4",
    "title": "Week 3: Conditional Probability",
    "section": "",
    "text": "\\[\n\\begin{align*}\n\\Pr(H = \\textsf{sick} \\mid T = \\textsf{T}^+) &= \\frac{\\Pr(T = \\textsf{T}^+ \\mid H = \\textsf{sick})\\Pr(H = \\textsf{sick})}{\\Pr(T = \\textsf{T}^+)} \\\\\n&= \\frac{(0.99)\\left(\\frac{1}{10000}\\right)}{(0.99)\\left( \\frac{1}{10000} \\right) + (0.01)\\left( \\frac{9999}{10000} \\right)}\n\\end{align*}\n\\]\n\np_sick &lt;- 1 / 10000\np_healthy &lt;- 1 - p_sick\np_pos_given_sick &lt;- 0.99\np_neg_given_sick &lt;- 1 - p_pos_given_sick\np_neg_given_healthy &lt;- 0.99\np_pos_given_healthy &lt;- 1 - p_neg_given_healthy\nnumer &lt;- p_pos_given_sick * p_sick\ndenom1 &lt;- numer\ndenom2 &lt;- p_pos_given_healthy * p_healthy\nfinal_prob &lt;- numer / (denom1 + denom2)\nfinal_prob\n\n[1] 0.009803922\n\n\n\n… Less than 1% 😱"
  },
  {
    "objectID": "w03/index.html#proof-in-the-pudding",
    "href": "w03/index.html#proof-in-the-pudding",
    "title": "Week 3: Conditional Probability",
    "section": "Proof in the Pudding",
    "text": "Proof in the Pudding\n\nLet’s generate a dataset of 5,000 people, using \\(\\Pr(\\textsf{Disease}) = \\frac{1}{10000}\\)\n\n\n\nCode\nlibrary(tibble)\nlibrary(dplyr)\n# Disease rarity\np_disease &lt;- 1 / 10000\n# 1K people\nnum_people &lt;- 10000\n# Give them ids\nppl_df &lt;- tibble(id=seq(1,num_people))\n# Whether they have the disease or not\nhas_disease &lt;- rbinom(num_people, 1, p_disease)\nppl_df &lt;- ppl_df %&gt;% mutate(has_disease=has_disease)\ndisp(ppl_df %&gt;% head())"
  },
  {
    "objectID": "w03/index.html#binary-variable-trick",
    "href": "w03/index.html#binary-variable-trick",
    "title": "Week 3: Conditional Probability",
    "section": "Binary Variable Trick",
    "text": "Binary Variable Trick\n\nSince has_disease \\(\\in \\{0, 1\\}\\), we can use\n\nsum(has_disease) to obtain the count of people with the disease, or\nmean(has_disease) to obtain the proportion of people who have the disease\n\nTo see this (or, if you forget in the future), just make a fake dataset with a binary variable and 3 rows, and think about sums vs. means of that variable:\n\n\n\n\n\nCode\nbinary_df &lt;- tibble(\n  id=c(1,2,3),\n  x=c(0,1,0)\n)\ndisp(binary_df)\n\n\n\n\n\n\n\n\nTaking the sum tells us: one row where x == 1:\n\n\nCode\nsum(binary_df$x)\n\n\n[1] 1\n\n\nTaking the mean tells us: 1/3 of rows have x == 1:\n\n\nCode\nmean(binary_df$x)\n\n\n[1] 0.3333333"
  },
  {
    "objectID": "w03/index.html#applying-this-to-the-disease-data",
    "href": "w03/index.html#applying-this-to-the-disease-data",
    "title": "Week 3: Conditional Probability",
    "section": "Applying This to the Disease Data",
    "text": "Applying This to the Disease Data\n\nIf we want the number of people who have the disease:\n\n\n\nCode\n# Compute the *number* of people who have the disease\nsum(ppl_df$has_disease)\n\n\n[1] 1\n\n\n\nIf we want the proportion of people who have the disease:\n\n\n\nCode\n# Compute the *proportion* of people who have the disease\nmean(ppl_df$has_disease)\n\n\n[1] 1e-04\n\n\n\n(And if you dislike scientific notation like I do…)\n\n\n\nCode\nformat(mean(ppl_df$has_disease), scientific = FALSE)\n\n\n[1] \"0.0001\"\n\n\n\n(Foreshadowing Monte Carlo methods)"
  },
  {
    "objectID": "w03/index.html#data-generating-process-test-results",
    "href": "w03/index.html#data-generating-process-test-results",
    "title": "Week 3: Conditional Probability",
    "section": "Data-Generating Process: Test Results",
    "text": "Data-Generating Process: Test Results\n\n\nCode\nlibrary(dplyr)\n# Data Generating Process\ntake_test &lt;- function(is_sick) {\n  if (is_sick) {\n    return(rbinom(1,1,p_pos_given_sick))\n  } else {\n    return(rbinom(1,1,p_pos_given_healthy))\n  }\n}\nppl_df['test_result'] &lt;- unlist(lapply(ppl_df$has_disease, take_test))\nnum_positive &lt;- sum(ppl_df$test_result)\np_positive &lt;- mean(ppl_df$test_result)\nwriteLines(paste0(num_positive,\" positive tests / \",num_people,\" total = \",p_positive))\n\n\n111 positive tests / 10000 total = 0.0111\n\n\n\ndisp(ppl_df %&gt;% head(50), obs_per_page = 3)"
  },
  {
    "objectID": "w03/index.html#zooming-in-on-positive-tests",
    "href": "w03/index.html#zooming-in-on-positive-tests",
    "title": "Week 3: Conditional Probability",
    "section": "Zooming In On Positive Tests",
    "text": "Zooming In On Positive Tests\n\n\n\npos_ppl &lt;- ppl_df %&gt;% filter(test_result == 1)\ndisp(pos_ppl, obs_per_page = 10)\n\n\n\n\n\n\n\n\nBo doesn’t have it, and neither do 110 of the 111 total people who tested positive!\nBut, in the real world, we only observe \\(T\\)"
  },
  {
    "objectID": "w03/index.html#zooming-in-on-disease-havers",
    "href": "w03/index.html#zooming-in-on-disease-havers",
    "title": "Week 3: Conditional Probability",
    "section": "Zooming In On Disease-Havers",
    "text": "Zooming In On Disease-Havers\n\nWhat if we look at only those who actually have the disease? Maybe the cost of 111 people panicking is worth it if we correctly catch those who do have it?\n\n\n\nCode\ndisp(ppl_df[ppl_df$has_disease == 1,])\n\n\n\n\n\n\n\nIs this always going to be the case?\n\n\n\n\nNum with disease: 1\nProportion with disease: 0.0002\nNumber of positive tests: 53\n\n\n\n\n\n\n\n\n\ndisp(simulate_disease(5000, 1/10000))\n\nNum with disease: 3\nProportion with disease: 0.0006\nNumber of positive tests: 63"
  },
  {
    "objectID": "w03/index.html#worst-case-worlds",
    "href": "w03/index.html#worst-case-worlds",
    "title": "Week 3: Conditional Probability",
    "section": "Worst-Case Worlds",
    "text": "Worst-Case Worlds\n\n\n\nfor (i in seq(1,1000)) {\n  sim_result &lt;- simulate_disease(5000, 1/10000, verbose = FALSE, return_all_detected = FALSE, return_df = FALSE, return_info = TRUE)\n  if (!sim_result$all_detected) {\n    writeLines(paste0(\"World #\",i,\" / 1000 (\",sim_result$num_people,\" people):\"))\n    print(sim_result$df)\n    writeLines('\\n')\n  }\n}\n\nWorld #413 / 1000 (5000 people):\n# A tibble: 2 × 3\n     id has_disease test_result\n  &lt;int&gt;       &lt;int&gt;       &lt;int&gt;\n1  2617           1           1\n2  4192           1           0\n\n\nWorld #501 / 1000 (5000 people):\n# A tibble: 1 × 3\n     id has_disease test_result\n  &lt;int&gt;       &lt;int&gt;       &lt;int&gt;\n1  3669           1           0\n\n\nWorld #670 / 1000 (5000 people):\n# A tibble: 1 × 3\n     id has_disease test_result\n  &lt;int&gt;       &lt;int&gt;       &lt;int&gt;\n1  1979           1           0\n\n\nWorld #698 / 1000 (5000 people):\n# A tibble: 1 × 3\n     id has_disease test_result\n  &lt;int&gt;       &lt;int&gt;       &lt;int&gt;\n1  1272           1           0\n\nformat(4 / 5000000, scientific = FALSE)\n\n[1] \"0.0000008\"\n\n\n\nHow unlikely is this? Math:\n\\[\n\\begin{align*}\n\\Pr(\\textsf{T}^- \\cap \\textsf{Sick}) &= \\Pr(\\textsf{T}^- \\mid \\textsf{Sick})\\Pr(\\textsf{Sick}) \\\\\n&= (0.01)\\frac{1}{10000} \\\\\n&= \\frac{1}{1000000}\n\\end{align*}\n\\]\nComputers:\n\nresult_df &lt;- simulate_disease(1000000, 1/10000, verbose = FALSE, return_full_df = TRUE)\nfalse_negatives &lt;- result_df[result_df$has_disease == 1 & result_df$test_result == 0,]\nnum_false_negatives &lt;- nrow(false_negatives)\nwriteLines(paste0(\"False Negatives: \",num_false_negatives,\", Total Cases: \", nrow(result_df)))\n\nFalse Negatives: 1, Total Cases: 1000000\n\nfalse_negative_rate &lt;- num_false_negatives / nrow(result_df)\nfalse_negative_rate_decimal &lt;- format(false_negative_rate, scientific = FALSE)\nwriteLines(paste0(\"False Negative Rate: \", false_negative_rate_decimal))\n\nFalse Negative Rate: 0.000001\n\n\n(Perfect match!)"
  },
  {
    "objectID": "w03/index.html#bayes-takeaway",
    "href": "w03/index.html#bayes-takeaway",
    "title": "Week 3: Conditional Probability",
    "section": "Bayes: Takeaway",
    "text": "Bayes: Takeaway\n\nBayesian approach allows new evidence to be weighed against existing evidence, with statistically principled way to derive these weights:\n\n\\[\n\\begin{array}{ccccc}\n\\Pr_{\\text{post}}(\\mathcal{H}) &\\hspace{-6mm}\\propto &\\hspace{-6mm} \\Pr(X \\mid \\mathcal{H}) &\\hspace{-6mm} \\times &\\hspace{-6mm} \\Pr_{\\text{pre}}(\\mathcal{H}) \\\\\n\\text{Posterior} &\\hspace{-6mm}\\propto &\\hspace{-6mm}\\text{Evidence} &\\hspace{-6mm} \\times &\\hspace{-6mm} \\text{Prior}\n\\end{array}\n\\]"
  },
  {
    "objectID": "w03/index.html#monte-carlo-methods-overview",
    "href": "w03/index.html#monte-carlo-methods-overview",
    "title": "Week 3: Conditional Probability",
    "section": "Monte Carlo Methods: Overview",
    "text": "Monte Carlo Methods: Overview\n\nYou already saw an example, in our rare disease simulation!\nGenerally, using computers (rather than math, “by hand”) to estimate probabilistic quantities\n\n\n\nPros:\n\nMost real-world processes have no analytic solution\nStep-by-step breakdown of complex processes\n\n\nCons:\n\nCan require immense computing power\n⚠️ Can generate incorrect answers ⚠️\n\n\n\n\nBy step-by-step I mean, a lot of the time you are just walking through, generating the next column using previously-generated columns. Like we did in the example above, generating test_result based on has_disease."
  },
  {
    "objectID": "w03/index.html#birthday-problem",
    "href": "w03/index.html#birthday-problem",
    "title": "Week 3: Conditional Probability",
    "section": "Birthday Problem",
    "text": "Birthday Problem\n\n\n\n30 people gather in a room together. What is the probability that two of them share the same birthday?\nAnalytic solution is fun, but requires some thought… Monte Carlo it!\n\n\n\n\nCode\ngen_bday_room &lt;- function(room_num=NULL) {\n  num_people &lt;- 30\n  num_days &lt;- 366\n  ppl_df &lt;- tibble(id=seq(1,num_people))\nbirthdays &lt;- sample(1:num_days, num_people,replace = T)\n  ppl_df['birthday'] &lt;- birthdays\n  if (!is.null(room_num)) {\n    ppl_df &lt;- ppl_df %&gt;% mutate(room_num=room_num) %&gt;% relocate(room_num)\n  }\n  return(ppl_df)\n}\nppl_df &lt;- gen_bday_room(1)\ndisp(ppl_df %&gt;% head()) #, obs_per_page = 3)"
  },
  {
    "objectID": "w03/index.html#section-5",
    "href": "w03/index.html#section-5",
    "title": "Week 3: Conditional Probability",
    "section": "",
    "text": "# Inefficient version (return_num=FALSE) is for: if you want tibbles of *all* shared bdays for each room\nget_shared_bdays &lt;- function(df, is_grouped=NULL, return_num=FALSE, return_bool=FALSE) {\n  bday_pairs &lt;- tibble()\n  for (i in 1:(nrow(df)-1)) {\n    i_data &lt;- df[i,]\n    i_bday &lt;- i_data$birthday\n    for (j in (i+1):nrow(df)) {\n      j_data &lt;- df[j,]\n      j_bday &lt;- j_data$birthday\n      # Check if they're the same\n      same_bday &lt;- i_bday == j_bday\n      if (same_bday) {\n        if (return_bool) {\n          return(1)\n        }\n        pair_data &lt;- tibble(i=i,j=j,bday=i_bday)\n        if (!is.null(is_grouped)) {\n          i_room &lt;- i_data$room_num\n          pair_data['room'] &lt;- i_room\n        }\n        bday_pairs &lt;- bind_rows(bday_pairs, pair_data)\n      }\n    }\n  }\n  if (return_bool) {\n    return(0)\n  }\n  if (return_num) {\n    return(nrow(bday_pairs))\n  }\n  return(bday_pairs)\n}\n#get_shared_bdays(ppl_df)\nget_shared_bdays(ppl_df)\n\n# A tibble: 2 × 3\n      i     j  bday\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     6    27   114\n2     8    28   337"
  },
  {
    "objectID": "w03/index.html#section-6",
    "href": "w03/index.html#section-6",
    "title": "Week 3: Conditional Probability",
    "section": "",
    "text": "Let’s try more rooms…\n\n\n\n# Get tibbles for each room\nlibrary(purrr)\ngen_bday_rooms &lt;- function(num_rooms) {\n  rooms_df &lt;- tibble()\n  for (r in seq(1, num_rooms)) {\n      cur_room &lt;- gen_bday_room(r)\n      rooms_df &lt;- bind_rows(rooms_df, cur_room)\n  }\n  return(rooms_df)\n}\nnum_rooms &lt;- 10\nrooms_df &lt;- gen_bday_rooms(num_rooms)\nrooms_df %&gt;% group_by(room_num) %&gt;% group_map(~ get_shared_bdays(.x, is_grouped=TRUE))\n\nWarning: Unknown or uninitialised column: `room_num`.\nUnknown or uninitialised column: `room_num`.\nUnknown or uninitialised column: `room_num`.\nUnknown or uninitialised column: `room_num`.\nUnknown or uninitialised column: `room_num`.\nUnknown or uninitialised column: `room_num`.\nUnknown or uninitialised column: `room_num`.\nUnknown or uninitialised column: `room_num`.\nUnknown or uninitialised column: `room_num`.\nUnknown or uninitialised column: `room_num`.\nUnknown or uninitialised column: `room_num`.\nUnknown or uninitialised column: `room_num`.\nUnknown or uninitialised column: `room_num`.\nUnknown or uninitialised column: `room_num`.\nUnknown or uninitialised column: `room_num`.\nUnknown or uninitialised column: `room_num`.\n\n\n[[1]]\n# A tibble: 0 × 0\n\n[[2]]\n# A tibble: 1 × 3\n      i     j  bday\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     7    19   242\n\n[[3]]\n# A tibble: 2 × 3\n      i     j  bday\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     2    30    45\n2     5    18    59\n\n[[4]]\n# A tibble: 1 × 3\n      i     j  bday\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     7    14   300\n\n[[5]]\n# A tibble: 1 × 3\n      i     j  bday\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     9    20   195\n\n[[6]]\n# A tibble: 4 × 3\n      i     j  bday\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     1    12   118\n2     1    28   118\n3     5    27   287\n4    12    28   118\n\n[[7]]\n# A tibble: 2 × 3\n      i     j  bday\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     9    18     6\n2    15    28    78\n\n[[8]]\n# A tibble: 1 × 3\n      i     j  bday\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     1    20    29\n\n[[9]]\n# A tibble: 2 × 3\n      i     j  bday\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     8     9    62\n2    10    24   321\n\n[[10]]\n# A tibble: 2 × 3\n      i     j  bday\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1    16    20    86\n2    19    22   163\n\n\n\nNumber of shared birthdays per room:\n\n# Now just get the # shared bdays\nshared_per_room &lt;- rooms_df %&gt;%\n    group_by(room_num) %&gt;%\n    group_map(~ get_shared_bdays(.x, is_grouped = TRUE, return_num=TRUE))\n\nWarning: Unknown or uninitialised column: `room_num`.\nUnknown or uninitialised column: `room_num`.\nUnknown or uninitialised column: `room_num`.\nUnknown or uninitialised column: `room_num`.\nUnknown or uninitialised column: `room_num`.\nUnknown or uninitialised column: `room_num`.\nUnknown or uninitialised column: `room_num`.\nUnknown or uninitialised column: `room_num`.\nUnknown or uninitialised column: `room_num`.\nUnknown or uninitialised column: `room_num`.\nUnknown or uninitialised column: `room_num`.\nUnknown or uninitialised column: `room_num`.\nUnknown or uninitialised column: `room_num`.\nUnknown or uninitialised column: `room_num`.\nUnknown or uninitialised column: `room_num`.\nUnknown or uninitialised column: `room_num`.\n\nshared_per_room &lt;- unlist(shared_per_room)\nshared_per_room\n\n [1] 0 1 2 1 1 4 2 1 2 2\n\n\n\n\\(\\widehat{\\Pr}(\\text{shared})\\)\n\n\nsum(shared_per_room &gt; 0) / num_rooms\n\n[1] 0.9"
  },
  {
    "objectID": "w03/index.html#section-7",
    "href": "w03/index.html#section-7",
    "title": "Week 3: Conditional Probability",
    "section": "",
    "text": "How about A THOUSAND ROOMS?\n\n\nnum_rooms_many &lt;- 100\nmany_rooms_df &lt;- gen_bday_rooms(num_rooms_many)\nanyshared_per_room &lt;- many_rooms_df %&gt;%\n    group_by(room_num) %&gt;%\n    group_map(~ get_shared_bdays(.x, is_grouped = TRUE, return_bool = TRUE))\nanyshared_per_room &lt;- unlist(anyshared_per_room)\nanyshared_per_room\n\n  [1] 1 0 1 0 1 0 1 0 0 0 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1 0\n [38] 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 0 1 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0 0 1 1 0\n [75] 0 1 1 1 1 0 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0\n\n\n\n\\(\\widehat{\\Pr}(\\text{shared bday})\\)?\n\n\n# And now the probability estimate\nsum(anyshared_per_room &gt; 0) / num_rooms_many\n\n[1] 0.66\n\n\n\nThe analytic solution: \\(\\Pr(\\text{shared} \\mid k\\text{ people in room}) = 1 - \\frac{366!}{366^{k}(366-k)!}\\)\nIn our case: \\(1 - \\frac{366!}{366^{30}(366-30)!} = 1 - \\frac{366!}{366^{30}336!} = 1 - \\frac{\\prod_{i=337}^{366}i}{366^{30}}\\)\nR can juust barely handle these numbers:\n\n\n(exact_solution &lt;- 1 - (prod(seq(337,366))) / (366^30))\n\n[1] 0.7053034"
  },
  {
    "objectID": "w03/index.html#wrapping-up",
    "href": "w03/index.html#wrapping-up",
    "title": "Week 3: Conditional Probability",
    "section": "Wrapping Up",
    "text": "Wrapping Up\n\nlibrary(ggplot2)\noptions(ggplot2.discrete.colour = cbPalette)\nglobal_theme &lt;- ggplot2::theme_classic() + ggplot2::theme(\n    plot.title = element_text(hjust = 0.5, size = 18),\n    axis.title = element_text(size = 16),\n    axis.text = element_text(size = 14),\n    legend.title = element_text(size = 16, hjust = 0.5),\n    legend.text = element_text(size = 14),\n    legend.box.background = element_rect(colour = \"black\")\n)\nknitr::opts_chunk$set(fig.align = \"center\")\ng_pointsize &lt;- 6\n# Bday problem\ntrials_per_roomsize &lt;- 3\nbday_est_lbounds &lt;- c()\nbday_est_means &lt;- c()\nbday_est_ubounds &lt;- c()\nsample_sizes &lt;- c()\nfor (num_rooms_many in c(10,50,100,500, 1000)) {\n  cur_size_ests &lt;- c()\n  for (trial_num in seq(1,trials_per_roomsize)) {\n    many_rooms_df &lt;- gen_bday_rooms(num_rooms_many)\n    anyshared_per_room &lt;- many_rooms_df %&gt;%\n        group_by(room_num) %&gt;%\n        group_map(~ get_shared_bdays(.x, is_grouped = TRUE, return_bool = TRUE))\n    anyshared_per_room &lt;- unlist(anyshared_per_room)\n    cur_est &lt;- sum(anyshared_per_room &gt; 0) / num_rooms_many\n    cur_size_ests &lt;- c(cur_size_ests, cur_est)\n  }\n  bday_est_lbounds &lt;- c(bday_est_lbounds, min(cur_size_ests))\n  bday_est_ubounds &lt;- c(bday_est_ubounds, max(cur_size_ests))\n  bday_est_means &lt;- c(bday_est_means, mean(cur_size_ests))\n  sample_sizes &lt;- c(sample_sizes, num_rooms_many)\n}\nresult_df &lt;- tibble(n=sample_sizes,est=bday_est_means, lbound=bday_est_lbounds, ubound=bday_est_ubounds)\nbase_plot &lt;- ggplot(result_df, aes(x=n, y=est)) +\n  geom_point(aes(color=\"black\")) +\n  geom_line(color=\"black\") +\n  geom_ribbon(aes(ymin = lbound, ymax = ubound, fill = cbPalette[1]), alpha = 0.3) +\n      geom_hline(aes(yintercept = exact_solution, linetype = \"dashed\"), color = \"purple\") +\n      scale_color_manual(\"\", values = c(\"black\", \"purple\"), labels = c(\"Sample Mean X\", \"True Mean mu\")) +\n      scale_linetype_manual(\"\", values = \"dashed\", labels = \"True Mean mu\") +\n      scale_fill_manual(\"\", values = cbPalette[1], labels = \"95% CI\") +\n      global_theme +\n      theme(\n          legend.title = element_blank(),\n          legend.spacing.y = unit(0, \"mm\")\n      ) +\n      labs(\n          title = \"Monte Carlo Estimates of Birthday Problem Solution\",\n          x = \"n (Sample Size)\",\n          y = \"Estimate\"\n      )\nlog_plot &lt;- base_plot + scale_x_log10(breaks=c(10,100,1000,10000,100000), labels=c(\"10\",\"100\",\"1000\",\"10000\",\"100000\"))\nlog_plot"
  },
  {
    "objectID": "w03/index.html#final-note-functions-of-random-variables",
    "href": "w03/index.html#final-note-functions-of-random-variables",
    "title": "Week 3: Conditional Probability",
    "section": "Final Note: Functions of Random Variables",
    "text": "Final Note: Functions of Random Variables\n\n\\(X \\sim U[0,1], Y \\sim U[0,1]\\).\n\\(P(Y &lt; X^2)\\)?\nThe hard way: solve analytically\nThe easy way: simulate!"
  },
  {
    "objectID": "w03/index.html#lab-2-demonstrations",
    "href": "w03/index.html#lab-2-demonstrations",
    "title": "Week 3: Conditional Probability",
    "section": "Lab 2 Demonstrations",
    "text": "Lab 2 Demonstrations\nLab 2 Demonstrations"
  },
  {
    "objectID": "w03/index.html#lab-2-assignment-overview",
    "href": "w03/index.html#lab-2-assignment-overview",
    "title": "Week 3: Conditional Probability",
    "section": "Lab 2 Assignment Overview",
    "text": "Lab 2 Assignment Overview\nLab 2 Assignment"
  },
  {
    "objectID": "w03/slides.html#recap-1",
    "href": "w03/slides.html#recap-1",
    "title": "Week 3: Conditional Probability",
    "section": "Recap",
    "text": "Recap\n\nLogic \\(\\rightarrow\\) Set Theory \\(\\rightarrow\\) Probability Theory\nEntirety of probability theory can be derived from two axioms:\n\n\n\n\nThe Entirety of Probability Theory Follows From…\n\n\nAxiom 1 (Unitarity): \\(\\Pr(\\Omega) = 1\\) (The probability that something happens is 1)\nAxiom 2 (\\(\\sigma\\)-additivity): For mutually-exclusive events \\(E_1, E_2, \\ldots\\),\n\\[\n\\underbrace{\\Pr\\left(\\bigcup_{i=1}^{\\infty}E_i\\right)}_{\\Pr(E_1\\text{ occurs }\\vee E_2\\text{ occurs } \\vee \\cdots)} = \\underbrace{\\sum_{i=1}^{\\infty}\\Pr(E_i)}_{\\Pr(E_1\\text{ occurs}) + \\Pr(E_2\\text{ occurs}) + \\cdots}\n\\]\n\n\n\n\nBut what does “mutually exclusive” mean…?"
  },
  {
    "objectID": "w03/slides.html#venn-diagrams-sets",
    "href": "w03/slides.html#venn-diagrams-sets",
    "title": "Week 3: Conditional Probability",
    "section": "Venn Diagrams: Sets",
    "text": "Venn Diagrams: Sets\n\n\n\n\n\n\n\n\n\\[\n\\begin{align*}\n&A = \\{0, 1, 2\\}, \\; B = \\{4, 5, 6\\} \\\\\n&\\implies A \\cap B = \\varnothing\n\\end{align*}\n\\]\nFigure 1: Mutually-exclusive (disjoint) sets\n\n\n\n\n\n\n\n\\[\n\\begin{align*}\n&A = \\{1, 2, 3\\}, \\; B = \\{3, 4, 5\\} \\\\\n&\\implies A \\cap B = \\{3\\}\n\\end{align*}\n\\]\nFigure 2: Non-mutually-exclusive sets"
  },
  {
    "objectID": "w03/slides.html#venn-diagrams-events-dice",
    "href": "w03/slides.html#venn-diagrams-events-dice",
    "title": "Week 3: Conditional Probability",
    "section": "Venn Diagrams: Events (Dice)",
    "text": "Venn Diagrams: Events (Dice)\n\\[\n\\begin{align*}\nA &= \\{\\text{Roll is even}\\} = \\{2, 4, 6\\} \\\\\nB &= \\{\\text{Roll is odd}\\} = \\{1, 3, 5\\} \\\\\nC &= \\{\\text{Roll is in Fibonnaci sequence}\\} = \\{1, 2, 3, 5\\}\n\\end{align*}\n\\]\n\n\n\n\n\n\n\n\n\n\nSet 1\nSet 2\nIntersection\nMutually Exclusive?\nCan Happen Simultaneously?\n\n\n\n\n\\(A\\)\n\\(B\\)\n\\(A \\cap B = \\varnothing\\)\nYes\nNo\n\n\n\\(A\\)\n\\(C\\)\n\\(A \\cap C = \\{2\\}\\)\nNo\nYes\n\n\n\\(B\\)\n\\(C\\)\n\\(B \\cap C = \\{1, 3, 5\\}\\)\nNo\nYes"
  },
  {
    "objectID": "w03/slides.html#rules-of-probability",
    "href": "w03/slides.html#rules-of-probability",
    "title": "Week 3: Conditional Probability",
    "section": "“Rules” of Probability",
    "text": "“Rules” of Probability\n\n(Remember: not “rules” but “facts resulting from the logic \\(\\leftrightarrow\\) probability connection”)\n\n\n\n\n“Rules” of Probability\n\n\nFor logical predicates \\(p, q \\in \\{T, F\\}\\), events \\(P, Q\\) defined so \\(P\\) = event that \\(p\\) becomes true, \\(Q\\) = event that \\(q\\) becomes true,\n\nLogical AND = Probabilistic Multiplication\n\n\\[\n\\Pr(p \\wedge q) = \\Pr(P \\cap Q) = \\Pr(P) \\cdot \\Pr(Q)\n\\]\n\nLogical OR = Probabilistic Addition\n\n\\[\n\\Pr(p \\vee q) = \\Pr(P \\cup Q) = \\Pr(P) + \\Pr(Q) - \\underbrace{\\Pr(P \\cap Q)}_{\\text{(see rule 1)}}\n\\]\n\nLogical NOT = Probabilistic Complement\n\n\\[\n\\Pr(\\neg p) = \\Pr(P^c) = 1 - \\Pr(P)\n\\]"
  },
  {
    "objectID": "w03/slides.html#conditional-probability",
    "href": "w03/slides.html#conditional-probability",
    "title": "Week 3: Conditional Probability",
    "section": "Conditional Probability",
    "text": "Conditional Probability\n\nUsually if someone asks you probabilistic questions, like\n\n“What is the likelihood that [our team] wins?”\n“Do you think it will rain tomorrow?” and so on\n\nYou don’t guess a random number, you consider and incorporate evidence.\nExample: \\(\\Pr(\\text{rain})\\) on its own, without any other info? A tough question… maybe \\(0.5\\)?\nIn reality, we would think about\n\n\\(\\Pr(\\text{rain} \\mid \\text{month of the year})\\)\n\\(\\Pr(\\text{rain} \\mid \\text{where we live})\\)\n\\(\\Pr(\\text{rain} \\mid \\text{did it rain yesterday?})\\)\n\nPsychologically, breaks down into two steps: (1) Think of a baseline probability, (2) Update baseline probability to incorporate relevant evidence (more on this in a bit…)\nAlso recall from last week: all probability is conditional probability, even if just conditioned on “something happened” (\\(\\Omega\\), the thing defined so \\(\\Pr(\\Omega) = 1\\))"
  },
  {
    "objectID": "w03/slides.html#naïve-definition-2.0",
    "href": "w03/slides.html#naïve-definition-2.0",
    "title": "Week 3: Conditional Probability",
    "section": "Naïve Definition 2.0",
    "text": "Naïve Definition 2.0\n\n\n\n[Slightly Less] Naïve Definition of Probability\n\n\n\\[\n\\Pr(A \\mid B) = \\frac{\\text{\\# of Desired Outcomes in world where }B\\text{ happened}}{\\text{\\# Total outcomes in world where }B\\text{ happened}} = \\frac{|B \\cap A|}{|B|}\n\\]\n\n\n\n\n\n\n\n\n\n\n\nWorld Name\nWeather in World\nLikelihood of Rain Today\n\n\n\n\n\\(R\\)\nRained for the past 5 days\n\\(\\Pr(\\text{rain} \\mid R) &gt; 0.5\\)\n\n\n\\(M\\)\nMix of rain and non-rain over past 5 days\n\\(\\Pr(\\text{rain} \\mid M) \\approx 0.5\\)\n\n\n\\(S\\)\nSunny for the past 5 days\n\\(\\Pr(\\text{rain} \\mid S) &lt; 0.5\\)"
  },
  {
    "objectID": "w03/slides.html#law-of-total-probability",
    "href": "w03/slides.html#law-of-total-probability",
    "title": "Week 3: Conditional Probability",
    "section": "Law of Total Probability",
    "text": "Law of Total Probability\n\nSuppose the events \\(B_1, \\ldots, B_k\\) form a partition of the space \\(S\\) and \\(\\Pr(B_j) &gt; 0 \\forall j\\).\nThen, for every event \\(A\\) in \\(S\\),\n\n\\[\n\\Pr(A) = \\sum_{i=1}^k \\Pr(B_j)\\Pr(A \\mid B_j)\n\\]\n\nProbability of an event is the sum of its conditional probabilities across all conditions.\nIn other words: \\(A\\) is some event, \\(B_1, \\ldots, B_n\\) are mutually exclusive events filling entire sample-space, then\n\n\\[\n\\Pr(A) = \\Pr(A \\mid B_1)\\Pr(B_1) + \\Pr(A \\mid B_2)\\Pr(B_2) + \\cdots + \\Pr(A \\mid B_n)\\Pr(B_n)\n\\]\ni.e. Compute the probability by summing over all possible cases."
  },
  {
    "objectID": "w03/slides.html#example",
    "href": "w03/slides.html#example",
    "title": "Week 3: Conditional Probability",
    "section": "Example",
    "text": "Example\n\nProbabilities of completing a job on time, with and without rain, are 0.42 and 0.90 respectively.\nProbability it will rain is 0.45. What is the probability the job will be completed on time?\n\\(A\\) = job will be completed on time, \\(B\\) = rain\n\n\\[\n\\Pr(B) = 0.45 \\implies \\Pr(B^c) = 1 - \\Pr(B) = 0.55.\n\\]\n\nNote: Events \\(B\\) and \\(B^c\\) are exclusive and form partitions of the sample space \\(S\\)\nWe know \\(\\Pr(A \\mid B) = 0.24\\), \\(\\Pr(A \\mid B^c) = 0.9\\).\nBy the Law of Total Probability, we have\n\n\\[\n\\begin{align*}\n\\Pr(A) &= \\Pr(B)\\Pr(A \\mid B) + \\Pr(B^c)\\Pr(A \\mid B^c) \\\\\n&= 0.45(0.42) + 0.55(0.9) = 0.189 + 0.495 = 0684.\n\\end{align*}\n\\]\nSo, the probability that the job will be completed on time is 0.684. (source)"
  },
  {
    "objectID": "w03/slides.html#deriving-bayes-theorem",
    "href": "w03/slides.html#deriving-bayes-theorem",
    "title": "Week 3: Conditional Probability",
    "section": "Deriving Bayes’ Theorem",
    "text": "Deriving Bayes’ Theorem\n\nLiterally just a re-writing of the conditional probability definition (don’t be scared)!\n\n\n\n\nFor two events \\(A\\) and \\(B\\), definition of conditional probability says that\n\n\\[\n\\begin{align*}\n\\Pr(A \\mid B) &= \\frac{\\Pr(A \\cap B)}{\\Pr(B)} \\tag{1} \\\\\n\\Pr(B \\mid A) &= \\frac{\\Pr(B \\cap A)}{\\Pr(A)} \\tag{2}\n\\end{align*}\n\\]\n\nMultiply to get rid of fractions\n\n\\[\n\\begin{align*}\n\\Pr(A \\mid B)\\Pr(B) &= \\Pr(A \\cap B) \\tag{1*} \\\\\n\\Pr(B \\mid A)\\Pr(A) &= \\Pr(B \\cap A) \\tag{2*}\n\\end{align*}\n\\]\n\n\nBut set intersection is associative (just like multiplication…), \\(A \\cap B = B \\cap A\\)! So, we know LHS of \\((\\text{1*})\\) = LHS of \\((\\text{2*})\\):\n\n\\[\n\\Pr(A \\mid B)\\Pr(B) = \\Pr(B \\mid A)\\Pr(A)\n\\]\n\nDivide both sides by \\(\\Pr(B)\\) to get a new definition of \\(\\Pr(A \\mid B)\\), Bayes’ Theorem!\n\n\n\n\\[\n\\boxed{\\Pr(A \\mid B) = \\frac{\\Pr(B \\mid A)\\Pr(A)}{\\Pr(B)}}\n\\]\nFigure 3: Bayes’ Theorem"
  },
  {
    "objectID": "w03/slides.html#why-is-this-helpful",
    "href": "w03/slides.html#why-is-this-helpful",
    "title": "Week 3: Conditional Probability",
    "section": "Why Is This Helpful?",
    "text": "Why Is This Helpful?\n\n\n\nBayes’ Theorem\n\n\nFor any two events \\(A\\) and \\(B\\), \\[\n\\Pr(A \\mid B) = \\frac{\\Pr(B \\mid A)\\Pr(A)}{\\Pr(B)}\n\\]\n\n\n\n\nIn words (as exciting as I can make it, for now): Bayes’ Theorem allows us to take information about \\(B \\mid A\\) and use it to infer information about \\(A \\mid B\\)\nIt isn’t until you work through some examples that this becomes mind-blowing, the most powerful equation we have for inferring unknowns from knowns…\nConsider \\(A = \\{\\text{person has disease}\\}\\), \\(B = \\{\\text{person tests positive for disease}\\}\\)\n\nIs \\(A\\) observable on its own? No, but…\n\nIs \\(B\\) observable on its own? Yes, and\nCan we infer information about \\(A\\) from knowing \\(B\\)? Also Yes, thanks to Bayes!\n\nTherefore, we can use \\(B\\) to infer information about \\(A\\), i.e., calculate \\(\\Pr(A \\mid B)\\)…"
  },
  {
    "objectID": "w03/slides.html#why-is-this-helpful-for-data-science",
    "href": "w03/slides.html#why-is-this-helpful-for-data-science",
    "title": "Week 3: Conditional Probability",
    "section": "Why Is This Helpful for Data Science?",
    "text": "Why Is This Helpful for Data Science?\n\nIt merges probability theory and hypothesis testing into a single framework:\n\n\\[\n\\Pr(\\text{hypothesis} \\mid \\text{data}) = \\frac{\\Pr(\\text{data} \\mid \\text{hypothesis})\\Pr(\\text{hypothesis})}{\\Pr(\\text{data})}\n\\]"
  },
  {
    "objectID": "w03/slides.html#probability-forwards-and-backwards",
    "href": "w03/slides.html#probability-forwards-and-backwards",
    "title": "Week 3: Conditional Probability",
    "section": "Probability Forwards and Backwards",
    "text": "Probability Forwards and Backwards\n\nTwo discrete RVs:\n\nWeather on a given day, \\(W \\in \\{\\textsf{Rain},\\textsf{Sun}\\}\\)\nAction that day, \\(A \\in \\{\\textsf{Go}, \\textsf{Stay}\\}\\): go to party or stay in and watch movie\n\nData-generating process: if \\(\\textsf{Sun}\\), rolls a die \\(R\\) and goes out unless \\(R = 6\\). If \\(\\textsf{Rain}\\), flips a coin and goes out if \\(\\textsf{H}\\).\nProbabilistic Graphical Model (PGM):"
  },
  {
    "objectID": "w03/slides.html#section",
    "href": "w03/slides.html#section",
    "title": "Week 3: Conditional Probability",
    "section": "",
    "text": "So, if we know \\(W = \\textsf{Sun}\\), what is \\(P(A = \\textsf{Go})\\)? \\[\n\\begin{align*}\nP(A = \\textsf{Go} \\mid W) &= 1 - P(R = 6) \\\\\n&= 1 - \\frac{1}{6} = \\frac{5}{6}\n\\end{align*}\n\\]\nConditional probability lets us go forwards (left to right):\n\n\n\n\n\n\n\nBut what if we want to perform inference going backwards?"
  },
  {
    "objectID": "w03/slides.html#section-1",
    "href": "w03/slides.html#section-1",
    "title": "Week 3: Conditional Probability",
    "section": "",
    "text": "If we see Ana at the party, we know \\(A = \\textsf{Go}\\)\nWhat does this tell us about the weather?\nIntuitively, we should increase our degree of belief that \\(W = \\textsf{Sun}\\). But, by how much?\nWe don’t know \\(P(W \\mid A)\\), only \\(P(A \\mid W)\\)…"
  },
  {
    "objectID": "w03/slides.html#section-2",
    "href": "w03/slides.html#section-2",
    "title": "Week 3: Conditional Probability",
    "section": "",
    "text": "\\[\nP(W = \\textsf{Sun} \\mid A = \\textsf{Go}) = \\frac{\\overbrace{P(A = \\textsf{Go} \\mid W = \\textsf{Sun})}^{5/6~ ✅}\\overbrace{P(W = \\textsf{Sun})}^{❓}}{\\underbrace{P(A = \\textsf{Go})}_{❓}}\n\\]\n\nWe’ve seen \\(P(W = \\textsf{Sun})\\) before, it’s our prior: the probability without having any additional relevant knowledge. So, let’s say 50/50. \\(P(W = \\textsf{Sun}) = \\frac{1}{2}\\)\nIf we lived in Seattle, we could pick \\(P(W = \\textsf{Sun}) = \\frac{1}{4}\\)"
  },
  {
    "objectID": "w03/slides.html#section-3",
    "href": "w03/slides.html#section-3",
    "title": "Week 3: Conditional Probability",
    "section": "",
    "text": "\\[\nP(W = \\textsf{Sun} \\mid A = \\textsf{Go}) = \\frac{\\overbrace{P(A = \\textsf{Go} \\mid W = \\textsf{Sunny})}^{5/6~ ✅}\\overbrace{P(W = \\textsf{Sun})}^{1/2~ ✅}}{\\underbrace{P(A = \\textsf{Go})}_{❓}}\n\\]\n\n\\(P(A = \\textsf{Go})\\) is trickier: the probability that Ana goes out regardless of what the weather is. But there are only two possible weather outcomes! So we just compute\n\n\\[\n\\begin{align*}\n&P(A = \\textsf{Go}) = \\sum_{\\omega \\in S(W)}P(A = \\textsf{Go}, \\omega) = \\sum_{\\omega \\in S(W)}P(A = \\textsf{Go} \\mid \\omega)P(\\omega) \\\\\n&= P(A = \\textsf{Go} \\mid W = \\textsf{Rain})P(W = \\textsf{Rain}) + P(A = \\textsf{Go} \\mid W = \\textsf{Sun})P(W = \\textsf{Sun}) \\\\\n&= \\left( \\frac{1}{2} \\right)\\left( \\frac{1}{2} \\right) + \\left( \\frac{5}{6} \\right)\\left( \\frac{1}{2} \\right) = \\frac{1}{4} + \\frac{5}{12} = \\frac{2}{3}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w03/slides.html#putting-it-all-together",
    "href": "w03/slides.html#putting-it-all-together",
    "title": "Week 3: Conditional Probability",
    "section": "Putting it All Together",
    "text": "Putting it All Together\n\\[\n\\begin{align*}\nP(W = \\textsf{Sun} \\mid A = \\textsf{Go}) &= \\frac{\\overbrace{P(A = \\textsf{Go} \\mid W = \\textsf{Sunny})}^{3/4~ ✅}\\overbrace{P(W = \\textsf{Sun})}^{1/2~ ✅}}{\\underbrace{P(A = \\textsf{Go})}_{1/2~ ✅}} \\\\\n&= \\frac{\\left(\\frac{3}{4}\\right)\\left(\\frac{1}{2}\\right)}{\\frac{1}{2}} = \\frac{\\frac{3}{8}}{\\frac{1}{2}} = \\frac{3}{4}.\n\\end{align*}\n\\]\n\nGiven that we see Ana at the party, we should update our beliefs, so that \\(P(W = \\textsf{Sun}) = \\frac{3}{4}, P(W = \\textsf{Rain}) = \\frac{1}{4}\\)."
  },
  {
    "objectID": "w03/slides.html#a-scarier-example",
    "href": "w03/slides.html#a-scarier-example",
    "title": "Week 3: Conditional Probability",
    "section": "A Scarier Example",
    "text": "A Scarier Example\n\nBo worries he has a rare disease. He takes a test with 99% accuracy and tests positive. What’s the probability Bo has the disease? (Intuition: 99%? …Let’s do the math!)\n\n\n\n\n\\(H \\in \\{\\textsf{sick}, \\textsf{healthy}\\}, T \\in \\{\\textsf{T}^+, \\textsf{T}^-\\}\\)\nThe test: 99% accurate. \\(\\Pr(T = \\textsf{T}^+ \\mid H = \\textsf{sick}) = 0.99\\), \\(\\Pr(T = \\textsf{T}^- \\mid H = \\textsf{healthy}) = 0.99\\).\nThe disease: 1 in 10K. \\(\\Pr(H = \\textsf{sick}) = \\frac{1}{10000}\\)\nWhat do we want to know? \\(\\Pr(H = \\textsf{sick} \\mid T = \\textsf{T}^+)\\)\nHow do we get there?\n\n\n\n\n\nThis photo, originally thought to be of Thomas Bayes, turns out to be probably someone else… \\(\\Pr(\\textsf{Bayes})\\)?\n\n\n\n\n\n\\(H\\) for health, \\(T\\) for test result\nPhoto credit: https://thedatascientist.com/wp-content/uploads/2019/04/reverend-thomas-bayes.jpg"
  },
  {
    "objectID": "w03/slides.html#section-4",
    "href": "w03/slides.html#section-4",
    "title": "Week 3: Conditional Probability",
    "section": "",
    "text": "\\[\n\\begin{align*}\n\\Pr(H = \\textsf{sick} \\mid T = \\textsf{T}^+) &= \\frac{\\Pr(T = \\textsf{T}^+ \\mid H = \\textsf{sick})\\Pr(H = \\textsf{sick})}{\\Pr(T = \\textsf{T}^+)} \\\\\n&= \\frac{(0.99)\\left(\\frac{1}{10000}\\right)}{(0.99)\\left( \\frac{1}{10000} \\right) + (0.01)\\left( \\frac{9999}{10000} \\right)}\n\\end{align*}\n\\]\n\np_sick &lt;- 1 / 10000\np_healthy &lt;- 1 - p_sick\np_pos_given_sick &lt;- 0.99\np_neg_given_sick &lt;- 1 - p_pos_given_sick\np_neg_given_healthy &lt;- 0.99\np_pos_given_healthy &lt;- 1 - p_neg_given_healthy\nnumer &lt;- p_pos_given_sick * p_sick\ndenom1 &lt;- numer\ndenom2 &lt;- p_pos_given_healthy * p_healthy\nfinal_prob &lt;- numer / (denom1 + denom2)\nfinal_prob\n\n[1] 0.009803922\n\n\n\n… Less than 1% 😱"
  },
  {
    "objectID": "w03/slides.html#proof-in-the-pudding",
    "href": "w03/slides.html#proof-in-the-pudding",
    "title": "Week 3: Conditional Probability",
    "section": "Proof in the Pudding",
    "text": "Proof in the Pudding\n\nLet’s generate a dataset of 5,000 people, using \\(\\Pr(\\textsf{Disease}) = \\frac{1}{10000}\\)\n\n\n\nCode\nlibrary(tibble)\nlibrary(dplyr)\n# Disease rarity\np_disease &lt;- 1 / 10000\n# 1K people\nnum_people &lt;- 10000\n# Give them ids\nppl_df &lt;- tibble(id=seq(1,num_people))\n# Whether they have the disease or not\nhas_disease &lt;- rbinom(num_people, 1, p_disease)\nppl_df &lt;- ppl_df %&gt;% mutate(has_disease=has_disease)\ndisp(ppl_df %&gt;% head())"
  },
  {
    "objectID": "w03/slides.html#binary-variable-trick",
    "href": "w03/slides.html#binary-variable-trick",
    "title": "Week 3: Conditional Probability",
    "section": "Binary Variable Trick",
    "text": "Binary Variable Trick\n\nSince has_disease \\(\\in \\{0, 1\\}\\), we can use\n\nsum(has_disease) to obtain the count of people with the disease, or\nmean(has_disease) to obtain the proportion of people who have the disease\n\nTo see this (or, if you forget in the future), just make a fake dataset with a binary variable and 3 rows, and think about sums vs. means of that variable:\n\n\n\n\n\nCode\nbinary_df &lt;- tibble(\n  id=c(1,2,3),\n  x=c(0,1,0)\n)\ndisp(binary_df)\n\n\n\n\n\n\n\n\nTaking the sum tells us: one row where x == 1:\n\n\nCode\nsum(binary_df$x)\n\n\n[1] 1\n\n\nTaking the mean tells us: 1/3 of rows have x == 1:\n\n\nCode\nmean(binary_df$x)\n\n\n[1] 0.3333333"
  },
  {
    "objectID": "w03/slides.html#applying-this-to-the-disease-data",
    "href": "w03/slides.html#applying-this-to-the-disease-data",
    "title": "Week 3: Conditional Probability",
    "section": "Applying This to the Disease Data",
    "text": "Applying This to the Disease Data\n\nIf we want the number of people who have the disease:\n\n\n\nCode\n# Compute the *number* of people who have the disease\nsum(ppl_df$has_disease)\n\n\n[1] 1\n\n\n\nIf we want the proportion of people who have the disease:\n\n\n\nCode\n# Compute the *proportion* of people who have the disease\nmean(ppl_df$has_disease)\n\n\n[1] 1e-04\n\n\n\n(And if you dislike scientific notation like I do…)\n\n\n\nCode\nformat(mean(ppl_df$has_disease), scientific = FALSE)\n\n\n[1] \"0.0001\"\n\n\n\n(Foreshadowing Monte Carlo methods)"
  },
  {
    "objectID": "w03/slides.html#data-generating-process-test-results",
    "href": "w03/slides.html#data-generating-process-test-results",
    "title": "Week 3: Conditional Probability",
    "section": "Data-Generating Process: Test Results",
    "text": "Data-Generating Process: Test Results\n\n\nCode\nlibrary(dplyr)\n# Data Generating Process\ntake_test &lt;- function(is_sick) {\n  if (is_sick) {\n    return(rbinom(1,1,p_pos_given_sick))\n  } else {\n    return(rbinom(1,1,p_pos_given_healthy))\n  }\n}\nppl_df['test_result'] &lt;- unlist(lapply(ppl_df$has_disease, take_test))\nnum_positive &lt;- sum(ppl_df$test_result)\np_positive &lt;- mean(ppl_df$test_result)\nwriteLines(paste0(num_positive,\" positive tests / \",num_people,\" total = \",p_positive))\n\n\n111 positive tests / 10000 total = 0.0111"
  },
  {
    "objectID": "w03/slides.html#zooming-in-on-positive-tests",
    "href": "w03/slides.html#zooming-in-on-positive-tests",
    "title": "Week 3: Conditional Probability",
    "section": "Zooming In On Positive Tests",
    "text": "Zooming In On Positive Tests\n\n\n\n\n\n\n\n\n\n\n\nBo doesn’t have it, and neither do 110 of the 111 total people who tested positive!\nBut, in the real world, we only observe \\(T\\)"
  },
  {
    "objectID": "w03/slides.html#zooming-in-on-disease-havers",
    "href": "w03/slides.html#zooming-in-on-disease-havers",
    "title": "Week 3: Conditional Probability",
    "section": "Zooming In On Disease-Havers",
    "text": "Zooming In On Disease-Havers\n\nWhat if we look at only those who actually have the disease? Maybe the cost of 111 people panicking is worth it if we correctly catch those who do have it?\n\n\n\nCode\ndisp(ppl_df[ppl_df$has_disease == 1,])\n\n\n\n\n\n\n\nIs this always going to be the case?\n\n\n\n\nNum with disease: 0\nProportion with disease: 0\nNumber of positive tests: 45\n\n\n\n\n\n\n\n\n\n\nNum with disease: 0\nProportion with disease: 0\nNumber of positive tests: 62"
  },
  {
    "objectID": "w03/slides.html#worst-case-worlds",
    "href": "w03/slides.html#worst-case-worlds",
    "title": "Week 3: Conditional Probability",
    "section": "Worst-Case Worlds",
    "text": "Worst-Case Worlds\n\n\n\n\nWorld #415 / 1000 (5000 people):\n# A tibble: 2 × 3\n     id has_disease test_result\n  &lt;int&gt;       &lt;int&gt;       &lt;int&gt;\n1   617           1           1\n2  2192           1           0\n\n\nWorld #503 / 1000 (5000 people):\n# A tibble: 1 × 3\n     id has_disease test_result\n  &lt;int&gt;       &lt;int&gt;       &lt;int&gt;\n1  1669           1           0\n\n\nWorld #729 / 1000 (5000 people):\n# A tibble: 3 × 3\n     id has_disease test_result\n  &lt;int&gt;       &lt;int&gt;       &lt;int&gt;\n1  1378           1           1\n2  1427           1           1\n3  4062           1           0\n\n\n[1] \"0.0000008\"\n\n\n\nHow unlikely is this? Math:\n\\[\n\\begin{align*}\n\\Pr(\\textsf{T}^- \\cap \\textsf{Sick}) &= \\Pr(\\textsf{T}^- \\mid \\textsf{Sick})\\Pr(\\textsf{Sick}) \\\\\n&= (0.01)\\frac{1}{10000} \\\\\n&= \\frac{1}{1000000}\n\\end{align*}\n\\]\nComputers:\n\n\nFalse Negatives: 1, Total Cases: 1000000\n\n\nFalse Negative Rate: 0.000001\n\n\n(Perfect match!)"
  },
  {
    "objectID": "w03/slides.html#bayes-takeaway",
    "href": "w03/slides.html#bayes-takeaway",
    "title": "Week 3: Conditional Probability",
    "section": "Bayes: Takeaway",
    "text": "Bayes: Takeaway\n\nBayesian approach allows new evidence to be weighed against existing evidence, with statistically principled way to derive these weights:\n\n\\[\n\\begin{array}{ccccc}\n\\Pr_{\\text{post}}(\\mathcal{H}) &\\hspace{-6mm}\\propto &\\hspace{-6mm} \\Pr(X \\mid \\mathcal{H}) &\\hspace{-6mm} \\times &\\hspace{-6mm} \\Pr_{\\text{pre}}(\\mathcal{H}) \\\\\n\\text{Posterior} &\\hspace{-6mm}\\propto &\\hspace{-6mm}\\text{Evidence} &\\hspace{-6mm} \\times &\\hspace{-6mm} \\text{Prior}\n\\end{array}\n\\]"
  },
  {
    "objectID": "w03/slides.html#monte-carlo-methods-overview",
    "href": "w03/slides.html#monte-carlo-methods-overview",
    "title": "Week 3: Conditional Probability",
    "section": "Monte Carlo Methods: Overview",
    "text": "Monte Carlo Methods: Overview\n\nYou already saw an example, in our rare disease simulation!\nGenerally, using computers (rather than math, “by hand”) to estimate probabilistic quantities\n\n\n\nPros:\n\nMost real-world processes have no analytic solution\nStep-by-step breakdown of complex processes\n\n\nCons:\n\nCan require immense computing power\n⚠️ Can generate incorrect answers ⚠️\n\n\n\n\nBy step-by-step I mean, a lot of the time you are just walking through, generating the next column using previously-generated columns. Like we did in the example above, generating test_result based on has_disease."
  },
  {
    "objectID": "w03/slides.html#birthday-problem",
    "href": "w03/slides.html#birthday-problem",
    "title": "Week 3: Conditional Probability",
    "section": "Birthday Problem",
    "text": "Birthday Problem\n\n\n\n30 people gather in a room together. What is the probability that two of them share the same birthday?\nAnalytic solution is fun, but requires some thought… Monte Carlo it!\n\n\n\n\nCode\ngen_bday_room &lt;- function(room_num=NULL) {\n  num_people &lt;- 30\n  num_days &lt;- 366\n  ppl_df &lt;- tibble(id=seq(1,num_people))\nbirthdays &lt;- sample(1:num_days, num_people,replace = T)\n  ppl_df['birthday'] &lt;- birthdays\n  if (!is.null(room_num)) {\n    ppl_df &lt;- ppl_df %&gt;% mutate(room_num=room_num) %&gt;% relocate(room_num)\n  }\n  return(ppl_df)\n}\nppl_df &lt;- gen_bday_room(1)\ndisp(ppl_df %&gt;% head()) #, obs_per_page = 3)"
  },
  {
    "objectID": "w03/slides.html#section-5",
    "href": "w03/slides.html#section-5",
    "title": "Week 3: Conditional Probability",
    "section": "",
    "text": "# A tibble: 0 × 0"
  },
  {
    "objectID": "w03/slides.html#section-6",
    "href": "w03/slides.html#section-6",
    "title": "Week 3: Conditional Probability",
    "section": "",
    "text": "Let’s try more rooms…\n\n\n\n# Get tibbles for each room\nlibrary(purrr)\ngen_bday_rooms &lt;- function(num_rooms) {\n  rooms_df &lt;- tibble()\n  for (r in seq(1, num_rooms)) {\n      cur_room &lt;- gen_bday_room(r)\n      rooms_df &lt;- bind_rows(rooms_df, cur_room)\n  }\n  return(rooms_df)\n}\nnum_rooms &lt;- 10\nrooms_df &lt;- gen_bday_rooms(num_rooms)\nrooms_df %&gt;% group_by(room_num) %&gt;% group_map(~ get_shared_bdays(.x, is_grouped=TRUE))\n\n[[1]]\n# A tibble: 3 × 3\n      i     j  bday\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     3     6   116\n2     7    12   287\n3    19    30   267\n\n[[2]]\n# A tibble: 0 × 0\n\n[[3]]\n# A tibble: 1 × 3\n      i     j  bday\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     7    23   138\n\n[[4]]\n# A tibble: 1 × 3\n      i     j  bday\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     6    18    72\n\n[[5]]\n# A tibble: 2 × 3\n      i     j  bday\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     8    10   255\n2    16    30    66\n\n[[6]]\n# A tibble: 0 × 0\n\n[[7]]\n# A tibble: 1 × 3\n      i     j  bday\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1    11    23   333\n\n[[8]]\n# A tibble: 1 × 3\n      i     j  bday\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     2    17   328\n\n[[9]]\n# A tibble: 2 × 3\n      i     j  bday\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     2     4   283\n2    13    21    28\n\n[[10]]\n# A tibble: 2 × 3\n      i     j  bday\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     8    23   135\n2    11    12   204\n\n\n\nNumber of shared birthdays per room:\n\n# Now just get the # shared bdays\nshared_per_room &lt;- rooms_df %&gt;%\n    group_by(room_num) %&gt;%\n    group_map(~ get_shared_bdays(.x, is_grouped = TRUE, return_num=TRUE))\nshared_per_room &lt;- unlist(shared_per_room)\nshared_per_room\n\n [1] 3 0 1 1 2 0 1 1 2 2\n\n\n\n\\(\\widehat{\\Pr}(\\text{shared})\\)\n\n\n\n[1] 0.8"
  },
  {
    "objectID": "w03/slides.html#section-7",
    "href": "w03/slides.html#section-7",
    "title": "Week 3: Conditional Probability",
    "section": "",
    "text": "How about A THOUSAND ROOMS?\n\n\n\n  [1] 1 0 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 0 1 1\n [38] 1 0 1 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1\n [75] 1 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1\n\n\n\n\\(\\widehat{\\Pr}(\\text{shared bday})\\)?\n\n\n\n[1] 0.72\n\n\n\nThe analytic solution: \\(\\Pr(\\text{shared} \\mid k\\text{ people in room}) = 1 - \\frac{366!}{366^{k}(366-k)!}\\)\nIn our case: \\(1 - \\frac{366!}{366^{30}(366-30)!} = 1 - \\frac{366!}{366^{30}336!} = 1 - \\frac{\\prod_{i=337}^{366}i}{366^{30}}\\)\nR can juust barely handle these numbers:\n\n\n\n[1] 0.7053034"
  },
  {
    "objectID": "w03/slides.html#wrapping-up",
    "href": "w03/slides.html#wrapping-up",
    "title": "Week 3: Conditional Probability",
    "section": "Wrapping Up",
    "text": "Wrapping Up"
  },
  {
    "objectID": "w03/slides.html#final-note-functions-of-random-variables",
    "href": "w03/slides.html#final-note-functions-of-random-variables",
    "title": "Week 3: Conditional Probability",
    "section": "Final Note: Functions of Random Variables",
    "text": "Final Note: Functions of Random Variables\n\n\\(X \\sim U[0,1], Y \\sim U[0,1]\\).\n\\(P(Y &lt; X^2)\\)?\nThe hard way: solve analytically\nThe easy way: simulate!"
  },
  {
    "objectID": "w03/slides.html#lab-2-demonstrations",
    "href": "w03/slides.html#lab-2-demonstrations",
    "title": "Week 3: Conditional Probability",
    "section": "Lab 2 Demonstrations",
    "text": "Lab 2 Demonstrations\nLab 2 Demonstrations"
  },
  {
    "objectID": "w03/slides.html#lab-2-assignment-overview",
    "href": "w03/slides.html#lab-2-assignment-overview",
    "title": "Week 3: Conditional Probability",
    "section": "Lab 2 Assignment Overview",
    "text": "Lab 2 Assignment Overview\nLab 2 Assignment"
  },
  {
    "objectID": "w05/index.html",
    "href": "w05/index.html",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "",
    "text": "Open slides in new window →"
  },
  {
    "objectID": "w05/index.html#from-last-week",
    "href": "w05/index.html#from-last-week",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "From Last Week",
    "text": "From Last Week\n\n\n\n\n\nlibrary(tibble)\nlibrary(ggplot2)\ndisc_df &lt;- tribble(\n  ~x, ~y, ~label,\n  0, 0, \"A\",\n  0, 1, \"B\",\n  1, 0, \"C\",\n  1, 1, \"D\"\n)\nggplot(disc_df, aes(x=x, y=y, label=label)) +\n    geom_point(size=g_pointsize) +\n    geom_text(\n      size=g_textsize,\n      hjust=1.5,\n      vjust=-0.5\n    ) +\n    xlim(-0.5,1.5) + ylim(-0.5,1.5) +\n    coord_fixed() +\n    dsan_theme(\"quarter\") +\n    labs(\n      title=\"Discrete Probability Space in N\"\n    )\n\n\n\n\n\\[\n\\Pr(A) = \\underbrace{\\frac{|\\{A\\}|}{|\\Omega|}}_{\\mathclap{\\small \\text{Probability }\\textbf{mass}}} = \\frac{1}{|\\{A,B,C,D\\}|} = \\frac{1}{4}\n\\]\nFigure 1: Visual and mathematical intuition for events in a discrete probability space\n\n\n\n\n\nlibrary(ggforce)\nggplot(disc_df, aes(x=x, y=y, label=label)) +\n    xlim(-0.5,1.5) + ylim(-0.5,1.5) +\n    geom_rect(aes(xmin = -0.5, xmax = 1.5, ymin = -0.5, ymax = 1.5), fill=cbPalette[1], color=\"black\", alpha=0.3) +\n    geom_circle(aes(x0=x, y0=y, r=0.25), fill=cbPalette[2]) +\n    coord_fixed() +\n    dsan_theme(\"quarter\") +\n    geom_text(\n      size=g_textsize,\n      #hjust=1.75,\n      #vjust=-0.75\n    ) +\n    geom_text(\n      data=data.frame(label=\"Ω\"),\n      aes(x=-0.4,y=1.39),\n      parse=TRUE,\n      size=g_textsize\n    ) +\n    labs(\n      title=expression(\"Continuous Probability Space in \"*R^2)\n    )\n\n\n\n\n\\[\n\\Pr(A) = \\underbrace{\\frac{\\text{Area}(\\{A\\})}{\\text{Area}(\\Omega)}}_{\\mathclap{\\small \\text{Probability }\\textbf{density}}} = \\frac{\\pi r^2}{s^2} = \\frac{\\pi \\left(\\frac{1}{4}\\right)^2}{4} = \\frac{\\pi}{64}\n\\]\nFigure 2: Visual and mathematical intuition for events a continuous probability space"
  },
  {
    "objectID": "w05/index.html#what-things-have-distributions",
    "href": "w05/index.html#what-things-have-distributions",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "What Things Have Distributions?",
    "text": "What Things Have Distributions?\n\nAnswer: Random Variables"
  },
  {
    "objectID": "w05/index.html#cdfspdfspmfs-what-are-they",
    "href": "w05/index.html#cdfspdfspmfs-what-are-they",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "CDFs/pdfs/pmfs: What Are They?",
    "text": "CDFs/pdfs/pmfs: What Are They?\n\nFunctions which answer questions about a Random Variable (\\(X\\) in this case) with respect to a non-random value (\\(v\\) in this case, for “value”)\nCDF: What is probability that \\(X\\) takes on a value less than or equal to \\(v\\)?\n\n\\[\nF_X(v) \\definedas \\Pr(X \\leq v)\n\\]\n\npmf: What is the probability of this exact value? (Discrete only)\n\n\\[\np_X(v) \\definedas \\Pr(X = v)\n\\]\n\npdf: 🙈 …It’s the thing you integrate to get the CDF\n\n\\[\nf_X(v) \\definedas \\frac{d}{dv}F_X(v) \\iff \\int_{-\\infty}^{v} f_X(v)dv = F_X(v)\n\\]"
  },
  {
    "objectID": "w05/index.html#cdfspdfspmfs-why-do-we-use-them",
    "href": "w05/index.html#cdfspdfspmfs-why-do-we-use-them",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "CDFs/pdfs/pmfs: Why Do We Use Them?",
    "text": "CDFs/pdfs/pmfs: Why Do We Use Them?\n\nCDF is like the “API” that allows you to access all of the information about the distribution (pdf/pmf is derived from the CDF)\nExample: we know there’s some “thing” called the Exponential Distribution…\nHow do we use this distribution to understand a random variable \\(X \\sim \\text{Exp}\\)?\n\nAnswer: the CDF of \\(X\\)!\nSince all exponentially-distributed RVs have the same PDF, we can call this PDF “the” exponential distribution\n\nSay we want to find the median of \\(X\\): The median is the number(s) \\(m\\) satisfying\n\n\\[\n\\Pr(X \\leq m) = \\frac{1}{2}\n\\]"
  },
  {
    "objectID": "w05/index.html#finding-a-median-via-the-cdf",
    "href": "w05/index.html#finding-a-median-via-the-cdf",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "Finding a Median via the CDF",
    "text": "Finding a Median via the CDF\n\n\n\n\n\n\nMedian of a Random Variable \\(X\\)\n\n\n\nThe median of a random variable \\(X\\) with some CDF \\(F_X(v_X)\\) is the [set of] numbers \\(m\\) for which the probability that \\(X\\) is lower than \\(m\\) is \\(\\frac{1}{2}\\):\n\\[\n\\begin{align*}\n\\text{Median}(X) &= \\left\\{m \\left| F_X(m) = \\frac{1}{2} \\right. \\right\\} \\\\\n&= \\left\\{m \\left| \\int_{-\\infty}^{m}f_X(v_X)dv_X = \\frac{1}{2} \\right. \\right\\}\n\\end{align*}\n\\]\n\n\n\n\n(In case you’re wondering why we start with the median rather than the more commonly-used mean: it’s specifically because I want you to get used to calculating general functions \\(f(X)\\) of a random variable \\(X\\). It’s easy to just e.g. learn how to compute the mean \\(\\expect{X}\\) and forget that this is only one of many possible choices for \\(f(X)\\).)"
  },
  {
    "objectID": "w05/index.html#median-via-cdf-example",
    "href": "w05/index.html#median-via-cdf-example",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "Median via CDF Example",
    "text": "Median via CDF Example\nExample: If \\(X \\sim \\text{Exp}(\\param{\\lambda})\\),\n\\[\nF_X(v) = 1 - e^{-\\lambda v}\n\\]\nSo we want to solve for \\(m\\) in\n\\[\nF_X(m) = \\frac{1}{2} \\iff 1 - e^{-\\lambda m} = \\frac{1}{2}\n\\]"
  },
  {
    "objectID": "w05/index.html#step-by-step",
    "href": "w05/index.html#step-by-step",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "Step-by-Step",
    "text": "Step-by-Step\n\\[\n\\begin{align*}\n1 - e^{-\\lambda m} &= \\frac{1}{2} \\\\\n\\iff e^{-\\lambda m} &= \\frac{1}{2} \\\\\n\\iff \\ln\\left[e^{-\\lambda m}\\right] &= \\ln\\left[\\frac{1}{2}\\right] \\\\\n\\iff -\\lambda m &= -\\ln(2) \\\\\n\\iff m &= \\frac{\\ln(2)}{\\lambda}\n%3x = 19-2y\n\\; \\llap{\\mathrel{\\boxed{\\phantom{m = \\frac{\\ln(2)}{\\lambda}}}}}.\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w05/index.html#what-is-a-pdf",
    "href": "w05/index.html#what-is-a-pdf",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "What is a pdf?",
    "text": "What is a pdf?\n\nAnswer: Has no meaning outside of its context: a random variable with a CDF giving the distribution of its possible values"
  },
  {
    "objectID": "w05/index.html#top-secret-fun-fact",
    "href": "w05/index.html#top-secret-fun-fact",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "Top Secret Fun Fact",
    "text": "Top Secret Fun Fact\n\nEvery Discrete Distribution is [technically, in a weird way] a Continuous Distribution!\n\n\nSame intuition as why every natural number is a real number, but converse is not true\nMarble example: Let \\(X\\) be an RV defined on this space, so that \\(X(A) = 1\\), \\(X(B) = 2\\), \\(X(C) = 3\\), \\(X(D) = 4\\). Then the pmf for \\(X\\) is \\(p_X(i) = \\frac{1}{4}\\) for \\(i \\in \\{1, 2, 3, 4\\}\\).\nWe can then use the Dirac delta function \\(\\delta(v)\\) to define a continuous pdf\n\\[\n  f_X(v) = \\sum_{i \\in \\mathcal{R}_X}p_X(i)\\delta(v - i) = \\sum_{i=1}^4p_X(i)\\delta(v-i) = \\frac{1}{4}\\sum_{i=1}^4 \\delta(v - i)\n  \\]\nand use either the (discrete) pmf \\(p_X(v)\\) or (continuous) pdf \\(f_X(v)\\) to describe \\(X\\):\n\n\\[\n\\begin{align*}\n\\overbrace{\\Pr(X \\leq 3)}^{\\text{CDF}} &= \\sum_{i=1}^3\\overbrace{p_X(i)}^{\\text{pmf}} = \\frac{1}{4} + \\frac{1}{4} + \\frac{1}{4} = \\frac{3}{4} \\\\\n\\underbrace{\\Pr(X \\leq 3)}_{\\text{CDF}} &= \\int_{-\\infty}^{3} \\underbrace{f_X(v)}_{\\text{pdf}} = \\frac{1}{4}\\int_{-\\infty}^{3} \\sum_{i = 1}^{4}\\overbrace{\\delta(v-i)}^{\\small 0\\text{ unless }v = i}dv = \\frac{3}{4}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w05/index.html#normal-distribution",
    "href": "w05/index.html#normal-distribution",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "Normal Distribution",
    "text": "Normal Distribution\n\nRecall from last week: the Binomial pdf\n\n\n\nCode\nk &lt;- seq(0, 10)\nprob &lt;- dbinom(k, 10, 0.5)\nbar_data &lt;- tibble(k, prob)\nggplot(bar_data, aes(x=k, y=prob)) +\n  geom_bar(stat=\"identity\", fill=cbPalette[1]) +\n  labs(\n    title=\"Binomial Distribution, N = 10, p = 0.5\",\n    y=\"Probability Mass\"\n  ) +\n  scale_x_continuous(breaks=seq(0,10)) +\n  dsan_theme(\"half\")"
  },
  {
    "objectID": "w05/index.html#the-emergence-of-order",
    "href": "w05/index.html#the-emergence-of-order",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "The Emergence of Order",
    "text": "The Emergence of Order\n\n\n\n\nWho can guess the state of this process after 10 steps, with 1 person?\n10 people? 50? 100? (If they find themselves on the same spot, they stand on each other’s heads)\n100 steps? 1000?"
  },
  {
    "objectID": "w05/index.html#the-result-16-steps",
    "href": "w05/index.html#the-result-16-steps",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "The Result: 16 Steps",
    "text": "The Result: 16 Steps\n\n\nCode\nlibrary(tibble)\nlibrary(ggplot2)\nlibrary(ggExtra)\nlibrary(dplyr)\nlibrary(tidyr)\n# From McElreath!\ngen_histo &lt;- function(reps, num_steps) {\n  support &lt;- c(-1,1)\n  pos &lt;-replicate(reps, sum(sample(support,num_steps,replace=TRUE,prob=c(0.5,0.5))))\n  #print(mean(pos))\n  #print(var(pos))\n  pos_df &lt;- tibble(x=pos)\n  clt_distr &lt;- function(x) dnorm(x, 0, sqrt(num_steps))\n  plot &lt;- ggplot(pos_df, aes(x=x)) +\n    geom_histogram(aes(y = after_stat(density)), fill=cbPalette[1], binwidth = 2) +\n    stat_function(fun = clt_distr) +\n    dsan_theme(\"quarter\") +\n    theme(title=element_text(size=16)) +\n    labs(\n      title=paste0(reps,\" Random Walks, \",num_steps,\" Steps\")\n    )\n  return(plot)\n}\ngen_walkplot &lt;- function(num_people, num_steps, opacity=0.15) {\n  support &lt;- c(-1, 1)\n  # Unique id for each person\n  pid &lt;- seq(1, num_people)\n  pid_tib &lt;- tibble(pid)\n  pos_df &lt;- tibble()\n  end_df &lt;- tibble()\n  all_steps &lt;- t(replicate(num_people, sample(support, num_steps, replace = TRUE, prob = c(0.5, 0.5))))\n  csums &lt;- t(apply(all_steps, 1, cumsum))\n  csums &lt;- cbind(0, csums)\n  # Last col is the ending positions\n  ending_pos &lt;- csums[, dim(csums)[2]]\n  end_tib &lt;- tibble(pid = seq(1, num_people), endpos = ending_pos, x = num_steps)\n  # Now convert to tibble\n  ctib &lt;- as_tibble(csums, name_repair = \"none\")\n  merged_tib &lt;- bind_cols(pid_tib, ctib)\n  long_tib &lt;- merged_tib %&gt;% pivot_longer(!pid)\n  # Convert name -&gt; step_num\n  long_tib &lt;- long_tib %&gt;% mutate(step_num = strtoi(gsub(\"V\", \"\", name)) - 1)\n  # print(end_df)\n  grid_color &lt;- rgb(0, 0, 0, 0.1)\n\n  # And plot!\n  walkplot &lt;- ggplot(\n      long_tib,\n      aes(\n          x = step_num,\n          y = value,\n          group = pid,\n          # color=factor(label)\n      )\n  ) +\n      geom_line(linewidth = g_linesize, alpha = opacity, color = cbPalette[1]) +\n      geom_point(data = end_tib, aes(x = x, y = endpos), alpha = 0) +\n      scale_x_continuous(breaks = seq(0, num_steps, num_steps / 4)) +\n      scale_y_continuous(breaks = seq(-20, 20, 10)) +\n      dsan_theme(\"quarter\") +\n      theme(\n          legend.position = \"none\",\n          title = element_text(size = 16)\n      ) +\n      theme(\n          panel.grid.major.y = element_line(color = grid_color, linewidth = 1, linetype = 1)\n      ) +\n      labs(\n          title = paste0(num_people, \" Random Walks, \", num_steps, \" Steps\"),\n          x = \"Number of Steps\",\n          y = \"Position\"\n      )\n}\nwp1 &lt;- gen_walkplot(500, 16, 0.05)\n\n\nWarning: The `x` argument of `as_tibble.matrix()` must have unique column names if\n`.name_repair` is omitted as of tibble 2.0.0.\nℹ Using compatibility `.name_repair`.\n\n\nCode\nggMarginal(wp1, margins = \"y\", type = \"histogram\", yparams = list(binwidth = 1))"
  },
  {
    "objectID": "w05/index.html#the-result-64-steps",
    "href": "w05/index.html#the-result-64-steps",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "The Result: 64 Steps",
    "text": "The Result: 64 Steps\n\n\nCode\nlibrary(ggExtra)\nwp2 &lt;- gen_walkplot(5000,64,0.008) +\n  ylim(-30,30)\n\n\nScale for y is already present.\nAdding another scale for y, which will replace the existing scale.\n\n\nCode\nggMarginal(wp2, margins = \"y\", type = \"histogram\", yparams = list(binwidth = 1))\n\n\n\n\n\n\n\n\np2 &lt;- gen_histo(1000, 16)\np2\n\n\n\n\n\np3 &lt;- gen_histo(10000, 32)\np3"
  },
  {
    "objectID": "w05/index.html#whats-going-on-here",
    "href": "w05/index.html#whats-going-on-here",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "What’s Going On Here?",
    "text": "What’s Going On Here?\n\n\n\n\n\n(Stay tuned for Markov processes \\(\\overset{t \\rightarrow \\infty}{\\leadsto}\\) Stationary distributions!)"
  },
  {
    "objectID": "w05/index.html#properties-of-the-normal-distribution",
    "href": "w05/index.html#properties-of-the-normal-distribution",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "Properties of the Normal Distribution",
    "text": "Properties of the Normal Distribution\n\nIf \\(X \\sim \\mathcal{N}(\\param{\\mu}, \\param{\\theta})\\), then \\(X\\) has pdf \\(f_X(v)\\) defined by\n\n\\[\nf_X(v) = \\frac{1}{\\sigma\\sqrt{2\\pi}}\\bigexp{-\\frac{1}{2}\\left(\\frac{v - \\mu}{\\sigma}\\right)^2}\n\\]\n\nI hate memorizing as much as you do, I promise 🥴\nThe important part (imo): this is the most conservative out of all possible (symmetric) prior distributions defined on \\(\\mathbb{R}\\) (defined from \\(-\\infty\\) to \\(\\infty\\))"
  },
  {
    "objectID": "w05/index.html#most-conservative-how",
    "href": "w05/index.html#most-conservative-how",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "“Most Conservative” How?",
    "text": "“Most Conservative” How?\n\nOf all possible distributions with mean \\(\\mu\\), variance \\(\\sigma^2\\), \\(\\mathcal{N}(\\mu, \\sigma^2)\\) is the entropy-maximizing distribution\nRoughly: using any other distribution (implicitly/secretly) imports additional information beyond the fact that mean is \\(\\mu\\) and variance is \\(\\sigma^2\\)\nExample: let \\(X\\) be an RV. If we know mean is \\(\\mu\\), variance is \\(\\sigma^2\\), but then we learn that \\(X \\neq 3\\), or \\(X\\) is even, or the 15th digit of \\(X\\) is 7, can update to derive a “better” distribution (incorporating this info)"
  },
  {
    "objectID": "w05/index.html#the-takeaway",
    "href": "w05/index.html#the-takeaway",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "The Takeaway",
    "text": "The Takeaway\n\nGiven info we know, we can find a distribution that “encodes” only this info\nMore straightforward example: if we only know that the value is something in the range \\([a,b]\\), entropy-maximizing distribution is the Uniform Distribution\n\n\n\n\n\n\n\n\n\nIf We Know\nAnd We Know\n(Max-Entropy) Distribution Is…\n\n\n\n\n\\(\\text{Mean}[X] = \\mu\\)\n\\(\\text{Var}[X] = \\sigma^2\\)\n\\(X \\sim \\mathcal{N}(\\mu, \\sigma^2)\\)\n\n\n\\(\\text{Mean}[X] = \\lambda\\)\n\\(X \\geq 0\\)\n\\(X \\sim \\text{Exp}\\left(\\frac{1}{\\lambda}\\right)\\)\n\n\n\\(X \\geq a\\)\n\\(X \\leq b\\)\n\\(X \\sim \\mathcal{U}[a,b]\\)"
  },
  {
    "objectID": "w05/index.html#recall-discrete-uniform-distribution",
    "href": "w05/index.html#recall-discrete-uniform-distribution",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "[Recall] Discrete Uniform Distribution",
    "text": "[Recall] Discrete Uniform Distribution\n\n\nCode\nlibrary(tibble)\nbar_data &lt;- tribble(\n  ~x, ~prob,\n  1, 1/6,\n  2, 1/6,\n  3, 1/6,\n  4, 1/6,\n  5, 1/6,\n  6, 1/6\n)\nggplot(bar_data, aes(x=x, y=prob)) +\n  geom_bar(stat=\"identity\", fill=cbPalette[1]) +\n  labs(\n    title=\"Discrete Uniform pmf: a = 1, b = 6\",\n    y=\"Probability Mass\",\n    x=\"Value\"\n  ) +\n  scale_x_continuous(breaks=seq(1,6)) +\n  dsan_theme(\"half\")"
  },
  {
    "objectID": "w05/index.html#continuous-uniform-distribution",
    "href": "w05/index.html#continuous-uniform-distribution",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "Continuous Uniform Distribution",
    "text": "Continuous Uniform Distribution\n\nIf \\(X \\sim \\mathcal{U}[a,b]\\), then intuitively \\(X\\) is a value randomly selected from within \\([a,b]\\), with all values equally likely.\nDiscrete case: what we’ve been using all along (e.g., dice): if \\(X \\sim \\mathcal{U}\\{1,6\\}\\), then\n\n\\[\n\\Pr(X = 1) = \\Pr(X = 2) = \\cdots = \\Pr(X = 6) = \\frac{1}{6}\n\\]\n\nFor continuous case… what do we put in the denominator? \\(X \\sim \\mathcal{U}[1,6] \\implies \\Pr(X = \\pi) = \\frac{1}{?}\\)…\n\nAnswer: \\(\\Pr(X = \\pi) = \\frac{1}{|[1,6]|} = \\frac{1}{\\aleph_0} = 0\\)"
  },
  {
    "objectID": "w05/index.html#constructing-the-uniform-cdf",
    "href": "w05/index.html#constructing-the-uniform-cdf",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "Constructing the Uniform CDF",
    "text": "Constructing the Uniform CDF\n\nWe were ready for this! We already knew \\(\\Pr(X = v) = 0\\) for continuous distributions.\nSo, we forget about \\(\\Pr(X = v)\\), and focus on \\(\\Pr(X \\in [v_0, v_1])\\).\nIn 2D (dartboard) we had \\(\\Pr(X \\in \\circ) = \\frac{\\text{Area}(\\circ)}{\\text{Area}(\\Omega)}\\), so here we should have\n\n\\[\nP(X \\in [v_0,v_1]) = \\frac{\\text{Length}([v_0,v_1])}{\\text{Length}([1,6])}\n\\]\n\nAnd indeed, the CDF of \\(X\\) is \\(\\boxed{F_X(v) = \\Pr(X \\leq v) = \\frac{v-a}{b-a}}\\), so that\n\n\\[\n\\Pr(X \\in [v_0,v_1]) = F_X(v_1) - F_X(v_0) = \\frac{v_1-a}{b-a} - \\frac{v_0-a}{b-a} = \\frac{v_1 - v_0}{b-a}\n\\]\n\nSince \\(a = 1\\), \\(b = 6\\) in our example, \\(\\Pr(X \\in [v_0,v_1]) = \\frac{v_1-v_0}{6-1} = \\frac{\\text{Length}([v_0,v_1])}{\\text{Length}([1,6])} \\; ✅\\)"
  },
  {
    "objectID": "w05/index.html#exponential-distribution",
    "href": "w05/index.html#exponential-distribution",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "Exponential Distribution",
    "text": "Exponential Distribution\n\nRecall the (discrete) Geometric Distribution:\n\n\n\nCode\nlibrary(ggplot2)\nk &lt;- seq(0, 8)\nprob &lt;- dgeom(k, 0.5)\nbar_data &lt;- tibble(k, prob)\nggplot(bar_data, aes(x = k, y = prob)) +\n    geom_bar(stat = \"identity\", fill = cbPalette[1]) +\n    labs(\n        title = \"Geometric Distribution pmf: p = 0.5\",\n        y = \"Probability Mass\"\n    ) +\n    scale_x_continuous(breaks = seq(0, 8)) +\n    dsan_theme(\"half\")"
  },
  {
    "objectID": "w05/index.html#now-in-continuous-form",
    "href": "w05/index.html#now-in-continuous-form",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "Now In Continuous Form!",
    "text": "Now In Continuous Form!\n\n\nCode\nmy_dexp &lt;- function(x) dexp(x, rate = 1/2)\nggplot(data.frame(x=c(0,8)), aes(x=x)) +\n  stat_function(fun=my_dexp, size=g_linesize, fill=cbPalette[1], alpha=0.8) +\n  stat_function(fun=my_dexp, geom='area', fill=cbPalette[1], alpha=0.75) +\n  dsan_theme(\"half\") +\n  labs(\n    title=\"Exponential Distribution pdf: λ (rate) = 0.5\",\n    x = \"v\",\n    y = \"f_X(v)\"\n  )\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nWarning in stat_function(fun = my_dexp, size = g_linesize, fill = cbPalette[1],\n: Ignoring unknown parameters: `fill`"
  },
  {
    "objectID": "w05/index.html#the-dreaded-cauchy-distribution",
    "href": "w05/index.html#the-dreaded-cauchy-distribution",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "The Dreaded Cauchy Distribution",
    "text": "The Dreaded Cauchy Distribution\n\nPaxton is a Denver Nuggets fan, while Jeff is a Washington Wizards fan. Paxton creates an RV \\(D\\) modeling how many games above .500 the Nuggets will be in a given season, while Jeff creates an RV \\(W\\) modeling how many games above .500 the Wizards will be.\nThey decide to combine their RVs to create a new RV, \\(R = \\frac{D}{W}\\), which now models how much better the Nuggets will be in a season (\\(R\\) for “Ratio”)\nFor example, if the Nuggets are \\(10\\) games above .500, while the Wizards are only \\(5\\) above .500, \\(R = \\frac{10}{5} = 2\\). If they’re both 3 games above .500, \\(R = \\frac{3}{3} = 1\\).\n\n\n\nCode\nggplot(data.frame(x=c(-4,4)), aes(x=x)) +\n  stat_function(fun=dcauchy, size=g_linesize, fill=cbPalette[1], alpha=0.75) +\n  stat_function(fun=dcauchy, geom='area', fill=cbPalette[1], alpha=0.75) +\n  dsan_theme(\"quarter\") +\n  labs(\n    title=\"PDF of R\",\n    x = \"r\",\n    y = \"f(r)\"\n  )\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nWarning in stat_function(fun = dcauchy, size = g_linesize, fill = cbPalette[1],\n: Ignoring unknown parameters: `fill`"
  },
  {
    "objectID": "w05/index.html#so-whats-the-issue",
    "href": "w05/index.html#so-whats-the-issue",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "So What’s the Issue?",
    "text": "So What’s the Issue?\n\nSo far so good. It turns out (though Paxton and Jeff don’t know this) that the teams are actually both mediocre, so that \\(D \\sim N(0,10)\\) and \\(W \\sim N(0,10)\\)… What is the distribution of \\(R\\) in this case?\n\n\n\n\n\\[\n\\begin{gather*}\nR \\sim \\text{Cauchy}\\left( 0, 1 \\right)\n\\end{gather*}\n\\]\n\\[\n\\begin{align*}\n\\expect{R} &= ☠️ \\\\\n\\Var{R} &= ☠️ \\\\\nM_R(t) &= ☠️\n\\end{align*}\n\\]\n\n\n\n\n\nFrom Agnesi (1801) [Internet Archive]\n\n\n\n\n\n\n\nEven worse, this is true regardless of variances: \\(D \\sim N(0,d), W \\sim N(0,w) \\implies R \\sim \\text{Cauchy}\\left( 0,\\frac{d}{w} \\right)\\)…"
  },
  {
    "objectID": "w05/index.html#lab-4-demo",
    "href": "w05/index.html#lab-4-demo",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "Lab 4 Demo",
    "text": "Lab 4 Demo\n\nLab 4 Demo Link \nChoose your own adventure:\n\nOfficial lab demo\nMath puzzle lab demo\nMove on to Expectation, Variance, Moments"
  },
  {
    "objectID": "w05/index.html#lab-4-assignment-prep",
    "href": "w05/index.html#lab-4-assignment-prep",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "Lab 4 Assignment Prep",
    "text": "Lab 4 Assignment Prep\n\nOne of my favorite math puzzles ever:\n\n\n\n\n\n\n\nThe Problem of the Broken Stick (Gardner 2001, 273–85)\n\n\n\nIf a stick is broken at random into three pieces, what is the probability that the pieces can be put back together into a triangle?\nThis cannot be answered without additional information about the exact method of breaking\n\nOne method is to select, independently and at random, two points from the points that range uniformly along the stick, then break the stick at these two points\nSuppose, however, that we interpret in a different way the statement “break a stick at random into three pieces”. We break the stick at random, we select randomly one of the two pieces, and we break that piece at random.\n\n\n\n\nWill these two interpretations result in the same probabilities?\nIf yes, what is that probability?\nIf no, what are the probabilities in each case?"
  },
  {
    "objectID": "w05/index.html#lab-4-assignment",
    "href": "w05/index.html#lab-4-assignment",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "Lab 4 Assignment",
    "text": "Lab 4 Assignment\n\nLab 4 Assignment Link"
  },
  {
    "objectID": "w05/index.html#references",
    "href": "w05/index.html#references",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "References",
    "text": "References\n\n\nAgnesi, Maria Gaetana. 1801. Analytical Institutions in Four Books: Originally Written in Italian. Taylor and Wilks.\n\n\nGardner, Martin. 2001. Colossal Book of Mathematics: Classic Puzzles Paradoxes And Problems. W. W. Norton & Company."
  },
  {
    "objectID": "w05/index.html#appendix-dirac-delta-function",
    "href": "w05/index.html#appendix-dirac-delta-function",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "Appendix: Dirac Delta Function",
    "text": "Appendix: Dirac Delta Function\n\n\\(\\delta(v)\\) as used in the “Top Secret Fun Fact” slide is called the Dirac Delta function.\nIt enables conversion of discrete distributions into continuous distributions as it represents an “infinite point mass” at \\(0\\) that can be integrated1:\n\n\\[\n\\delta(v) = \\begin{cases}\\infty & v = 0 \\\\ 0 & v \\neq 0\\end{cases}\n\\]\n\nIts integral also has a name: integrating over \\(v \\in (-\\infty, \\infty)\\) produces the Heaviside step function \\(\\theta(v)\\):\n\n\\[\n\\int_{-\\infty}^{\\infty}\\delta(v)dv = \\theta(v) = \\begin{cases} 1 & v = 0 \\\\ 0 & v \\neq 0\\end{cases}\n\\]"
  },
  {
    "objectID": "w05/index.html#footnotes",
    "href": "w05/index.html#footnotes",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis is leaving out some of the complexities of defining this function so it “works” in this way: for example, we need to use the Lebesgue integral rather than the (standard) Riemann integral for it to be defined at all, and even then it technically fails the conditions necessary for a fully-well-defined Lebesgue integral. For full details see this section from the Wiki article on PDFs, and follow the links therein.↩︎"
  },
  {
    "objectID": "w05/slides.html#from-last-week",
    "href": "w05/slides.html#from-last-week",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "From Last Week",
    "text": "From Last Week\n\n\n\n\n\n\nCode\nlibrary(tibble)\nlibrary(ggplot2)\ndisc_df &lt;- tribble(\n  ~x, ~y, ~label,\n  0, 0, \"A\",\n  0, 1, \"B\",\n  1, 0, \"C\",\n  1, 1, \"D\"\n)\nggplot(disc_df, aes(x=x, y=y, label=label)) +\n    geom_point(size=g_pointsize) +\n    geom_text(\n      size=g_textsize,\n      hjust=1.5,\n      vjust=-0.5\n    ) +\n    xlim(-0.5,1.5) + ylim(-0.5,1.5) +\n    coord_fixed() +\n    dsan_theme(\"quarter\") +\n    labs(\n      title=\"Discrete Probability Space in N\"\n    )\n\n\n\n\n\n\n\n\n\n\\[\n\\Pr(A) = \\underbrace{\\frac{|\\{A\\}|}{|\\Omega|}}_{\\mathclap{\\small \\text{Probability }\\textbf{mass}}} = \\frac{1}{|\\{A,B,C,D\\}|} = \\frac{1}{4}\n\\]\nFigure 1: Visual and mathematical intuition for events in a discrete probability space\n\n\n\n\n\n\nCode\nlibrary(ggforce)\nggplot(disc_df, aes(x=x, y=y, label=label)) +\n    xlim(-0.5,1.5) + ylim(-0.5,1.5) +\n    geom_rect(aes(xmin = -0.5, xmax = 1.5, ymin = -0.5, ymax = 1.5), fill=cbPalette[1], color=\"black\", alpha=0.3) +\n    geom_circle(aes(x0=x, y0=y, r=0.25), fill=cbPalette[2]) +\n    coord_fixed() +\n    dsan_theme(\"quarter\") +\n    geom_text(\n      size=g_textsize,\n      #hjust=1.75,\n      #vjust=-0.75\n    ) +\n    geom_text(\n      data=data.frame(label=\"Ω\"),\n      aes(x=-0.4,y=1.39),\n      parse=TRUE,\n      size=g_textsize\n    ) +\n    labs(\n      title=expression(\"Continuous Probability Space in \"*R^2)\n    )\n\n\n\n\n\n\n\n\n\n\\[\n\\Pr(A) = \\underbrace{\\frac{\\text{Area}(\\{A\\})}{\\text{Area}(\\Omega)}}_{\\mathclap{\\small \\text{Probability }\\textbf{density}}} = \\frac{\\pi r^2}{s^2} = \\frac{\\pi \\left(\\frac{1}{4}\\right)^2}{4} = \\frac{\\pi}{64}\n\\]\nFigure 2: Visual and mathematical intuition for events a continuous probability space"
  },
  {
    "objectID": "w05/slides.html#what-things-have-distributions",
    "href": "w05/slides.html#what-things-have-distributions",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "What Things Have Distributions?",
    "text": "What Things Have Distributions?\n\nAnswer: Random Variables"
  },
  {
    "objectID": "w05/slides.html#cdfspdfspmfs-what-are-they",
    "href": "w05/slides.html#cdfspdfspmfs-what-are-they",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "CDFs/pdfs/pmfs: What Are They?",
    "text": "CDFs/pdfs/pmfs: What Are They?\n\nFunctions which answer questions about a Random Variable (\\(X\\) in this case) with respect to a non-random value (\\(v\\) in this case, for “value”)\nCDF: What is probability that \\(X\\) takes on a value less than or equal to \\(v\\)?\n\n\\[\nF_X(v) \\definedas \\Pr(X \\leq v)\n\\]\n\npmf: What is the probability of this exact value? (Discrete only)\n\n\\[\np_X(v) \\definedas \\Pr(X = v)\n\\]\n\npdf: 🙈 …It’s the thing you integrate to get the CDF\n\n\\[\nf_X(v) \\definedas \\frac{d}{dv}F_X(v) \\iff \\int_{-\\infty}^{v} f_X(v)dv = F_X(v)\n\\]"
  },
  {
    "objectID": "w05/slides.html#cdfspdfspmfs-why-do-we-use-them",
    "href": "w05/slides.html#cdfspdfspmfs-why-do-we-use-them",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "CDFs/pdfs/pmfs: Why Do We Use Them?",
    "text": "CDFs/pdfs/pmfs: Why Do We Use Them?\n\nCDF is like the “API” that allows you to access all of the information about the distribution (pdf/pmf is derived from the CDF)\nExample: we know there’s some “thing” called the Exponential Distribution…\nHow do we use this distribution to understand a random variable \\(X \\sim \\text{Exp}\\)?\n\nAnswer: the CDF of \\(X\\)!\nSince all exponentially-distributed RVs have the same PDF, we can call this PDF “the” exponential distribution\n\nSay we want to find the median of \\(X\\): The median is the number(s) \\(m\\) satisfying\n\n\\[\n\\Pr(X \\leq m) = \\frac{1}{2}\n\\]"
  },
  {
    "objectID": "w05/slides.html#finding-a-median-via-the-cdf",
    "href": "w05/slides.html#finding-a-median-via-the-cdf",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "Finding a Median via the CDF",
    "text": "Finding a Median via the CDF\n\n\n\n\n\n\nMedian of a Random Variable \\(X\\)\n\n\nThe median of a random variable \\(X\\) with some CDF \\(F_X(v_X)\\) is the [set of] numbers \\(m\\) for which the probability that \\(X\\) is lower than \\(m\\) is \\(\\frac{1}{2}\\):\n\\[\n\\begin{align*}\n\\text{Median}(X) &= \\left\\{m \\left| F_X(m) = \\frac{1}{2} \\right. \\right\\} \\\\\n&= \\left\\{m \\left| \\int_{-\\infty}^{m}f_X(v_X)dv_X = \\frac{1}{2} \\right. \\right\\}\n\\end{align*}\n\\]\n\n\n\n\n\n(In case you’re wondering why we start with the median rather than the more commonly-used mean: it’s specifically because I want you to get used to calculating general functions \\(f(X)\\) of a random variable \\(X\\). It’s easy to just e.g. learn how to compute the mean \\(\\expect{X}\\) and forget that this is only one of many possible choices for \\(f(X)\\).)"
  },
  {
    "objectID": "w05/slides.html#median-via-cdf-example",
    "href": "w05/slides.html#median-via-cdf-example",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "Median via CDF Example",
    "text": "Median via CDF Example\nExample: If \\(X \\sim \\text{Exp}(\\param{\\lambda})\\),\n\\[\nF_X(v) = 1 - e^{-\\lambda v}\n\\]\nSo we want to solve for \\(m\\) in\n\\[\nF_X(m) = \\frac{1}{2} \\iff 1 - e^{-\\lambda m} = \\frac{1}{2}\n\\]"
  },
  {
    "objectID": "w05/slides.html#step-by-step",
    "href": "w05/slides.html#step-by-step",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "Step-by-Step",
    "text": "Step-by-Step\n\\[\n\\begin{align*}\n1 - e^{-\\lambda m} &= \\frac{1}{2} \\\\\n\\iff e^{-\\lambda m} &= \\frac{1}{2} \\\\\n\\iff \\ln\\left[e^{-\\lambda m}\\right] &= \\ln\\left[\\frac{1}{2}\\right] \\\\\n\\iff -\\lambda m &= -\\ln(2) \\\\\n\\iff m &= \\frac{\\ln(2)}{\\lambda}\n%3x = 19-2y\n\\; \\llap{\\mathrel{\\boxed{\\phantom{m = \\frac{\\ln(2)}{\\lambda}}}}}.\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w05/slides.html#what-is-a-pdf",
    "href": "w05/slides.html#what-is-a-pdf",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "What is a pdf?",
    "text": "What is a pdf?\n\nAnswer: Has no meaning outside of its context: a random variable with a CDF giving the distribution of its possible values"
  },
  {
    "objectID": "w05/slides.html#top-secret-fun-fact",
    "href": "w05/slides.html#top-secret-fun-fact",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "Top Secret Fun Fact",
    "text": "Top Secret Fun Fact\n\nEvery Discrete Distribution is [technically, in a weird way] a Continuous Distribution!\n\n\nSame intuition as why every natural number is a real number, but converse is not true\nMarble example: Let \\(X\\) be an RV defined on this space, so that \\(X(A) = 1\\), \\(X(B) = 2\\), \\(X(C) = 3\\), \\(X(D) = 4\\). Then the pmf for \\(X\\) is \\(p_X(i) = \\frac{1}{4}\\) for \\(i \\in \\{1, 2, 3, 4\\}\\).\nWe can then use the Dirac delta function \\(\\delta(v)\\) to define a continuous pdf\n\\[\n  f_X(v) = \\sum_{i \\in \\mathcal{R}_X}p_X(i)\\delta(v - i) = \\sum_{i=1}^4p_X(i)\\delta(v-i) = \\frac{1}{4}\\sum_{i=1}^4 \\delta(v - i)\n  \\]\nand use either the (discrete) pmf \\(p_X(v)\\) or (continuous) pdf \\(f_X(v)\\) to describe \\(X\\):\n\n\\[\n\\begin{align*}\n\\overbrace{\\Pr(X \\leq 3)}^{\\text{CDF}} &= \\sum_{i=1}^3\\overbrace{p_X(i)}^{\\text{pmf}} = \\frac{1}{4} + \\frac{1}{4} + \\frac{1}{4} = \\frac{3}{4} \\\\\n\\underbrace{\\Pr(X \\leq 3)}_{\\text{CDF}} &= \\int_{-\\infty}^{3} \\underbrace{f_X(v)}_{\\text{pdf}} = \\frac{1}{4}\\int_{-\\infty}^{3} \\sum_{i = 1}^{4}\\overbrace{\\delta(v-i)}^{\\small 0\\text{ unless }v = i}dv = \\frac{3}{4}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w05/slides.html#normal-distribution",
    "href": "w05/slides.html#normal-distribution",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "Normal Distribution",
    "text": "Normal Distribution\n\nRecall from last week: the Binomial pdf\n\n\n\nCode\nk &lt;- seq(0, 10)\nprob &lt;- dbinom(k, 10, 0.5)\nbar_data &lt;- tibble(k, prob)\nggplot(bar_data, aes(x=k, y=prob)) +\n  geom_bar(stat=\"identity\", fill=cbPalette[1]) +\n  labs(\n    title=\"Binomial Distribution, N = 10, p = 0.5\",\n    y=\"Probability Mass\"\n  ) +\n  scale_x_continuous(breaks=seq(0,10)) +\n  dsan_theme(\"half\")"
  },
  {
    "objectID": "w05/slides.html#the-emergence-of-order",
    "href": "w05/slides.html#the-emergence-of-order",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "The Emergence of Order",
    "text": "The Emergence of Order\n\n\n\n\nWho can guess the state of this process after 10 steps, with 1 person?\n10 people? 50? 100? (If they find themselves on the same spot, they stand on each other’s heads)\n100 steps? 1000?"
  },
  {
    "objectID": "w05/slides.html#the-result-16-steps",
    "href": "w05/slides.html#the-result-16-steps",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "The Result: 16 Steps",
    "text": "The Result: 16 Steps\n\n\nCode\nlibrary(tibble)\nlibrary(ggplot2)\nlibrary(ggExtra)\nlibrary(dplyr)\nlibrary(tidyr)\n# From McElreath!\ngen_histo &lt;- function(reps, num_steps) {\n  support &lt;- c(-1,1)\n  pos &lt;-replicate(reps, sum(sample(support,num_steps,replace=TRUE,prob=c(0.5,0.5))))\n  #print(mean(pos))\n  #print(var(pos))\n  pos_df &lt;- tibble(x=pos)\n  clt_distr &lt;- function(x) dnorm(x, 0, sqrt(num_steps))\n  plot &lt;- ggplot(pos_df, aes(x=x)) +\n    geom_histogram(aes(y = after_stat(density)), fill=cbPalette[1], binwidth = 2) +\n    stat_function(fun = clt_distr) +\n    dsan_theme(\"quarter\") +\n    theme(title=element_text(size=16)) +\n    labs(\n      title=paste0(reps,\" Random Walks, \",num_steps,\" Steps\")\n    )\n  return(plot)\n}\ngen_walkplot &lt;- function(num_people, num_steps, opacity=0.15) {\n  support &lt;- c(-1, 1)\n  # Unique id for each person\n  pid &lt;- seq(1, num_people)\n  pid_tib &lt;- tibble(pid)\n  pos_df &lt;- tibble()\n  end_df &lt;- tibble()\n  all_steps &lt;- t(replicate(num_people, sample(support, num_steps, replace = TRUE, prob = c(0.5, 0.5))))\n  csums &lt;- t(apply(all_steps, 1, cumsum))\n  csums &lt;- cbind(0, csums)\n  # Last col is the ending positions\n  ending_pos &lt;- csums[, dim(csums)[2]]\n  end_tib &lt;- tibble(pid = seq(1, num_people), endpos = ending_pos, x = num_steps)\n  # Now convert to tibble\n  ctib &lt;- as_tibble(csums, name_repair = \"none\")\n  merged_tib &lt;- bind_cols(pid_tib, ctib)\n  long_tib &lt;- merged_tib %&gt;% pivot_longer(!pid)\n  # Convert name -&gt; step_num\n  long_tib &lt;- long_tib %&gt;% mutate(step_num = strtoi(gsub(\"V\", \"\", name)) - 1)\n  # print(end_df)\n  grid_color &lt;- rgb(0, 0, 0, 0.1)\n\n  # And plot!\n  walkplot &lt;- ggplot(\n      long_tib,\n      aes(\n          x = step_num,\n          y = value,\n          group = pid,\n          # color=factor(label)\n      )\n  ) +\n      geom_line(linewidth = g_linesize, alpha = opacity, color = cbPalette[1]) +\n      geom_point(data = end_tib, aes(x = x, y = endpos), alpha = 0) +\n      scale_x_continuous(breaks = seq(0, num_steps, num_steps / 4)) +\n      scale_y_continuous(breaks = seq(-20, 20, 10)) +\n      dsan_theme(\"quarter\") +\n      theme(\n          legend.position = \"none\",\n          title = element_text(size = 16)\n      ) +\n      theme(\n          panel.grid.major.y = element_line(color = grid_color, linewidth = 1, linetype = 1)\n      ) +\n      labs(\n          title = paste0(num_people, \" Random Walks, \", num_steps, \" Steps\"),\n          x = \"Number of Steps\",\n          y = \"Position\"\n      )\n}\nwp1 &lt;- gen_walkplot(500, 16, 0.05)\nggMarginal(wp1, margins = \"y\", type = \"histogram\", yparams = list(binwidth = 1))"
  },
  {
    "objectID": "w05/slides.html#the-result-64-steps",
    "href": "w05/slides.html#the-result-64-steps",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "The Result: 64 Steps",
    "text": "The Result: 64 Steps\n\n\nCode\nlibrary(ggExtra)\nwp2 &lt;- gen_walkplot(5000,64,0.008) +\n  ylim(-30,30)\nggMarginal(wp2, margins = \"y\", type = \"histogram\", yparams = list(binwidth = 1))\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\np2 &lt;- gen_histo(1000, 16)\np2\n\n\n\n\n\n\n\n\n\n\n\nCode\np3 &lt;- gen_histo(10000, 32)\np3"
  },
  {
    "objectID": "w05/slides.html#whats-going-on-here",
    "href": "w05/slides.html#whats-going-on-here",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "What’s Going On Here?",
    "text": "What’s Going On Here?\n\n(Stay tuned for Markov processes \\(\\overset{t \\rightarrow \\infty}{\\leadsto}\\) Stationary distributions!)"
  },
  {
    "objectID": "w05/slides.html#properties-of-the-normal-distribution",
    "href": "w05/slides.html#properties-of-the-normal-distribution",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "Properties of the Normal Distribution",
    "text": "Properties of the Normal Distribution\n\nIf \\(X \\sim \\mathcal{N}(\\param{\\mu}, \\param{\\theta})\\), then \\(X\\) has pdf \\(f_X(v)\\) defined by\n\n\\[\nf_X(v) = \\frac{1}{\\sigma\\sqrt{2\\pi}}\\bigexp{-\\frac{1}{2}\\left(\\frac{v - \\mu}{\\sigma}\\right)^2}\n\\]\n\nI hate memorizing as much as you do, I promise 🥴\nThe important part (imo): this is the most conservative out of all possible (symmetric) prior distributions defined on \\(\\mathbb{R}\\) (defined from \\(-\\infty\\) to \\(\\infty\\))"
  },
  {
    "objectID": "w05/slides.html#most-conservative-how",
    "href": "w05/slides.html#most-conservative-how",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "“Most Conservative” How?",
    "text": "“Most Conservative” How?\n\nOf all possible distributions with mean \\(\\mu\\), variance \\(\\sigma^2\\), \\(\\mathcal{N}(\\mu, \\sigma^2)\\) is the entropy-maximizing distribution\nRoughly: using any other distribution (implicitly/secretly) imports additional information beyond the fact that mean is \\(\\mu\\) and variance is \\(\\sigma^2\\)\nExample: let \\(X\\) be an RV. If we know mean is \\(\\mu\\), variance is \\(\\sigma^2\\), but then we learn that \\(X \\neq 3\\), or \\(X\\) is even, or the 15th digit of \\(X\\) is 7, can update to derive a “better” distribution (incorporating this info)"
  },
  {
    "objectID": "w05/slides.html#the-takeaway",
    "href": "w05/slides.html#the-takeaway",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "The Takeaway",
    "text": "The Takeaway\n\nGiven info we know, we can find a distribution that “encodes” only this info\nMore straightforward example: if we only know that the value is something in the range \\([a,b]\\), entropy-maximizing distribution is the Uniform Distribution\n\n\n\n\n\n\n\n\n\nIf We Know\nAnd We Know\n(Max-Entropy) Distribution Is…\n\n\n\n\n\\(\\text{Mean}[X] = \\mu\\)\n\\(\\text{Var}[X] = \\sigma^2\\)\n\\(X \\sim \\mathcal{N}(\\mu, \\sigma^2)\\)\n\n\n\\(\\text{Mean}[X] = \\lambda\\)\n\\(X \\geq 0\\)\n\\(X \\sim \\text{Exp}\\left(\\frac{1}{\\lambda}\\right)\\)\n\n\n\\(X \\geq a\\)\n\\(X \\leq b\\)\n\\(X \\sim \\mathcal{U}[a,b]\\)"
  },
  {
    "objectID": "w05/slides.html#recall-discrete-uniform-distribution",
    "href": "w05/slides.html#recall-discrete-uniform-distribution",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "[Recall] Discrete Uniform Distribution",
    "text": "[Recall] Discrete Uniform Distribution\n\n\nCode\nlibrary(tibble)\nbar_data &lt;- tribble(\n  ~x, ~prob,\n  1, 1/6,\n  2, 1/6,\n  3, 1/6,\n  4, 1/6,\n  5, 1/6,\n  6, 1/6\n)\nggplot(bar_data, aes(x=x, y=prob)) +\n  geom_bar(stat=\"identity\", fill=cbPalette[1]) +\n  labs(\n    title=\"Discrete Uniform pmf: a = 1, b = 6\",\n    y=\"Probability Mass\",\n    x=\"Value\"\n  ) +\n  scale_x_continuous(breaks=seq(1,6)) +\n  dsan_theme(\"half\")"
  },
  {
    "objectID": "w05/slides.html#continuous-uniform-distribution",
    "href": "w05/slides.html#continuous-uniform-distribution",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "Continuous Uniform Distribution",
    "text": "Continuous Uniform Distribution\n\nIf \\(X \\sim \\mathcal{U}[a,b]\\), then intuitively \\(X\\) is a value randomly selected from within \\([a,b]\\), with all values equally likely.\nDiscrete case: what we’ve been using all along (e.g., dice): if \\(X \\sim \\mathcal{U}\\{1,6\\}\\), then\n\n\\[\n\\Pr(X = 1) = \\Pr(X = 2) = \\cdots = \\Pr(X = 6) = \\frac{1}{6}\n\\]\n\nFor continuous case… what do we put in the denominator? \\(X \\sim \\mathcal{U}[1,6] \\implies \\Pr(X = \\pi) = \\frac{1}{?}\\)…\n\nAnswer: \\(\\Pr(X = \\pi) = \\frac{1}{|[1,6]|} = \\frac{1}{\\aleph_0} = 0\\)"
  },
  {
    "objectID": "w05/slides.html#constructing-the-uniform-cdf",
    "href": "w05/slides.html#constructing-the-uniform-cdf",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "Constructing the Uniform CDF",
    "text": "Constructing the Uniform CDF\n\nWe were ready for this! We already knew \\(\\Pr(X = v) = 0\\) for continuous distributions.\nSo, we forget about \\(\\Pr(X = v)\\), and focus on \\(\\Pr(X \\in [v_0, v_1])\\).\nIn 2D (dartboard) we had \\(\\Pr(X \\in \\circ) = \\frac{\\text{Area}(\\circ)}{\\text{Area}(\\Omega)}\\), so here we should have\n\n\\[\nP(X \\in [v_0,v_1]) = \\frac{\\text{Length}([v_0,v_1])}{\\text{Length}([1,6])}\n\\]\n\nAnd indeed, the CDF of \\(X\\) is \\(\\boxed{F_X(v) = \\Pr(X \\leq v) = \\frac{v-a}{b-a}}\\), so that\n\n\\[\n\\Pr(X \\in [v_0,v_1]) = F_X(v_1) - F_X(v_0) = \\frac{v_1-a}{b-a} - \\frac{v_0-a}{b-a} = \\frac{v_1 - v_0}{b-a}\n\\]\n\nSince \\(a = 1\\), \\(b = 6\\) in our example, \\(\\Pr(X \\in [v_0,v_1]) = \\frac{v_1-v_0}{6-1} = \\frac{\\text{Length}([v_0,v_1])}{\\text{Length}([1,6])} \\; ✅\\)"
  },
  {
    "objectID": "w05/slides.html#exponential-distribution",
    "href": "w05/slides.html#exponential-distribution",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "Exponential Distribution",
    "text": "Exponential Distribution\n\nRecall the (discrete) Geometric Distribution:\n\n\n\nCode\nlibrary(ggplot2)\nk &lt;- seq(0, 8)\nprob &lt;- dgeom(k, 0.5)\nbar_data &lt;- tibble(k, prob)\nggplot(bar_data, aes(x = k, y = prob)) +\n    geom_bar(stat = \"identity\", fill = cbPalette[1]) +\n    labs(\n        title = \"Geometric Distribution pmf: p = 0.5\",\n        y = \"Probability Mass\"\n    ) +\n    scale_x_continuous(breaks = seq(0, 8)) +\n    dsan_theme(\"half\")"
  },
  {
    "objectID": "w05/slides.html#now-in-continuous-form",
    "href": "w05/slides.html#now-in-continuous-form",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "Now In Continuous Form!",
    "text": "Now In Continuous Form!\n\n\nCode\nmy_dexp &lt;- function(x) dexp(x, rate = 1/2)\nggplot(data.frame(x=c(0,8)), aes(x=x)) +\n  stat_function(fun=my_dexp, size=g_linesize, fill=cbPalette[1], alpha=0.8) +\n  stat_function(fun=my_dexp, geom='area', fill=cbPalette[1], alpha=0.75) +\n  dsan_theme(\"half\") +\n  labs(\n    title=\"Exponential Distribution pdf: λ (rate) = 0.5\",\n    x = \"v\",\n    y = \"f_X(v)\"\n  )"
  },
  {
    "objectID": "w05/slides.html#the-dreaded-cauchy-distribution",
    "href": "w05/slides.html#the-dreaded-cauchy-distribution",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "The Dreaded Cauchy Distribution",
    "text": "The Dreaded Cauchy Distribution\n\nPaxton is a Denver Nuggets fan, while Jeff is a Washington Wizards fan. Paxton creates an RV \\(D\\) modeling how many games above .500 the Nuggets will be in a given season, while Jeff creates an RV \\(W\\) modeling how many games above .500 the Wizards will be.\nThey decide to combine their RVs to create a new RV, \\(R = \\frac{D}{W}\\), which now models how much better the Nuggets will be in a season (\\(R\\) for “Ratio”)\nFor example, if the Nuggets are \\(10\\) games above .500, while the Wizards are only \\(5\\) above .500, \\(R = \\frac{10}{5} = 2\\). If they’re both 3 games above .500, \\(R = \\frac{3}{3} = 1\\).\n\n\n\nCode\nggplot(data.frame(x=c(-4,4)), aes(x=x)) +\n  stat_function(fun=dcauchy, size=g_linesize, fill=cbPalette[1], alpha=0.75) +\n  stat_function(fun=dcauchy, geom='area', fill=cbPalette[1], alpha=0.75) +\n  dsan_theme(\"quarter\") +\n  labs(\n    title=\"PDF of R\",\n    x = \"r\",\n    y = \"f(r)\"\n  )"
  },
  {
    "objectID": "w05/slides.html#so-whats-the-issue",
    "href": "w05/slides.html#so-whats-the-issue",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "So What’s the Issue?",
    "text": "So What’s the Issue?\n\nSo far so good. It turns out (though Paxton and Jeff don’t know this) that the teams are actually both mediocre, so that \\(D \\sim N(0,10)\\) and \\(W \\sim N(0,10)\\)… What is the distribution of \\(R\\) in this case?\n\n\n\n\n\\[\n\\begin{gather*}\nR \\sim \\text{Cauchy}\\left( 0, 1 \\right)\n\\end{gather*}\n\\]\n\\[\n\\begin{align*}\n\\expect{R} &= ☠️ \\\\\n\\Var{R} &= ☠️ \\\\\nM_R(t) &= ☠️\n\\end{align*}\n\\]\n\n\n\n\n\nFrom Agnesi (1801) [Internet Archive]\n\n\n\n\n\n\n\nEven worse, this is true regardless of variances: \\(D \\sim N(0,d), W \\sim N(0,w) \\implies R \\sim \\text{Cauchy}\\left( 0,\\frac{d}{w} \\right)\\)…"
  },
  {
    "objectID": "w05/slides.html#lab-4-demo",
    "href": "w05/slides.html#lab-4-demo",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "Lab 4 Demo",
    "text": "Lab 4 Demo\n\nLab 4 Demo Link \nChoose your own adventure:\n\nOfficial lab demo\nMath puzzle lab demo\nMove on to Expectation, Variance, Moments"
  },
  {
    "objectID": "w05/slides.html#lab-4-assignment-prep",
    "href": "w05/slides.html#lab-4-assignment-prep",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "Lab 4 Assignment Prep",
    "text": "Lab 4 Assignment Prep\n\nOne of my favorite math puzzles ever:\n\n\n\n\nThe Problem of the Broken Stick (Gardner 2001, 273–85)\n\n\nIf a stick is broken at random into three pieces, what is the probability that the pieces can be put back together into a triangle?\nThis cannot be answered without additional information about the exact method of breaking\n\nOne method is to select, independently and at random, two points from the points that range uniformly along the stick, then break the stick at these two points\nSuppose, however, that we interpret in a different way the statement “break a stick at random into three pieces”. We break the stick at random, we select randomly one of the two pieces, and we break that piece at random.\n\n\n\n\n\nWill these two interpretations result in the same probabilities?\nIf yes, what is that probability?\nIf no, what are the probabilities in each case?"
  },
  {
    "objectID": "w05/slides.html#lab-4-assignment",
    "href": "w05/slides.html#lab-4-assignment",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "Lab 4 Assignment",
    "text": "Lab 4 Assignment\n\nLab 4 Assignment Link"
  },
  {
    "objectID": "w05/slides.html#references",
    "href": "w05/slides.html#references",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "References",
    "text": "References\n\n\nAgnesi, Maria Gaetana. 1801. Analytical Institutions in Four Books: Originally Written in Italian. Taylor and Wilks.\n\n\nGardner, Martin. 2001. Colossal Book of Mathematics: Classic Puzzles Paradoxes And Problems. W. W. Norton & Company."
  },
  {
    "objectID": "w05/slides.html#appendix-dirac-delta-function",
    "href": "w05/slides.html#appendix-dirac-delta-function",
    "title": "Week 5: Continuous Probability Distributions",
    "section": "Appendix: Dirac Delta Function",
    "text": "Appendix: Dirac Delta Function\n\n\\(\\delta(v)\\) as used in the “Top Secret Fun Fact” slide is called the Dirac Delta function.\nIt enables conversion of discrete distributions into continuous distributions as it represents an “infinite point mass” at \\(0\\) that can be integrated1:\n\n\\[\n\\delta(v) = \\begin{cases}\\infty & v = 0 \\\\ 0 & v \\neq 0\\end{cases}\n\\]\n\nIts integral also has a name: integrating over \\(v \\in (-\\infty, \\infty)\\) produces the Heaviside step function \\(\\theta(v)\\):\n\n\\[\n\\int_{-\\infty}^{\\infty}\\delta(v)dv = \\theta(v) = \\begin{cases} 1 & v = 0 \\\\ 0 & v \\neq 0\\end{cases}\n\\]\n\n\n\n\nThis is leaving out some of the complexities of defining this function so it “works” in this way: for example, we need to use the Lebesgue integral rather than the (standard) Riemann integral for it to be defined at all, and even then it technically fails the conditions necessary for a fully-well-defined Lebesgue integral. For full details see this section from the Wiki article on PDFs, and follow the links therein."
  },
  {
    "objectID": "recordings/index.html",
    "href": "recordings/index.html",
    "title": "Lecture Recordings",
    "section": "",
    "text": "Order By\n       Default\n         \n          Week\n        \n         \n          Title\n        \n         \n          Last Updated - Oldest\n        \n         \n          Last Updated - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nWeek\n\n\nTitle\n\n\nLast Updated\n\n\n\n\n\n\n6\n\n\nWeek 06 Lecture Recording\n\n\nThursday Sep 28, 2023\n\n\n\n\n5\n\n\nWeek 05 Lecture Recording\n\n\nThursday Sep 21, 2023\n\n\n\n\n4\n\n\nWeek 04 Lecture Recording\n\n\nThursday Sep 14, 2023\n\n\n\n\n3\n\n\nWeek 03 Lecture Recording\n\n\nTuesday Sep 5, 2023\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "writeups/marginalization/index.html",
    "href": "writeups/marginalization/index.html",
    "title": "Marginal Distributions and “Marginalizing Out” A Variable",
    "section": "",
    "text": "My last writeup was focused on how to get started on Problem 1 of the Lab 5 Assignment, so in this one we will focus on how to do the parts towards the end of this problem: namely, figuring out what marginal distributions are, and what it means to “marginalize out” a variable, to go from some joint pdf \\(f_{X,Y}(x,y)\\) to a marginal pdf \\(f_X(x)\\) (by “marginalizing out” the variable \\(Y\\)) or \\(f_Y(y)\\) (by “marginalizing out” the variable \\(X\\))."
  },
  {
    "objectID": "writeups/marginalization/index.html#marginalization-in-discrete-world",
    "href": "writeups/marginalization/index.html#marginalization-in-discrete-world",
    "title": "Marginal Distributions and “Marginalizing Out” A Variable",
    "section": "Marginalization In Discrete World",
    "text": "Marginalization In Discrete World\nMarginalization provides an example of where, unlike the case for some topics in the course, having a good intuition for the discrete case will actually help us a ton even when considering the continuous case. So, let’s start out by thinking through a joint discrete distribution, and thinking about what a marginal distribution derived from this joint discrete distribution actually represents.\nConsider a case where we are the principal at a “senior high school” (in the US, this means a high school/secondary school that students attend for grades 10, 11, and 12), where each student is in some grade but also has an honor student status which is 1 if the student is an honor student and 0 otherwise. We can represent the discrete frequency distribution (not that it is not a probability distribution, since the numbers in each “bin” are not between 0 and 1) using the following raw frequency table:\n\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\n\n\n\n\n\\(G = 10\\)\n10\n5\n\n\n\\(G = 11\\)\n6\n4\n\n\n\\(G = 12\\)\n7\n1\n\n\n\nSo far, we can’t use this table for much of anything, since it doesn’t contain probabilities and we also don’t (yet) know the total number of students, so that we don’t know what proportions of all students fall into each bin.\nSo now let’s say someone asks us the probability that, if we randomly select a student from the school (at uniform), the randomly-selected student will be an honor student in 11th grade.\nBy thinking about what specifically they’re asking for here, we can see that they’re asking us a question about the joint distribution of \\(G\\) and \\(H\\) at the school: specifically, they’re asking us for \\(\\Pr(G = 11, H = 1)\\), a question we can answer if we know the joint distribution \\(f_{G,H}(v_G, v_H)\\).\nUsing our naïve definition of probability, we can compute this probability using the frequencies in the table as\n\\[\n\\Pr(G = 11, H = 1) = \\frac{\\#(G = 11, H = 1)}{\\#\\text{ Students Total}}\n\\]\nand, plugging in the values from the above table, we obtain the answer\n\\[\n\\Pr(G = 11, H = 1) = \\frac{4}{33} \\approx 0.121\n\\]\nFollowing the same logic for all remaining cells in the table, we can convert our frequency table into a probability table by normalizing the counts to be proportions of the total. But, let’s think about two different ways we could compute the total number of students, since we’ll need to think about these two ways later on:\n\nComputing Overall Total by Column (Honors-Status Totals)\nStarting from our original frequency table:\n\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\n\n\n\n\n\\(G = 10\\)\n10\n5\n\n\n\\(G = 11\\)\n6\n4\n\n\n\\(G = 12\\)\n7\n1\n\n\n\nWe could start computing the total number of students by summing columns, to obtain:\n\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\n\n\n\n\n\\(G = 10\\)\n10\n5\n\n\n\\(G = 11\\)\n6\n4\n\n\n\\(G = 12\\)\n7\n1\n\n\nTotal\n23\n10\n\n\n\nAnd then we could total these two numbers in the totals row to obtain the overall total:\n\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\nTotal\n\n\n\n\n\\(G = 10\\)\n10\n5\n\n\n\n\\(G = 11\\)\n6\n4\n\n\n\n\\(G = 12\\)\n7\n1\n\n\n\nTotal\n23\n10\n33\n\n\n\n\n\nComputing Overall Total by Row (Grade)\nAs an alternative to starting our computation of the overall totals by summing columns, we could start by summing rows.\nStarting from our original frequency table:\n\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\n\n\n\n\n\\(G = 10\\)\n10\n5\n\n\n\\(G = 11\\)\n6\n4\n\n\n\\(G = 12\\)\n7\n1\n\n\n\nWe could first sum each row, to obtain:\n\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\nTotal\n\n\n\n\n\\(G = 10\\)\n10\n5\n15\n\n\n\\(G = 11\\)\n6\n4\n10\n\n\n\\(G = 12\\)\n7\n1\n8\n\n\n\nAnd then we could total the three partial sums in the totals column to obtain the overall total:\n\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\nTotal\n\n\n\n\n\\(G = 10\\)\n10\n5\n15\n\n\n\\(G = 11\\)\n6\n4\n10\n\n\n\\(G = 12\\)\n7\n1\n8\n\n\nTotal\n\n\n33\n\n\n\n\n\nBringing Both Methods Together\nNotice how we obtained the same overall total, the total number of students, regardless of which dimension we chose to sum over first. So, let’s make a complete frequency table, where we have not only the frequencies of each bin but also the row totals, column totals, and a cell in the bottom-right representing the overall total:\n\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\nTotal\n\n\n\n\n\\(G = 10\\)\n10\n5\n15\n\n\n\\(G = 11\\)\n6\n4\n10\n\n\n\\(G = 12\\)\n7\n1\n8\n\n\nTotal\n23\n10\n33\n\n\n\n\n\nConverting Frequencies into Probabilities\nNow, before we think about the totals row/column, let’s use the overall total (33) to convert our counts into probabilities:\n\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\nTotal\n\n\n\n\n\\(G = 10\\)\n\\(\\frac{10}{33}\\)\n\\(\\frac{5}{33}\\)\n\\(\\frac{15}{33}\\)\n\n\n\\(G = 11\\)\n\\(\\frac{6}{33}\\)\n\\(\\frac{4}{33}\\)\n\\(\\frac{10}{33}\\)\n\n\n\\(G = 12\\)\n\\(\\frac{7}{33}\\)\n\\(\\frac{1}{33}\\)\n\\(\\frac{8}{33}\\)\n\n\nTotal\n\\(\\frac{23}{33}\\)\n\\(\\frac{10}{33}\\)\n\\(\\frac{33}{33}\\)\n\n\n\n\n\nMore Than One Distribution Can Be Derived From This Table!\nNow that we see the normalized counts, we can see the different ways we can look at this table to obtain probability distributions:\n\nFirst, there’s the distribution we were originally thinking about: the entries in each non-total cell form a probabiltiy distribution called the joint distribution of \\(G\\) and \\(H\\), since each entry is between 0 and 1 and the entries sum to 1:\n\n\\[\n\\begin{align*}\n&\\underbrace{\\Pr(G = 10, H = 0)}_{10 / 33} + \\underbrace{\\Pr(G = 10, H = 1)}_{5 / 33} + \\\\\n&\\underbrace{\\Pr(G = 11, H = 0)}_{6 / 33} + \\underbrace{\\Pr(G = 11, H = 1)}_{4 / 33} + \\\\\n&\\underbrace{\\Pr(G = 12, H = 0)}_{7 / 33} + \\underbrace{\\Pr(G = 12, H = 1)}_{1 / 33} = 1\n\\end{align*}\n\\]\n\nBut, we can also notice that the two entries in the totals row (excluding the overall total) form a probability distribution, called the marginal distribution of \\(H\\):\n\n\\[\n\\begin{align*}\n\\underbrace{\\Pr(H = 0)}_{23 / 33} + \\underbrace{\\Pr(H = 1)}_{10 / 33} = 1\n\\end{align*}\n\\]\n\nAnd, the three entries in the totals column (excluding the overall total) form a probability distribution, called the marginal distribution of \\(G\\):\n\n\\[\n\\underbrace{\\Pr(G = 10)}_{15 / 33} + \\underbrace{\\Pr(G = 11)}_{10 / 33} + \\underbrace{\\Pr(G = 12)}_{8 / 33} = 1\n\\]\nLet’s consider in a little more detail how we used the joint distribution—the full set of entries in the original table—to derive two different marginal distributions:\nSumming the values in each column:\nWhen we summed up the values in each column, we were summing up all possible pdf values \\(f_{G,H}(v_G, v_H)\\) where \\(v_H = 0\\) and then all possible pdf values \\(f_{G,H}(v_G, v_H)\\) where \\(v_H = 1\\). This gave us two new counts (or probabilities, if used the probability table rather than the frequency table) representing the marginal distribution of \\(H\\), a distribution where the variable \\(G\\) no longer appeared!\nSumming the values in each row:\nWhen we instead summed the values in each row, we summed all possible pdf values \\(f_{G,H}(v_G, v_H)\\) where \\(v_G = 10\\), then all possible pdf values \\(f_{G,H}(v_G, v_H)\\) where \\(v_G = 11\\), and finally all possible pdf values \\(f_{G,H}(v_G, v_H)\\) where \\(v_G = 12\\). This gave us three new counts/probabilities representing the marginal distribution of \\(G\\), a distribution where the variable \\(H\\) no longer appeared!"
  },
  {
    "objectID": "writeups/marginalization/index.html#whats-missing-conditional-distributions",
    "href": "writeups/marginalization/index.html#whats-missing-conditional-distributions",
    "title": "Marginal Distributions and “Marginalizing Out” A Variable",
    "section": "What’s Missing? Conditional Distributions",
    "text": "What’s Missing? Conditional Distributions\nSo far we’ve discussed the interrelationship between joint distributions and marginal distributions: the latter was obtained from the former by summing.\nHowever, there is one type of distribution that is mentioned on your Lab assignment that we haven’t seen yet. The conditional distribution is a bit different from the joint and marginal distributions, in the sense that the conditional distribution does not represent a sum across some dimension of the table but a slice of the table: that is, it represents the new distribution which “pops out” when we consider one particular row or one particular column of the table.\nHowever, just like how above we figured out the marginal distributions by summing over columns and summing over rows separately, and seeing what resulted, let’s explore what conditional distributions look like by slicing the table by column first, then slicing the table by row:\n\nComputing Conditional Distributions as Columns (Honors-Status Values)\nLet’s consider what the table would look like if we just selected a single column: for example, let’s select just the column of values for which \\(H = 1\\). Throwing away all of the other columns in the table, this would give us a one-column table that looks like:\n\n\n\n\n\\(H = 1\\)\n\n\n\n\n\\(G = 10\\)\n5\n\n\n\\(G = 11\\)\n4\n\n\n\\(G = 12\\)\n1\n\n\nTotal\n10\n\n\n\nNow notice that, just like how we were able to convert our frequency table into a probability table representing joint probabilities by dividing each of these values by 33 (the overall total of students across all possible grades and honors-status values), now we can convert this slice of the full table into its own distribution by dividing each of these individual values in the \\(H = 1\\) column by the total number of students in the \\(H = 1\\) column:\n\n\n\n\n\\(H = 1\\)\n\n\n\n\n\\(G = 10\\)\n\\(\\frac{5}{10}\\)\n\n\n\\(G = 11\\)\n\\(\\frac{4}{10}\\)\n\n\n\\(G = 12\\)\n\\(\\frac{1}{10}\\)\n\n\nTotal\n\\(\\frac{10}{10}\\)\n\n\n\nNotice how, unlike in the above two cases, we now have to interpret the numeric value of the probabilities in each cell differently:\n\nJoint and marginal distributions represented some count relative to the total number of students in the school, hence the denominator of all probabilities in either of these cases was 33\nConditional distributions, however, represent a count relative to the number of students within the category we are conditioning on: the denominator is now 10 in each case, since we’re considering the number of students represented by each cell within the column as a proportion of the total number of students across the entire column."
  },
  {
    "objectID": "writeups/marginalization/index.html#discrete-world-summary",
    "href": "writeups/marginalization/index.html#discrete-world-summary",
    "title": "Marginal Distributions and “Marginalizing Out” A Variable",
    "section": "Discrete World Summary",
    "text": "Discrete World Summary\nSo, as long as we notice that conditional distributions are weird in the sense that they require us to renormalize all of our probabilities from our table of joint and marginal distributions, we now have the link between all three types of distributions that get talked about when working with multivariate probability distributions:\n\nA single joint distribution: The normalized counts in each cell of the full 2D table; in other words, the probability that a randomly-selected student from across the entire school will be in a particular bin (when students are binned by grade and honors status).\n\nFor example, the bin in the upper-left corner of our original table represents non-honors students in 10th grade (\\(G = 10, H = 0\\)).\n\nTwo marginal distributions: The normalized totals across each row, or across each column, of the full 2D table; in other words, the probability that a randomly-selected student from across the entire school will be in a particular aggregated bin.\n\nIf we aggregated by summing columns, for example, our first aggregated bin represents all non-honors students, students for whom \\(H = 0\\) (regardless of grade), and our second aggregated bin contains all honors students, students for whom \\(H = 1\\) (regardless of grade).\n\nSix possible conditional distributions: The re-normalized counts within a particular column or a particular row; in other words, the probability that a randomly-selected student from a particular category (the category we’re conditioning on) will be in one of the bins represented by individual slots within this row/column.\n\nIf we conditioned on the \\(H = 1\\) column, for example, then once we renormalize the counts in this column, the first entry represents the probability of a randomly-selected honors student being in grade 10: \\(\\Pr(G = 10 \\mid H = 1)\\)\n\n\nNotice, lastly, how we could use this intuition built from frequency tables to figure out how to go in opposite directions from the directions we derived things above: for example, if we were only given marginal distributions and conditional distributions, we could use this information to derive the full-on joint distribution table. Since we know the definition of conditional probability for example, that\n\\[\n\\Pr(B \\mid A) = \\frac{\\Pr(B, A)}{\\Pr(A)},\n\\]\nwe could re-arrange terms in this equality to obtain\n\\[\n\\Pr(B, A) = \\Pr(B \\mid A)\\Pr(A),\n\\]\nfrom which we can see that if we know the conditional distribution \\(\\Pr(B \\mid A)\\) and the marginal distribution \\(\\Pr(A)\\), we can combine these (via multiplication) to obtain the joint distribution \\(\\Pr(B,A)\\)."
  },
  {
    "objectID": "writeups/marginalization/index.html#moving-to-continuous-world",
    "href": "writeups/marginalization/index.html#moving-to-continuous-world",
    "title": "Marginal Distributions and “Marginalizing Out” A Variable",
    "section": "Moving to Continuous World",
    "text": "Moving to Continuous World\nThe reason I’ve spent so much time focusing on the discrete case here is because the intuitions we just built do indeed translate naturally into good intuitions for reasoning about continuous distributions!\nTaking our discrete table, for example, we can imagine moving into continuous space the same way that we learned how to take discrete rectangles approximating the the space underneath a curve and convert them into integrals: by taking the limit of the area of these rectangles as they got skinnier and skinnier:\n\n\n\n\n\nIn the above figure, we see how we can imagine summing the area of rectangles approximating the area “under” the curve (really, between the curve and the \\(x\\)-axis), then imagine the rectangles becoming skinnier and skinnier such that the sum of the rectangles’ areas converges to the integral of the function.\nSimilarly, now imagine taking the above table and continuizing our variables: imagine that instead of a student’s progress in school being recorded by a discrete random variable \\(G\\) such that \\(\\mathcal{R}_G = \\{10, 11, 12\\}\\), now we record a student’s progress using a continuous random variable \\(G\\) such that \\(\\mathcal{R}_G = [10,12] \\subset \\mathbb{R}\\).\nBy the same logic, rather than tracking each student’s honor status using a discrete random variable \\(H\\) such that \\(\\mathcal{R}_H = \\{0, 1\\}\\), now we keep track of a student’s honor status using a continuous random variable \\(H\\) such that \\(\\mathcal{R}_H = [0, 1] \\subset \\mathbb{R}\\).\nIn this new continuous world, therefore, we might say that a student near the beginning of 10th grade who is towards the “high end” of the “honors spectrum” might be represented by a pair of values \\(G = 10.03\\) and \\(H = 0.95\\), for example.\nHowever, in this case we can still derive all of the distributions from other distributions in the same way, by:\n\nReplacing the sums we computed above with integrals, and\nReplacing the operation of re-normalization (which we performed to ensure that our probability mass values summed to 1) with the operation of ensuring that our probability density values integrate to 1.\n\nSo, for example, now rather than being given a frequency table, we may just be given the information that students’ \\(G\\) values are distributed according to the continuous uniform distribution, \\(G \\sim \\mathcal{U}(10, 12)\\), that their \\(H\\) values are distributed according to the truncated normal distribution \\(\\mathcal{TN}(\\mu = 0.5, \\sigma = 0.1, a = 0, b = 1)\\)1, and that these two variables are independent, which means that \\(\\Pr(G \\mid H) = \\Pr(G)\\) and \\(\\Pr(H \\mid G) = \\Pr(H)\\) (the conditional distributions are the marginal distributions).\nIn this case, then, we know (by the definition of independence) that we can obtain the joint pdf \\(f_{G,H}(v_G, v_H)\\) by just multiplying the pdf of the marginal distribution of \\(G\\), \\(f_G(v_G)\\) and the pdf of the marginal distribution of \\(H\\), \\(f_H(v_H)\\):\n\\[\nf_{G,H}(v_G, v_H) = f_G(v_G) \\cdot f_H(v_H).\n\\]\nSince we know that \\(G\\) has a continuous uniform distribution, \\(G \\sim \\mathcal{U}(10,12)\\), we know (or we could look up) that \\(G\\) has pdf\n\\[\nf_G(v_G) = \\frac{1}{12 - 10} = \\frac{1}{2}.\n\\]\nSince we know that \\(H\\) has a truncated normal distribution, \\(H \\sim \\mathcal{TN}(0.5, 0.1, 0, 1)\\), we know (or we could look up) that \\(H\\) has the pdf\n\\[\nf_H(v_H) = \\frac{1}{\\sigma}\\frac{\\varphi(\\frac{v_H-\\mu}{\\sigma})}{\\Phi(\\frac{b-\\mu}{\\sigma}) - \\Phi(\\frac{a - \\mu}{\\sigma})},\n\\]\nwhere \\(\\varphi\\) is the pdf of the standard normal distribution \\(\\mathcal{N}(0,1)\\) and \\(\\Phi\\) is the CDF of the standard normal distribution \\(\\mathcal{N}(0,1)\\) (note the consistent usage of lowercase letters to describe pdfs and capital letters to describe CDFs, even in Greek!).\nTherefore, given the independence condition, we can obtain the joint pdf \\(f_{G,H}(v_G, v_H)\\) by just multiplying these pdfs:\n\\[\nf_{G,H}(v_G, v_H) = \\frac{1}{2\\sigma}\\frac{\\varphi(\\frac{v_H-\\mu}{\\sigma})}{\\Phi(\\frac{b-\\mu}{\\sigma}) - \\Phi(\\frac{a - \\mu}{\\sigma})}.\n\\]\nAnd, given this joint pdf, we can integrate wherever we took sums in the discrete case to obtain the marginal pdfs:\n\\[\nf_G(v_G) = \\int_{0}^{1}f_{G,H}(v_G,v_H)dv_H\n\\]\nor\n\\[\nf_H(v_H) = \\int_{10}^{12}f_{G,H}(v_G, v_H)dv_G\n\\]\nAnd we can compute conditional pdfs by renormalizing so that the denominator is no longer the integral of the distribution over all its possible values (hence just the number \\(1\\)) but a ratio of joint distribution to marginal distribution values like the following:\n\\[\nf_{H \\mid G}(v_H | v_G) = \\frac{f_{G,H}(v_G, v_H)}{f_G(v_G)}.\n\\]\nSo, while the continuous case does have scarier math than the discrete case, I hope that rather than “lingering” in the continuous world, trying to churn through the meaning of the above equations on their own, you can instead try to link the continuous equations back to their simpler discrete forms given in the previous section, then just convert sums to integrals to complete the picture. That way, you never have to just stare at an integral-filled equation again.\nFor example, given two continuous variables with confusing-looking pdfs or CDFs, start by discretizing (“binning”) the possible values of these continuous values, to obtain a discrete distribution, and build up your intuitions about the relationships between the variables in discrete world.\nIn the previous case, for example, if you were asked to start with the continuous version where \\(G\\) ranges continuously across \\([10,12]\\) and \\(H\\) ranges continuously across \\([0,1]\\), you could start by discretizing these continuous distributions to obtain a table very similar to the table presented at the very beginning of this writeup: if you split the range \\([10,12]\\) into three bins of equal length, and the range \\([0,1]\\) into two bins of equal length, you can start by sampling (say) 1000 \\(G\\) and \\(H\\) values using code, sorting these 1000 samples into these equal-length bins, and reasoning through what the joint/marginal/conditional distributions of this binned distribution look like, before moving back over into continuous world to complete the various portions of the problem…"
  },
  {
    "objectID": "writeups/marginalization/index.html#footnotes",
    "href": "writeups/marginalization/index.html#footnotes",
    "title": "Marginal Distributions and “Marginalizing Out” A Variable",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis may look scary, but \\(\\mathcal{TN}(\\mu, \\sigma, a, b)\\) just says: start by sampling a value \\(x\\) from the normal distribution \\(\\mathcal{N}(\\mu, \\sigma)\\), but then: if \\(x &lt; a\\) transform this value to just be \\(a\\), and if \\(x &gt; b\\) then transform this value to just be \\(b\\). In other words, if \\(x \\sim \\mathcal{N}(\\mu, \\sigma)\\), we can obtain a truncated-normal-distributed variable \\(x'\\) from the normally-distributed variable \\(x\\) as \\(x' = \\begin{cases}x &\\text{if }a &lt; x &lt; b \\\\a &\\text{if }x &lt; a \\\\ b &\\text{if }x &gt; b\\end{cases}\\)↩︎"
  },
  {
    "objectID": "writeups/lab-4-prep/DSAN5100_Lab_4_Prep.html",
    "href": "writeups/lab-4-prep/DSAN5100_Lab_4_Prep.html",
    "title": "Lab 4 Prep",
    "section": "",
    "text": "Colab Link\n\n\n\n\nClick here to open in Colab\n\nIf you are trying to edit this notebook in Colab, you’ll also want to make sure to run the following code cell, which will install some global functions that we use in the course: mainly the dsan_theme() function, which just ensures that the plots you create have a standardized theme, (making it easier for us and the TAs to quickly understand what’s going on in your plots)\nIf the dsan_theme() function still gives you trouble after running this, no worries. You can just comment out dsan_theme() anywhere you see it, and use the default ggplot2 theme instead.\nif (Sys.getenv('COLAB_RELEASE_TAG') != '') {\n    writeLines(\"Colab detected: sourcing DSAN R globals\")\n    library(devtools)\n    source_url('https://raw.githubusercontent.com/jpowerj/dsan5100-03/main/_globals.r')\n} else {\n    writeLines(\"No Colab environment detected\")\n    source(\"../../_globals.r\")\n}\n\nNo Colab environment detected\nHere, to prepare you for Lab 4, I’m going to walk you through generating data from a distribution via simulation, and then analyzing properties of this data (and therefore, if the data is sufficiently representative, properties of the distribution) by computing new pieces of information on the basis of the original data. Hopefully this helps drive the point home that probability distributions like the Normal distribution that we’ll look at in this case are not arbitrarily, pulled out of thin air or out of the brain of some imaginative mathematician. Rather, they\nIn the latter case, I say “principled” in the sense that: we can “encode” information we have at some point in time as a particularly-suitable distribution and then, when we learn new information, we can update this distribution to reflect the new information, using Bayes’ rule 🧐‼️🧐."
  },
  {
    "objectID": "writeups/lab-4-prep/DSAN5100_Lab_4_Prep.html#the-drunkards-walk",
    "href": "writeups/lab-4-prep/DSAN5100_Lab_4_Prep.html#the-drunkards-walk",
    "title": "Lab 4 Prep",
    "section": "The Drunkard’s Walk",
    "text": "The Drunkard’s Walk\nIn class today I described one of the many Data Generating Processes that could give rise to normally-distributed data. It involved a simple random walk, where you imagine a person on a numberline at the point \\(x = 0\\), and then imagine them flipping a coin repeatedly: when the coin comes up Tails, they move 1 unit to the left, and when the coin comes up Heads they move 1 unit to the right. This stochastic process can be visualized via the following diagram[^drunkard]:\n\nHere we can think of the “layers” (the vertical columns) in the diagram as representing the branching possibilities in each step: at time \\(t = 0\\), before any coin flips have been carried out, there is only one possible state of the system: the person is at the point \\(x = 0\\).\nAfter a single time step, at time \\(t = 1\\), there are now two possible states of the system: if the (single) coin flip came up Tails the person is at \\(x = -1\\), and if it came up Heads the person is at \\(x = 1\\).\nHopefully some general aspects and mathematical properties of this stochastic process immediately stand out:\n\nThere are two ways we could describe a given state of this system at a time \\(t\\):\n\nFirst, we could describe the history of all choices that led to the current state: the node at the top of the \\(t = 2\\) column, for example, could be represented as a vector \\((L, L)\\), corresponding to the fact that the person ended up at this state by moving left, then moving left again.\nAlternatively, we could choose to only keep track of the person’s position on the number line, dropping the information about their history (how they got there). If we choose this option, the state can be described by a single number: the \\(x\\) coordinate of where the person is located at that time.\nNotice how this second option “collapses” some of the nodes in the diagram down into a single state: for example, the three history vectors \\(()\\) (the vector corresponding to the start node, where no moves have been made yet), \\((L,R)\\) and \\((R,L)\\), which are three different states under the first option, both represent the single state \\(x = 0\\) if we use this option.\n\nThe number of possible states (nodes) at each time step \\(t\\) is just \\(2^t\\). This comes from our multiplication rule from earlier in the semester: if we’re making \\(n\\) choices, where each choice involves choosing between \\(k\\) alternatives, the total number of choice vectors (decisions for all \\(n\\) choices) is \\(k^n\\). Here we’re making \\(t\\) choices (one at each time step), choosing between \\(2\\) alternatives each time (going left vs. going right), giving \\(2^t\\) total choice vectors.\n\nNow that we have an idea of some of the mathematical properties of this system, let’s focus in on converting this into code!\nFirst things first, we make sure to use R’s set.seed() function to ensure reproducibility of our results across different runs of the notebook:\nset.seed(5100)\nYour first intuition might be to create a variable x to keep track of the state, then create a loop that will run N times, updating the state each time through the loop. In data science world, it turns out that this approach is very inefficient (in terms of memory usage but also, more importantly, in terms of the time it will take to run the simulation). But, let’s start with that and work our way towards the more efficient solution.\nFor concreteness, let’s try to simulate a person following this procedure for N = 10 steps, where each coin flip is with a fair coin, with \\(\\Pr(H) = 0.5\\). I am forever infinitely mad about the fact that R does not come with built-in support for the Bernoulli distribution (literally the distribution that every single other possible discrete distribution is built on top of…), so instead of using dbinom() incorrectly like I did in class, I am instead going to import the Rlab library, which adds in functions like dbern(), rbern(), etc., that are bafflingly absent from base-R:\n\nlibrary(Rlab)\nt &lt;- 0\nx &lt;- 0\nwriteLines(paste0(\"Starting state (t = \",t,\"): x = \",x))\nfor (i in seq(from = 1, to = 10)) {\n    writeLines(paste0(\"=====[ Step \",i,\" ]=====\"))\n    # Flip coin\n    flip_outcome &lt;- rbern(1,0.5)\n    writeLines(paste0(\"Coin flip outcome: \",flip_outcome))\n    # Choose direction based on result\n    direction &lt;- \"\"\n    if (flip_outcome == 0) {\n        # Outcome = Tails\n        direction &lt;- \"Left\"\n        x &lt;- x - 1\n    } else {\n        # Outcome = Heads\n        direction &lt;- \"Right\"\n        x &lt;- x + 1\n    }\n    # And increment the time counter\n    t &lt;- t + 1\n    writeLines(paste0(\"Moved \",direction))\n    writeLines(paste0(\"New state (t = \",t,\"): x = \",x))\n}\n\n# # Unique id for each person\n# pid &lt;- seq(1, num_people)\n# pid_tib &lt;- tibble(pid)\n# pos_df &lt;- tibble()\n# end_df &lt;- tibble()\n#   all_steps &lt;- t(replicate(num_people, sample(support, num_steps, replace = TRUE, prob = c(0.5, 0.5))))\n\nRlab 4.0 attached.\n\n\n\nAttaching package: 'Rlab'\n\n\nThe following objects are masked from 'package:stats':\n\n    dexp, dgamma, dweibull, pexp, pgamma, pweibull, qexp, qgamma,\n    qweibull, rexp, rgamma, rweibull\n\n\nThe following object is masked from 'package:datasets':\n\n    precip\n\n\n\n\nStarting state (t = 0): x = 0\n=====[ Step 1 ]=====\nCoin flip outcome: 1\nMoved Right\nNew state (t = 1): x = 1\n=====[ Step 2 ]=====\nCoin flip outcome: 0\nMoved Left\nNew state (t = 2): x = 0\n=====[ Step 3 ]=====\nCoin flip outcome: 0\nMoved Left\nNew state (t = 3): x = -1\n=====[ Step 4 ]=====\nCoin flip outcome: 0\nMoved Left\nNew state (t = 4): x = -2\n=====[ Step 5 ]=====\nCoin flip outcome: 1\nMoved Right\nNew state (t = 5): x = -1\n=====[ Step 6 ]=====\nCoin flip outcome: 0\nMoved Left\nNew state (t = 6): x = -2\n=====[ Step 7 ]=====\nCoin flip outcome: 0\nMoved Left\nNew state (t = 7): x = -3\n=====[ Step 8 ]=====\nCoin flip outcome: 0\nMoved Left\nNew state (t = 8): x = -4\n=====[ Step 9 ]=====\nCoin flip outcome: 0\nMoved Left\nNew state (t = 9): x = -5\n=====[ Step 10 ]=====\nCoin flip outcome: 1\nMoved Right\nNew state (t = 10): x = -4\n\n\nTechnically, this code is sufficient to carry out our whole simulation, if we didn’t care about memory/time considerations. For example, we could use it to write a slow_simulation function, that takes in num_steps as its argument, simulates this many steps of the process, and returns the resulting state. To avoid the function printing out all of the above information 100 times, which will make things run even more slowly, I will also add a verbose argument that is set to FALSE by default. This is good practice in some cases, software-engineering-wise, since if something goes wrong during a call to the function we can re-run the function with verbose set to be TRUE and see the same type of info we printed out above.\n\nslow_simulation &lt;- function(num_steps, verbose = FALSE) {\n    t &lt;- 0\n    x &lt;- 0\n    if (verbose) {\n        writeLines(paste0(\"Starting state (t = \",t,\"): x = \",x))\n    }\n    for (i in 1:num_steps) {\n        if (verbose) {\n            writeLines(paste0(\"=====[ Step \",i,\" ]=====\"))\n        }\n        # Flip coin\n        flip_outcome &lt;- rbern(1,0.5)\n        if (verbose) {\n            writeLines(paste0(\"Coin flip outcome: \",flip_outcome))\n        }\n        # Choose direction based on result\n        direction &lt;- \"\"\n        if (flip_outcome == 0) {\n            # Outcome = Tails\n            direction &lt;- \"Left\"\n            x &lt;- x - 1\n        } else {\n            # Outcome = Heads\n            direction &lt;- \"Right\"\n            x &lt;- x + 1\n        }\n        # And increment the time counter\n        t &lt;- t + 1\n        if (verbose) {\n            writeLines(paste0(\"Moved \",direction))\n            writeLines(paste0(\"New state: x = \",x))\n        }\n    }\n    return(x)\n}\n\nIt is usually good practice, once you’ve written a function like this, to test that it works for the simplest “corner cases” or “base cases”: in this case, for example, we should quickly verify that it always produces the expected output \\(x = 0\\) when we ask it for the result of the process after zero steps:\n\nreplicate(10, slow_simulation(0))\n\n\n00-200-200-2-2\n\n\nAnd alas, we have already found a bug in our implementation! It turns out that, unlike in Python or most other programming languages, using just the colon operator (:) can lead to some terrifying bugs,since if the number after the : is less than the number before the :, R will just start iterating backwards from the first number down to the second number:\n\n5:-3\n\n\n543210-1-2-3\n\n\nThis may seem inocuous, until you try to write a function like this which loops a specific number of times, and you try to support the case of running zero times. For example, if you use 1:n, and you accept n as an argument to your function, you’ll get a case like the following:\n\nn &lt;- 0\n1:n\n\n\n10\n\n\nThe takeaway is: if we want to be fully careful, and we want to make sure our function also produces the correct answer for zero steps, then we need to use R’s seq_len() function! seq_len(N) can be used in a loop to ensure that R loops over a sequence from 1 to N, and always counts up, so we avoid this case:\n\nslow_simulation &lt;- function(num_steps, verbose = FALSE) {\n    t &lt;- 0\n    x &lt;- 0\n    if (verbose) {\n        writeLines(paste0(\"Starting state (t = \",t,\"): x = \",x))\n    }\n    for (i in seq_len(num_steps)) {\n        if (verbose) {\n            writeLines(paste0(\"=====[ Step \",i,\" ]=====\"))\n        }\n        # Flip coin\n        flip_outcome &lt;- rbern(1,0.5)\n        if (verbose) {\n            writeLines(paste0(\"Coin flip outcome: \",flip_outcome))\n        }\n        # Choose direction based on result\n        direction &lt;- \"\"\n        if (flip_outcome == 0) {\n            # Outcome = Tails\n            direction &lt;- \"Left\"\n            x &lt;- x - 1\n        } else {\n            # Outcome = Heads\n            direction &lt;- \"Right\"\n            x &lt;- x + 1\n        }\n        # And increment the time counter\n        t &lt;- t + 1\n        if (verbose) {\n            writeLines(paste0(\"Moved \",direction))\n            writeLines(paste0(\"New state: x = \",x))\n        }\n    }\n    return(x)\n}\n\nRe-running our tests, to make sure it works as expected now even in the N = 0 case, we get:\n\nreplicate(10, slow_simulation(0))\n\n\n0000000000\n\n\nThere may still be issues, but now let’s use this function to find the state of the system after N = 100 steps (we’ll run it 3 times here, just to show how it can produces different outcomes each time it is re-run)\n\nslow_simulation(100)\n\n6\n\n\n\nslow_simulation(100)\n\n-20\n\n\n\nslow_simulation(100)\n\n-6\n\n\nAnd we see that, repeating the process 4 times, the random-walker ended up at \\(x = -20\\), \\(x = 2\\), and \\(x = -2\\) after 100 steps. From this (or from intuition from the diagram, or from thinking about the process in general), we could infer another fact: that the random-walker will end up at an even-numbered coordinate if they take an even number of steps (including 0 steps). By similar reasoning, if we run the process for an odd number of steps, the random-walker will end up on an odd-numbered coordinate (here we run for a few even and odd values, so you can start to see this general pattern):\n\nslow_simulation(7)\n\n1\n\n\n\nslow_simulation(8)\n\n2\n\n\n\nslow_simulation(9)\n\n1\n\n\n\nslow_simulation(11)\n\n-1\n\n\n\nslow_simulation(13)\n\n1\n\n\nHere we have to pause, because we have to take into account the fact that we really want to simulate this process for a large number of people, and a large number of steps, so that this loop-based approach is going to become super slow and unwieldy as we increase the number of people/steps.\nSo, let’s think about how we could speed it up. Honestly, this can often be more of an art than a science, but it is genuinely so important, as it can mean the difference between your code finishing in a few seconds and finishing in a few hours.\nFor this problem, there are a number of ways you could arrive at a faster, more efficient approach, but for the sake of brevity I will cut to the chase and just mention that a key property we can use here is the fact that the outcome after N steps, regardless of how big N is, is really just a sum of independently-generated 0/1 variables!\nWe could derive this insight, for example, by recalling the above discussion about the two different ways to store the state of the system (storing just the value of \\(x\\) vs. storing the entire history), and thinking about the relationship between these two representations:\n\nIf we know the entire history of a random-walker, we could use that information to figure out their position, by just starting from \\(x = 0\\) and following each of the steps recorded in their history vector.\nThe converse isn’t true, though: if we know that the random-walker is at \\(x = 0\\), we cannot infer (at least, cannot infer with certainty) the history of states that led them to end up at that coordinate. As we already saw just in considering two time steps, for example, they could have arrived at \\(x = 0\\) via the histories \\(()\\), \\((L,R)\\), or \\((R,L)\\).\n\nThis insight becomes especially helpful if we think about how we could encode what we’re currently writing as \\(R\\) or \\(L\\) in a more helpful way: leaping once again over lots of thinking about it, if we chose to instead encode a move left as the number \\(-1\\), and a move right as the number \\(1\\), suddenly we may be able to see the relationship between the full-history state space and the “collapsed” state space where we just keep track of \\(x\\). We can write out some histories using this \\(-1\\) or \\(1\\) representation, then look at the \\(x\\) value these histories produce, and try to see the pattern:\n\n\n\n\n\n\n\n\nHistory vector(original)\nHistory vector(numeric representation)\nResulting values of \\(x\\)\n\n\n\n\n\\(()\\)\n\\(()\\)\n\\(x = 0\\)\n\n\n\\((L,L,R)\\)\n\\((-1, -1, 1)\\)\n\\(x = -1\\)\n\n\n\\((L,R)\\)\n\\((-1,1)\\)\n\\(x = 0\\)\n\n\n\\((R,R,R,R)\\)\n\\((1,1,1,1)\\)\n\\(x = 4\\)\n\n\n\\((R,L,R,L,R,L)\\)\n\\((1,-1,1,-1,1,-1)\\)\n\\(x = 0\\)\n\n\n\nDo you see the pattern? Jumping to the punchline: by using the numeric representation of the history vector, we can immediately derive the final position of the random-walker by summing up the values of their history vector in this representation!\nIf it’s still unclear why this is helpful, that’s ok: it may be an appreciation that only comes from spending hours debugging hundreds of tiny little errors in C code that your professor/boss has asked you to optimize down to the individual-bits-of-RAM level 😛 But it will hopefully become a little more clear regardless once we compare the runtimes of our two approaches!\nLet’s use this sum-to-get-final-state insight to rewrite our code without any loops. The main thing left to figure out is: how to generate a sequence of random values drawn uniformly from \\(\\{-1, 1\\}\\)? We could approach this using the discrete uniform distribution, or we could approach this by transforming the Bernoulli distribution (which produces values in \\(\\{0,1\\}\\)) in a smart way. But, optimizing for laziness, we can do even less work: there is already a name for this distribution (of a random variable \\(X\\) with equally-likely outcomes drawn from the support set \\(\\mathcal{R}_X = \\{-1,1\\}\\)): it’s called the Rademacher Distribution.\nAs with the Bernoulli distribution, base-R does not have a built-in function for generating random Rademacher-distributed variables, so instead we can use an implementation provided by the extraDistr library, a function named rsign() (since you can think about this distribution as determining a random sign: positive or negative). Let’s use rsign() to rewrite our function so it just\n\nGenerates num_steps random numbers, each one representing a piece of the history vector, and then\nSums them to get our resulting \\(x\\) value\n\n\n# (Uncomment and run the following line if you\n# don't have the extraDistr library installed)\n#install.packages(\"extraDistr\")\n\n\nlibrary(extraDistr)\nfaster_simulation &lt;- function(num_steps, verbose = FALSE) {\n    # Generate a history vector with length `num_steps`,\n    # in the representation where every step is a coin\n    # flip, but we record -1 for tails and 1 for heads\n    history_vec &lt;- rsign(num_steps)\n    final_x &lt;- sum(history_vec)\n    return(final_x)\n}\n\n\nAttaching package: 'extraDistr'\n\n\nThe following objects are masked from 'package:Rlab':\n\n    dbern, pbern, qbern, rbern\n\n\n\n\nAnd now let’s check that it works for the corner case we identified above:\n\nreplicate(10,faster_simulation(0))\n\n\n0000000000\n\n\nAnd check that the values it generates still seem right, for non-corner-case values:\n\nfaster_simulation(100)\n\n2\n\n\n\nfaster_simulation(100)\n\n20\n\n\n\nfaster_simulation(100)\n\n12"
  },
  {
    "objectID": "writeups/lab-4-prep/DSAN5100_Lab_4_Prep.html#moving-from-individual-to-aggregated-simulation",
    "href": "writeups/lab-4-prep/DSAN5100_Lab_4_Prep.html#moving-from-individual-to-aggregated-simulation",
    "title": "Lab 4 Prep",
    "section": "Moving From Individual to Aggregated Simulation",
    "text": "Moving From Individual to Aggregated Simulation\nNow that we have this new version of our function, we can maybe already see how much faster it runs than our first attempt (it will be even more clear once we use it to simulate more people/steps). There are a few ways to measure the time that it takes for R functions to run, but to me the easiest way (and you want it to be easy when you’re spending hours and hours just trying to tweak the runtime of one function) is to use the tictoc library (not part of base-R): once you load this library using library(tictoc), you literally just put tic() somewhere in your code, then toc() somewhere afterwards, and it measures the time that elapsed in between these two function calls:\n\n# (Uncomment to install, if needed)\n#install.packages(\"tictoc\")\n\n\nlibrary(tictoc)\ntic()\n1 + 1\ntoc()\n\n2\n\n\n0.001 sec elapsed\n\n\nSo, let’s use this library to measure how long it takes the two approaches to simulate 1 million steps of the process (for one person):\n\nsteps_to_simulate &lt;- 1000000\n\n\n# Our first attempt\ntic()\nslow_simulation(steps_to_simulate)\nslow_sim_times &lt;- toc()\nslow_sim_elapsed &lt;- as.numeric(slow_sim_times$toc - slow_sim_times$tic)\nslow_sim_elapsed\n\n2150\n\n\n1.603 sec elapsed\n\n\n1.603\n\n\n\ntic()\nfaster_simulation(steps_to_simulate)\nfast_sim_times &lt;- toc()\nfast_sim_elapsed &lt;- as.numeric(fast_sim_times$toc - fast_sim_times$tic)\nfast_sim_elapsed\n\n-98\n\n\n0.008 sec elapsed\n\n\n0.00800000000000001\n\n\nBy dividing the elapsed times for the two approaches (which we’ll be able to interpret since these are ratio variables 😉):\n\nelapsed_ratio &lt;- slow_sim_elapsed / fast_sim_elapsed\nelapsed_ratio\n\n200.375\n\n\nWe can see that, already (just for one person), the improved version using sum() runs 128 times faster than our original approach using a for loop 😳\nWe could optimize the move to multiple people even more, but even if we just keep the two implementations as they currently are, and use replicate() to repeat them 10 times (i.e., generate history vectors and results for 10 people instead of 1), the efficiency difference becomes even more pronounced:\n\nnum_people &lt;- 10\n\n\n# Our first attempt, now for 10 people\ntic()\nreplicate(num_people, slow_simulation(steps_to_simulate))\nslow_sim_times &lt;- toc()\nslow_sim_elapsed &lt;- as.numeric(slow_sim_times$toc - slow_sim_times$tic)\nslow_sim_elapsed\n\n\n-220482-1626-308390952-1410-14781180-548\n\n\n15.27 sec elapsed\n\n\n15.27\n\n\n\ntic()\nreplicate(num_people, faster_simulation(steps_to_simulate))\nfast_sim_times &lt;- toc()\nfast_sim_elapsed &lt;- as.numeric(fast_sim_times$toc - fast_sim_times$tic)\nfast_sim_elapsed\n\n\n-3789121174-688-1264360-2514-298-3421208\n\n\n0.077 sec elapsed\n\n\n0.0769999999999982\n\n\nWe now, in both cases, have simulated data for 10 people performing this random walk procedure, both equally valid in terms of our use to simulate [one of] the data-generating process[es] underlying the Normal Distribution. But the original approach takes about 15 seconds to generate this simulated data, while the second approach takes less than 1/10th of 1 second to generate the same amount of data… 🤯\nThis represents a speedup of\n\nslow_sim_elapsed / fast_sim_elapsed\n\n198.311688311693\n\n\ni.e., about a 20,000% speed boost…\nSo, if this efficiency gap has convinced you1, we can now drop the first approach and just use the faster version to start digging into the Normal Distribution!"
  },
  {
    "objectID": "writeups/lab-4-prep/DSAN5100_Lab_4_Prep.html#simulating-n-normally-distributed-random-variables",
    "href": "writeups/lab-4-prep/DSAN5100_Lab_4_Prep.html#simulating-n-normally-distributed-random-variables",
    "title": "Lab 4 Prep",
    "section": "Simulating N Normally-Distributed Random Variables",
    "text": "Simulating N Normally-Distributed Random Variables\nNow that we have a function that will efficiently generate random variables for us, let’s use it to generate a tibble in tidy format:\n\nEach row will correspond to one person,\nEach of these people will be given a unique ID, and\nEach column will represent one property of this person.\n\nIn this case, the property will be called x_T, and it will represent the person’s position x after T steps, where T is some value we will choose (as a hyperparameter of our simulation).\nSo that we have a large enough dataset (the N value), and so that each person will be simulated for enough steps to make the resulting outcomes very close to Normally-distributed (the T value), let’s set\n\nN (number of people) = 100,000\nT (number of time steps each person should run the process for) = 1000\n\n\ntic()\nN &lt;- 100000\nT &lt;- 1000\nx_T_vals &lt;- replicate(N, faster_simulation(T))\ntoc()\n\n0.861 sec elapsed\n\n\n(Using tic() and toc() one last time, we see that it was able to generate the entire dataset, at least on my computer, in under a second!)\n\nclass(x_T_vals)\n\n'numeric'\n\n\nAnd now, rather than the (numeric) vector format that the replicate() function has produced here, for the sake of analyzing this dataset let’s store the data in a structured format as a tibble. That way, we can also give each observation a unique ID:\n\nlibrary(tibble)\nx_tibble &lt;- tibble(obs_id=1:length(x_T_vals), x_T=x_T_vals)\nx_tibble |&gt; head()\n\n\nAttaching package: 'tibble'\n\n\nThe following object is masked from 'package:Rlab':\n\n    view\n\n\n\n\n\nA tibble: 6 x 2\n\n\nobs_id\nx_T\n\n\n&lt;int&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n54\n\n\n2\n22\n\n\n3\n-8\n\n\n4\n40\n\n\n5\n-4\n\n\n6\n-18\n\n\n\n\n\nNow, since in Lab 4 we ask you to simulate a “base” distribution, then simulate distributions derived by applying (mathematical) transformations (sum, product, max, min, etc.) to the base distribution, let’s start by making a plot to see what our base distribution—in the form of our x_tibble dataset—looks like:\n\nlibrary(ggplot2)\nggplot(x_tibble, aes(x=x_T)) +\n  geom_histogram(binwidth=6) +\n  dsan_theme()\n\n\n\n\nAnd… it should look familiar! It’s our old friend the “bell curve”! We can see from the plot that the mean of this simulated data is probably something very close to 0, but the standard deviation is harder to figure out just from looking at the picture, so let’s compute these directly from the data:\n\nmu &lt;- mean(x_tibble$x_T)\nmu\n\n0.0840000000000668\n\n\n\nsigma &lt;- sd(x_tibble$x_T)\nsigma\n\n31.6289283392758\n\n\nSo the overall mean \\(\\mu\\) of the final positions of all 1 million people is about 0.084, while the overall standard deviation \\(\\sigma\\) is about 31.629. The mean has an intuitive interpretation, but we need to use the 68-95-99.7 Rule to interpret the standard deviation as follows:\n\nApproximately 68% of the data lies within the range \\([\\mu - 1\\cdot \\sigma, \\mu + 1 \\cdot \\sigma]\\), which in our case is\n\n\nc(mu - sigma, mu + sigma)\n\n\n-31.544928339275731.7129283392759\n\n\n\nApproximately 95% of the data lies within the range \\([\\mu - 2\\cdot \\sigma, \\; \\mu + 2 \\cdot \\sigma]\\), which in our case is\n\n\nc(mu - 2 * sigma, mu + 2 * sigma)\n\n\n-63.173856678551563.3418566785516\n\n\n\nApproximately 99.7% of the data lies within 3 standard deviations of the mean, that is, within the range \\([\\mu - 3 \\cdot \\sigma, \\; \\mu + 3 \\cdot \\sigma]\\), which in our case is\n\n\nc(mu - 3 * sigma, mu + 3 * sigma)\n\n\n-94.802785017827394.9707850178274\n\n\nRoughly, then, we can interpret this last fact as saying that nearly all (99.7%) of the random walkers will still remain within 100 units of their starting position, after 1000 steps."
  },
  {
    "objectID": "writeups/lab-4-prep/DSAN5100_Lab_4_Prep.html#applying-transformations-to-x_t",
    "href": "writeups/lab-4-prep/DSAN5100_Lab_4_Prep.html#applying-transformations-to-x_t",
    "title": "Lab 4 Prep",
    "section": "Applying Transformations to x_T",
    "text": "Applying Transformations to x_T\nIt may have seemed like overkill to take the length-1000000 vector we had and convert it into a 1000000-row tibble, since we only had one column. But now let’s see why we did this: let’s take this column of the raw (simulated) values of \\(x_T\\) and use it to derive simulated values of functions of \\(x_T\\).\nFor example, instead of analyzing the positions, perhaps in the context of our problem we only care about how far away the people end up from their starting point. In that case, what we really care about is not \\(x\\) itself but \\(|x - 0| = |x|\\), the absolute distance (on the numberline) of the person’s final position from their starting position.\nNow that you’ve seen how changing from a for-loop-based approach to a “vectorized” approach can vastly improve efficiency, I also want you to move your focus away from how these absolute distances could be computed using a loop and instead focus on how they could be computed using a mathematical function that could be applied to an entire vector of data (in this case, the vector that we get by pulling the x_T column out of the tibble). In this case hopefully this mathematical operation is clear: we just want to apply the absolute value function to the x_T column vector. So, here let’s use the mutate() function from dplyr (part of the tidyverse) to create a new column in our tibble called abs_dist, computed on the basis of x_T and representing this absolute distance:\n\nlibrary(dplyr)\nx_tibble &lt;- x_tibble |&gt; mutate(abs_dist = abs(x_T))\nx_tibble |&gt; head()\n\n\nAttaching package: 'dplyr'\n\n\nThe following object is masked from 'package:Rlab':\n\n    count\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\n\n\n\nA tibble: 6 x 3\n\n\nobs_id\nx_T\nabs_dist\n\n\n&lt;int&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n54\n54\n\n\n2\n22\n22\n\n\n3\n-8\n8\n\n\n4\n40\n40\n\n\n5\n-4\n4\n\n\n6\n-18\n18\n\n\n\n\n\nAnd we see that, at least in the first six columns, our “pipeline” has successfully taken the absolute values of the x_T column: -42 has been transformed to 42, -70 to 70, and so on.\nNow, just as we did above, we can plot the distribution of this data, which is not the “raw” (simulated) data but a function of the raw data, which forms its own distribution that may be different from the distribution of the original data:\n\nggplot(x_tibble, aes(x = abs_dist)) +\n  geom_histogram(binwidth=6) +\n  dsan_theme()\n\n\n\n\nNow that we’ve plotted two distributions using the geom_histogram() function from the ggplot2 library, it’s probably a good time to also mention how (like the warning messages from ggplot2 will try to warn you) histograms can sometimes be more misleading than helpful when it comes to understanding your data: skipping over lots of details2, the way that the hisogram looks depends a good amount on the bin width or number of bins parameter, so that (a) it’s good to examine the histogram of the distribution under many different choices for this bin width/number of bins, but also (b) it’s good to check what the kernel density plot of the distribution looks like, as an alternative to the histogram:\n\nggplot(x_tibble, aes(x = abs_dist)) +\n  geom_density() +\n  dsan_theme()\n\n\n\n\nThe kernel density plot’s bandwidth parameter can be tweaked to make the plot look different, just like the binwidth parameter of geom_histogram() can be tweaked to make the histogram look different, but in my experience geom_density() tends to require less tweaking: it usually produces the distribution that I’m expecting to see (if I already know what the distribution should look like), so that I trust it a bit more to give a reasonably accurate “picture” of the distribution of data that I haven’t seen before.\nThis distribution, just like the Normal and Rademacher distributions we’ve seen so far, has a name! It is called the Folded Normal Distribution, if you’d like to learn how that works."
  },
  {
    "objectID": "writeups/lab-4-prep/DSAN5100_Lab_4_Prep.html#transformation-2-squared-distance-from-0",
    "href": "writeups/lab-4-prep/DSAN5100_Lab_4_Prep.html#transformation-2-squared-distance-from-0",
    "title": "Lab 4 Prep",
    "section": "Transformation 2: Squared Distance from 0",
    "text": "Transformation 2: Squared Distance from 0\nAs I described in class today, though, it is more common in data science to use the squared distance to assess how far the data is from some target value (like its mean, or median, or mode, etc.). This is because the squared distance function \\(f(x) = x^2\\) is differentiable everywhere, unlike the absolute value function \\(f(x) = |x|\\):\n\nbase &lt;-\n  ggplot() +\n  xlim(-5, 5) +\n  ylim(0, 25) +\n  labs(\n    x = \"x\",\n    y = expression(\"(x - \"*mu*\")\"^2)\n  ) +\n  dsan_theme()\n\nmy_fn &lt;- function(x) { return(x^2) }\nmy_deriv2 &lt;- function(x) { return(4*x - 4) }\nmy_derivN4 &lt;- function(x) { return(-8*x - 16) }\nbase + geom_function(\n  fun = my_fn, color=cbPalette[1], linewidth=1\n  ) +\n  geom_point(data=as.data.frame(list(x=2,y=4)), aes(x=x,y=y), color=cbPalette[2], size=g_pointsize/2) + \n  geom_function(fun = my_deriv2, color=cbPalette[2], linewidth=1) +\n  geom_point(data=as.data.frame(list(x=-4,y=16)), aes(x=x,y=y), color=cbPalette[3], size=g_pointsize/2) + \n  geom_function(fun = my_derivN4, color=cbPalette[3], linewidth=1)\n\nWarning message:\n\"Removed 60 rows containing missing values (`geom_function()`).\"\nWarning message:\n\"Removed 70 rows containing missing values (`geom_function()`).\"\n\n\n\n\n\n\nmy_fake_deriv &lt;- function(x) { return(-x) }\nmy_fake_deriv2 &lt;- function(x) { return(-(1/2)*x + 1/2) }\nmy_fake_deriv3 &lt;- function(x) { return(-(1/4)*x + 3/4) }\n\nd=data.frame(x=c(-2,-1,0,1,2), y=c(1,0,0,1,1))\nbase &lt;- ggplot() +\n  xlim(-5,5) +\n  ylim(0,2) +\n  labs(\n    x=\"x\",\n    y=expression(\"|x - \"*mu*\"|\"),\n    parse = TRUE\n  ) +\n  geom_step(data=d, mapping=aes(x=x, y=y), linewidth=1) +\n  dsan_theme()\n#geom_step(data=d, mapping=aes(x=x, y=y), direction=\"vh\", linetype=3) +\n#geom_point(data=d, mapping=aes(x=x, y=y), color=\"red\")\n\nbase + geom_point(data=as.data.frame(list(x=2,y=4)), aes(x=x,y=y), color=cbPalette[2], size=g_pointsize/2) + \n  geom_function(fun = my_fake_deriv, color=cbPalette[2], linewidth=1) +\n  geom_function(fun = my_fake_deriv2, color=cbPalette[3], linewidth=1) +\n  geom_function(fun = my_fake_deriv3, color=cbPalette[4], linewidth=1) +\n  geom_point(data=as.data.frame(list(x=-1,y=1)), aes(x=x,y=y), color=cbPalette[2], size=g_pointsize/2) +\n  annotate(\"text\", x = -0.7, y = 1.1, label = \"?\", size=6)\n\nWarning message:\n\"Removed 1 rows containing missing values (`geom_point()`).\"\nWarning message:\n\"Removed 80 rows containing missing values (`geom_function()`).\"\nWarning message:\n\"Removed 60 rows containing missing values (`geom_function()`).\"\nWarning message:\n\"Removed 20 rows containing missing values (`geom_function()`).\"\n\n\n\n\n\nSo, given this rationale, let’s compute a new column in our tibble, representing the squared distance from 0 of each value in our original (random-walk-based) data, again using the mutate() function from dplyr:\n\nx_tibble &lt;- x_tibble |&gt; mutate(sq_dist = x_T^2)\nx_tibble |&gt; head()\n\n\nA tibble: 6 x 4\n\n\nobs_id\nx_T\nabs_dist\nsq_dist\n\n\n&lt;int&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n54\n54\n2916\n\n\n2\n22\n22\n484\n\n\n3\n-8\n8\n64\n\n\n4\n40\n40\n1600\n\n\n5\n-4\n4\n16\n\n\n6\n-18\n18\n324\n\n\n\n\n\nAnd once again, it looks like we’ve computed this column successfully: the negative values have again been transformed into positive values, this time via a fully differentiable transformation function \\(f(x) = x^2\\). And, again using code similar to that used above, let’s look at the distribution of this new variable by plotting a histogram:\n\nggplot(x_tibble, aes(x = sq_dist)) +\n  geom_histogram() +\n  dsan_theme()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\nggplot(x_tibble, aes(x = sq_dist)) +\n  geom_density() +\n  dsan_theme()\n\n\n\n\nBy the way, just like in the absolute value case, this distribution has a name, and is far more common than the folded distribution: the Chi-Squared (\\(\\chi^2\\)) Distribution. We’ll learn more about this distribution soon."
  },
  {
    "objectID": "writeups/lab-4-prep/DSAN5100_Lab_4_Prep.html#row-wise-operations-in-tidyverse",
    "href": "writeups/lab-4-prep/DSAN5100_Lab_4_Prep.html#row-wise-operations-in-tidyverse",
    "title": "Lab 4 Prep",
    "section": "Row-Wise Operations in tidyverse",
    "text": "Row-Wise Operations in tidyverse\nIn terms of what you have to do to complete Lab 4, this is probably the most important thing to know about tidyverse functions, especially those in dplyr: they are not as easy to use row-wise as the base-R functions are!\nWe just saw how “naturally” the tidyverse functions allow us to compute new columns by applying a unary transformation (like abs() or ^2) to one previously-existing column. But, if you want to compute a new column by applying an arbitrary function to two or more columns of your tibble at a time, you have to use the tidyverse construct rowwise(), and (frustratingly) not all transformation functions work well with this rowwise() operator.\nTo see what I mean, let’s go back to our simulation function from above and generate another column x2_T, containing the results from running the random walk 1000 steps for 1 million simulated people again:\n\nx2_T_vals &lt;- replicate(N, faster_simulation(T))\nx_tibble &lt;- x_tibble %&gt;% mutate(x2_T = x2_T_vals)\nx_tibble |&gt; head()\n\n\nA tibble: 6 x 5\n\n\nobs_id\nx_T\nabs_dist\nsq_dist\nx2_T\n\n\n&lt;int&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n54\n54\n2916\n-10\n\n\n2\n22\n22\n484\n-2\n\n\n3\n-8\n8\n64\n52\n\n\n4\n40\n40\n1600\n62\n\n\n5\n-4\n4\n16\n-14\n\n\n6\n-18\n18\n324\n6\n\n\n\n\n\nAnd now let’s assume we are interested in the maximum of these two values for a given person: intuitively, we might think we could just write max(x_T, x2_T) and it should work out, but let’s see what happens when we try this using tidyverse functions:\n\nx_tibble &lt;- x_tibble |&gt; mutate(x_max = max(x_T, x2_T))\nx_tibble |&gt; head()\n\n\nA tibble: 6 x 6\n\n\nobs_id\nx_T\nabs_dist\nsq_dist\nx2_T\nx_max\n\n\n&lt;int&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n54\n54\n2916\n-10\n156\n\n\n2\n22\n22\n484\n-2\n156\n\n\n3\n-8\n8\n64\n52\n156\n\n\n4\n40\n40\n1600\n62\n156\n\n\n5\n-4\n4\n16\n-14\n156\n\n\n6\n-18\n18\n324\n6\n156\n\n\n\n\n\nSomething has gone horribly wrong, right? Every single value is the same, and this value doesn’t seem to correspond to any of the x2 values in the first six rows of the tibble.\nWhat happened is: R interpreted the expression max(x_T, x2_T) as saying “find the maximum value across both of these two vectors I’m giving you”, so it found that maximum value (156 in this case), and then the call to the mutate() function was interpreted in turn by tidyverse as you telling it to “create a new column called x_max and store the number 156 in it, in every slot”.\nTo further confirm what happened, we can actually go and find the row that led it to produce the number 156:\n\nx_tibble |&gt; filter((x_T == 156) | (x2_T == 156))\n\n\nA tibble: 1 x 6\n\n\nobs_id\nx_T\nabs_dist\nsq_dist\nx2_T\nx_max\n\n\n&lt;int&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n60249\n-30\n30\n900\n156\n156\n\n\n\n\n\nAnd we see that participant number 60249 in our simulation indeed ended up at \\(x = -30\\) on their first run, but then at \\(x = 156\\) on their second run, the furthest to the right that anyone in the dataset ended up.\nTo properly compute the max of the values in a row (or some subset of the values, like we want in this case), we have to add the rowwise() transformation into our pipeline right before we use the mutate() function. This will then let the mutate() function know that, when we say max(), we mean the maximum over the specified values within each row, not across the entire dataset. So, redoing the above code with rowwise() added in looks like:\n\nx_tibble &lt;- x_tibble |&gt;\n  rowwise() |&gt;\n  mutate(x_max = max(x_T, x2_T))\nx_tibble |&gt; head()\n\n\nA rowwise_df: 6 x 6\n\n\nobs_id\nx_T\nabs_dist\nsq_dist\nx2_T\nx_max\n\n\n&lt;int&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n54\n54\n2916\n-10\n54\n\n\n2\n22\n22\n484\n-2\n22\n\n\n3\n-8\n8\n64\n52\n52\n\n\n4\n40\n40\n1600\n62\n62\n\n\n5\n-4\n4\n16\n-14\n-4\n\n\n6\n-18\n18\n324\n6\n6\n\n\n\n\n\nAnd now we can breathe a sigh of relief: the max() function used within mutate() has now been interpreted as we wanted: as a rowwise maximum, so that the value in the x_max column now represents that individual’s highest x_T value. And, we can take a look at the distribution of this maximum value, seeing whether (for example) it is still normal or whether it takes on the shape of some other known distribution:\n\nggplot(x_tibble, aes(x = x_max)) +\n  geom_histogram() +\n  dsan_theme()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nAnd using the kernel density geometry instead:\n\nggplot(x_tibble, aes(x = x_max)) +\n  geom_density()\n\n\n\n\nThis time, the data does look approximately normal. I will leave it to you all (just like on Lab 4) to interpret why this may be the case! (Or whether it’s the case at all…) But if you are stuck just let me know / come to my office hours, and I’m happy to help you think more about this max() transformation!"
  },
  {
    "objectID": "writeups/lab-4-prep/DSAN5100_Lab_4_Prep.html#footnotes",
    "href": "writeups/lab-4-prep/DSAN5100_Lab_4_Prep.html#footnotes",
    "title": "Lab 4 Prep",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIf it still hasn’t convinced you, try doing what we did earlier with the number of steps, increasing it to 1 million, and do that with the number of people as well… You will be sitting at your computer for a while.↩︎\nThey boil down to, “there’s no such thing as a free lunch”: if we abandon histograms and switch to some other visualization tool, that tool will have its own issues that we’ll need to grapple with.↩︎"
  },
  {
    "objectID": "writeups/computing-probabilities/index.html",
    "href": "writeups/computing-probabilities/index.html",
    "title": "Two Ways to Compute Probabilities in R/Python",
    "section": "",
    "text": "In several of the assignments for DSAN5100, we ask you to “compute” a probability. This can be ambiguous, as we’ve already learned several different ways to compute probabilities, so here I will try to distinguish between two different approaches to computing a probability using a computer. Hopefully it will help you in general when asking us questions, and will help us clarify which of these approaches we are looking for when we ask you to compute a probability in future assignments."
  },
  {
    "objectID": "writeups/computing-probabilities/index.html#approach-1-using-r-like-a-fancy-spreadsheet-program",
    "href": "writeups/computing-probabilities/index.html#approach-1-using-r-like-a-fancy-spreadsheet-program",
    "title": "Two Ways to Compute Probabilities in R/Python",
    "section": "Approach 1: Using R Like a Fancy Spreadsheet Program",
    "text": "Approach 1: Using R Like a Fancy Spreadsheet Program\nThis approach implicitly assumes the naïve definition of probability, from early on in the course:\n\n\n\n\n\n\nNaïve Definition of Probability\n\n\n\nGiven a sample space \\(\\Omega\\) and an event \\(E \\subseteq \\Omega\\),\n\\[\n\\Pr(\\underbrace{E}_{\\mathclap{\\text{event}}}) = \\frac{\\text{\\# Outcomes in E}}{\\text{\\# Possible Outcomes}} = \\frac{|E|}{|\\Omega|}\n\\]\n\n\nIt follows the following logic:\n\nIf we want to use our computer to compute a probability, and if the probability space we’re working in is finite, then\n\nWe can represent the entire sample space \\(\\Omega\\) as a big tibble, and\n\n\nWe can represent the event of interest \\(E\\) as a subset of this tibble1.\n\n\nAs a super simple example that hopefully illustrates this approach, consider the case of rolling a single die, so that the sample space is\n\\[\n\\Omega = \\{1, 2, 3, 4, 5, 6\\}\n\\]\nand then consider the event of interest \\(E\\) to be “the outcome of the roll is even”, so that\n\\[\nE = \\{2, 4, 6\\} \\subseteq \\Omega\n\\]\nIn this approach we could construct a tibble representing the entire sample space \\(\\Omega\\) like\n\nsource(\"../../_globals.r\")\nlibrary(tibble)\nsample_space_df &lt;- tibble(outcome=seq(1,6))\nsample_space_df\n\n\n\n\n\noutcome\n\n\n\n\n1\n\n\n2\n\n\n3\n\n\n4\n\n\n5\n\n\n6\n\n\n\n\n\n\nThen we could extract a subset of this tibble corresponding to the event \\(E\\) by selecting only those rows whose outcome value is even2:\n\nlibrary(dplyr)\nevent_df &lt;- sample_space_df %&gt;% filter(outcome %% 2 == 0)\nevent_df\n\n\n\n\n\noutcome\n\n\n\n\n2\n\n\n4\n\n\n6\n\n\n\n\n\n\nThese two tibbles together allow us to compute a probability using the naïve definition:\n\nnrow(event_df) / nrow(sample_space_df)\n\n[1] 0.5\n\n\nIt’s a bit silly to use this approach to study dice, since we can figure out the probabilistic properties of dice pretty intuitively (see below), but this approach becomes more useful when we think about problems focusing on data analysis.\nFor example, we might give you a problem that says\nLoad this dataset of country/region GDP data, and keep just the observations for the year 2010. What is the probability that an entity in this dataset had a GDP lower than $10 billion, and a country code containing the letter Z, in this year?\n\nlibrary(readr)\nlibrary(dplyr)\nlibrary(stringr)\ngdp_df &lt;- read_csv(\"https://gist.githubusercontent.com/jpowerj/fecd437b96d0954893de727383f2eaf2/raw/fec58507f7095cb8341b229d6eb74ce53232d663/gdp_2010.csv\")\nbelow_10b_df &lt;- gdp_df %&gt;% filter(value &lt; 10000000000)\nbelow_10b_z_df &lt;- below_10b_df %&gt;% filter(str_detect(code, 'Z'))\nbelow_10b_z_df\n\n\n\n\n\nname\ncode\nyear\nvalue\n\n\n\n\nBelize\nBLZ\n2010\n1397113450\n\n\nKyrgyz Republic\nKGZ\n2010\n4794357795\n\n\nSwaziland\nSWZ\n2010\n4438778424\n\n\n\n\n\n\nSo that now we could compute the probability of a country having these properties:\n\np_event &lt;- nrow(below_10b_z_df) / nrow(gdp_df)\np_event\n\n[1] 0.01470588\n\n\nSo, this approach works well when we’re dealing with nice, simple, finite sample-spacing and outcomes which are easily definable using and or or (for example), but we won’t be able to use it to handle fancier cases like continuous probability distributions."
  },
  {
    "objectID": "writeups/computing-probabilities/index.html#approach-2-using-r-like-a-fancy-calculator",
    "href": "writeups/computing-probabilities/index.html#approach-2-using-r-like-a-fancy-calculator",
    "title": "Two Ways to Compute Probabilities in R/Python",
    "section": "Approach 2: Using R Like a Fancy Calculator",
    "text": "Approach 2: Using R Like a Fancy Calculator\nIn this approach, we basically just use R (or Python, or whatever else) as a glorified calculator. We take the hard part—reasoning about what the sample space might look like, for example, or whether events are independent—and do it in our heads, then use R to figure out what happens when we multiply/add/divide the things we already figured out.\nContinuing the dice example, for instance, this approach would go something like: we ask you\n\nWhat is the probability that you observe a roll greater than 4, followed by a roll less than or equal to 4, followed by a roll greater than 4?\n\nand you reason through this like,\n\nI already know that there are 6 outcomes, and that they’re all equally likely, so that the probability of seeing a particular outcome in \\(\\Omega = \\{1, 2, 3, 4, 5, 6\\}\\) is always \\(\\frac{1}{6}\\). Therefore I can define an event \\(E_&gt;\\) representing the event of observing an outcome greater than 4, and another event \\(E_\\leq\\) of observing an outcome less than or equal to 4. I know that\n\n\n\nSince the possible outcomes greater than 4 are 5 and 6, my event \\(E_&gt; = \\{5, 6\\}\\), and since \\(\\Omega = \\{1, 2, 3, 4, 5, 6\\}\\), I can compute the probability of \\(E_&gt;\\) as \\[\n\\Pr(E_&gt;) = \\frac{|E_&gt;|}{|\\Omega|} = \\frac{|\\{5, 6\\}|}{6} = \\frac{1}{3}\n\\]\n\n\n\n\nSince the possible outcomes less than or equal to 4 are 1, 2, 3, and 4, my event \\(E_\\leq = \\{1, 2, 3, 4\\}\\), so I can compute the probability of \\(E_\\leq\\) as \\[\n\\Pr(E_\\leq) = \\frac{|E_\\leq|}{|\\Omega|} = \\frac{|\\{1, 2, 3, 4|}{6} = \\frac{2}{3}\n\\]\n\n\n\nAnd now I can use R with these probabilities I computed in my head to derive the probabilities of them occurring in a particular sequence:\n\n\n# Encode probabilities of my two events\np_greater &lt;- 1/3\np_less_or_equal &lt;- 2/3\n# Use them to compute the probabilities of sequences\np_sequence &lt;- p_greater * p_less_or_equal * p_greater\np_sequence\n\n[1] 0.07407407\n\n\nThis approach may seem boring at first, since again we could have done this just on a calculator, but it becomes interesting when we ask you to vary the numbers to see what happens to the resulting probabilities.\nFor example, if you wrote the above code for some problem, then in the next problem we could say “It turns out the person providing you with the dice was cheating! They rigged it so that there’s actually a 99% chance of getting a number greater than 4! Go back and compute the probability of this sequence but using the rigged die”\nAnd then you could just change the first line of your code, and re-run the whole thing, to obtain the new probability:\n\np_greater &lt;- 0.99\np_less_or_equal &lt;- 0.01\np_sequence &lt;- p_greater * p_less_or_equal * p_greater\np_sequence\n\n[1] 0.009801\n\n\nFinally, we might then ask you something like:\n“Your friend actually invented a machine that can generated any rigged die at all, so that the probability of rolling a number greater than 4 is whatever they want it to be.\nYou are worried because you always play a game with this friend where you win if you roll something greater than 4, then less than or equal to 4, then greater than 4. So you want to see how the friend’s rigging machine could affect your likelihood of winning.\nWrite a function that computes your likelihood of winning (i.e., your likelihood of getting this sequence of three rolls), for any die with any probability of producing an outcome greater than 4.\nIn this case, you could now take your code and transform it into a function, like\n\ncompute_win_prob &lt;- function(p_greater) {\n    p_less_or_equal &lt;- 1 - p_greater\n    p_sequence &lt;- p_greater * p_less_or_equal * p_greater\n    return(p_sequence)\n}\n\nAnd then test it on some values:\n\ncompute_win_prob(0.01)\n\n[1] 9.9e-05\n\ncompute_win_prob(0.5)\n\n[1] 0.125\n\ncompute_win_prob(0.99)\n\n[1] 0.009801\n\n\nThen we could ask you to think about\nWhat value for p_greater do you think would maximize your probability of winning?\nand then\nProduce a plot showing your likelihood of winning for 1000 different values of p_greater, evenly spread between 0 and 1\nand you could use the function you wrote like\n\nlibrary(ggplot2)\np_greater_vals &lt;- seq(from = 0, to = 1, length.out = 1000)\n#p_greater_vals\nwin_prob_vals &lt;- sapply(p_greater_vals, compute_win_prob)\nwin_df &lt;- tibble(p_greater=p_greater_vals, win_prob=win_prob_vals)\nggplot(win_df, aes(x=p_greater, y=win_prob)) +\n  geom_line() +\n  dsan_theme(\"full\") +\n  labs(\n    title = \"Probability of Winning With Rigged Die\",\n    x = \"Pr(Result &gt; 4)\",\n    y = \"Pr(Win)\"\n  )\n\n\n\n\n\n\n\n\nAnd finally, we could ask you to draw a conclusion about this situation:\nLooking at the plot, approximately what value for the rigged die looks like it produces the maximum likelihood of winning? Now write code to compute the actual value, out of the 1000 evenly-spaced values you computed the win probability for, that maximizes your probability of winning. Does it match your guess from earlier?\nFor which you could write code like\n\nmax_prob &lt;- max(win_df$win_prob)\nmax_row &lt;- win_df %&gt;% filter(win_prob == max_prob)\nmax_row\n\n\n\n\n\np_greater\nwin_prob\n\n\n\n\n0.6666667\n0.1481481\n\n\n\n\n\n\nMy point in writing all this out is just to say: that was a whole other way to compute probabilities using a computer, where the focus wasn’t on making a big tibble and then extracting smaller chunks out of it and dividing their sizes. We did have to construct a tibble, in order to compute the win probabilities for a spectrum of values, but that was just so we could generate a plot (since ggplot() needed to know specifically what points to put at what coordinates).\nSo, in this approach, we don’t have a single tibble throughout the entire problem that serves as our sample space. We just use tibbles when we need them, as tools for doing math or making plots, while the probabilities themselves are still getting computed using simple multiplication.\nAnd, I mentioned above how the tibble-subsetting method doesn’t allow us to deal with continuous probability distributions. We’ve now seen, on the other hand, how this “fancy calculator” approach is able to deal with such distributions: we were really looking at the distribution of all possible rigged dice, meaning, the space of all dice with \\(\\Pr(\\text{roll greater than 4}) = p\\) for \\(p \\in [0,1]\\). We had to approximate this continuous space using a grid of 1000 samples, which brought us closer to the fancy-spreadsheet approach, but hopefully this can help make it a bit clearer how the fancy-calculator approach can help us when the fancy-spreadsheet approach can’t, even if it (the fancy-calculator approach) requires us to do a lot more math in our heads."
  },
  {
    "objectID": "writeups/computing-probabilities/index.html#footnotes",
    "href": "writeups/computing-probabilities/index.html#footnotes",
    "title": "Two Ways to Compute Probabilities in R/Python",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIf you’re a Python absolutist, you can take tibble here and replace it with pd.DataFrame, for example. If you’re a base-R absolutist you can replace it with data.frame.↩︎\nThe %% operator in R performs modular division: a %% b produces the remainder after dividing a by b (for example, 7 %% 3 produces 1).↩︎"
  },
  {
    "objectID": "writeups/index.html",
    "href": "writeups/index.html",
    "title": "Extra Writeups",
    "section": "",
    "text": "Order By\n       Default\n         \n          Last Updated - Oldest\n        \n         \n          Last Updated - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nTitle\n\n\nLast Updated\n\n\nCategory\n\n\n\n\n\n\nContinuous Probability and the Order of Integration\n\n\nMonday, October 9, 2023\n\n\nExtra Writeups\n\n\n\n\nMarginal Distributions and “Marginalizing Out” A Variable\n\n\nWednesday, October 4, 2023\n\n\nExtra Writeups\n\n\n\n\nDeriving a pdf from Scratch\n\n\nTuesday, October 3, 2023\n\n\nExtra Writeups\n\n\n\n\nSimulating Sample Spaces With Tibbles\n\n\nWednesday, September 27, 2023\n\n\nExtra Writeups\n\n\n\n\nLab 4 Prep\n\n\nFriday, September 22, 2023\n\n\nExtra Writeups\n\n\n\n\nTwo Ways of Sampling from a Data Frame\n\n\nMonday, September 18, 2023\n\n\nExtra Writeups\n\n\n\n\nTwo Ways to Compute Probabilities in R/Python\n\n\nSaturday, September 16, 2023\n\n\nExtra Writeups\n\n\n\n\nQuiz 1 Clarifications\n\n\nWednesday, September 13, 2023\n\n\nClarifications\n\n\n\n\nBayes’ Theorem: Disease Probabilities\n\n\nWednesday, September 13, 2023\n\n\nExtra Writeups\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "writeups/bayes-disease-tests/index.html",
    "href": "writeups/bayes-disease-tests/index.html",
    "title": "Bayes’ Theorem: Disease Probabilities",
    "section": "",
    "text": "\\(D \\in \\{0, 1\\}\\) = has disease\n\\(T \\in \\{0, 1\\}\\) = test result\n(In the real world, however, we cannot observe \\(D\\), only \\(T\\))\n99% accuracy:\n\n\\(\\Pr(T = 1 \\mid D = 1) = 0.99\\)\n\\(\\Pr(T = 0 \\mid D = 0) = 0.99\\)\n\nRare disease: 1 in 10000 people has it\n\n\\(\\Pr(D = 1) = \\frac{1}{10000}\\)"
  },
  {
    "objectID": "writeups/bayes-disease-tests/index.html#what-were-given",
    "href": "writeups/bayes-disease-tests/index.html#what-were-given",
    "title": "Bayes’ Theorem: Disease Probabilities",
    "section": "",
    "text": "\\(D \\in \\{0, 1\\}\\) = has disease\n\\(T \\in \\{0, 1\\}\\) = test result\n(In the real world, however, we cannot observe \\(D\\), only \\(T\\))\n99% accuracy:\n\n\\(\\Pr(T = 1 \\mid D = 1) = 0.99\\)\n\\(\\Pr(T = 0 \\mid D = 0) = 0.99\\)\n\nRare disease: 1 in 10000 people has it\n\n\\(\\Pr(D = 1) = \\frac{1}{10000}\\)"
  },
  {
    "objectID": "writeups/bayes-disease-tests/index.html#basic-bayes-probability-of-disease-given-positive-test",
    "href": "writeups/bayes-disease-tests/index.html#basic-bayes-probability-of-disease-given-positive-test",
    "title": "Bayes’ Theorem: Disease Probabilities",
    "section": "Basic Bayes: Probability of Disease Given Positive Test",
    "text": "Basic Bayes: Probability of Disease Given Positive Test\nWe want\n\\[\n\\Pr(D = 1 \\mid T = 1)\n\\]\nWhich we can compute, using the given information, via Bayes’ rule (where the second line is how I like to write it out, a bit more cluttered but makes it clear how to compute the denominator)\n\\[\n\\begin{align*}\n\\Pr(D = 1 \\mid T = 1) &= \\frac{\\Pr(T = 1 \\mid D = 1)\\Pr(D = 1)}{\\Pr(T = 1)} \\\\\n&= \\frac{\\Pr(T = 1 \\mid D = 1)\\Pr(D = 1)}{\\Pr(T = 1 \\mid D = 1)\\Pr(D = 1) + \\Pr(T = 1 \\mid D = 0)\\Pr(D = 0)}\n\\end{align*}\n\\]\nNumerically:\n\\[\n\\Pr(D = 1 \\mid T = 1) = \\frac{(0.99)(1/10000)}{(0.99)(1/10000) + (0.01)(9999/10000)} \\approx 0.0098\n\\]\n(Less than 1%)"
  },
  {
    "objectID": "writeups/bayes-disease-tests/index.html#deeper-dive",
    "href": "writeups/bayes-disease-tests/index.html#deeper-dive",
    "title": "Bayes’ Theorem: Disease Probabilities",
    "section": "Deeper Dive",
    "text": "Deeper Dive\nBut now let’s think about what’s behind this… It’s a dangerous, highly contagious disease, meaning that (societally) false negatives are much, much worse than false positives:\n\nA false negative, in this case, means that someone is walking around thinking they don’t have the disease (because they tested negative), when they actually do. This means that they are not quarantining, they are going out to parties and events and etc., spreading the disease.\nA false positive, on the other hand, means someone who panics unnecessarily: maybe it means, they go to the hospital, the hospital performs additional tests, and successfully discovers that the person, despite their positive test result, doesn’t have the disease.\nSo, consequence-wise, a false negative potentially means a new outbreak of the disease in the society, while a false positive means a quick (scary, but hopefully quick) trip to the hospital\n\n\nThe Catastrophic Case\nSo, let’s focus on the disastrous first case: what’s the probability of a false negative? First, we can compute the conditional probability of a negative test, conditional on someone having the disease? Here we just use our complement rule of probability: that \\(\\Pr(E^c) = 1 - \\Pr(E)\\) for any event \\(E\\):\n\\[\n\\Pr(T = 0 \\mid D = 1) = 1 - \\Pr(T = 1 \\mid D = 1) = 0.01\n\\]\nNow that we know this, let’s incorporate the base rate information—that is, the information we have about the likelihood of having the disease (the thing we conditioned on above):\n\\[\n\\Pr(D = 1) = \\frac{1}{10000}\n\\]\nSo, given these two pieces of information, we can compute the probability of a person in the population being a false negative case: having the disease, but not being detected by the test.\n\\[\n\\begin{align*}\n\\Pr(T = 0 \\cap D = 1) &= \\Pr(T = 0 \\mid D = 1)\\Pr(D = 1) \\\\\n&= (0.01)(1/10000) = \\frac{1}{1000000},\n\\end{align*}\n\\]\ni.e., one in a million.\n\n\nThe Bad (But Not Catastrophic) Case\nNow let’s turn to the second, bad but not catastrophic, case: the probability of a false positive. As before, we start by computing the conditional probability of a positive test result for someone who in fact does not have the disease:\n\\[\n\\Pr(T = 1 \\mid D = 0) = 1 - \\Pr(T = 0 \\mid D = 0) = 0.01\n\\]\nThis time, however, we’ll see that the base rate will make a big difference. The base rate in this case—the probability of someone not having the disease—is:\n\\[\n\\Pr(D = 0) = 1 - \\Pr(D = 1) = \\frac{9999}{10000}\n\\]\nSo, incorporating these two pieces of information, we can compute the likelihood of a false positive case: someone in the population who doesn’t have the disease but does test positive:\n\\[\n\\begin{align*}\n\\Pr(T = 1 \\cap D = 0) &= \\Pr(T = 1 \\mid D = 0)\\Pr(D = 0) \\\\\n&= (0.01)(9999/10000) = \\frac{9999}{1000000}\n\\end{align*}\n\\]\nIn words: for every million people in the population, 9999 of them will have a false positive panic: they won’t have the disease, but they will think they have the disease because of their positive test."
  },
  {
    "objectID": "writeups/bayes-disease-tests/index.html#putting-it-together",
    "href": "writeups/bayes-disease-tests/index.html#putting-it-together",
    "title": "Bayes’ Theorem: Disease Probabilities",
    "section": "Putting It Together:",
    "text": "Putting It Together:\nAt first, this example is depressing: “Oh no, that’s terrible! We’re forcing thousands of people to panic, thinking that they have the disease, when they really don’t!”\nBut, walking through it with this false negative / false positive paradigm, we see the real takeaway: that there is always a tradeoff between false positives and false negatives. In this case, from a public health perspective for example, it’s actually somewhat of a good situation: at the “cost” of having several thousand people panic unnecessarily, we achieve the benefit of making it very, very unlikely (one in a million, literally) that someone goes undetected in the population with this dangerous, contagious disease.\n\n\n\n\n\n\n\n\n\n\\(N = 1000000\\)\nTrue State of the World\n\n\n\\(D = 0\\)\n(Doesn't have disease)\n\\(D = 1\\)\n(Has disease)\n\n\n\n\nPrediction\n\\(T = 0\\)\n(Tested negative)\nTrue Negative\nSuccessfully detected no disease 👍\n989,901 People\nFalse Negative\nFailed to detect disease 🚨😵🚨\n1 Person\n\n\n\\(T = 1\\)\n(Tested positive)\nFalse Positive\nFalse alarm 😬 sorry!\n9999 People\nTrue Positive\nSuccessfully detected disease 😮‍💨\n99 People\n\n\n\n\n(Compuation of the remaining two cells:)\nTrue Positive:\n\\[\n\\begin{align*}\n\\Pr(T = 1 \\cap D = 1) &= \\Pr(T = 1 \\mid D = 1)\\Pr(D = 1) \\\\\n&= (0.99)\\frac{1}{10000} = \\frac{99}{1000000}\n\\end{align*}\n\\]\nTrue Negative:\n\\[\n\\begin{align*}\n\\Pr(T = 0 \\cap D = 0) &= \\Pr(T = 0 \\mid D = 0)\\Pr(D = 0) \\\\\n&= (0.99)\\frac{9999}{10000} = \\frac{989901}{1000000}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w07/index.html",
    "href": "w07/index.html",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "",
    "text": "Open slides in new window →"
  },
  {
    "objectID": "w07/index.html#frequency-tables",
    "href": "w07/index.html#frequency-tables",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Frequency Tables",
    "text": "Frequency Tables\n\n\n\n\nWhat does this tell us on its own (before computing proportions in our heads) that is useful for probability?\nAnswer: Not very much!\nBut, if we can find the overall total, then it would tell us a lot (everything we need to know)!\n\n\n\n\nTable 1: A frequency table of HS students (\\(G\\) = grade, \\(H\\) = honors status)This tells us, e.g., there are 5 honors students in grade 10\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\n\n\n\n\n\\(G = 10\\)\n10\n5\n\n\n\\(G = 11\\)\n6\n4\n\n\n\\(G = 12\\)\n7\n1\n\n\n\n\n\n\n\nA frequency table where each row corresponds to a grade in a certain senior high school, each column corresponds to honor-student-status (\\(H=1\\) represents honors, \\(H=0\\) represents non-honors), and each cell contains the number of students in that grade with that honors-status"
  },
  {
    "objectID": "w07/index.html#why-do-we-need-the-total",
    "href": "w07/index.html#why-do-we-need-the-total",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Why Do We Need The Total?",
    "text": "Why Do We Need The Total?\n\nQ1: Someone asks the probability that a randomly-selected student will be an honor student in 11th grade.\nQ2: Someone asks what proportion of students are honors\nQ3: Someone asks what % of 12th grade are honors\n\nQ1, for example, is asking us for \\(\\Pr(G = 11, H = 1)\\), a question we can answer if we know the joint distribution \\(f_{G,H}(v_G, v_H)\\)."
  },
  {
    "objectID": "w07/index.html#back-to-the-naïve-definition",
    "href": "w07/index.html#back-to-the-naïve-definition",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Back to the Naïve Definition",
    "text": "Back to the Naïve Definition\nUsing our naïve definition of probability, we can compute this probability using the frequencies in the table as\n\\[\n\\Pr(G = 11, H = 1) = \\frac{\\#(G = 11, H = 1)}{\\#\\text{ Students Total}}\n\\]\nPlugging in the values from Table 1, we obtain the answer:\n\\[\n\\Pr(G = 11, H = 1) = \\frac{4}{33} \\approx 0.121\n\\]"
  },
  {
    "objectID": "w07/index.html#frequency-table-rightarrow-probability-table",
    "href": "w07/index.html#frequency-table-rightarrow-probability-table",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Frequency Table \\(\\rightarrow\\) Probability Table",
    "text": "Frequency Table \\(\\rightarrow\\) Probability Table\n\nWhen we divide by 33, we are normalizing the counts, producing probabilities (normalized counts)\nBy normalizing all cells in the table, we convert our frequency table into a probability table"
  },
  {
    "objectID": "w07/index.html#computing-overall-total-by-column",
    "href": "w07/index.html#computing-overall-total-by-column",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Computing Overall Total by Column",
    "text": "Computing Overall Total by Column\nWe could compute the total by summing columns, then summing over our individual column totals to get 33:\n\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\nTotal\n\n\n\n\n\\(G = 10\\)\n10\n5\n\n\n\n\\(G = 11\\)\n6\n4\n\n\n\n\\(G = 12\\)\n7\n1\n\n\n\nTotal\n23\n10\n33"
  },
  {
    "objectID": "w07/index.html#computing-overall-total-by-row",
    "href": "w07/index.html#computing-overall-total-by-row",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Computing Overall Total by Row",
    "text": "Computing Overall Total by Row\nOr, we could compute the total by summing rows, then summing over our individual row totals to get 33:\n\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\nTotal\n\n\n\n\n\n\\(G = 10\\)\n10\n5\n15\n\n\n\n\\(G = 11\\)\n6\n4\n10\n\n\n\n\\(G = 12\\)\n7\n1\n8\n\n\n\nTotal\n\n\n33"
  },
  {
    "objectID": "w07/index.html#bringing-both-methods-together",
    "href": "w07/index.html#bringing-both-methods-together",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Bringing Both Methods Together",
    "text": "Bringing Both Methods Together\n\n\nTable 2: The same frequency table as in Table 1, but now with row and column totals representing marginal frequencies\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\nTotal\n\n\n\n\n\n\\(G = 10\\)\n10\n5\n15\n\n\n\n\\(G = 11\\)\n6\n4\n10\n\n\n\n\\(G = 12\\)\n7\n1\n8\n\n\n\nTotal\n23\n10\n33"
  },
  {
    "objectID": "w07/index.html#frequencies-to-probabilities",
    "href": "w07/index.html#frequencies-to-probabilities",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Frequencies to Probabilities",
    "text": "Frequencies to Probabilities\n\n\n\n\nNow (before we think about row/column totals) let’s use overall total (33) to convert counts into probabilities:\n\n\n\n\nTable 3: Table from prev slide with all values normalized (divided by the total number of obs)\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\nTotal\n\n\n\n\n\\(G = 10\\)\n\\(\\frac{10}{33}\\)\n\\(\\frac{5}{33}\\)\n\\(\\frac{15}{33}\\)\n\n\n\\(G = 11\\)\n\\(\\frac{6}{33}\\)\n\\(\\frac{4}{33}\\)\n\\(\\frac{10}{33}\\)\n\n\n\\(G = 12\\)\n\\(\\frac{7}{33}\\)\n\\(\\frac{1}{33}\\)\n\\(\\frac{8}{33}\\)\n\n\nTotal\n\\(\\frac{23}{33}\\)\n\\(\\frac{10}{33}\\)\n\\(\\frac{33}{33}\\)"
  },
  {
    "objectID": "w07/index.html#one-table-three-distributions",
    "href": "w07/index.html#one-table-three-distributions",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "One Table, Three Distributions!",
    "text": "One Table, Three Distributions!\nNow that we have normalized counts, different pieces of this table give different probability distributions:\n\n\n\n\nJoint Distribution \\(f_{G,H}(v_G, v_H)\\): Look at value in row \\(v_G\\), col \\(v_H\\)\nMarginal Distributions\n\n\\(f_G(v_G)\\): Look at total for row \\(v_G\\)\n\\(f_H(v_H)\\): Look at total for column \\(v_H\\)\n\n\n\n\n\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\nTotal\n\n\n\n\n\\(G = 10\\)\n\\(\\frac{10}{33}\\)\n\\(\\frac{5}{33}\\)\n\\(\\frac{15}{33}\\)\n\n\n\\(G = 11\\)\n\\(\\frac{6}{33}\\)\n\\(\\frac{4}{33}\\)\n\\(\\frac{10}{33}\\)\n\n\n\\(G = 12\\)\n\\(\\frac{7}{33}\\)\n\\(\\frac{1}{33}\\)\n\\(\\frac{8}{33}\\)\n\n\nTotal\n\\(\\frac{23}{33}\\)\n\\(\\frac{10}{33}\\)\n\\(\\frac{33}{33}\\)"
  },
  {
    "objectID": "w07/index.html#summary-joint-rightarrow-marginal",
    "href": "w07/index.html#summary-joint-rightarrow-marginal",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Summary: Joint \\(\\rightarrow\\) Marginal",
    "text": "Summary: Joint \\(\\rightarrow\\) Marginal\n\nNote how marginal distributions were obtained by summing the joint distribution over a particular dimension:\nSumming each column (\\(H = 0\\) and \\(H = 1\\)) produced marginal distribution of \\(H\\):\n\n\n\n\n\n\n\n\n\\(\\Pr(H = 0, G = 10)\\)\n\n\n+\n\\(\\Pr(H = 0, G = 11)\\)\n\n\n+\n\\(\\Pr(H = 0, G = 12)\\)\n\n\n=\n\\(\\Pr(H = 0)\\)\n\n\n\n\n\n\n\n\n\n\\(\\Pr(H = 1, G = 10)\\)\n\n\n+\n\\(\\Pr(H = 1, G = 11)\\)\n\n\n+\n\\(\\Pr(H = 1, G = 12)\\)\n\n\n=\n\\(\\Pr(H = 1)\\)\n\n\n\n\n\n\n\nSumming each row (\\(G = 10\\), \\(G = 11\\), \\(G = 12\\)) produced marginal distribution of \\(G\\):\n\n\n\n\n\\(\\Pr(G = 10, H = 0)\\)\n+\n\\(\\Pr(G = 10, H = 1)\\)\n=\n\\(\\Pr(G = 10)\\)\n\n\n\\(\\Pr(G = 11, H = 0)\\)\n+\n\\(\\Pr(G = 11, H = 1)\\)\n=\n\\(\\Pr(G = 11)\\)\n\n\n\\(\\Pr(G = 12, H = 0)\\)\n+\n\\(\\Pr(G = 12, H = 1)\\)\n=\n\\(\\Pr(G = 12)\\)"
  },
  {
    "objectID": "w07/index.html#whats-missing-conditional-distributions",
    "href": "w07/index.html#whats-missing-conditional-distributions",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "What’s Missing? Conditional Distributions",
    "text": "What’s Missing? Conditional Distributions\n\nConditional distribution does not represent a sum but a slice: we consider e.g. one particular row or one particular column of the table.\n🚨Warning🚨! unlike in joint and marginal cases, when computing conditional distributions we have to renormalize, since we are “entering world” where we only consider subsets of the table where condition is met!\nRecall slide about how all distributions are conditional distributions:\n\n\n\n\n\\(\\Pr(G = 10, H = 1)\\)\n\n\\[\n\\begin{align*}\n= &\\Pr(G = 10, H = 1 \\mid \\Omega) \\\\[0.6em]\n= &\\frac{\\#(G = 10, H = 1, \\Omega)}{\\#\\text{ Total }(\\Omega)\\text{ ✅}}\n\\end{align*}\n\\]\n\n\n\\(\\Pr(G = 10)\\)\n\n\\[\n\\begin{align*}\n= &\\Pr(G = 10 \\mid \\Omega) \\\\[0.6em]\n= &\\frac{\\#(G = 10, \\Omega)}{\\#\\text{ Total }(\\Omega)\\text{ ✅}}\n\\end{align*}\n\\]\n\n\n\\(\\Pr(G = 10 \\mid H = 1)\\)\n\n\\[\n\\begin{align*}\n= &\\frac{\\Pr(G = 10, H = 1)}{\\Pr(H = 1)} \\\\[0.6em]\n= &\\frac{\\#(G = 10, H = 1)}{\\#(H = 1)\\text{ 😳}}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w07/index.html#conditional-distributions-from-columns",
    "href": "w07/index.html#conditional-distributions-from-columns",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Conditional Distributions from Columns",
    "text": "Conditional Distributions from Columns\nLet’s extract just the \\(H = 1\\) column:\n\n\n\n\n\n\n\n\\(H = 1\\)\n\n\n\n\n\\(G = 10\\)\n5\n\n\n\\(G = 11\\)\n4\n\n\n\\(G = 12\\)\n1\n\n\nTotal\n10\n\n\n\n\n\n→\n\n\n\n\n\n\n\\(H = 1\\)\n\n\n\n\n\\(G = 10\\)\n\\(\\frac{5}{10}\\)\n\n\n\\(G = 11\\)\n\\(\\frac{4}{10}\\)\n\n\n\\(G = 12\\)\n\\(\\frac{1}{10}\\)\n\n\nTotal\n\\(\\frac{10}{10}\\)\n\n\n\n\n\n\n\nBefore, 10 was a particular marginal frequency of interest; now 10 is just a total that we use to renormalize"
  },
  {
    "objectID": "w07/index.html#conditional-distributions-from-rows",
    "href": "w07/index.html#conditional-distributions-from-rows",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Conditional Distributions from Rows",
    "text": "Conditional Distributions from Rows\nLet’s extract just the \\(G = 10\\) row:\n\n\n\n\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\nTotal\n\n\n\n\n\\(G = 10\\)\n5\n10\n15\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\nTotal\n\n\n\n\n\\(G = 10\\)\n\\(\\frac{5}{15}\\)\n\\(\\frac{10}{15}\\)\n\\(\\frac{15}{15}\\)\n\n\n\n\n\n\n\nBefore, 15 was a particular marginal frequency of interest; now 15 is just a total that we use to renormalize"
  },
  {
    "objectID": "w07/index.html#discrete-world-summary",
    "href": "w07/index.html#discrete-world-summary",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Discrete World Summary",
    "text": "Discrete World Summary\nWe now have the link between three types of distributions derived from our table:\n\n\n\n\n\n\n\n\n\n\n\nDistribution Type\nHow Many?\nExample Value\n\n\n\n\nJoint Distribution\n1\n\\(\\Pr(G = 11, H = 1)\\)\\(= \\frac{4}{33}\\)\n\n\nMarginal Distributions\n2\n\\(\\Pr(H = 1) = \\frac{10}{33}\\)\n\n\nConditional Distributions\n6\n\\(\\Pr(G = 10 \\mid H = 1)\\)\\(= \\frac{5}{10}\\)\n\n\n\n\n\n\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\nTotal\n\n\n\n\n\\(G = 10\\)\n\\(\\frac{10}{33}\\)\n\\(\\frac{5}{33}\\)\n\\(\\frac{15}{33}\\)\n\n\n\\(G = 11\\)\n\\(\\frac{6}{33}\\)\n\\(\\frac{4}{33}\\)\n\\(\\frac{10}{33}\\)\n\n\n\\(G = 12\\)\n\\(\\frac{7}{33}\\)\n\\(\\frac{1}{33}\\)\n\\(\\frac{8}{33}\\)\n\n\nTotal\n\\(\\frac{23}{33}\\)\n\\(\\frac{10}{33}\\)\n\\(\\frac{33}{33}\\)\n\n\n\n\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\n\n\n\n\n\\(G = 10\\)\n\\(\\frac{10}{23}\\)\n\\(\\frac{5}{10}\\)\n\n\n\\(G = 11\\)\n\\(\\frac{6}{23}\\)\n\\(\\frac{4}{10}\\)\n\n\n\\(G = 12\\)\n\\(\\frac{7}{23}\\)\n\\(\\frac{1}{10}\\)\n\n\nTotal\n\\(\\frac{23}{23}\\)\n\\(\\frac{10}{10}\\)"
  },
  {
    "objectID": "w07/index.html#working-backwards",
    "href": "w07/index.html#working-backwards",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Working Backwards",
    "text": "Working Backwards\n\nHere we started from the joint distribution and derived marginal and conditional distributions\nSame intuition, plus math, lets us go in opposite direction: given marginal and conditional distributions, we could derive joint distribution, since (defn of conditional prob):\n\n\n\n\n\n\n\n\\(\\Pr(A \\mid B)\\)\n\\(=\\)\n\\(\\Pr(A, B)\\)\n\n\n\\(\\Pr(B)\\)\n\n\n\n\n\n\\[\n\\iff\n\\]\n\n\n\n\n\n\\(\\Pr(A,B)\\)\n\\(=\\)\n\\(\\Pr(A \\mid B)\\)\n\\(\\cdot\\)\n\\(\\Pr(B)\\)\n\n\n\n\n\n\n\nfrom which we can see that if we know the conditional distribution \\(\\Pr(B \\mid A)\\) and the marginal distribution \\(\\Pr(A)\\), we can combine these (via multiplication) to obtain the joint distribution \\(\\Pr(B,A)\\)."
  },
  {
    "objectID": "w07/index.html#moving-to-continuous-world",
    "href": "w07/index.html#moving-to-continuous-world",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Moving to Continuous World",
    "text": "Moving to Continuous World\n\nIntuitions from discrete world do translate into good intuitions for continuous world, in this case!\nWe can “move” discrete table into continuous space similar to how Riemann sums “move” discrete sums into integrals:"
  },
  {
    "objectID": "w07/index.html#smoothing-our-example",
    "href": "w07/index.html#smoothing-our-example",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "“Smoothing” Our Example",
    "text": "“Smoothing” Our Example\n\nInstead of discrete \\(G\\) with \\(\\mathcal{R}_G = \\{10, 11, 12\\}\\), we have a continuous \\(G\\) with \\(\\mathcal{R}_G = [10,12] \\subset \\mathbb{R}\\) (“progress” through senior HS)\nInstead of discrete \\(H\\) with \\(\\mathcal{R}_H = \\{0, 1\\}\\), now we keep track of continuous “honors spectrum” \\(H\\) with \\(\\mathcal{R}_H = [0, 1] \\subset \\mathbb{R}\\)\nA student near the beginning of 10th grade who is towards the “high end” of the “honors spectrum”: (\\(G = 10.03\\) and \\(H = 0.95\\))"
  },
  {
    "objectID": "w07/index.html#smoothing-our-tables",
    "href": "w07/index.html#smoothing-our-tables",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "“Smoothing” Our Tables",
    "text": "“Smoothing” Our Tables\n\nSums become integrals\nRe-normalization (ensuring that probability mass values sum to 1) becomes ensuring that probability density values integrate to 1.\nWhat comes in place of frequency table?\nAnswer in theory: Joint pdf\nAnswer in practice: Depends on the context 😬"
  },
  {
    "objectID": "w07/index.html#working-backwards-redux",
    "href": "w07/index.html#working-backwards-redux",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Working Backwards Redux",
    "text": "Working Backwards Redux\n\nWhile in discrete world we could easily provide a table, in continuous world we often/usually have to work backwards; we may just be given:\n\\(G \\sim \\mathcal{U}(10, 12)\\)\n\\(H \\sim \\ddot{\\mathcal{N}}(\\mu = 0.5, \\sigma = 0.1, a = 0, b = 1)\\), and\n\\(G \\perp H\\) (so \\(\\Pr(G \\mid H) = \\Pr(G), \\Pr(H \\mid G) = \\Pr(H)\\))\n(i.e., marginal distributions = conditional distributions)."
  },
  {
    "objectID": "w07/index.html#the-marginal-pdfs-of-g-and-h",
    "href": "w07/index.html#the-marginal-pdfs-of-g-and-h",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "The Marginal pdfs of \\(G\\) and \\(H\\)",
    "text": "The Marginal pdfs of \\(G\\) and \\(H\\)\n\nSince we know \\(G \\sim \\mathcal{U}(10,12)\\), we know (or we could look up) that \\(G\\) has pdf\n\n\\[\nf_G(v_G) = \\frac{1}{12 - 10} = \\frac{1}{2}.\n\\]\n\n\\(H\\) has a slightly fancier distribution, the truncated normal distribution, but nonetheless a pdf we can derive from (a) knowing the pdf of the normal distribution and (b) knowing what we’ve just talked about regarding conditional distributions"
  },
  {
    "objectID": "w07/index.html#the-truncated-normal-distribution",
    "href": "w07/index.html#the-truncated-normal-distribution",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "The Truncated Normal Distribution",
    "text": "The Truncated Normal Distribution\n\n\\(\\ddot{\\mathcal{N}}\\) may look scary, but \\(X \\sim \\ddot{\\mathcal{N}}(\\mu, \\sigma, a, b)\\) just means that \\(X\\) can be “constructed from scratch” (similar to Problem 1 on the Lab 5 Assignment) as\n\n\\[\nX \\sim \\mathcal{N}(\\mu, \\sigma) \\implies [X \\mid a &lt; X &lt; b] \\sim \\ddot{\\mathcal{N}}(\\mu, \\sigma, a, b)\n\\]\n\nrnormt &lt;- function(n, range, mu, s = 1) {\n  \n  # range is a vector of two values\n  \n  F.a &lt;- pnorm(min(range), mean = mu, sd = s)\n  F.b &lt;- pnorm(max(range), mean = mu, sd = s)\n  \n  u &lt;- runif(n, min = F.a, max = F.b)\n  \n  qnorm(u, mean = mu, sd = s)\n  \n}\nlibrary(data.table)\nlibrary(simstudy)\nlibrary(paletteer)\n\ndefC &lt;- defCondition(condition= \"tt == 1\", \n                     formula = \"rnormt(10000, c(-Inf, Inf), mu = 0, s = 3)\")\ndefC &lt;- defCondition(defC, \"tt == 2\", \n                     formula = \"rnormt(10000, c(0, Inf), mu = 0, s = 3)\")\ndefC &lt;- defCondition(defC, \"tt == 3\", \n                     formula = \"rnormt(10000, c(-3, 3.5), mu = 0, s = 3)\")\n\ndd &lt;- genData(30000)\ndd &lt;- trtAssign(dd, nTrt = 3, grpName = \"tt\")\ndd &lt;- addCondition(defC, dd, \"x\")\n\ndd[, tt := factor(tt, \n     labels = c(\"No truncation\", \"Left truncation at 0\", \"Left and right truncation\"))]\n\nggplot(data = dd, aes(x = x, group = tt)) +\n  geom_histogram(aes(fill = tt), alpha = 1, binwidth = .2, boundary = 0) +\n  facet_grid(~tt) +\n  theme(panel.grid = element_blank(),\n        axis.title = element_blank(),\n        legend.position = \"none\") +\n  dsan_theme()\n\n\n\n\nAdapted from simstudy package documentation"
  },
  {
    "objectID": "w07/index.html#the-truncated-normal-pdf",
    "href": "w07/index.html#the-truncated-normal-pdf",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "The Truncated Normal pdf",
    "text": "The Truncated Normal pdf\n\nSince we see a conditioning bar on the previous slide, we can infer what the pdf of this conditional distribution would look like. If \\(X \\sim \\ddot{\\mathcal{N}}(\\mu, \\sigma, a, b)\\), then \\(X\\) has pdf\n\n\\[\nf_X(v) = \\frac{\\frac{1}{\\sigma}\\varphi\\left(\\frac{v_H-\\mu}{\\sigma}\\right)}{\\Phi\\left(\\frac{b-\\mu}{\\sigma}\\right) - \\Phi\\left(\\frac{a - \\mu}{\\sigma}\\right)} \\approx \\frac{\\Pr(X = v, a &lt; X &lt; b)}{\\Pr(a &lt; X &lt; b)}\n\\]\n\n\\(\\varphi\\) is the pdf of \\(\\mathcal{N}(0,1)\\)\n\\(\\Phi\\) is the CDF of \\(\\mathcal{N}(0,1)\\)\n\n\n\n(note the consistent usage of lowercase letters to describe pdfs and capital letters to describe CDFs, even in Greek!)"
  },
  {
    "objectID": "w07/index.html#back-to-working-backwards",
    "href": "w07/index.html#back-to-working-backwards",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Back to Working Backwards",
    "text": "Back to Working Backwards\n\nBy the definition of independence, we can obtain joint pdf \\(f_{G,H}(v_G, v_H)\\) by multiplying the marginal pdf \\(f_G(v_G)\\) and marginal pdf \\(f_H(v_H)\\):\n\n\\[\n\\begin{align*}\nf_{G,H}(v_G, v_H) &= f_G(v_G) \\cdot f_H(v_H) \\\\\n&= \\frac{\\frac{1}{2\\sigma}\\varphi\\left(\\frac{v_H-\\mu}{\\sigma}\\right)}{\\Phi\\left(\\frac{b-\\mu}{\\sigma}\\right) - \\Phi\\left(\\frac{a - \\mu}{\\sigma}\\right)}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w07/index.html#moving-forwards-again",
    "href": "w07/index.html#moving-forwards-again",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Moving Forwards Again",
    "text": "Moving Forwards Again\n\nWe’ve arrived at the case we had in discrete world, where we know the joint distribution!\nWe can integrate wherever we took sums in the discrete case to obtain marginal pdfs:\n\n\\[\n\\begin{align*}\nf_G(v_G) &= \\int_{0}^{1}f_{G,H}(v_G,v_H)dv_H = \\frac{1}{2}, \\\\\nf_H(v_H) &= \\int_{10}^{12}f_{G,H}(v_G, v_H)dv_G = \\frac{\\frac{1}{\\sigma}\\varphi\\left(\\frac{v_H-\\mu}{\\sigma}\\right)}{\\Phi\\left(\\frac{b-\\mu}{\\sigma}\\right) - \\Phi\\left(\\frac{a - \\mu}{\\sigma}\\right)}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w07/index.html#conditional-distributions-in-continuous-world",
    "href": "w07/index.html#conditional-distributions-in-continuous-world",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Conditional Distributions in Continuous World",
    "text": "Conditional Distributions in Continuous World\nAnd we can compute conditional pdfs by renormalizing so that the denominator is no longer the integral of the distribution over all its possible values (hence just the number \\(1\\)) but a ratio of joint distribution to marginal distribution values like the following:\n\\[\nf_{H \\mid G}(v_H | v_G) = \\frac{f_{G,H}(v_G, v_H)}{f_G(v_G)}.\n\\]"
  },
  {
    "objectID": "w07/index.html#you-dont-have-to-stare-helplessly-at-scary-math",
    "href": "w07/index.html#you-dont-have-to-stare-helplessly-at-scary-math",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "You Don’t Have To Stare Helplessly At Scary Math!",
    "text": "You Don’t Have To Stare Helplessly At Scary Math!\n\nTry to link the continuous equations back to their simpler discrete forms\nWork with the discrete forms to develop intuition, then\nConvert sums back into integrals once you’re ready"
  },
  {
    "objectID": "w07/index.html#a-concrete-strategy",
    "href": "w07/index.html#a-concrete-strategy",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "A Concrete Strategy",
    "text": "A Concrete Strategy\n\nStart by discretizing (“binning”) the possible values of a continuous RV to obtain a discrete RV:\n\nSplit \\([10,12]\\) into three equal-length bins, \\([0,1]\\) into two equal-length bins\nSimulate (\\(G\\), \\(H\\)) pairs, sort into bins, visualize the joint/marginal/conditional distributions of binned data\n\nAs you make bins thinner and thinner…"
  },
  {
    "objectID": "w07/index.html#the-multinoulli-distribution",
    "href": "w07/index.html#the-multinoulli-distribution",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "The Multinoulli Distribution",
    "text": "The Multinoulli Distribution\n\nThis may seem like a weird/contrived distribution, but it’s perfect for building intuition, as your first \\(N\\)-dimensional distribution (\\(N &gt; 2\\))\n\\(\\mathbf{X}\\) is a six-dimensional Vector-Valued RV, so that\n\\[\n  \\mathbf{X} = (X_1, X_2, X_3, X_4, X_5, X_6),\n  \\]\nwhere \\(\\mathcal{R}_{X_1} = \\{0, 1\\}, \\mathcal{R}_{X_2} = \\{0, 1\\}, \\ldots, \\mathcal{R}_{X_6} = \\{0, 1\\}\\)\nBut, \\(X_1, X_2, \\ldots, X_6\\) are not independent! In fact, they are so dependent that if one has the value \\(1\\), the rest must have value \\(0\\), so that we can infer the support of \\(\\mathbf{X}\\):\n\\[\n  \\begin{align*}\n  \\mathcal{R}_{\\mathbf{X}} = \\{ &(1,0,0,0,0,0),(0,1,0,0,0,0),(0,0,1,0,0,0), \\\\\n  &(0,0,0,1,0,0),(0,0,0,0,1,0),(0,0,0,0,0,1)\\}\n  \\end{align*}\n  \\]\nLastly, we have to define the probability that \\(\\mathbf{X}\\) takes on any of these values. Let’s say \\(\\Pr(\\mathbf{X} = \\mathbf{v}) = \\frac{1}{6}\\) for all \\(\\mathbf{v} \\in \\mathcal{R}_{\\mathbf{X}}\\). Do we see the structure behind this contrived case?\n(For math major friends, there is an isomorphism afoot… For the rest, it’s an extremely inefficient way to model outcomes from rolling a fair die)"
  },
  {
    "objectID": "w07/index.html#the-multivariate-normal-distribution",
    "href": "w07/index.html#the-multivariate-normal-distribution",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "The Multivariate Normal Distribution",
    "text": "The Multivariate Normal Distribution\n\nWe’ve already seen the matrix notation for writing the parameters of this distribution: \\(\\mathbf{X}_{[k \\times 1]} \\sim \\mathcal{N}_k(\\boldsymbol\\mu_{[k \\times 1]}, \\Sigma_{[k \\times k]})\\)\nNow we get to crack open the matrix notation for writing its pdf:\n\n\\[\nf_\\mathbf{X}(\\mathbf{v}_{[k \\times 1]}) = \\underbrace{\\left(\\frac{1}{\\sqrt{2\\pi}}\\right)^k \\frac{1}{\\sqrt{\\det(\\Sigma)}}}_{\\text{Normalizing constants}} \\exp\\left(-\\frac{1}{2}\\underbrace{(\\mathbf{v} - \\boldsymbol\\mu)^\\top \\Sigma^{-1} (\\mathbf{v} - \\boldsymbol\\mu)}_{\\text{Quadratic form}}\\right)\n\\]\n\nTry to squint your eyes while looking at the above, and compare with the pdf we’ve seen for 1D \\(\\mathcal{N}(\\mu,\\sigma)\\) (W05) and the structure you’ve seen for 2D \\(\\Sigma\\) (W06):\n\n\n\n\n\\[\nf_X(v) = \\frac{1}{\\sigma\\sqrt{2\\pi}}\\bigexp{-\\frac{1}{2}\\left(\\frac{v - \\mu}{\\sigma}\\right)^2}\n\\]\n\n\n\\[\n\\begin{align*}\n\\mathbf{\\Sigma} &= \\begin{bmatrix}\\sigma_1^2 & \\rho\\sigma_1\\sigma_2 \\\\ \\rho\\sigma_2\\sigma_1 & \\sigma_2^2\\end{bmatrix} \\\\[0.1em]\n\\implies \\det(\\Sigma) &= \\sigma_1^2\\sigma_2^2 - \\rho^2\\sigma_1^2\\sigma_2^2 \\\\\n&= \\sigma_1^2\\sigma_2^2(1-\\rho^2)\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w07/index.html#quadratic-forms",
    "href": "w07/index.html#quadratic-forms",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Quadratic Forms",
    "text": "Quadratic Forms\n\nQuadratic forms will seem scary until someone forces you to write out the matrix multiplication!\nStart with the 1D case: \\(\\mathbf{v} = [v_1]\\), \\(\\boldsymbol\\mu = [\\mu_1]\\), \\(\\Sigma = [\\sigma^2]\\). Then\n\n\\[\n(\\mathbf{v} - \\boldsymbol\\mu)^\\top \\Sigma^{-1} (\\mathbf{v - \\boldsymbol\\mu}) = (v_1 - \\mu_1)\\frac{1}{\\sigma^2}(v_1 - \\mu_1) = \\left(\\frac{v_1-\\mu_1}{\\sigma}\\right)^2.\n\\]"
  },
  {
    "objectID": "w07/index.html#the-2d-case",
    "href": "w07/index.html#the-2d-case",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "The 2D Case",
    "text": "The 2D Case\n\nLet \\(\\mathbf{v} = \\left[\\begin{smallmatrix}v_1 \\\\ v_2\\end{smallmatrix}\\right]\\), \\(\\boldsymbol\\mu = \\left[ \\begin{smallmatrix}\\mu_1 \\\\ \\mu_2 \\end{smallmatrix}\\right]\\), \\(\\Sigma\\) as in previous slide. Then \\(\\mathbf{v} - \\boldsymbol\\mu = \\left[ \\begin{smallmatrix} v_1 - \\mu_1 \\\\ v_2 - \\mu_2 \\end{smallmatrix} \\right]\\).\nUsing what we know about \\(2 \\times 2\\) matrix inversion,\n\n\\[\n\\Sigma^{-1} = \\frac{1}{\\det(\\Sigma)}\\left[ \\begin{smallmatrix} \\sigma_2^2 & -\\rho \\sigma_2\\sigma_1 \\\\ -\\rho \\sigma_1\\sigma_2 & \\sigma_1^2\\end{smallmatrix} \\right] = \\frac{1}{\\sigma_1^2\\sigma_2^2(1-\\rho^2)}\\left[ \\begin{smallmatrix} \\sigma_2^2 & -\\rho \\sigma_2\\sigma_1 \\\\ -\\rho \\sigma_1\\sigma_2 & \\sigma_1^2\\end{smallmatrix} \\right]\n\\]\n\nSo we can write everything as just a bunch of matrix multiplications:\n\n\\[\n\\begin{align*}\n&(\\mathbf{v} - \\boldsymbol\\mu)^\\top \\Sigma^{-1} (\\mathbf{v - \\boldsymbol\\mu}) = \\frac{1}{\\sigma_1^2\\sigma_2^2(1-\\rho^2)}\\begin{bmatrix}v_1 - \\mu_1 & v_2 - \\mu_2\\end{bmatrix} \\cdot \\begin{bmatrix} \\sigma_2^2 & -\\rho \\sigma_2\\sigma_1 \\\\ -\\rho \\sigma_1\\sigma_2 & \\sigma_1^2\\end{bmatrix} \\cdot \\begin{bmatrix}v_1 - \\mu_1 \\\\ v_2 - \\mu_2\\end{bmatrix} \\\\\n&= \\frac{1}{\\sigma_1^2\\sigma_2^2(1-\\rho^2)}\\begin{bmatrix}(v_1-\\mu_1)\\sigma_2^2 - (v_2-\\mu_2)\\rho\\sigma_1\\sigma_2 & (v_2-\\mu_2)\\sigma_1^2 - (v_1-\\mu_1)\\rho\\sigma_2\\sigma_1 \\end{bmatrix}\\cdot \\begin{bmatrix}v_1 - \\mu_1 \\\\ v_2 - \\mu_2\\end{bmatrix} \\\\\n&= \\frac{1}{\\sigma_1^2\\sigma_2^2(1-\\rho^2)}\\left( (v_1-\\mu_1)^2\\sigma_2^2 - (v_1-\\mu_1)(v_1-\\mu_2)\\sigma_1\\sigma_2 + (v_2-\\mu_2)^2\\sigma_1^2 - (v_1-\\mu_1)(v_2-\\mu_2)\\sigma_2\\sigma_1 \\right) \\\\\n&= \\boxed{\\frac{1}{1-\\rho^2}\\left( \\left(\\frac{v_1-\\mu_1}{\\sigma_1}\\right)^2 + \\left(\\frac{v_2-\\mu_2}{\\sigma_2}\\right)^2 - 2\\rho\\frac{(v_1-\\mu_1)(v_2-\\mu_2)}{\\sigma_1\\sigma_2} \\right)}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w07/index.html#the-2d-case-in-its-final-form",
    "href": "w07/index.html#the-2d-case-in-its-final-form",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "The 2D Case In Its FINAL FORM",
    "text": "The 2D Case In Its FINAL FORM\n\\[\nf_{\\mathbf{X}}(\\mathbf{v}) = C\\bigexp{-\\frac{1}{2}\\frac{1}{1-\\rho^2}\\left( \\left(\\frac{v_1-\\mu_1}{\\sigma_1}\\right)^2 + \\left(\\frac{v_2-\\mu_2}{\\sigma_2}\\right)^2 - 2\\rho\\frac{(v_1-\\mu_1)(v_2-\\mu_2)}{\\sigma_1\\sigma_2} \\right)}\n\\]\nwhere\n\\[\nC = \\frac{1}{2\\pi\\sigma_1\\sigma_2\\sqrt{1-\\rho^2}}.\n\\]"
  },
  {
    "objectID": "w07/slides.html#frequency-tables",
    "href": "w07/slides.html#frequency-tables",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Frequency Tables",
    "text": "Frequency Tables\n\n\n\n\nWhat does this tell us on its own (before computing proportions in our heads) that is useful for probability?\nAnswer: Not very much!\nBut, if we can find the overall total, then it would tell us a lot (everything we need to know)!\n\n\n\n\nTable 1: A frequency table of HS students (\\(G\\) = grade, \\(H\\) = honors status)This tells us, e.g., there are 5 honors students in grade 10\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\n\n\n\n\n\\(G = 10\\)\n10\n5\n\n\n\\(G = 11\\)\n6\n4\n\n\n\\(G = 12\\)\n7\n1\n\n\n\n\n\n\n\nA frequency table where each row corresponds to a grade in a certain senior high school, each column corresponds to honor-student-status (\\(H=1\\) represents honors, \\(H=0\\) represents non-honors), and each cell contains the number of students in that grade with that honors-status"
  },
  {
    "objectID": "w07/slides.html#why-do-we-need-the-total",
    "href": "w07/slides.html#why-do-we-need-the-total",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Why Do We Need The Total?",
    "text": "Why Do We Need The Total?\n\nQ1: Someone asks the probability that a randomly-selected student will be an honor student in 11th grade.\nQ2: Someone asks what proportion of students are honors\nQ3: Someone asks what % of 12th grade are honors\n\nQ1, for example, is asking us for \\(\\Pr(G = 11, H = 1)\\), a question we can answer if we know the joint distribution \\(f_{G,H}(v_G, v_H)\\)."
  },
  {
    "objectID": "w07/slides.html#back-to-the-naïve-definition",
    "href": "w07/slides.html#back-to-the-naïve-definition",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Back to the Naïve Definition",
    "text": "Back to the Naïve Definition\nUsing our naïve definition of probability, we can compute this probability using the frequencies in the table as\n\\[\n\\Pr(G = 11, H = 1) = \\frac{\\#(G = 11, H = 1)}{\\#\\text{ Students Total}}\n\\]\nPlugging in the values from Table 1, we obtain the answer:\n\\[\n\\Pr(G = 11, H = 1) = \\frac{4}{33} \\approx 0.121\n\\]"
  },
  {
    "objectID": "w07/slides.html#frequency-table-rightarrow-probability-table",
    "href": "w07/slides.html#frequency-table-rightarrow-probability-table",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Frequency Table \\(\\rightarrow\\) Probability Table",
    "text": "Frequency Table \\(\\rightarrow\\) Probability Table\n\nWhen we divide by 33, we are normalizing the counts, producing probabilities (normalized counts)\nBy normalizing all cells in the table, we convert our frequency table into a probability table"
  },
  {
    "objectID": "w07/slides.html#computing-overall-total-by-column",
    "href": "w07/slides.html#computing-overall-total-by-column",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Computing Overall Total by Column",
    "text": "Computing Overall Total by Column\nWe could compute the total by summing columns, then summing over our individual column totals to get 33:\n\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\nTotal\n\n\n\n\n\\(G = 10\\)\n10\n5\n\n\n\n\\(G = 11\\)\n6\n4\n\n\n\n\\(G = 12\\)\n7\n1\n\n\n\nTotal\n23\n10\n33"
  },
  {
    "objectID": "w07/slides.html#computing-overall-total-by-row",
    "href": "w07/slides.html#computing-overall-total-by-row",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Computing Overall Total by Row",
    "text": "Computing Overall Total by Row\nOr, we could compute the total by summing rows, then summing over our individual row totals to get 33:\n\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\nTotal\n\n\n\n\n\n\\(G = 10\\)\n10\n5\n15\n\n\n\n\\(G = 11\\)\n6\n4\n10\n\n\n\n\\(G = 12\\)\n7\n1\n8\n\n\n\nTotal\n\n\n33"
  },
  {
    "objectID": "w07/slides.html#bringing-both-methods-together",
    "href": "w07/slides.html#bringing-both-methods-together",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Bringing Both Methods Together",
    "text": "Bringing Both Methods Together\n\n\nTable 2: The same frequency table as in Table 1, but now with row and column totals representing marginal frequencies\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\nTotal\n\n\n\n\n\n\\(G = 10\\)\n10\n5\n15\n\n\n\n\\(G = 11\\)\n6\n4\n10\n\n\n\n\\(G = 12\\)\n7\n1\n8\n\n\n\nTotal\n23\n10\n33"
  },
  {
    "objectID": "w07/slides.html#frequencies-to-probabilities",
    "href": "w07/slides.html#frequencies-to-probabilities",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Frequencies to Probabilities",
    "text": "Frequencies to Probabilities\n\n\n\n\nNow (before we think about row/column totals) let’s use overall total (33) to convert counts into probabilities:\n\n\n\n\nTable 3: Table from prev slide with all values normalized (divided by the total number of obs)\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\nTotal\n\n\n\n\n\\(G = 10\\)\n\\(\\frac{10}{33}\\)\n\\(\\frac{5}{33}\\)\n\\(\\frac{15}{33}\\)\n\n\n\\(G = 11\\)\n\\(\\frac{6}{33}\\)\n\\(\\frac{4}{33}\\)\n\\(\\frac{10}{33}\\)\n\n\n\\(G = 12\\)\n\\(\\frac{7}{33}\\)\n\\(\\frac{1}{33}\\)\n\\(\\frac{8}{33}\\)\n\n\nTotal\n\\(\\frac{23}{33}\\)\n\\(\\frac{10}{33}\\)\n\\(\\frac{33}{33}\\)"
  },
  {
    "objectID": "w07/slides.html#one-table-three-distributions",
    "href": "w07/slides.html#one-table-three-distributions",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "One Table, Three Distributions!",
    "text": "One Table, Three Distributions!\nNow that we have normalized counts, different pieces of this table give different probability distributions:\n\n\n\n\nJoint Distribution \\(f_{G,H}(v_G, v_H)\\): Look at value in row \\(v_G\\), col \\(v_H\\)\nMarginal Distributions\n\n\\(f_G(v_G)\\): Look at total for row \\(v_G\\)\n\\(f_H(v_H)\\): Look at total for column \\(v_H\\)\n\n\n\n\n\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\nTotal\n\n\n\n\n\\(G = 10\\)\n\\(\\frac{10}{33}\\)\n\\(\\frac{5}{33}\\)\n\\(\\frac{15}{33}\\)\n\n\n\\(G = 11\\)\n\\(\\frac{6}{33}\\)\n\\(\\frac{4}{33}\\)\n\\(\\frac{10}{33}\\)\n\n\n\\(G = 12\\)\n\\(\\frac{7}{33}\\)\n\\(\\frac{1}{33}\\)\n\\(\\frac{8}{33}\\)\n\n\nTotal\n\\(\\frac{23}{33}\\)\n\\(\\frac{10}{33}\\)\n\\(\\frac{33}{33}\\)"
  },
  {
    "objectID": "w07/slides.html#summary-joint-rightarrow-marginal",
    "href": "w07/slides.html#summary-joint-rightarrow-marginal",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Summary: Joint \\(\\rightarrow\\) Marginal",
    "text": "Summary: Joint \\(\\rightarrow\\) Marginal\n\nNote how marginal distributions were obtained by summing the joint distribution over a particular dimension:\nSumming each column (\\(H = 0\\) and \\(H = 1\\)) produced marginal distribution of \\(H\\):\n\n\n\n\n\n\n\n\n\\(\\Pr(H = 0, G = 10)\\)\n\n\n+\n\\(\\Pr(H = 0, G = 11)\\)\n\n\n+\n\\(\\Pr(H = 0, G = 12)\\)\n\n\n=\n\\(\\Pr(H = 0)\\)\n\n\n\n\n\n\n\n\n\n\\(\\Pr(H = 1, G = 10)\\)\n\n\n+\n\\(\\Pr(H = 1, G = 11)\\)\n\n\n+\n\\(\\Pr(H = 1, G = 12)\\)\n\n\n=\n\\(\\Pr(H = 1)\\)\n\n\n\n\n\n\n\nSumming each row (\\(G = 10\\), \\(G = 11\\), \\(G = 12\\)) produced marginal distribution of \\(G\\):\n\n\n\n\n\\(\\Pr(G = 10, H = 0)\\)\n+\n\\(\\Pr(G = 10, H = 1)\\)\n=\n\\(\\Pr(G = 10)\\)\n\n\n\\(\\Pr(G = 11, H = 0)\\)\n+\n\\(\\Pr(G = 11, H = 1)\\)\n=\n\\(\\Pr(G = 11)\\)\n\n\n\\(\\Pr(G = 12, H = 0)\\)\n+\n\\(\\Pr(G = 12, H = 1)\\)\n=\n\\(\\Pr(G = 12)\\)"
  },
  {
    "objectID": "w07/slides.html#whats-missing-conditional-distributions",
    "href": "w07/slides.html#whats-missing-conditional-distributions",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "What’s Missing? Conditional Distributions",
    "text": "What’s Missing? Conditional Distributions\n\nConditional distribution does not represent a sum but a slice: we consider e.g. one particular row or one particular column of the table.\n🚨Warning🚨! unlike in joint and marginal cases, when computing conditional distributions we have to renormalize, since we are “entering world” where we only consider subsets of the table where condition is met!\nRecall slide about how all distributions are conditional distributions:\n\n\n\n\n\\(\\Pr(G = 10, H = 1)\\)\n\n\\[\n\\begin{align*}\n= &\\Pr(G = 10, H = 1 \\mid \\Omega) \\\\[0.6em]\n= &\\frac{\\#(G = 10, H = 1, \\Omega)}{\\#\\text{ Total }(\\Omega)\\text{ ✅}}\n\\end{align*}\n\\]\n\n\n\\(\\Pr(G = 10)\\)\n\n\\[\n\\begin{align*}\n= &\\Pr(G = 10 \\mid \\Omega) \\\\[0.6em]\n= &\\frac{\\#(G = 10, \\Omega)}{\\#\\text{ Total }(\\Omega)\\text{ ✅}}\n\\end{align*}\n\\]\n\n\n\\(\\Pr(G = 10 \\mid H = 1)\\)\n\n\\[\n\\begin{align*}\n= &\\frac{\\Pr(G = 10, H = 1)}{\\Pr(H = 1)} \\\\[0.6em]\n= &\\frac{\\#(G = 10, H = 1)}{\\#(H = 1)\\text{ 😳}}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w07/slides.html#conditional-distributions-from-columns",
    "href": "w07/slides.html#conditional-distributions-from-columns",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Conditional Distributions from Columns",
    "text": "Conditional Distributions from Columns\nLet’s extract just the \\(H = 1\\) column:\n\n\n\n\n\n\n\n\\(H = 1\\)\n\n\n\n\n\\(G = 10\\)\n5\n\n\n\\(G = 11\\)\n4\n\n\n\\(G = 12\\)\n1\n\n\nTotal\n10\n\n\n\n\n\n→\n\n\n\n\n\n\n\\(H = 1\\)\n\n\n\n\n\\(G = 10\\)\n\\(\\frac{5}{10}\\)\n\n\n\\(G = 11\\)\n\\(\\frac{4}{10}\\)\n\n\n\\(G = 12\\)\n\\(\\frac{1}{10}\\)\n\n\nTotal\n\\(\\frac{10}{10}\\)\n\n\n\n\n\n\n\nBefore, 10 was a particular marginal frequency of interest; now 10 is just a total that we use to renormalize"
  },
  {
    "objectID": "w07/slides.html#conditional-distributions-from-rows",
    "href": "w07/slides.html#conditional-distributions-from-rows",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Conditional Distributions from Rows",
    "text": "Conditional Distributions from Rows\nLet’s extract just the \\(G = 10\\) row:\n\n\n\n\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\nTotal\n\n\n\n\n\\(G = 10\\)\n5\n10\n15\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\nTotal\n\n\n\n\n\\(G = 10\\)\n\\(\\frac{5}{15}\\)\n\\(\\frac{10}{15}\\)\n\\(\\frac{15}{15}\\)\n\n\n\n\n\n\n\nBefore, 15 was a particular marginal frequency of interest; now 15 is just a total that we use to renormalize"
  },
  {
    "objectID": "w07/slides.html#discrete-world-summary",
    "href": "w07/slides.html#discrete-world-summary",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Discrete World Summary",
    "text": "Discrete World Summary\nWe now have the link between three types of distributions derived from our table:\n\n\n\n\n\n\n\n\n\n\n\nDistribution Type\nHow Many?\nExample Value\n\n\n\n\nJoint Distribution\n1\n\\(\\Pr(G = 11, H = 1)\\)\\(= \\frac{4}{33}\\)\n\n\nMarginal Distributions\n2\n\\(\\Pr(H = 1) = \\frac{10}{33}\\)\n\n\nConditional Distributions\n6\n\\(\\Pr(G = 10 \\mid H = 1)\\)\\(= \\frac{5}{10}\\)\n\n\n\n\n\n\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\nTotal\n\n\n\n\n\\(G = 10\\)\n\\(\\frac{10}{33}\\)\n\\(\\frac{5}{33}\\)\n\\(\\frac{15}{33}\\)\n\n\n\\(G = 11\\)\n\\(\\frac{6}{33}\\)\n\\(\\frac{4}{33}\\)\n\\(\\frac{10}{33}\\)\n\n\n\\(G = 12\\)\n\\(\\frac{7}{33}\\)\n\\(\\frac{1}{33}\\)\n\\(\\frac{8}{33}\\)\n\n\nTotal\n\\(\\frac{23}{33}\\)\n\\(\\frac{10}{33}\\)\n\\(\\frac{33}{33}\\)\n\n\n\n\n\n\n\n\\(H = 0\\)\n\\(H = 1\\)\n\n\n\n\n\\(G = 10\\)\n\\(\\frac{10}{23}\\)\n\\(\\frac{5}{10}\\)\n\n\n\\(G = 11\\)\n\\(\\frac{6}{23}\\)\n\\(\\frac{4}{10}\\)\n\n\n\\(G = 12\\)\n\\(\\frac{7}{23}\\)\n\\(\\frac{1}{10}\\)\n\n\nTotal\n\\(\\frac{23}{23}\\)\n\\(\\frac{10}{10}\\)"
  },
  {
    "objectID": "w07/slides.html#working-backwards",
    "href": "w07/slides.html#working-backwards",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Working Backwards",
    "text": "Working Backwards\n\nHere we started from the joint distribution and derived marginal and conditional distributions\nSame intuition, plus math, lets us go in opposite direction: given marginal and conditional distributions, we could derive joint distribution, since (defn of conditional prob):\n\n\n\n\n\n\n\n\\(\\Pr(A \\mid B)\\)\n\\(=\\)\n\\(\\Pr(A, B)\\)\n\n\n\\(\\Pr(B)\\)\n\n\n\n\n\n\\[\n\\iff\n\\]\n\n\n\n\n\n\\(\\Pr(A,B)\\)\n\\(=\\)\n\\(\\Pr(A \\mid B)\\)\n\\(\\cdot\\)\n\\(\\Pr(B)\\)\n\n\n\n\n\n\n\nfrom which we can see that if we know the conditional distribution \\(\\Pr(B \\mid A)\\) and the marginal distribution \\(\\Pr(A)\\), we can combine these (via multiplication) to obtain the joint distribution \\(\\Pr(B,A)\\)."
  },
  {
    "objectID": "w07/slides.html#moving-to-continuous-world",
    "href": "w07/slides.html#moving-to-continuous-world",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Moving to Continuous World",
    "text": "Moving to Continuous World\n\nIntuitions from discrete world do translate into good intuitions for continuous world, in this case!\nWe can “move” discrete table into continuous space similar to how Riemann sums “move” discrete sums into integrals:"
  },
  {
    "objectID": "w07/slides.html#smoothing-our-example",
    "href": "w07/slides.html#smoothing-our-example",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "“Smoothing” Our Example",
    "text": "“Smoothing” Our Example\n\nInstead of discrete \\(G\\) with \\(\\mathcal{R}_G = \\{10, 11, 12\\}\\), we have a continuous \\(G\\) with \\(\\mathcal{R}_G = [10,12] \\subset \\mathbb{R}\\) (“progress” through senior HS)\nInstead of discrete \\(H\\) with \\(\\mathcal{R}_H = \\{0, 1\\}\\), now we keep track of continuous “honors spectrum” \\(H\\) with \\(\\mathcal{R}_H = [0, 1] \\subset \\mathbb{R}\\)\nA student near the beginning of 10th grade who is towards the “high end” of the “honors spectrum”: (\\(G = 10.03\\) and \\(H = 0.95\\))"
  },
  {
    "objectID": "w07/slides.html#smoothing-our-tables",
    "href": "w07/slides.html#smoothing-our-tables",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "“Smoothing” Our Tables",
    "text": "“Smoothing” Our Tables\n\nSums become integrals\nRe-normalization (ensuring that probability mass values sum to 1) becomes ensuring that probability density values integrate to 1.\nWhat comes in place of frequency table?\nAnswer in theory: Joint pdf\nAnswer in practice: Depends on the context 😬"
  },
  {
    "objectID": "w07/slides.html#working-backwards-redux",
    "href": "w07/slides.html#working-backwards-redux",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Working Backwards Redux",
    "text": "Working Backwards Redux\n\nWhile in discrete world we could easily provide a table, in continuous world we often/usually have to work backwards; we may just be given:\n\\(G \\sim \\mathcal{U}(10, 12)\\)\n\\(H \\sim \\ddot{\\mathcal{N}}(\\mu = 0.5, \\sigma = 0.1, a = 0, b = 1)\\), and\n\\(G \\perp H\\) (so \\(\\Pr(G \\mid H) = \\Pr(G), \\Pr(H \\mid G) = \\Pr(H)\\))\n(i.e., marginal distributions = conditional distributions)."
  },
  {
    "objectID": "w07/slides.html#the-marginal-pdfs-of-g-and-h",
    "href": "w07/slides.html#the-marginal-pdfs-of-g-and-h",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "The Marginal pdfs of \\(G\\) and \\(H\\)",
    "text": "The Marginal pdfs of \\(G\\) and \\(H\\)\n\nSince we know \\(G \\sim \\mathcal{U}(10,12)\\), we know (or we could look up) that \\(G\\) has pdf\n\n\\[\nf_G(v_G) = \\frac{1}{12 - 10} = \\frac{1}{2}.\n\\]\n\n\\(H\\) has a slightly fancier distribution, the truncated normal distribution, but nonetheless a pdf we can derive from (a) knowing the pdf of the normal distribution and (b) knowing what we’ve just talked about regarding conditional distributions"
  },
  {
    "objectID": "w07/slides.html#the-truncated-normal-distribution",
    "href": "w07/slides.html#the-truncated-normal-distribution",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "The Truncated Normal Distribution",
    "text": "The Truncated Normal Distribution\n\n\\(\\ddot{\\mathcal{N}}\\) may look scary, but \\(X \\sim \\ddot{\\mathcal{N}}(\\mu, \\sigma, a, b)\\) just means that \\(X\\) can be “constructed from scratch” (similar to Problem 1 on the Lab 5 Assignment) as\n\n\\[\nX \\sim \\mathcal{N}(\\mu, \\sigma) \\implies [X \\mid a &lt; X &lt; b] \\sim \\ddot{\\mathcal{N}}(\\mu, \\sigma, a, b)\n\\]\n\n\nCode\nrnormt &lt;- function(n, range, mu, s = 1) {\n  \n  # range is a vector of two values\n  \n  F.a &lt;- pnorm(min(range), mean = mu, sd = s)\n  F.b &lt;- pnorm(max(range), mean = mu, sd = s)\n  \n  u &lt;- runif(n, min = F.a, max = F.b)\n  \n  qnorm(u, mean = mu, sd = s)\n  \n}\nlibrary(data.table)\nlibrary(simstudy)\nlibrary(paletteer)\n\ndefC &lt;- defCondition(condition= \"tt == 1\", \n                     formula = \"rnormt(10000, c(-Inf, Inf), mu = 0, s = 3)\")\ndefC &lt;- defCondition(defC, \"tt == 2\", \n                     formula = \"rnormt(10000, c(0, Inf), mu = 0, s = 3)\")\ndefC &lt;- defCondition(defC, \"tt == 3\", \n                     formula = \"rnormt(10000, c(-3, 3.5), mu = 0, s = 3)\")\n\ndd &lt;- genData(30000)\ndd &lt;- trtAssign(dd, nTrt = 3, grpName = \"tt\")\ndd &lt;- addCondition(defC, dd, \"x\")\n\ndd[, tt := factor(tt, \n     labels = c(\"No truncation\", \"Left truncation at 0\", \"Left and right truncation\"))]\n\nggplot(data = dd, aes(x = x, group = tt)) +\n  geom_histogram(aes(fill = tt), alpha = 1, binwidth = .2, boundary = 0) +\n  facet_grid(~tt) +\n  theme(panel.grid = element_blank(),\n        axis.title = element_blank(),\n        legend.position = \"none\") +\n  dsan_theme()\n\n\n\nAdapted from simstudy package documentation"
  },
  {
    "objectID": "w07/slides.html#the-truncated-normal-pdf",
    "href": "w07/slides.html#the-truncated-normal-pdf",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "The Truncated Normal pdf",
    "text": "The Truncated Normal pdf\n\nSince we see a conditioning bar on the previous slide, we can infer what the pdf of this conditional distribution would look like. If \\(X \\sim \\ddot{\\mathcal{N}}(\\mu, \\sigma, a, b)\\), then \\(X\\) has pdf\n\n\\[\nf_X(v) = \\frac{\\frac{1}{\\sigma}\\varphi\\left(\\frac{v_H-\\mu}{\\sigma}\\right)}{\\Phi\\left(\\frac{b-\\mu}{\\sigma}\\right) - \\Phi\\left(\\frac{a - \\mu}{\\sigma}\\right)} \\approx \\frac{\\Pr(X = v, a &lt; X &lt; b)}{\\Pr(a &lt; X &lt; b)}\n\\]\n\n\\(\\varphi\\) is the pdf of \\(\\mathcal{N}(0,1)\\)\n\\(\\Phi\\) is the CDF of \\(\\mathcal{N}(0,1)\\)\n\n\n\n(note the consistent usage of lowercase letters to describe pdfs and capital letters to describe CDFs, even in Greek!)"
  },
  {
    "objectID": "w07/slides.html#back-to-working-backwards",
    "href": "w07/slides.html#back-to-working-backwards",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Back to Working Backwards",
    "text": "Back to Working Backwards\n\nBy the definition of independence, we can obtain joint pdf \\(f_{G,H}(v_G, v_H)\\) by multiplying the marginal pdf \\(f_G(v_G)\\) and marginal pdf \\(f_H(v_H)\\):\n\n\\[\n\\begin{align*}\nf_{G,H}(v_G, v_H) &= f_G(v_G) \\cdot f_H(v_H) \\\\\n&= \\frac{\\frac{1}{2\\sigma}\\varphi\\left(\\frac{v_H-\\mu}{\\sigma}\\right)}{\\Phi\\left(\\frac{b-\\mu}{\\sigma}\\right) - \\Phi\\left(\\frac{a - \\mu}{\\sigma}\\right)}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w07/slides.html#moving-forwards-again",
    "href": "w07/slides.html#moving-forwards-again",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Moving Forwards Again",
    "text": "Moving Forwards Again\n\nWe’ve arrived at the case we had in discrete world, where we know the joint distribution!\nWe can integrate wherever we took sums in the discrete case to obtain marginal pdfs:\n\n\\[\n\\begin{align*}\nf_G(v_G) &= \\int_{0}^{1}f_{G,H}(v_G,v_H)dv_H = \\frac{1}{2}, \\\\\nf_H(v_H) &= \\int_{10}^{12}f_{G,H}(v_G, v_H)dv_G = \\frac{\\frac{1}{\\sigma}\\varphi\\left(\\frac{v_H-\\mu}{\\sigma}\\right)}{\\Phi\\left(\\frac{b-\\mu}{\\sigma}\\right) - \\Phi\\left(\\frac{a - \\mu}{\\sigma}\\right)}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w07/slides.html#conditional-distributions-in-continuous-world",
    "href": "w07/slides.html#conditional-distributions-in-continuous-world",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Conditional Distributions in Continuous World",
    "text": "Conditional Distributions in Continuous World\nAnd we can compute conditional pdfs by renormalizing so that the denominator is no longer the integral of the distribution over all its possible values (hence just the number \\(1\\)) but a ratio of joint distribution to marginal distribution values like the following:\n\\[\nf_{H \\mid G}(v_H | v_G) = \\frac{f_{G,H}(v_G, v_H)}{f_G(v_G)}.\n\\]"
  },
  {
    "objectID": "w07/slides.html#you-dont-have-to-stare-helplessly-at-scary-math",
    "href": "w07/slides.html#you-dont-have-to-stare-helplessly-at-scary-math",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "You Don’t Have To Stare Helplessly At Scary Math!",
    "text": "You Don’t Have To Stare Helplessly At Scary Math!\n\nTry to link the continuous equations back to their simpler discrete forms\nWork with the discrete forms to develop intuition, then\nConvert sums back into integrals once you’re ready"
  },
  {
    "objectID": "w07/slides.html#a-concrete-strategy",
    "href": "w07/slides.html#a-concrete-strategy",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "A Concrete Strategy",
    "text": "A Concrete Strategy\n\nStart by discretizing (“binning”) the possible values of a continuous RV to obtain a discrete RV:\n\nSplit \\([10,12]\\) into three equal-length bins, \\([0,1]\\) into two equal-length bins\nSimulate (\\(G\\), \\(H\\)) pairs, sort into bins, visualize the joint/marginal/conditional distributions of binned data\n\nAs you make bins thinner and thinner…"
  },
  {
    "objectID": "w07/slides.html#the-multinoulli-distribution",
    "href": "w07/slides.html#the-multinoulli-distribution",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "The Multinoulli Distribution",
    "text": "The Multinoulli Distribution\n\nThis may seem like a weird/contrived distribution, but it’s perfect for building intuition, as your first \\(N\\)-dimensional distribution (\\(N &gt; 2\\))\n\\(\\mathbf{X}\\) is a six-dimensional Vector-Valued RV, so that\n\\[\n  \\mathbf{X} = (X_1, X_2, X_3, X_4, X_5, X_6),\n  \\]\nwhere \\(\\mathcal{R}_{X_1} = \\{0, 1\\}, \\mathcal{R}_{X_2} = \\{0, 1\\}, \\ldots, \\mathcal{R}_{X_6} = \\{0, 1\\}\\)\nBut, \\(X_1, X_2, \\ldots, X_6\\) are not independent! In fact, they are so dependent that if one has the value \\(1\\), the rest must have value \\(0\\), so that we can infer the support of \\(\\mathbf{X}\\):\n\\[\n  \\begin{align*}\n  \\mathcal{R}_{\\mathbf{X}} = \\{ &(1,0,0,0,0,0),(0,1,0,0,0,0),(0,0,1,0,0,0), \\\\\n  &(0,0,0,1,0,0),(0,0,0,0,1,0),(0,0,0,0,0,1)\\}\n  \\end{align*}\n  \\]\nLastly, we have to define the probability that \\(\\mathbf{X}\\) takes on any of these values. Let’s say \\(\\Pr(\\mathbf{X} = \\mathbf{v}) = \\frac{1}{6}\\) for all \\(\\mathbf{v} \\in \\mathcal{R}_{\\mathbf{X}}\\). Do we see the structure behind this contrived case?\n(For math major friends, there is an isomorphism afoot… For the rest, it’s an extremely inefficient way to model outcomes from rolling a fair die)"
  },
  {
    "objectID": "w07/slides.html#the-multivariate-normal-distribution",
    "href": "w07/slides.html#the-multivariate-normal-distribution",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "The Multivariate Normal Distribution",
    "text": "The Multivariate Normal Distribution\n\nWe’ve already seen the matrix notation for writing the parameters of this distribution: \\(\\mathbf{X}_{[k \\times 1]} \\sim \\mathcal{N}_k(\\boldsymbol\\mu_{[k \\times 1]}, \\Sigma_{[k \\times k]})\\)\nNow we get to crack open the matrix notation for writing its pdf:\n\n\\[\nf_\\mathbf{X}(\\mathbf{v}_{[k \\times 1]}) = \\underbrace{\\left(\\frac{1}{\\sqrt{2\\pi}}\\right)^k \\frac{1}{\\sqrt{\\det(\\Sigma)}}}_{\\text{Normalizing constants}} \\exp\\left(-\\frac{1}{2}\\underbrace{(\\mathbf{v} - \\boldsymbol\\mu)^\\top \\Sigma^{-1} (\\mathbf{v} - \\boldsymbol\\mu)}_{\\text{Quadratic form}}\\right)\n\\]\n\nTry to squint your eyes while looking at the above, and compare with the pdf we’ve seen for 1D \\(\\mathcal{N}(\\mu,\\sigma)\\) (W05) and the structure you’ve seen for 2D \\(\\Sigma\\) (W06):\n\n\n\n\n\\[\nf_X(v) = \\frac{1}{\\sigma\\sqrt{2\\pi}}\\bigexp{-\\frac{1}{2}\\left(\\frac{v - \\mu}{\\sigma}\\right)^2}\n\\]\n\n\n\\[\n\\begin{align*}\n\\mathbf{\\Sigma} &= \\begin{bmatrix}\\sigma_1^2 & \\rho\\sigma_1\\sigma_2 \\\\ \\rho\\sigma_2\\sigma_1 & \\sigma_2^2\\end{bmatrix} \\\\[0.1em]\n\\implies \\det(\\Sigma) &= \\sigma_1^2\\sigma_2^2 - \\rho^2\\sigma_1^2\\sigma_2^2 \\\\\n&= \\sigma_1^2\\sigma_2^2(1-\\rho^2)\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w07/slides.html#quadratic-forms",
    "href": "w07/slides.html#quadratic-forms",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "Quadratic Forms",
    "text": "Quadratic Forms\n\nQuadratic forms will seem scary until someone forces you to write out the matrix multiplication!\nStart with the 1D case: \\(\\mathbf{v} = [v_1]\\), \\(\\boldsymbol\\mu = [\\mu_1]\\), \\(\\Sigma = [\\sigma^2]\\). Then\n\n\\[\n(\\mathbf{v} - \\boldsymbol\\mu)^\\top \\Sigma^{-1} (\\mathbf{v - \\boldsymbol\\mu}) = (v_1 - \\mu_1)\\frac{1}{\\sigma^2}(v_1 - \\mu_1) = \\left(\\frac{v_1-\\mu_1}{\\sigma}\\right)^2.\n\\]"
  },
  {
    "objectID": "w07/slides.html#the-2d-case",
    "href": "w07/slides.html#the-2d-case",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "The 2D Case",
    "text": "The 2D Case\n\nLet \\(\\mathbf{v} = \\left[\\begin{smallmatrix}v_1 \\\\ v_2\\end{smallmatrix}\\right]\\), \\(\\boldsymbol\\mu = \\left[ \\begin{smallmatrix}\\mu_1 \\\\ \\mu_2 \\end{smallmatrix}\\right]\\), \\(\\Sigma\\) as in previous slide. Then \\(\\mathbf{v} - \\boldsymbol\\mu = \\left[ \\begin{smallmatrix} v_1 - \\mu_1 \\\\ v_2 - \\mu_2 \\end{smallmatrix} \\right]\\).\nUsing what we know about \\(2 \\times 2\\) matrix inversion,\n\n\\[\n\\Sigma^{-1} = \\frac{1}{\\det(\\Sigma)}\\left[ \\begin{smallmatrix} \\sigma_2^2 & -\\rho \\sigma_2\\sigma_1 \\\\ -\\rho \\sigma_1\\sigma_2 & \\sigma_1^2\\end{smallmatrix} \\right] = \\frac{1}{\\sigma_1^2\\sigma_2^2(1-\\rho^2)}\\left[ \\begin{smallmatrix} \\sigma_2^2 & -\\rho \\sigma_2\\sigma_1 \\\\ -\\rho \\sigma_1\\sigma_2 & \\sigma_1^2\\end{smallmatrix} \\right]\n\\]\n\nSo we can write everything as just a bunch of matrix multiplications:\n\n\\[\n\\begin{align*}\n&(\\mathbf{v} - \\boldsymbol\\mu)^\\top \\Sigma^{-1} (\\mathbf{v - \\boldsymbol\\mu}) = \\frac{1}{\\sigma_1^2\\sigma_2^2(1-\\rho^2)}\\begin{bmatrix}v_1 - \\mu_1 & v_2 - \\mu_2\\end{bmatrix} \\cdot \\begin{bmatrix} \\sigma_2^2 & -\\rho \\sigma_2\\sigma_1 \\\\ -\\rho \\sigma_1\\sigma_2 & \\sigma_1^2\\end{bmatrix} \\cdot \\begin{bmatrix}v_1 - \\mu_1 \\\\ v_2 - \\mu_2\\end{bmatrix} \\\\\n&= \\frac{1}{\\sigma_1^2\\sigma_2^2(1-\\rho^2)}\\begin{bmatrix}(v_1-\\mu_1)\\sigma_2^2 - (v_2-\\mu_2)\\rho\\sigma_1\\sigma_2 & (v_2-\\mu_2)\\sigma_1^2 - (v_1-\\mu_1)\\rho\\sigma_2\\sigma_1 \\end{bmatrix}\\cdot \\begin{bmatrix}v_1 - \\mu_1 \\\\ v_2 - \\mu_2\\end{bmatrix} \\\\\n&= \\frac{1}{\\sigma_1^2\\sigma_2^2(1-\\rho^2)}\\left( (v_1-\\mu_1)^2\\sigma_2^2 - (v_1-\\mu_1)(v_1-\\mu_2)\\sigma_1\\sigma_2 + (v_2-\\mu_2)^2\\sigma_1^2 - (v_1-\\mu_1)(v_2-\\mu_2)\\sigma_2\\sigma_1 \\right) \\\\\n&= \\boxed{\\frac{1}{1-\\rho^2}\\left( \\left(\\frac{v_1-\\mu_1}{\\sigma_1}\\right)^2 + \\left(\\frac{v_2-\\mu_2}{\\sigma_2}\\right)^2 - 2\\rho\\frac{(v_1-\\mu_1)(v_2-\\mu_2)}{\\sigma_1\\sigma_2} \\right)}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w07/slides.html#the-2d-case-in-its-final-form",
    "href": "w07/slides.html#the-2d-case-in-its-final-form",
    "title": "Week 7: Joint, Marginal, and Conditional Distributions",
    "section": "The 2D Case In Its FINAL FORM",
    "text": "The 2D Case In Its FINAL FORM\n\\[\nf_{\\mathbf{X}}(\\mathbf{v}) = C\\bigexp{-\\frac{1}{2}\\frac{1}{1-\\rho^2}\\left( \\left(\\frac{v_1-\\mu_1}{\\sigma_1}\\right)^2 + \\left(\\frac{v_2-\\mu_2}{\\sigma_2}\\right)^2 - 2\\rho\\frac{(v_1-\\mu_1)(v_2-\\mu_2)}{\\sigma_1\\sigma_2} \\right)}\n\\]\nwhere\n\\[\nC = \\frac{1}{2\\pi\\sigma_1\\sigma_2\\sqrt{1-\\rho^2}}.\n\\]\n\n\nDSAN 5100-03 Week 7: Joint, Marginal, Conditional Distributions"
  },
  {
    "objectID": "w08/index.html",
    "href": "w08/index.html",
    "title": "Week 8: Markov Models",
    "section": "",
    "text": "Open slides in new window →"
  },
  {
    "objectID": "w08/index.html#the-course-so-far",
    "href": "w08/index.html#the-course-so-far",
    "title": "Week 8: Markov Models",
    "section": "The Course So Far",
    "text": "The Course So Far\n\nLogic: Reasoning about T/F statements using and and or\n\\(\\rightarrow\\) Set Theory: Reasoning about collections of objects and their union and intersection\n\n\nDeterministic\n\n\n\nProbabilistic\n\n\n\\(\\rightarrow\\) Probability: Assigning “likelihood values” in \\([0,1]\\) to logical/set-theoretic statements about outcomes\n\\(\\rightarrow\\) Random Variables: Doing math (beyond and and or) with the probabilities of these uncertain outcomes\nAll have been reasoning about uncertainty in more and more complex ways!"
  },
  {
    "objectID": "w08/index.html#the-new-dimension-evolution-through-time",
    "href": "w08/index.html#the-new-dimension-evolution-through-time",
    "title": "Week 8: Markov Models",
    "section": "The New Dimension: Evolution Through Time",
    "text": "The New Dimension: Evolution Through Time\n\nMarkov models are a stepping-stone towards full-on time series analysis: reasoning about uncertainty over time\nSo why are time series the topic of an entire course, while Markov models only the topic of one week in DSAN5000?"
  },
  {
    "objectID": "w08/index.html#recall-definition-of-conditional-probability",
    "href": "w08/index.html#recall-definition-of-conditional-probability",
    "title": "Week 8: Markov Models",
    "section": "Recall: Definition of Conditional Probability",
    "text": "Recall: Definition of Conditional Probability\n\\[\n\\Pr(A \\mid B) \\definedas \\frac{\\Pr(A, B)}{\\Pr(B)} \\genfrac{}{}{0pt}{}{\\leftarrow A\\text{ and }B\\text{ happen}}{\\leftarrow \\text{In world where }\\Omega = B}\n\\]"
  },
  {
    "objectID": "w08/index.html#the-markov-property",
    "href": "w08/index.html#the-markov-property",
    "title": "Week 8: Markov Models",
    "section": "The Markov Property",
    "text": "The Markov Property\n\\[\nP(\\text{future} \\mid \\text{present}, {\\color{orange}\\text{past}}) = P(\\text{future} \\mid \\text{present})\n\\]"
  },
  {
    "objectID": "w08/index.html#the-markov-assumption",
    "href": "w08/index.html#the-markov-assumption",
    "title": "Week 8: Markov Models",
    "section": "The Markov Assumption",
    "text": "The Markov Assumption\nOften stated in many different (confusing) ways, but think of anterograde amnesia:"
  },
  {
    "objectID": "w08/index.html#keeping-track-of-states",
    "href": "w08/index.html#keeping-track-of-states",
    "title": "Week 8: Markov Models",
    "section": "Keeping Track of States",
    "text": "Keeping Track of States\n\nSince Markov models come more from engineering than “pure” math/probability, we have “fancier” objects we’re keeping track of, rather than just Random Variables\nWe now keep track of the state of a system over time: this could be a single RV, but could be a collection of multiple (potentially dependent) RVs"
  },
  {
    "objectID": "w08/index.html#what-information-should-we-keep-track-of",
    "href": "w08/index.html#what-information-should-we-keep-track-of",
    "title": "Week 8: Markov Models",
    "section": "What Information Should We Keep Track Of?",
    "text": "What Information Should We Keep Track Of?\n\nSometimes answer seems “obvious”, lulls us into false sense of confidence (that we don’t have to think too hard about it)1\n\n\n\n\nSystem\nState Space\n\n\n\n\nChess\nPosition of each piece, whose turn it is\n\n\nIndoor Robot\nModel of room + objects inside it\n\n\nPredator-Prey Ecosystem\nRelative species populations\n\n\nMove Left/Move Right Game\n?\n\n\nWeather Prediction\n?\n\n\nMusic\n?\n\n\n\n\nTension between too little information (cannot model phenomena of interest) vs. too much information (solving model becomes intractable)"
  },
  {
    "objectID": "w08/index.html#modeling-music-where-is-the-downbeat",
    "href": "w08/index.html#modeling-music-where-is-the-downbeat",
    "title": "Week 8: Markov Models",
    "section": "Modeling Music: Where is the Downbeat?",
    "text": "Modeling Music: Where is the Downbeat?"
  },
  {
    "objectID": "w08/index.html#state-space-choice-rightarrow-information-loss",
    "href": "w08/index.html#state-space-choice-rightarrow-information-loss",
    "title": "Week 8: Markov Models",
    "section": "State Space Choice \\(\\rightarrow\\) Information Loss",
    "text": "State Space Choice \\(\\rightarrow\\) Information Loss\n\nRecall the Move Left/Move Right Game (especially from Lab 4 Prep)\n\n\n\n\n\n\n\n\n\n\nPossible State Spaces:\n\n\n\n\nHistory vector\nPosition\nSteps\n#L\n#R\n\n\n\n\n\\(()\\)\n\\(x = 0\\)\n0\n0\n0\n\n\n\\((L,R)\\)\n\\(x = 0\\)\n2\n1\n1\n\n\n\\((R,L)\\)\n\\(x = 0\\)\n2\n1\n1\n\n\n\\((R,L,R,\\)\\(~L,R,L)\\)\n\\(x = 0\\)\n6\n3\n3\n\n\n\\((L)\\)\n\\(x = -1\\)\n1\n1\n0\n\n\n\\((L,L,R)\\)\n\\(x = -1\\)\n3\n2\n1"
  },
  {
    "objectID": "w08/index.html#finite-state-automata",
    "href": "w08/index.html#finite-state-automata",
    "title": "Week 8: Markov Models",
    "section": "Finite-State Automata",
    "text": "Finite-State Automata\n(Deterministic!) Only “accepts” strings with even number of 1s:\n\n\n\n\n\n\n\n\n\n\n\nInput String\nResult\nInput String\nResult\n\n\n\n\n\\(\\varepsilon\\)\n✅\n01\n\n\n\n0\n✅\n10\n\n\n\n1\n\n1000000\n\n\n\n00\n✅\n10000001\n✅\n\n\n\n\n\n\n\n…But we’re trying to model probabilistic evolution!"
  },
  {
    "objectID": "w08/index.html#enter-markov-chains",
    "href": "w08/index.html#enter-markov-chains",
    "title": "Week 8: Markov Models",
    "section": "Enter Markov Chains",
    "text": "Enter Markov Chains\n\n\n\nGraphically\n\n\n\n\n\n\n\n\n\n\n\n\n\nMathematically\n\n\\[\n\\begin{array}{c c}\n& \\begin{array}{c c c} 1 & 2 & 3 \\\\ \\end{array} \\\\\n\\begin{array}{c c c}1 \\\\ 2 \\\\ 3 \\end{array} &\n\\left[\n\\begin{array}{c c c}\n0 & 1/2 & 1/2 \\\\\n1/3 & 0 & 2/3 \\\\\n1/3 & 2/3 & 0\n\\end{array}\n\\right]\n\\end{array}\n\\]\n\\[\n\\begin{array}{c c}\n& \\begin{array}{c c c} 1 & 2 & 3 \\\\ \\end{array} \\\\\n\\begin{array}{c c c}1 \\\\ 2 \\\\ 3 \\end{array} &\n\\left[\n\\begin{array}{c c c}\n1/2 & 1/3 & 1/6 \\\\\n1/10 & 1/2 & 2/5 \\\\\n1/8 & 3/8 & 1/2\n\\end{array}\n\\right]\n\\end{array}\n\\]"
  },
  {
    "objectID": "w08/index.html#hidden-markov-models",
    "href": "w08/index.html#hidden-markov-models",
    "title": "Week 8: Markov Models",
    "section": "Hidden Markov Models",
    "text": "Hidden Markov Models\n\nUse observed data to infer unobserved variables\n\n\n\n\n\n\n\n(What our brains are doing, most of the time!)"
  },
  {
    "objectID": "w08/index.html#pagerank-matrix-magic",
    "href": "w08/index.html#pagerank-matrix-magic",
    "title": "Week 8: Markov Models",
    "section": "PageRank (Matrix Magic)",
    "text": "PageRank (Matrix Magic)\n\nWhat is the relevance of this abstract topic? …🤑\n\n\nlibrary(readr)\nlibrary(ggplot2)\ngoog_df &lt;- read_csv(\"assets/google_yearly_revenue.csv\")\n\nRows: 21 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (2): year, revenue_billions\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nggplot(goog_df, aes(x=year, y=revenue_billions)) +\n  geom_bar(stat=\"identity\", fill=cbPalette[1]) +\n  labs(\n    title = \"Google Yearly Revenue, 2002-2022\",\n    x = \"Year\",\n    y = \"Revenue (Billion USD)\"\n  ) +\n  dsan_theme(\"full\")\n\n\n\n\n\n\n\n\n\nPageRank = The “spark” that ignited the Google flame"
  },
  {
    "objectID": "w08/index.html#pagerank-visualized",
    "href": "w08/index.html#pagerank-visualized",
    "title": "Week 8: Markov Models",
    "section": "PageRank Visualized",
    "text": "PageRank Visualized\n\nNodes = Webpages, Edges = Links\n\n\n\n\n\n\n\nGoal: Rank the relative “importance” of a site \\(S_i\\), taking into account the importance of other sites that link to \\(S_i\\)\n\n“Important” sites are linked to often, and linked to often by other important sites"
  },
  {
    "objectID": "w08/index.html#chickens-and-eggs",
    "href": "w08/index.html#chickens-and-eggs",
    "title": "Week 8: Markov Models",
    "section": "Chickens and Eggs",
    "text": "Chickens and Eggs\n\nParadoxical at first: how are we supposed to figure out the importance of a site \\(S_i\\), when that’s determined by\n\nthe importance of sites \\(S_j\\) that link to \\(S_i\\), which is determined by\n\nthe importance of sites \\(S_k\\) that link to sites \\(S_j\\), which is determined by\n\nthe importance of the sites \\(S_\\ell\\) that link to those sites \\(S_k\\), which is determined by…\n\n\n\n\n\\[\n\\begin{align*}\n\\mathsf{Importance}(S_i) &= f(\\mathsf{Importance}(S_{j \\rightarrow i})) = f(f(\\mathsf{Importance}(S_{k \\rightarrow j \\rightarrow i}))) \\\\\n&= f(f(f(\\mathsf{Importance}(S_{\\ell \\rightarrow k \\rightarrow j \\rightarrow i})))) = \\cdots\n\\end{align*}\n\\]\n\n\nSanity hint: Remember infinite sums from calculus! They can converge, despite having infinitely-many terms… This is something like that, but for recursion (the mathematical term for an object whose definition refers to itself)"
  },
  {
    "objectID": "w08/index.html#resolving-recursive-definitions",
    "href": "w08/index.html#resolving-recursive-definitions",
    "title": "Week 8: Markov Models",
    "section": "Resolving Recursive Definitions",
    "text": "Resolving Recursive Definitions\n\nWe can compute this importance ranking, despite its recursive definition!\nRecall, for example, the Fibonacci sequence: \\(1, 1, 2, 3, 5, 8, 13, 21, \\ldots\\)\nDefined recursively!\n\n\\[\nf(n) = \\begin{cases}\n1 & n = 1\\text{ or }n = 2 \\\\\nf(n-2) + f(n-1) & n &gt; 2\n\\end{cases}\n\\]\n\nAnd yet, a guy named Bernoulli figured out\n\n\\[\nf(n) = \\frac{\\varphi^n - \\psi^n}{\\varphi - \\psi} = \\frac{\\varphi^n - \\psi^n}{\\sqrt{5}},\n\\]\nwhere \\(\\varphi\\) is the “Golden Ratio” \\(\\frac{1 + \\sqrt{5}}{2}\\) and \\(\\psi\\) its conjugate \\(\\frac{1 - \\sqrt{5}}{2}\\)."
  },
  {
    "objectID": "w08/index.html#the-pagerank-process",
    "href": "w08/index.html#the-pagerank-process",
    "title": "Week 8: Markov Models",
    "section": "The PageRank Process",
    "text": "The PageRank Process\n\nEvery site starts with equal PageRank score: \\(r^{(0)}_1 = r^{(0)}_2 = r^{(0)}_3 = \\frac{1}{3}\\).\nEach link \\(S_i \\rightarrow S_j\\) is a vote of confidence that \\(S_i\\) is giving to \\(S_j\\)\nAt each time \\(t\\), a site \\(S_i\\) “spends” whatever voting power it currently has (\\(r^{(t)}_i\\)) on the sites it links to.\n\n\\(S_1\\) casts one vote for itself and one vote for \\(S_2\\), thus spending \\(\\frac{1}{2}\\) of its total PageRank on itself and \\(\\frac{1}{2}\\) of its total PageRank on \\(S_2\\).\n\nState of the process at time \\(t\\): \\(\\mathbf{r}^{(t)} = \\begin{bmatrix}r^{(t)}_1 & r^{(t)}_2 & r^{(t)}_3\\end{bmatrix}^\\top\\)\nCan form a matrix specifying exactly how this state evolves from time \\(t\\) to time \\(t+1\\)!\n\n\\[\n\\mathbf{E} = \\begin{bmatrix}\n\\frac{1}{2} & \\frac{1}{2} & 0 \\\\\n\\frac{1}{2} & 0 & 1 \\\\\n0 & \\frac{1}{2} & 0\n\\end{bmatrix} \\; \\leadsto \\; \\mathbf{r}^{(t+1)} = \\mathbf{E}\\mathbf{r}^{(t)}\n\\]\n\n\nGiven the “\\(S_1\\) casts one vote for itself…” part, can you say exactly what \\(S_1\\) will “spend” on itself and on \\(S_2\\) at time \\(t = 0\\) (in the first round)?"
  },
  {
    "objectID": "w08/index.html#section",
    "href": "w08/index.html#section",
    "title": "Week 8: Markov Models",
    "section": "",
    "text": "We can use \\(\\mathbf{E}\\) to figure out the state at each step, starting from \\(t = 0\\)!\n\n\\[\n\\begin{array}{c@{}c@{}c@{}c@{}c@{}c@{}c}\n\\mathbf{r}^{(1)} & = & \\mathbf{E}\\mathbf{r}^{(0)} & = & \\begin{bmatrix}\n\\frac{1}{2} & \\frac{1}{2} & 0 \\\\\n\\frac{1}{2} & 0 & 1 \\\\\n0 & \\frac{1}{2} & 0\n\\end{bmatrix}\\begin{bmatrix}\n\\frac{1}{3} \\\\\n\\frac{1}{3} \\\\\n\\frac{1}{3}\\end{bmatrix} & = & \\begin{bmatrix}\n\\frac{1}{3} \\\\\n\\frac{1}{2} \\\\\n\\frac{1}{6}\n\\end{bmatrix} \\\\\n~ & ~ & ~ & ~ & ~ & \\swarrow & ~ \\\\\n\\mathbf{r}^{(2)} & = & \\mathbf{E}\\mathbf{r}^{(1)} & = & \\begin{bmatrix}\n\\frac{1}{2} & \\frac{1}{2} & 0 \\\\\n\\frac{1}{2} & 0 & 1 \\\\\n0 & \\frac{1}{2} & 0\n\\end{bmatrix}\\begin{bmatrix}\\frac{1}{3} \\\\ \\frac{1}{2} \\\\ \\frac{1}{6}\\end{bmatrix} & = & \\begin{bmatrix}\\frac{5}{12} \\\\ \\frac{1}{3} \\\\ \\frac{1}{4}\\end{bmatrix} \\\\\n~ & ~ & ~ & ~ & ~ & \\swarrow & ~ \\\\\n\\mathbf{r}^{(3)} & = & \\mathbf{E}\\mathbf{r}^{(2)} & = & \\cdots & ~ & ~\n\\end{array}\n\\]"
  },
  {
    "objectID": "w08/index.html#matrix-magic",
    "href": "w08/index.html#matrix-magic",
    "title": "Week 8: Markov Models",
    "section": "Matrix Magic",
    "text": "Matrix Magic\n\n\nWon’t we just have to run this forever? (2) How do we know it’ll converge to something?\n\nAnswers: (1) no, (2) because Markov matrix magic\n“Steady state” = state where \\(\\mathbf{r}^{(t)} = \\mathbf{r}^{(t+1)} = \\mathbf{r}^{(t+2)} = \\cdots \\definedas \\mathbf{r}^*\\). But this means\n\n\\[\n\\mathbf{r}^{(t+1)} = \\mathbf{r}^{(t)} \\iff \\mathbf{E}\\mathbf{r}^{(t)} = \\mathbf{r}^{(t)} \\iff \\mathbf{E}\\mathbf{r}^* = \\mathbf{r}^*\n\\]\n\nThis \\(\\mathbf{r}^*\\) is—by definition!—an Eigenvector of \\(\\mathbf{E}\\), corresponding to Eigenvalue \\(\\lambda = 1\\)!2\n\n\n\nIn my opinion, along with e.g. insolubility of the quintic, this is maybe the most mind-blowing case of math magic :3"
  },
  {
    "objectID": "w08/index.html#solving-the-matrix-magic",
    "href": "w08/index.html#solving-the-matrix-magic",
    "title": "Week 8: Markov Models",
    "section": "Solving the Matrix Magic",
    "text": "Solving the Matrix Magic\n\nSince we already know the Eigenvalue of interest, \\(\\lambda = 1\\), all that’s left is solving for its corresponding Eigenvector:\n\n\\[\n\\mathbf{E}\\mathbf{r}^* = \\mathbf{r}^* \\iff \\mathbf{E}\\mathbf{r}^* - \\mathbf{r}^* = \\mathbf{0} \\iff (\\mathbf{E} - \\mathbf{I})\\mathbf{r}^* = \\mathbf{0}\n\\]\n\nWritten out, we see that this gives us a system of linear equations:\n\n\\[\n\\begin{bmatrix}\n\\frac{1}{2} & \\frac{1}{2} & 0 \\\\\n\\frac{1}{2} & 0 & 1 \\\\\n0 & \\frac{1}{2} & 0\n\\end{bmatrix}\\begin{bmatrix}r^*_1 \\\\ r^*_2 \\\\ r^*_3\\end{bmatrix} = \\begin{bmatrix}0 \\\\ 0 \\\\ 0\\end{bmatrix} \\iff \\begin{array}{ccccccc}\\frac{1}{2}r^*_1 & + & \\frac{1}{2}r^*_2 & ~ & ~ & = & 0 \\\\ \\frac{1}{2}r^*_1 & ~ & ~ & + & r^*_3 & = & 0 \\\\ ~ & ~ & \\frac{1}{2}r^*_2 & ~ & ~ & = & 0\\end{array}\n\\]\nwhich we can solve however we want!\n\nTo handle the fact that this system is underspecified, we impose the additional restriction that \\(r^*_1 + r^*_2 + r^*_3 = 1\\), so that the ranks form a probability distribution…"
  },
  {
    "objectID": "w08/index.html#the-point-of-all-this",
    "href": "w08/index.html#the-point-of-all-this",
    "title": "Week 8: Markov Models",
    "section": "The Point of All This",
    "text": "The Point of All This\n\nThe final restriction \\(r^*_1 + r^*_2 + r^*_3 = 1\\) ensures that the resulting PageRank values form a probability distribution\nThis is called the Stationary Distribution of the Markov chain: represents the probability that a random walker through the chain will be at page \\(S_i\\) at a given time!\n\nEquivalently: expected proportion of total walking time a random-walker will spend at each node\n\nEvery Markov chain has a Stationary Distribution! This fact has cool implications even above and beyond the Google $$$ implications 😜"
  },
  {
    "objectID": "w08/index.html#footnotes",
    "href": "w08/index.html#footnotes",
    "title": "Week 8: Markov Models",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nTo snap out of this lull, keep in mind that engineering/nonlinear dynamical systems programs have entire courses just on state space representations↩︎\nThis is because an Eigenvalue-Eigenvector pair for a matrix \\(\\mathbf{M}\\) is a vector \\(\\mathbf{v}\\) and scalar value \\(\\lambda\\) which satisfy \\(\\mathbf{M}\\mathbf{v} = \\lambda \\mathbf{v}\\). In words: the result of (left) matrix-multiplying \\(\\mathbf{v}\\) by \\(\\mathbf{M}\\) is the same as scalar-multiplying \\(\\mathbf{v}\\) by a factor of \\(\\lambda\\). In our case the Eigenvector is \\(\\mathbf{r}^*\\) and the Eigenvalue is \\(\\lambda = 1\\), since \\(\\mathbf{E}\\mathbf{r}^* = 1 \\cdot \\mathbf{r}^*\\).For the math-curious, there are lots of fun results from matrix theory which assure us that \\(\\mathbf{E}\\) is guaranteed to have principal eigenvalue \\(\\lambda = 1\\) 💆↩︎"
  },
  {
    "objectID": "w08/slides.html#the-course-so-far",
    "href": "w08/slides.html#the-course-so-far",
    "title": "Week 8: Markov Models",
    "section": "The Course So Far",
    "text": "The Course So Far\n\nLogic: Reasoning about T/F statements using and and or\n\\(\\rightarrow\\) Set Theory: Reasoning about collections of objects and their union and intersection\n\n\nDeterministic\n\n\n\nProbabilistic\n\n\n\\(\\rightarrow\\) Probability: Assigning “likelihood values” in \\([0,1]\\) to logical/set-theoretic statements about outcomes\n\\(\\rightarrow\\) Random Variables: Doing math (beyond and and or) with the probabilities of these uncertain outcomes\nAll have been reasoning about uncertainty in more and more complex ways!"
  },
  {
    "objectID": "w08/slides.html#the-new-dimension-evolution-through-time",
    "href": "w08/slides.html#the-new-dimension-evolution-through-time",
    "title": "Week 8: Markov Models",
    "section": "The New Dimension: Evolution Through Time",
    "text": "The New Dimension: Evolution Through Time\n\nMarkov models are a stepping-stone towards full-on time series analysis: reasoning about uncertainty over time\nSo why are time series the topic of an entire course, while Markov models only the topic of one week in DSAN5000?"
  },
  {
    "objectID": "w08/slides.html#recall-definition-of-conditional-probability",
    "href": "w08/slides.html#recall-definition-of-conditional-probability",
    "title": "Week 8: Markov Models",
    "section": "Recall: Definition of Conditional Probability",
    "text": "Recall: Definition of Conditional Probability\n\\[\n\\Pr(A \\mid B) \\definedas \\frac{\\Pr(A, B)}{\\Pr(B)} \\genfrac{}{}{0pt}{}{\\leftarrow A\\text{ and }B\\text{ happen}}{\\leftarrow \\text{In world where }\\Omega = B}\n\\]"
  },
  {
    "objectID": "w08/slides.html#the-markov-property",
    "href": "w08/slides.html#the-markov-property",
    "title": "Week 8: Markov Models",
    "section": "The Markov Property",
    "text": "The Markov Property\n\\[\nP(\\text{future} \\mid \\text{present}, {\\color{orange}\\text{past}}) = P(\\text{future} \\mid \\text{present})\n\\]"
  },
  {
    "objectID": "w08/slides.html#the-markov-assumption",
    "href": "w08/slides.html#the-markov-assumption",
    "title": "Week 8: Markov Models",
    "section": "The Markov Assumption",
    "text": "The Markov Assumption\nOften stated in many different (confusing) ways, but think of anterograde amnesia:"
  },
  {
    "objectID": "w08/slides.html#keeping-track-of-states",
    "href": "w08/slides.html#keeping-track-of-states",
    "title": "Week 8: Markov Models",
    "section": "Keeping Track of States",
    "text": "Keeping Track of States\n\nSince Markov models come more from engineering than “pure” math/probability, we have “fancier” objects we’re keeping track of, rather than just Random Variables\nWe now keep track of the state of a system over time: this could be a single RV, but could be a collection of multiple (potentially dependent) RVs"
  },
  {
    "objectID": "w08/slides.html#what-information-should-we-keep-track-of",
    "href": "w08/slides.html#what-information-should-we-keep-track-of",
    "title": "Week 8: Markov Models",
    "section": "What Information Should We Keep Track Of?",
    "text": "What Information Should We Keep Track Of?\n\nSometimes answer seems “obvious”, lulls us into false sense of confidence (that we don’t have to think too hard about it)1\n\n\n\n\nSystem\nState Space\n\n\n\n\nChess\nPosition of each piece, whose turn it is\n\n\nIndoor Robot\nModel of room + objects inside it\n\n\nPredator-Prey Ecosystem\nRelative species populations\n\n\nMove Left/Move Right Game\n?\n\n\nWeather Prediction\n?\n\n\nMusic\n?\n\n\n\n\nTension between too little information (cannot model phenomena of interest) vs. too much information (solving model becomes intractable)\n\nTo snap out of this lull, keep in mind that engineering/nonlinear dynamical systems programs have entire courses just on state space representations"
  },
  {
    "objectID": "w08/slides.html#modeling-music-where-is-the-downbeat",
    "href": "w08/slides.html#modeling-music-where-is-the-downbeat",
    "title": "Week 8: Markov Models",
    "section": "Modeling Music: Where is the Downbeat?",
    "text": "Modeling Music: Where is the Downbeat?"
  },
  {
    "objectID": "w08/slides.html#state-space-choice-rightarrow-information-loss",
    "href": "w08/slides.html#state-space-choice-rightarrow-information-loss",
    "title": "Week 8: Markov Models",
    "section": "State Space Choice \\(\\rightarrow\\) Information Loss",
    "text": "State Space Choice \\(\\rightarrow\\) Information Loss\n\nRecall the Move Left/Move Right Game (especially from Lab 4 Prep)\n\n\n\n\n\n\n\n\n\n\nPossible State Spaces:\n\n\n\n\nHistory vector\nPosition\nSteps\n#L\n#R\n\n\n\n\n\\(()\\)\n\\(x = 0\\)\n0\n0\n0\n\n\n\\((L,R)\\)\n\\(x = 0\\)\n2\n1\n1\n\n\n\\((R,L)\\)\n\\(x = 0\\)\n2\n1\n1\n\n\n\\((R,L,R,\\)\\(~L,R,L)\\)\n\\(x = 0\\)\n6\n3\n3\n\n\n\\((L)\\)\n\\(x = -1\\)\n1\n1\n0\n\n\n\\((L,L,R)\\)\n\\(x = -1\\)\n3\n2\n1"
  },
  {
    "objectID": "w08/slides.html#finite-state-automata",
    "href": "w08/slides.html#finite-state-automata",
    "title": "Week 8: Markov Models",
    "section": "Finite-State Automata",
    "text": "Finite-State Automata\n(Deterministic!) Only “accepts” strings with even number of 1s:\n\n\n\n\n\n\n\n\n\n\n\nInput String\nResult\nInput String\nResult\n\n\n\n\n\\(\\varepsilon\\)\n✅\n01\n\n\n\n0\n✅\n10\n\n\n\n1\n\n1000000\n\n\n\n00\n✅\n10000001\n✅\n\n\n\n\n\n\n\n…But we’re trying to model probabilistic evolution!"
  },
  {
    "objectID": "w08/slides.html#enter-markov-chains",
    "href": "w08/slides.html#enter-markov-chains",
    "title": "Week 8: Markov Models",
    "section": "Enter Markov Chains",
    "text": "Enter Markov Chains\n\n\n\nGraphically\n\n\n\n\n\n\n\n\n\n\n\n\n\nMathematically\n\n\\[\n\\begin{array}{c c}\n& \\begin{array}{c c c} 1 & 2 & 3 \\\\ \\end{array} \\\\\n\\begin{array}{c c c}1 \\\\ 2 \\\\ 3 \\end{array} &\n\\left[\n\\begin{array}{c c c}\n0 & 1/2 & 1/2 \\\\\n1/3 & 0 & 2/3 \\\\\n1/3 & 2/3 & 0\n\\end{array}\n\\right]\n\\end{array}\n\\]\n\\[\n\\begin{array}{c c}\n& \\begin{array}{c c c} 1 & 2 & 3 \\\\ \\end{array} \\\\\n\\begin{array}{c c c}1 \\\\ 2 \\\\ 3 \\end{array} &\n\\left[\n\\begin{array}{c c c}\n1/2 & 1/3 & 1/6 \\\\\n1/10 & 1/2 & 2/5 \\\\\n1/8 & 3/8 & 1/2\n\\end{array}\n\\right]\n\\end{array}\n\\]"
  },
  {
    "objectID": "w08/slides.html#hidden-markov-models",
    "href": "w08/slides.html#hidden-markov-models",
    "title": "Week 8: Markov Models",
    "section": "Hidden Markov Models",
    "text": "Hidden Markov Models\n\nUse observed data to infer unobserved variables\n\n\n\n(What our brains are doing, most of the time!)"
  },
  {
    "objectID": "w08/slides.html#pagerank-matrix-magic",
    "href": "w08/slides.html#pagerank-matrix-magic",
    "title": "Week 8: Markov Models",
    "section": "PageRank (Matrix Magic)",
    "text": "PageRank (Matrix Magic)\n\nWhat is the relevance of this abstract topic? …🤑\n\n\n\nCode\nlibrary(readr)\nlibrary(ggplot2)\ngoog_df &lt;- read_csv(\"assets/google_yearly_revenue.csv\")\nggplot(goog_df, aes(x=year, y=revenue_billions)) +\n  geom_bar(stat=\"identity\", fill=cbPalette[1]) +\n  labs(\n    title = \"Google Yearly Revenue, 2002-2022\",\n    x = \"Year\",\n    y = \"Revenue (Billion USD)\"\n  ) +\n  dsan_theme(\"full\")\n\n\n\n\nPageRank = The “spark” that ignited the Google flame"
  },
  {
    "objectID": "w08/slides.html#pagerank-visualized",
    "href": "w08/slides.html#pagerank-visualized",
    "title": "Week 8: Markov Models",
    "section": "PageRank Visualized",
    "text": "PageRank Visualized\n\nNodes = Webpages, Edges = Links\n\n\n\nGoal: Rank the relative “importance” of a site \\(S_i\\), taking into account the importance of other sites that link to \\(S_i\\)\n\n“Important” sites are linked to often, and linked to often by other important sites"
  },
  {
    "objectID": "w08/slides.html#chickens-and-eggs",
    "href": "w08/slides.html#chickens-and-eggs",
    "title": "Week 8: Markov Models",
    "section": "Chickens and Eggs",
    "text": "Chickens and Eggs\n\nParadoxical at first: how are we supposed to figure out the importance of a site \\(S_i\\), when that’s determined by\n\nthe importance of sites \\(S_j\\) that link to \\(S_i\\), which is determined by\n\nthe importance of sites \\(S_k\\) that link to sites \\(S_j\\), which is determined by\n\nthe importance of the sites \\(S_\\ell\\) that link to those sites \\(S_k\\), which is determined by…\n\n\n\n\n\\[\n\\begin{align*}\n\\mathsf{Importance}(S_i) &= f(\\mathsf{Importance}(S_{j \\rightarrow i})) = f(f(\\mathsf{Importance}(S_{k \\rightarrow j \\rightarrow i}))) \\\\\n&= f(f(f(\\mathsf{Importance}(S_{\\ell \\rightarrow k \\rightarrow j \\rightarrow i})))) = \\cdots\n\\end{align*}\n\\]\n\n\nSanity hint: Remember infinite sums from calculus! They can converge, despite having infinitely-many terms… This is something like that, but for recursion (the mathematical term for an object whose definition refers to itself)"
  },
  {
    "objectID": "w08/slides.html#resolving-recursive-definitions",
    "href": "w08/slides.html#resolving-recursive-definitions",
    "title": "Week 8: Markov Models",
    "section": "Resolving Recursive Definitions",
    "text": "Resolving Recursive Definitions\n\nWe can compute this importance ranking, despite its recursive definition!\nRecall, for example, the Fibonacci sequence: \\(1, 1, 2, 3, 5, 8, 13, 21, \\ldots\\)\nDefined recursively!\n\n\\[\nf(n) = \\begin{cases}\n1 & n = 1\\text{ or }n = 2 \\\\\nf(n-2) + f(n-1) & n &gt; 2\n\\end{cases}\n\\]\n\nAnd yet, a guy named Bernoulli figured out\n\n\\[\nf(n) = \\frac{\\varphi^n - \\psi^n}{\\varphi - \\psi} = \\frac{\\varphi^n - \\psi^n}{\\sqrt{5}},\n\\]\nwhere \\(\\varphi\\) is the “Golden Ratio” \\(\\frac{1 + \\sqrt{5}}{2}\\) and \\(\\psi\\) its conjugate \\(\\frac{1 - \\sqrt{5}}{2}\\)."
  },
  {
    "objectID": "w08/slides.html#the-pagerank-process",
    "href": "w08/slides.html#the-pagerank-process",
    "title": "Week 8: Markov Models",
    "section": "The PageRank Process",
    "text": "The PageRank Process\n\nEvery site starts with equal PageRank score: \\(r^{(0)}_1 = r^{(0)}_2 = r^{(0)}_3 = \\frac{1}{3}\\).\nEach link \\(S_i \\rightarrow S_j\\) is a vote of confidence that \\(S_i\\) is giving to \\(S_j\\)\nAt each time \\(t\\), a site \\(S_i\\) “spends” whatever voting power it currently has (\\(r^{(t)}_i\\)) on the sites it links to.\n\n\\(S_1\\) casts one vote for itself and one vote for \\(S_2\\), thus spending \\(\\frac{1}{2}\\) of its total PageRank on itself and \\(\\frac{1}{2}\\) of its total PageRank on \\(S_2\\).\n\nState of the process at time \\(t\\): \\(\\mathbf{r}^{(t)} = \\begin{bmatrix}r^{(t)}_1 & r^{(t)}_2 & r^{(t)}_3\\end{bmatrix}^\\top\\)\nCan form a matrix specifying exactly how this state evolves from time \\(t\\) to time \\(t+1\\)!\n\n\\[\n\\mathbf{E} = \\begin{bmatrix}\n\\frac{1}{2} & \\frac{1}{2} & 0 \\\\\n\\frac{1}{2} & 0 & 1 \\\\\n0 & \\frac{1}{2} & 0\n\\end{bmatrix} \\; \\leadsto \\; \\mathbf{r}^{(t+1)} = \\mathbf{E}\\mathbf{r}^{(t)}\n\\]\n\n\nGiven the “\\(S_1\\) casts one vote for itself…” part, can you say exactly what \\(S_1\\) will “spend” on itself and on \\(S_2\\) at time \\(t = 0\\) (in the first round)?"
  },
  {
    "objectID": "w08/slides.html#section",
    "href": "w08/slides.html#section",
    "title": "Week 8: Markov Models",
    "section": "",
    "text": "We can use \\(\\mathbf{E}\\) to figure out the state at each step, starting from \\(t = 0\\)!\n\n\\[\n\\begin{array}{c@{}c@{}c@{}c@{}c@{}c@{}c}\n\\mathbf{r}^{(1)} & = & \\mathbf{E}\\mathbf{r}^{(0)} & = & \\begin{bmatrix}\n\\frac{1}{2} & \\frac{1}{2} & 0 \\\\\n\\frac{1}{2} & 0 & 1 \\\\\n0 & \\frac{1}{2} & 0\n\\end{bmatrix}\\begin{bmatrix}\n\\frac{1}{3} \\\\\n\\frac{1}{3} \\\\\n\\frac{1}{3}\\end{bmatrix} & = & \\begin{bmatrix}\n\\frac{1}{3} \\\\\n\\frac{1}{2} \\\\\n\\frac{1}{6}\n\\end{bmatrix} \\\\\n~ & ~ & ~ & ~ & ~ & \\swarrow & ~ \\\\\n\\mathbf{r}^{(2)} & = & \\mathbf{E}\\mathbf{r}^{(1)} & = & \\begin{bmatrix}\n\\frac{1}{2} & \\frac{1}{2} & 0 \\\\\n\\frac{1}{2} & 0 & 1 \\\\\n0 & \\frac{1}{2} & 0\n\\end{bmatrix}\\begin{bmatrix}\\frac{1}{3} \\\\ \\frac{1}{2} \\\\ \\frac{1}{6}\\end{bmatrix} & = & \\begin{bmatrix}\\frac{5}{12} \\\\ \\frac{1}{3} \\\\ \\frac{1}{4}\\end{bmatrix} \\\\\n~ & ~ & ~ & ~ & ~ & \\swarrow & ~ \\\\\n\\mathbf{r}^{(3)} & = & \\mathbf{E}\\mathbf{r}^{(2)} & = & \\cdots & ~ & ~\n\\end{array}\n\\]"
  },
  {
    "objectID": "w08/slides.html#matrix-magic",
    "href": "w08/slides.html#matrix-magic",
    "title": "Week 8: Markov Models",
    "section": "Matrix Magic",
    "text": "Matrix Magic\n\n\nWon’t we just have to run this forever? (2) How do we know it’ll converge to something?\n\nAnswers: (1) no, (2) because Markov matrix magic\n“Steady state” = state where \\(\\mathbf{r}^{(t)} = \\mathbf{r}^{(t+1)} = \\mathbf{r}^{(t+2)} = \\cdots \\definedas \\mathbf{r}^*\\). But this means\n\n\\[\n\\mathbf{r}^{(t+1)} = \\mathbf{r}^{(t)} \\iff \\mathbf{E}\\mathbf{r}^{(t)} = \\mathbf{r}^{(t)} \\iff \\mathbf{E}\\mathbf{r}^* = \\mathbf{r}^*\n\\]\n\nThis \\(\\mathbf{r}^*\\) is—by definition!—an Eigenvector of \\(\\mathbf{E}\\), corresponding to Eigenvalue \\(\\lambda = 1\\)!1\n\n\n\nIn my opinion, along with e.g. insolubility of the quintic, this is maybe the most mind-blowing case of math magic :3\n\n\nThis is because an Eigenvalue-Eigenvector pair for a matrix \\(\\mathbf{M}\\) is a vector \\(\\mathbf{v}\\) and scalar value \\(\\lambda\\) which satisfy \\(\\mathbf{M}\\mathbf{v} = \\lambda \\mathbf{v}\\). In words: the result of (left) matrix-multiplying \\(\\mathbf{v}\\) by \\(\\mathbf{M}\\) is the same as scalar-multiplying \\(\\mathbf{v}\\) by a factor of \\(\\lambda\\). In our case the Eigenvector is \\(\\mathbf{r}^*\\) and the Eigenvalue is \\(\\lambda = 1\\), since \\(\\mathbf{E}\\mathbf{r}^* = 1 \\cdot \\mathbf{r}^*\\).For the math-curious, there are lots of fun results from matrix theory which assure us that \\(\\mathbf{E}\\) is guaranteed to have principal eigenvalue \\(\\lambda = 1\\) 💆"
  },
  {
    "objectID": "w08/slides.html#solving-the-matrix-magic",
    "href": "w08/slides.html#solving-the-matrix-magic",
    "title": "Week 8: Markov Models",
    "section": "Solving the Matrix Magic",
    "text": "Solving the Matrix Magic\n\nSince we already know the Eigenvalue of interest, \\(\\lambda = 1\\), all that’s left is solving for its corresponding Eigenvector:\n\n\\[\n\\mathbf{E}\\mathbf{r}^* = \\mathbf{r}^* \\iff \\mathbf{E}\\mathbf{r}^* - \\mathbf{r}^* = \\mathbf{0} \\iff (\\mathbf{E} - \\mathbf{I})\\mathbf{r}^* = \\mathbf{0}\n\\]\n\nWritten out, we see that this gives us a system of linear equations:\n\n\\[\n\\begin{bmatrix}\n\\frac{1}{2} & \\frac{1}{2} & 0 \\\\\n\\frac{1}{2} & 0 & 1 \\\\\n0 & \\frac{1}{2} & 0\n\\end{bmatrix}\\begin{bmatrix}r^*_1 \\\\ r^*_2 \\\\ r^*_3\\end{bmatrix} = \\begin{bmatrix}0 \\\\ 0 \\\\ 0\\end{bmatrix} \\iff \\begin{array}{ccccccc}\\frac{1}{2}r^*_1 & + & \\frac{1}{2}r^*_2 & ~ & ~ & = & 0 \\\\ \\frac{1}{2}r^*_1 & ~ & ~ & + & r^*_3 & = & 0 \\\\ ~ & ~ & \\frac{1}{2}r^*_2 & ~ & ~ & = & 0\\end{array}\n\\]\nwhich we can solve however we want!\n\nTo handle the fact that this system is underspecified, we impose the additional restriction that \\(r^*_1 + r^*_2 + r^*_3 = 1\\), so that the ranks form a probability distribution…"
  },
  {
    "objectID": "w08/slides.html#the-point-of-all-this",
    "href": "w08/slides.html#the-point-of-all-this",
    "title": "Week 8: Markov Models",
    "section": "The Point of All This",
    "text": "The Point of All This\n\nThe final restriction \\(r^*_1 + r^*_2 + r^*_3 = 1\\) ensures that the resulting PageRank values form a probability distribution\nThis is called the Stationary Distribution of the Markov chain: represents the probability that a random walker through the chain will be at page \\(S_i\\) at a given time!\n\nEquivalently: expected proportion of total walking time a random-walker will spend at each node\n\nEvery Markov chain has a Stationary Distribution! This fact has cool implications even above and beyond the Google $$$ implications 😜\n\n\n\nDSAN 5100-03 Week 8: Markov Models"
  },
  {
    "objectID": "w06/index.html",
    "href": "w06/index.html",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "",
    "text": "Open slides in new window →"
  },
  {
    "objectID": "w06/index.html#probability-theory-gives-us-distributions-for-rvs-not-numbers",
    "href": "w06/index.html#probability-theory-gives-us-distributions-for-rvs-not-numbers",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "Probability Theory Gives Us Distributions for RVs, not Numbers!",
    "text": "Probability Theory Gives Us Distributions for RVs, not Numbers!\n\nWe’re going beyond “base” probability theory if we want to summarize these distributions\nHowever, we can understand a lot about the full distribution by looking at some basic summary statistics. Most common way to summarize:\n\n\n\n\n\n\n\n\n\n\\(\\underbrace{\\text{point estimate}}_{\\text{mean/median}}\\)\n\\(\\pm\\)\n\\(\\underbrace{\\text{uncertainty}}_{\\text{variance/standard deviation}}\\)"
  },
  {
    "objectID": "w06/index.html#example-game-reviews",
    "href": "w06/index.html#example-game-reviews",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "Example: Game Reviews",
    "text": "Example: Game Reviews\n\nlibrary(readr)\nfig_title &lt;- \"Reviews for a Popular Nintendo Switch Game\"\nfig_subtitle &lt;- \"(That I definitely didn't play for &gt;400 hours this summer...)\"\n#score_df &lt;- read_csv(\"https://gist.githubusercontent.com/jpowerj/8b2b6a50cef5a682db640e874a14646b/raw/e3c2b9d258380e817289fbb64f91ba9ed4357d62/totk_scores.csv\")\nscore_df &lt;- read_csv(\"assets/totk_scores.csv\")\n\nRows: 145 Columns: 1\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (1): score\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nmean_score &lt;- mean(score_df$score)\nlibrary(ggplot2)\nggplot(score_df, aes(x=score)) +\n  geom_histogram() +\n  #geom_vline(xintercept=mean_score) +\n  labs(\n    title=fig_title,\n    subtitle=fig_subtitle,\n    x=\"Review Score\",\n    y=\"Number of Reviews\"\n  ) +\n  dsan_theme(\"full\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n(Data from Metacritic)"
  },
  {
    "objectID": "w06/index.html#adding-a-single-line",
    "href": "w06/index.html#adding-a-single-line",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "Adding a Single Line",
    "text": "Adding a Single Line\n\nlibrary(readr)\nmean_score &lt;- mean(score_df$score)\nmean_score_label &lt;- sprintf(\"%0.2f\", mean_score)\nlibrary(ggplot2)\nggplot(score_df, aes(x=score)) +\n  geom_histogram() +\n  geom_vline(aes(xintercept=mean_score, linetype=\"dashed\"), color=\"purple\", size=1) +\n  scale_linetype_manual(\"\", values=c(\"dashed\"=\"dashed\"), labels=c(\"dashed\"=\"Mean Score\")) +\n  # Add single additional tick\n  scale_x_continuous(breaks=c(60, 70, 80, 90, mean_score, 100), labels=c(\"60\",\"70\",\"80\",\"90\",mean_score_label,\"100\")) +\n  labs(\n    title=fig_title,\n    subtitle=fig_subtitle,\n    x=\"Review Score\",\n    y=\"Number of Reviews\"\n  ) +\n  dsan_theme(\"full\") +\n  theme(\n    legend.title = element_blank(),\n    legend.spacing.y = unit(0, \"mm\")\n  ) +\n  theme(axis.text.x = element_text(colour = c('black', 'black','black', 'black', 'purple', 'black')))\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nWarning: Vectorized input to `element_text()` is not officially supported.\nℹ Results may be unexpected or may change in future versions of ggplot2.\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n(Data from Metacritic)"
  },
  {
    "objectID": "w06/index.html#or-a-single-ribbon",
    "href": "w06/index.html#or-a-single-ribbon",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "Or a Single Ribbon",
    "text": "Or a Single Ribbon\n\n\n\nlibrary(tibble)\nN &lt;- 10\n# Each x value gets 10 y values\nx &lt;- sort(rep(seq(1,10),10))\ny &lt;- x + rnorm(length(x), 0, 5)\ndf &lt;- tibble(x=x,y=y)\ntotal_N &lt;- nrow(df)\nggplot(df, aes(x=x,y=y)) +\n  geom_point(size=g_pointsize) +\n  dsan_theme(\"quarter_small\") +\n  labs(\n    title=paste0(\"N=\",total_N,\" Randomly-Generated Points\")\n  )\n\n\n\n\n\n\n\n\n\n# This time, just the means\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nmean_df &lt;- df %&gt;% group_by(x) %&gt;% summarize(mean=mean(y), min=min(y), max=max(y))\nggplot(mean_df, aes(x=x, y=mean)) +\n  geom_ribbon(aes(ymin=min, ymax=max, fill=\"ribbon\"), alpha=0.5) +\n  geom_point(aes(color=\"mean\"), size=g_pointsize) +\n  geom_line(size=g_linesize) +\n  dsan_theme(\"quarter_small\") +\n  scale_color_manual(\"\", values=c(\"mean\"=\"black\"), labels=c(\"mean\"=\"Mean\")) +\n  scale_fill_manual(\"\", values=c(\"ribbon\"=cbPalette[1]), labels=c(\"ribbon\"=\"Range\")) +\n  remove_legend_title() +\n  labs(\n    title=paste0(\"Means of N=\",total_N,\" Randomly-Generated Points\")\n  )\n\n\n\n\n\n\n\n\n\n\n\nlibrary(tibble)\nN &lt;- 100\n# Each x value gets 10 y values\nx &lt;- sort(rep(seq(1,10),10))\ny &lt;- x + rnorm(length(x), 0, 1)\ndf &lt;- tibble(x=x,y=y)\ntotal_N &lt;- nrow(df)\nggplot(df, aes(x=x,y=y)) +\n  geom_point(size=g_pointsize) +\n  dsan_theme(\"quarter_small\") +\n  labs(\n    title=paste0(\"N=\",total_N,\" Randomly-Generated Points\")\n  )\n\n\n\n\n\n\n\n\n\n# This time, just the means\nlibrary(dplyr)\nmean_df &lt;- df %&gt;% group_by(x) %&gt;% summarize(mean=mean(y), min=min(y), max=max(y))\nggplot(mean_df, aes(x=x, y=mean)) +\n  geom_ribbon(aes(ymin=min, ymax=max, fill=\"ribbon\"), alpha=0.5) +\n  geom_point(aes(color=\"mean\"), size=g_pointsize) +\n  geom_line(size=g_linesize) +\n  dsan_theme(\"quarter_small\") +\n  scale_color_manual(\"\", values=c(\"mean\"=\"black\"), labels=c(\"mean\"=\"Mean\")) +\n  scale_fill_manual(\"\", values=c(\"ribbon\"=cbPalette[1]), labels=c(\"ribbon\"=\"Range\")) +\n  remove_legend_title() +\n  labs(\n    title=paste0(\"Means of N=\",total_N,\" Randomly-Generated Points\")\n  )"
  },
  {
    "objectID": "w06/index.html#expectations-weighted-means",
    "href": "w06/index.html#expectations-weighted-means",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "Expectations = Weighted Means",
    "text": "Expectations = Weighted Means\n\nWe already know how to find the (unweighted) mean of a list of numbers:\n\n\\[\n\\begin{align*}\n\\begin{array}{|p{1cm}||p{1cm}|p{1cm}|p{1cm}|}\\hline X & \\orange{4} & \\orange{10} & \\orange{8} \\\\\\hline\\end{array} \\implies \\overline{X} &= \\frac{\\orange{4} + \\orange{10} + \\orange{8}}{\\purp{3}} = \\purp{\\left(\\frac{1}{3}\\right)} \\cdot \\orange{4} + \\purp{\\left( \\frac{1}{3} \\right)} \\cdot \\orange{10} + \\purp{\\left( \\frac{1}{3} \\right)} \\cdot \\orange{8} \\\\\n&= \\frac{22}{3} \\approx 7.33\n\\end{align*}\n\\]\n\nDiscrete distributions are just lists of numbers alongside their probability of occurring!\n\n\\[\n\\begin{align*}\n\\begin{array}{|p{1cm}|p{1cm}|p{1cm}|p{1cm}|}\\hline X & \\orange{4} & \\orange{10} & \\orange{8} \\\\\\hline \\Pr(X) & \\purp{0.01} & \\purp{0.01} & \\purp{0.98}\\\\\\hline\\end{array} \\implies \\overline{X} &= \\purp{\\left( \\frac{1}{100} \\right)} \\cdot \\orange{4} + \\purp{\\left( \\frac{1}{100} \\right)} \\cdot \\orange{10} + \\purp{\\left( \\frac{98}{100} \\right)} \\cdot \\orange{8} \\\\\n&= \\left.\\frac{798}{100}\\right.^{1} \\approx 7.98\n\\end{align*}\n\\]\n\n\n\nIt will be helpful for later/life as a data scientist to notice that this is exactly \\(\\frac{4 + 10 + \\overbrace{8 + \\cdots + 8}^{98\\text{ times}}}{100}\\). That is: weighted mean = normal mean where numbers are repeated proportionally to their probabilities. (See Laplace smoothing!)."
  },
  {
    "objectID": "w06/index.html#different-types-of-averages",
    "href": "w06/index.html#different-types-of-averages",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "Different Types of “Averages”",
    "text": "Different Types of “Averages”\n\n(This will seem like overkill now, but will help us later!)\nTo avoid confusion, we denote the “regular” (arithmetic) mean function as \\(M_1(\\cdot)\\)\n\nIf \\(V = \\{v_1, \\ldots, v_n\\}\\), \\(M_1(V) \\definedas \\frac{v_1+\\cdots+v_n}{n}\\).\n\nThen \\(\\overline{V}\\) will denote the number which results from applying \\(M_1\\) to the set \\(V\\).\nOther common functions which get called “averages” in Machine Learning: median, harmonic mean (\\(M_{-1}\\)), geometric mean (\\(M_0\\)), the hadamard product \\(\\odot\\), etc.—pop up surprisingly often in Data Science/Machine Learning!\nThe things we’re averaging also take on weird forms: bits, logical predicates, vectors, tensors (Hence Google’s Machine Learning platform, TensorFlow), …\n\n\n\nFor what these subscripts (\\(M_{-1}\\), \\(M_0\\), \\(M_1\\)) mean, and more on the Hadamard product and its importance to Machine Learning, see Section 6.1"
  },
  {
    "objectID": "w06/index.html#definition",
    "href": "w06/index.html#definition",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "Definition",
    "text": "Definition\n\nFor a discrete RV \\(X\\):\n\n\\[\n\\expect{X} = \\sum_{x \\in \\mathcal{R}_X}x P(x)\n\\]\n\nFor a continuous RV \\(X\\):\n\n\\[\n\\expect{X} = \\int_{-\\infty}^{\\infty}xf(x)dx\n\\]\n\n\nRemember that \\(\\mathcal{R}_X\\) is the support of the random variable \\(X\\). If \\(X\\) is discrete, this is just \\(\\mathcal{R}_X = \\{x \\in \\mathbb{R} \\given P(X = x) &gt; 0\\}\\). If \\(X\\) is continuous, we can almost always* use the similar definition \\(\\mathcal{R}_X = \\{x \\in \\mathbb{R} \\given f_X(x) &gt; 0\\}\\), remembering that \\(f_X(x) \\neq P(X = x)\\)!!! See Section 6.2 for the scarier definition that works for all continuous RVs."
  },
  {
    "objectID": "w06/index.html#important-properties",
    "href": "w06/index.html#important-properties",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "Important Properties",
    "text": "Important Properties\n\n\nFor RVs \\(X\\), \\(Y\\), and \\(a, b \\in \\mathbb{R}\\):\n\n\n\n\n\n\nLinear\n\n\\[\n\\expect{aX} = a\\expect{X}\n\\]\n\n\n\n\nAdditive\n\n\\[\n\\expect{X + Y} = \\expect{X} + \\expect{Y}\n\\]\n\n\n\n\nAffine1\n\n\\[\n\\expect{aX + b} = a\\expect{X} + b\n\\]\n\n\n\n\nLOTUS:\n\n\\[\n\\expect{g(X)} = g(x)f(x)dx\n\\]\n\nNot Multiplicative:\n\n\\[\n\\expect{X \\cdot Y} = \\expect{X} \\cdot \\expect{Y} \\iff X \\perp Y\n\\]\n\nReally these should be called affine functions, but this property is usually just known as “linearity”, so for the sake of being able to google it I’m calling it “Linear” here as well, for now"
  },
  {
    "objectID": "w06/index.html#variance-motivation",
    "href": "w06/index.html#variance-motivation",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "Variance: Motivation",
    "text": "Variance: Motivation\n\nWe’ve now got a “measure of central tendency”, the expectation \\(\\expect{X}\\), with some nice properties. We can use it to produce point estimates.\nNow, how do we describe and communicate the spread of the data in a dataset? Similarly, how can we describe our uncertainty about a point estimate?\nLet’s try to develop a function, \\(\\text{Spread}\\), that takes in a set of values and computes how spread out they are\n(Hint: we can use the arithmetic mean, but apply it to differences between points rather than points themselves)"
  },
  {
    "objectID": "w06/index.html#first-attempt",
    "href": "w06/index.html#first-attempt",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "First Attempt",
    "text": "First Attempt\n\nWhat properties should \\(\\text{Spread}(\\cdot)\\) have?\n\nShould be \\(0\\) if every data point is identical, then increase as they spread apart\n\nHow about: average difference between each point and the overall (arithmetic) mean? \\[\n\\text{Spread}(X) = M_1(X - \\overline{X}) = \\frac{(x_1 - \\overline{X}) + (x_2 - \\overline{X}) + \\cdots + (x_n - \\overline{X})}{n}\n\\]\n\n\n\n\nlibrary(latex2exp)\nN &lt;- 10\nx &lt;- seq(1,N)\ny &lt;- rnorm(N, 0, 10)\nmean_y &lt;- mean(y)\nspread &lt;- y - mean_y\ndf &lt;- tibble(x=x, y=y, spread=spread)\nggplot(df, aes(x=x, y=y)) +\n  geom_hline(aes(yintercept=mean_y, linetype=\"dashed\"), color=\"purple\", size=g_linesize) +\n  geom_segment(aes(xend=x, yend=mean_y, color=ifelse(y&gt;0,\"Positive\",\"Negative\")), size=g_linesize) +\n  geom_point(size=g_pointsize) +\n  scale_linetype_manual(element_blank(), values=c(\"dashed\"=\"dashed\"), labels=c(\"dashed\"=unname(TeX(c(\"$M_1(X)$\"))))) +\n  dsan_theme(\"half\") +\n  scale_color_manual(\"Spread\", values=c(\"Positive\"=cbPalette[3],\"Negative\"=cbPalette[6]), labels=c(\"Positive\"=\"Positive\",\"Negative\"=\"Negative\")) +\n  scale_x_continuous(breaks=seq(0,10,2)) +\n  #remove_legend_title() +\n  theme(legend.spacing.y=unit(0.1,\"mm\")) +\n  labs(\n    title=paste0(N, \" Randomly-Generated Points, N(0,10)\"),\n    x=\"Index\",\n    y=\"Value\"\n  )\n\n\n\n\n\n\n\n\n\nThe result? To ten decimal places:\n\nspread_fmt &lt;- sprintf(\"%0.10f\", mean(df$spread))\nwriteLines(spread_fmt)\n\n0.0000000000\n\n\n😞 What happened?"
  },
  {
    "objectID": "w06/index.html#avoiding-cancellation",
    "href": "w06/index.html#avoiding-cancellation",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "Avoiding Cancellation",
    "text": "Avoiding Cancellation\n\nHow do we avoid positive deviations and negative deviations cancelling out?\nTwo options\n\nAbsolute value \\(|X - \\overline{X}|\\)\nSquared error \\(\\left( X - \\overline{X} \\right)^2\\)…\n\nGhost of calculus past: which is differentiable everywhere?2\n\n\n\n\n# Could use facet_grid() here, but it doesn't work too nicely with stat_function() :(\nggplot(data.frame(x=c(-4,4)), aes(x=x)) +\n  stat_function(fun=~ .x^2, linewidth = g_linewidth) +\n  dsan_theme(\"quarter\") +\n  labs(\n    title=\"f(x) = x^2\",\n    y=\"f(x)\"\n  )\n\n\n\n\n\n\n\n\n\n\n# Could use facet_grid() here, but it doesn't work too nicely with stat_function() :(\nggplot(data.frame(x=c(-4,4)), aes(x=x)) +\n  stat_function(fun=~ abs(.x), linewidth=g_linewidth) +\n  dsan_theme(\"quarter\") +\n  labs(\n    title=\"f(x) = |x|\",\n    y=\"f(x)\"\n  )"
  },
  {
    "objectID": "w06/index.html#weve-arrived-at-variance",
    "href": "w06/index.html#weve-arrived-at-variance",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "We’ve Arrived at Variance!",
    "text": "We’ve Arrived at Variance!\n\\[\n\\Var{X} = \\bigexpect{ \\left(X - \\expect{X}\\right)^2 }\n\\]\n\nAnd, we can apply what we know about \\(\\expect{X}\\) to derive:\n\n\\[\n\\begin{align*}\n\\Var{X} &= \\bigexpect{ \\left(X - \\expect{X}\\right)^2 } = \\bigexpect{ X^2 - 2X\\expect{X} + \\left( \\expect{X} \\right)^2 } \\\\\n&= \\expect{X^2} - \\expect{2 X\\expect{X}} + \\left( \\expect{X} \\right)^2 \\\\\n&= \\expect{X^2} - 2\\expect{X}\\expect{X} + \\left(\\expect{X}\\right)^2 \\\\\n&= \\expect{X^2} - \\left( \\expect{X} \\right)^2 \\; \\; \\green{\\small{\\text{ (we'll need this in a minute)}}}\n\\end{align*}\n\\]\n\n\nWhy does \\(\\expect{2X\\expect{X}} = 2\\expect{X}\\expect{X}\\)? Remember: \\(X\\) is an RV, but \\(\\expect{X}\\) is a number!"
  },
  {
    "objectID": "w06/index.html#standard-deviation",
    "href": "w06/index.html#standard-deviation",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "Standard Deviation",
    "text": "Standard Deviation\n\nWhen we squared the deviations, we lost the units of our datapoints!\nTo see spread, but in the same units as the original data, let’s just undo the squaring!\n\n\\[\n\\text{SD}[X] = \\sqrt{\\Var{X}}\n\\]\n\nBut, computers don’t care about the unit of this measure (just minimizing it). No reason to do this additional step if humans aren’t looking at the results!"
  },
  {
    "objectID": "w06/index.html#properties-of-variance",
    "href": "w06/index.html#properties-of-variance",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "Properties of Variance",
    "text": "Properties of Variance\n\nRecall that Expectation was an affine function:\n\n\\[\n\\mathbb{E}[aX + b] = a\\mathbb{E}[X] + b\n\\]\n\nVariance has a similar property, but is called homogeneous of degree 2, which means\n\n\\[\n\\Var{aX + b} = a^2\\Var{X} \\; \\underbrace{\\phantom{+ b}}_{\\mathclap{\\text{(Something missing?)}}}\n\\]\n\n\nNote that since the expected value function is linear, it is also homogeneous, of degree 1, even though the \\(b\\) term doesn’t “disappear” like it does in the variance equation!"
  },
  {
    "objectID": "w06/index.html#what-happened-to-the-b-term",
    "href": "w06/index.html#what-happened-to-the-b-term",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "What Happened to the \\(b\\) Term?",
    "text": "What Happened to the \\(b\\) Term?\nMathematically:\n\\[\n\\begin{align*}\n\\Var{aX + b} \\definedas \\; &\\mathbb{E}[(aX + b - \\mathbb{E}[aX + b])^2] \\\\\n\\definedalign \\; &\\expect{(aX \\color{orange}{+ b} - a\\expect{X} \\color{orange}{- b})^2} \\\\\n\\definedalign \\; &\\expect{a^2X^2 - 2a^2\\expectsq{X} + a^2\\expectsq{X}} \\\\\n\\definedalign \\; &a^2 \\expect{X^2 - \\expectsq{X}} = a^2(\\expect{X^2} - \\expectsq{X})b \\\\\n\\definedas \\; & a^2\\Var{X}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w06/index.html#what-happened-to-the-b-term-1",
    "href": "w06/index.html#what-happened-to-the-b-term-1",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "What Happened to the \\(b\\) Term?",
    "text": "What Happened to the \\(b\\) Term?\n\nVisually (Assuming \\(X \\sim \\mathcal{N}(0,1)\\))\n\n\npdf_alpha &lt;- 0.333\nconst_variance &lt;- 0.25\ndnorm_center &lt;- function(x) dnorm(x, 0, const_variance)\ndnorm_p1 &lt;- function(x) dnorm(x, 1, const_variance)\ndnorm_m3 &lt;- function(x) dnorm(x, -3, const_variance)\nggplot(data.frame(x = c(-4, 2)), aes(x = x)) +\n    # X - 3\n    stat_function(aes(color=cbPalette[1]), fun = dnorm_m3, size=g_linesize) +\n    geom_area(stat = \"function\", fun = dnorm_m3, fill = cbPalette[3], xlim = c(-4, 2), alpha=pdf_alpha) +\n    # X + 1\n    stat_function(aes(color=cbPalette[2]), fun = dnorm_p1, size=g_linesize) +\n    geom_area(stat = \"function\", fun = dnorm_p1, fill = cbPalette[2], xlim = c(-4, 2), alpha=pdf_alpha) +\n    # X\n    stat_function(aes(color=cbPalette[3]), fun = dnorm_center, size = g_linesize) +\n    geom_area(stat = \"function\", fun = dnorm_center, fill = cbPalette[1], xlim = c(-4, 2), alpha=pdf_alpha) +\n    # Scales\n    scale_color_manual(\"RV\", values=c(cbPalette[1], cbPalette[2], cbPalette[3]), labels=c(\"X\", \"X + 1\", \"X - 3\")) +\n    geom_segment(x=0, y=0, xend=0, yend=dnorm_center(0), size = g_linesize, color=cbPalette[1]) +\n    geom_segment(x=1, y=0, xend=1, yend=dnorm_p1(1), size = g_linesize, color=cbPalette[2]) +\n    geom_segment(x=-3, y=0, xend=-3, yend=dnorm_m3(-3), size = g_linesize, color=cbPalette[3]) +\n    dsan_theme(\"quarter\") +\n    theme(\n      title = element_text(size=20)\n    ) +\n    labs(\n        title = \"Normal Distributions with Shifted Means\",\n        y = \"f(x)\"\n    )\n\n\n\n\n\n\n\n\n\\[\n\\begin{align*}\n\\expect{{\\color{lightblue}X + 1}} = \\expect{{\\color{orange}X}} + 1, \\; \\; \\Var{{\\color{lightblue}X + 1}} = \\Var{{\\color{orange}X}} \\\\\n\\expect{{\\color{green}X - 3}} = \\expect{{\\color{orange}X}} - 3, \\; \\; \\Var{{\\color{green}X - 3}} = \\Var{{\\color{orange}X}}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w06/index.html#generalizing-from-expectation-and-variance",
    "href": "w06/index.html#generalizing-from-expectation-and-variance",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "Generalizing from Expectation and Variance",
    "text": "Generalizing from Expectation and Variance\n\nIt turns out that, expectation and variance are just two “levels” of a hierarchy of information about a distribution!\nIn calculus: knowing \\(f(x)\\) is sufficient information for us to subsequently figure out \\(f'(x)\\), \\(f''(x)\\), …\nIn probability/statistics: knowing \\(M_X(t)\\) is sufficient information for us to figure out \\(\\expect{X}\\), \\(\\Var{X}\\), …"
  },
  {
    "objectID": "w06/index.html#not-a-metaphor",
    "href": "w06/index.html#not-a-metaphor",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "Not a Metaphor!",
    "text": "Not a Metaphor!\n\nThis calculus \\(\\leftrightarrow\\) statistics connection is not a metaphor: differentiating \\(M_X(t)\\) literally gives us \\(\\expect{X}\\), \\(\\Var{X}\\), …\nLet’s look at MGF for \\(X \\sim \\text{Bern}(\\param{p})\\), and try to derive \\(\\expect{X}\\)3.\n\n\\[\n\\begin{align*}\nM_X(t) &= (1 - p) + pe^t \\\\\nM'_X(t) &= pe^t,\\text{ and }\\expect{X} = M'_X(0) = \\green{p} \\; ✅\n\\end{align*}\n\\]\n\n\\(\\Var{X}\\)?\n\n\\[\n\\begin{align*}\nM''_{X}(t) &= pe^t,\\text{ and }\\expect{X^2} = M''_X(0) = p \\\\\n\\Var{X} &\\definedas{} \\expect{X^2} - (\\expect{X})^2 = p - p^2 = \\green{p(1-p)} \\; ✅\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w06/index.html#mgf-in-econometrics",
    "href": "w06/index.html#mgf-in-econometrics",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "MGF in Econometrics",
    "text": "MGF in Econometrics\n\n\n\n\n\n\n\nOpen in new window →\n\n\n\nIn case it doesn’t load: (hansen_large_1982?) has 17,253 citations as of 2023-05-21"
  },
  {
    "objectID": "w06/index.html#beware",
    "href": "w06/index.html#beware",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "BEWARE ☠️",
    "text": "BEWARE ☠️\nAs we saw last week (the Dreaded Cauchy Distribution):\n\nNot all random variables have moment-generating functions.\nWorse yet, not all random variables have well-defined variances\nWorse yet, not all random variables have well-defined means\n(This happens in non-contrived cases!)"
  },
  {
    "objectID": "w06/index.html#multivariate-distributions-w02",
    "href": "w06/index.html#multivariate-distributions-w02",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "Multivariate Distributions (W02)",
    "text": "Multivariate Distributions (W02)\n\nThe bivariate normal distribution represents the distribution of two normally-distributed RVs \\(\\mathbf{X} = [\\begin{smallmatrix} X_1 & X_2\\end{smallmatrix}]\\), which may or may not be correlated:\n\n\n\\[\n\\mathbf{X} = \\begin{bmatrix}X_1 \\\\ X_2\\end{bmatrix}, \\; \\boldsymbol{\\mu} =\n%\\begin{bmatrix}\\mu_1 \\\\ \\mu_2\\end{bmatrix}\n\\begin{bmatrix}\\smash{\\overbrace{\\mu_1}^{\\mathbb{E}[X_1]}} \\\\ \\smash{\\underbrace{\\mu_2}_{\\mathbb{E}[X_2]}}\\end{bmatrix}\n, \\; \\mathbf{\\Sigma} = \\begin{bmatrix}\\smash{\\overbrace{\\sigma_1^2}^{\\text{Var}[X_1]}} & \\smash{\\overbrace{\\rho\\sigma_1\\sigma_2}^{\\text{Cov}[X_1,X_2]}} \\\\ \\smash{\\underbrace{\\rho\\sigma_2\\sigma_1}_{\\text{Cov}[X_2,X_1]}} & \\smash{\\underbrace{\\sigma_2^2}_{\\text{Var}[X_2]}}\\end{bmatrix}\n% \\begin{bmatrix}\\sigma_1^2 & \\rho\\sigma_1\\sigma_2 \\\\ \\rho\\sigma_2\\sigma_1 & \\sigma_2^2 \\end{bmatrix}\n% = \\begin{bmatrix}\\text{Var}[X_1] & \\text{Cov}[X_1,X_2] \\\\ \\text{Cov}[X_2,X_1] & \\text{Var}[X_2] \\end{bmatrix}\n\\]\n\n\nBy squishing all this information intro matrices, we can specify the parameters of multivariate-normally-distributed vectors of RVs similarly to how we specify single-dimensional normally-distributed RVs:\n\n\n\\[\n\\begin{align*}\n\\overbrace{X}^{\\mathclap{\\text{scalar}}} &\\sim \\mathcal{N}\\phantom{_k}(\\overbrace{\\mu}^{\\text{scalar}}, \\overbrace{\\sigma}^{\\text{scalar}}) \\tag{Univariate} \\\\\n\\underbrace{\\mathbf{X}}_{\\text{vector}} &\\sim \\boldsymbol{\\mathcal{N}}_k(\\smash{\\underbrace{\\boldsymbol{\\mu}}_{\\text{vector}}}, \\underbrace{\\mathbf{\\Sigma}}_{\\text{matrix}}) \\tag{Multivariate}\n\\end{align*}\n\\]\n\n\nNote: In the future I’ll use the notation \\(\\mathbf{X}_{[a \\times b]}\\) to denote the dimensions of the vectors/matrices, like \\(\\mathbf{X}_{[k \\times 1]} \\sim \\boldsymbol{\\mathcal{N}}_k(\\boldsymbol{\\mu}_{[k \\times 1]}, \\mathbf{\\Sigma}_{[k \\times k]})\\)"
  },
  {
    "objectID": "w06/index.html#visualizing-3d-distributions-projection",
    "href": "w06/index.html#visualizing-3d-distributions-projection",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "Visualizing 3D Distributions: Projection",
    "text": "Visualizing 3D Distributions: Projection\n\nSince most of our intuitions about plots come from 2D plots, it is extremely useful to be able to take a 3D plot like this and imagine “projecting” it down into different 2D plots:\n\n\n\n\nAdapted (and corrected!) from LaTeX code in this StackExchange thread"
  },
  {
    "objectID": "w06/index.html#visualizing-3d-distributions-contours",
    "href": "w06/index.html#visualizing-3d-distributions-contours",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "Visualizing 3D Distributions: Contours",
    "text": "Visualizing 3D Distributions: Contours\n\n\n\nFrom Prof. Hickman’s slides!"
  },
  {
    "objectID": "w06/index.html#visualizing-3d-distributions-contours-1",
    "href": "w06/index.html#visualizing-3d-distributions-contours-1",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "Visualizing 3D Distributions: Contours",
    "text": "Visualizing 3D Distributions: Contours\n\n\n\nAlso from Prof. Hickman’s slides!"
  },
  {
    "objectID": "w06/index.html#bivariate-distributions",
    "href": "w06/index.html#bivariate-distributions",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "Bivariate Distributions",
    "text": "Bivariate Distributions\nDeGroot and Schervish (2013, 118) | DSPS Sec. 3.4 \n\nWe generalize the concept of the distribution of a random variable to the joint distribution of two random variables.\nIn doing so, we introduce the joint pmf for two discrete random variables, the joint pdf for two continuous variables, and the joint CDF for any two random variables."
  },
  {
    "objectID": "w06/index.html#sec-hadamard",
    "href": "w06/index.html#sec-hadamard",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "Appendix A: The Hadamard Product",
    "text": "Appendix A: The Hadamard Product\n\n\n\nUsed in nearly all neural NLP algorithms, as the basis of LSTM (see LSTM equations on the right)\nThe subscripts for the harmonic mean \\(M_{-1}\\), geometric mean \\(M_0\\), and arithmetic mean \\(M_1\\) come from the definition of the generalized mean:\n\n\\[\nM_p(V) = \\left( \\frac{1}{n} \\sum_{i=1}^n v_i^p \\right)^{1/p}\n\\]\n\n\\[\n\\begin{align*}\nf_t &= \\sigma(W_f [h_{t - 1}, x_t] + b_f) \\\\\ni_t &= \\sigma(W_i [h_{t - 1}, x_t] + b_i) \\\\\n\\tilde{C}_t &= \\tanh(W_C [h_{t - 1}, x_t] + b_C) \\\\\nC_t &= f_t \\odot C_{t - 1} + i_t \\odot \\tilde{C}_t \\\\\no_t &= \\sigma(W_o [h_{t - 1}, x_t] + b_o) \\\\\nh_t &= o_t \\odot \\tanh(C_t) \\\\\n\\hat{y} &= \\text{softmax}(W_y h_t + b_y)\n\\end{align*}\n\\]\n\n\n\nIf you’re a dork like me, you can read about generalized means, Fréchet means, or Stata’s trimmean function, all of which bring together seemingly-unrelated functions used throughout Machine Learning!"
  },
  {
    "objectID": "w06/index.html#sec-continuous-support",
    "href": "w06/index.html#sec-continuous-support",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "Appendix B: Continuous RV Support",
    "text": "Appendix B: Continuous RV Support\nIn most cases, for continuous RVs, the definition\n\\[\n\\mathcal{R}_X = \\{x \\in \\mathsf{Domain}(f_X) \\given f_X(x) &gt; 0\\}\n\\]\nworks fine. But, to fully capture all possible continuous RVs, the following formal definition is necessary:\n\\[\n\\mathcal{R}_X = \\left\\{x \\in \\mathbb{R} \\given \\forall r &gt; 0 \\left[ f_X(B(x,r)) &gt; 0 \\right] \\right\\},\n\\]\nwhere \\(B(x,r)\\) is a “band”4 around \\(x\\) with radius \\(r\\).\n\n\n\n\n\nFor a full explanation, see this StackExchange discussion."
  },
  {
    "objectID": "w06/index.html#footnotes",
    "href": "w06/index.html#footnotes",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nMathematically, it’s somewhat important to call \\(aX + b\\) an “affine transformation”, not a linear transformation. In practice, everyone calls this “linear”, so I’ll try to use both (for sake of Googling!). The reason it matters will come up when we discuss Variance!↩︎\nFor why differentiability matters a lot for modern Machine Learning, see the Backpropagation algorithm.↩︎\nRecall that, for a Bernoulli-distributed random variable \\(X\\), \\(\\expect{X} = p\\)↩︎\nIn one dimension, this would be an interval; in two dimensions, a circle; in three dimensions, a sphere; etc.↩︎"
  },
  {
    "objectID": "w06/slides.html#probability-theory-gives-us-distributions-for-rvs-not-numbers",
    "href": "w06/slides.html#probability-theory-gives-us-distributions-for-rvs-not-numbers",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "Probability Theory Gives Us Distributions for RVs, not Numbers!",
    "text": "Probability Theory Gives Us Distributions for RVs, not Numbers!\n\nWe’re going beyond “base” probability theory if we want to summarize these distributions\nHowever, we can understand a lot about the full distribution by looking at some basic summary statistics. Most common way to summarize:\n\n\n\n\n\n\n\n\n\n\\(\\underbrace{\\text{point estimate}}_{\\text{mean/median}}\\)\n\\(\\pm\\)\n\\(\\underbrace{\\text{uncertainty}}_{\\text{variance/standard deviation}}\\)"
  },
  {
    "objectID": "w06/slides.html#example-game-reviews",
    "href": "w06/slides.html#example-game-reviews",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "Example: Game Reviews",
    "text": "Example: Game Reviews\n\n\nCode\nlibrary(readr)\nfig_title &lt;- \"Reviews for a Popular Nintendo Switch Game\"\nfig_subtitle &lt;- \"(That I definitely didn't play for &gt;400 hours this summer...)\"\n#score_df &lt;- read_csv(\"https://gist.githubusercontent.com/jpowerj/8b2b6a50cef5a682db640e874a14646b/raw/e3c2b9d258380e817289fbb64f91ba9ed4357d62/totk_scores.csv\")\nscore_df &lt;- read_csv(\"assets/totk_scores.csv\")\nmean_score &lt;- mean(score_df$score)\nlibrary(ggplot2)\nggplot(score_df, aes(x=score)) +\n  geom_histogram() +\n  #geom_vline(xintercept=mean_score) +\n  labs(\n    title=fig_title,\n    subtitle=fig_subtitle,\n    x=\"Review Score\",\n    y=\"Number of Reviews\"\n  ) +\n  dsan_theme(\"full\")\n\n\n\n(Data from Metacritic)"
  },
  {
    "objectID": "w06/slides.html#adding-a-single-line",
    "href": "w06/slides.html#adding-a-single-line",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "Adding a Single Line",
    "text": "Adding a Single Line\n\n\nCode\nlibrary(readr)\nmean_score &lt;- mean(score_df$score)\nmean_score_label &lt;- sprintf(\"%0.2f\", mean_score)\nlibrary(ggplot2)\nggplot(score_df, aes(x=score)) +\n  geom_histogram() +\n  geom_vline(aes(xintercept=mean_score, linetype=\"dashed\"), color=\"purple\", size=1) +\n  scale_linetype_manual(\"\", values=c(\"dashed\"=\"dashed\"), labels=c(\"dashed\"=\"Mean Score\")) +\n  # Add single additional tick\n  scale_x_continuous(breaks=c(60, 70, 80, 90, mean_score, 100), labels=c(\"60\",\"70\",\"80\",\"90\",mean_score_label,\"100\")) +\n  labs(\n    title=fig_title,\n    subtitle=fig_subtitle,\n    x=\"Review Score\",\n    y=\"Number of Reviews\"\n  ) +\n  dsan_theme(\"full\") +\n  theme(\n    legend.title = element_blank(),\n    legend.spacing.y = unit(0, \"mm\")\n  ) +\n  theme(axis.text.x = element_text(colour = c('black', 'black','black', 'black', 'purple', 'black')))\n\n\n\n(Data from Metacritic)"
  },
  {
    "objectID": "w06/slides.html#or-a-single-ribbon",
    "href": "w06/slides.html#or-a-single-ribbon",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "Or a Single Ribbon",
    "text": "Or a Single Ribbon\n\n\n\n\nCode\nlibrary(tibble)\nN &lt;- 10\n# Each x value gets 10 y values\nx &lt;- sort(rep(seq(1,10),10))\ny &lt;- x + rnorm(length(x), 0, 5)\ndf &lt;- tibble(x=x,y=y)\ntotal_N &lt;- nrow(df)\nggplot(df, aes(x=x,y=y)) +\n  geom_point(size=g_pointsize) +\n  dsan_theme(\"quarter_small\") +\n  labs(\n    title=paste0(\"N=\",total_N,\" Randomly-Generated Points\")\n  )\n\n\n\n\n\n\n\n\n\n\n\nCode\n# This time, just the means\nlibrary(dplyr)\nmean_df &lt;- df %&gt;% group_by(x) %&gt;% summarize(mean=mean(y), min=min(y), max=max(y))\nggplot(mean_df, aes(x=x, y=mean)) +\n  geom_ribbon(aes(ymin=min, ymax=max, fill=\"ribbon\"), alpha=0.5) +\n  geom_point(aes(color=\"mean\"), size=g_pointsize) +\n  geom_line(size=g_linesize) +\n  dsan_theme(\"quarter_small\") +\n  scale_color_manual(\"\", values=c(\"mean\"=\"black\"), labels=c(\"mean\"=\"Mean\")) +\n  scale_fill_manual(\"\", values=c(\"ribbon\"=cbPalette[1]), labels=c(\"ribbon\"=\"Range\")) +\n  remove_legend_title() +\n  labs(\n    title=paste0(\"Means of N=\",total_N,\" Randomly-Generated Points\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nlibrary(tibble)\nN &lt;- 100\n# Each x value gets 10 y values\nx &lt;- sort(rep(seq(1,10),10))\ny &lt;- x + rnorm(length(x), 0, 1)\ndf &lt;- tibble(x=x,y=y)\ntotal_N &lt;- nrow(df)\nggplot(df, aes(x=x,y=y)) +\n  geom_point(size=g_pointsize) +\n  dsan_theme(\"quarter_small\") +\n  labs(\n    title=paste0(\"N=\",total_N,\" Randomly-Generated Points\")\n  )\n\n\n\n\n\n\n\n\n\n\n\nCode\n# This time, just the means\nlibrary(dplyr)\nmean_df &lt;- df %&gt;% group_by(x) %&gt;% summarize(mean=mean(y), min=min(y), max=max(y))\nggplot(mean_df, aes(x=x, y=mean)) +\n  geom_ribbon(aes(ymin=min, ymax=max, fill=\"ribbon\"), alpha=0.5) +\n  geom_point(aes(color=\"mean\"), size=g_pointsize) +\n  geom_line(size=g_linesize) +\n  dsan_theme(\"quarter_small\") +\n  scale_color_manual(\"\", values=c(\"mean\"=\"black\"), labels=c(\"mean\"=\"Mean\")) +\n  scale_fill_manual(\"\", values=c(\"ribbon\"=cbPalette[1]), labels=c(\"ribbon\"=\"Range\")) +\n  remove_legend_title() +\n  labs(\n    title=paste0(\"Means of N=\",total_N,\" Randomly-Generated Points\")\n  )"
  },
  {
    "objectID": "w06/slides.html#expectations-weighted-means",
    "href": "w06/slides.html#expectations-weighted-means",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "Expectations = Weighted Means",
    "text": "Expectations = Weighted Means\n\nWe already know how to find the (unweighted) mean of a list of numbers:\n\n\\[\n\\begin{align*}\n\\begin{array}{|p{1cm}||p{1cm}|p{1cm}|p{1cm}|}\\hline X & \\orange{4} & \\orange{10} & \\orange{8} \\\\\\hline\\end{array} \\implies \\overline{X} &= \\frac{\\orange{4} + \\orange{10} + \\orange{8}}{\\purp{3}} = \\purp{\\left(\\frac{1}{3}\\right)} \\cdot \\orange{4} + \\purp{\\left( \\frac{1}{3} \\right)} \\cdot \\orange{10} + \\purp{\\left( \\frac{1}{3} \\right)} \\cdot \\orange{8} \\\\\n&= \\frac{22}{3} \\approx 7.33\n\\end{align*}\n\\]\n\nDiscrete distributions are just lists of numbers alongside their probability of occurring!\n\n\\[\n\\begin{align*}\n\\begin{array}{|p{1cm}|p{1cm}|p{1cm}|p{1cm}|}\\hline X & \\orange{4} & \\orange{10} & \\orange{8} \\\\\\hline \\Pr(X) & \\purp{0.01} & \\purp{0.01} & \\purp{0.98}\\\\\\hline\\end{array} \\implies \\overline{X} &= \\purp{\\left( \\frac{1}{100} \\right)} \\cdot \\orange{4} + \\purp{\\left( \\frac{1}{100} \\right)} \\cdot \\orange{10} + \\purp{\\left( \\frac{98}{100} \\right)} \\cdot \\orange{8} \\\\\n&= \\left.\\frac{798}{100}\\right.^{1} \\approx 7.98\n\\end{align*}\n\\]\n\n\n\nIt will be helpful for later/life as a data scientist to notice that this is exactly \\(\\frac{4 + 10 + \\overbrace{8 + \\cdots + 8}^{98\\text{ times}}}{100}\\). That is: weighted mean = normal mean where numbers are repeated proportionally to their probabilities. (See Laplace smoothing!)."
  },
  {
    "objectID": "w06/slides.html#different-types-of-averages",
    "href": "w06/slides.html#different-types-of-averages",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "Different Types of “Averages”",
    "text": "Different Types of “Averages”\n\n(This will seem like overkill now, but will help us later!)\nTo avoid confusion, we denote the “regular” (arithmetic) mean function as \\(M_1(\\cdot)\\)\n\nIf \\(V = \\{v_1, \\ldots, v_n\\}\\), \\(M_1(V) \\definedas \\frac{v_1+\\cdots+v_n}{n}\\).\n\nThen \\(\\overline{V}\\) will denote the number which results from applying \\(M_1\\) to the set \\(V\\).\nOther common functions which get called “averages” in Machine Learning: median, harmonic mean (\\(M_{-1}\\)), geometric mean (\\(M_0\\)), the hadamard product \\(\\odot\\), etc.—pop up surprisingly often in Data Science/Machine Learning!\nThe things we’re averaging also take on weird forms: bits, logical predicates, vectors, tensors (Hence Google’s Machine Learning platform, TensorFlow), …\n\n\n\nFor what these subscripts (\\(M_{-1}\\), \\(M_0\\), \\(M_1\\)) mean, and more on the Hadamard product and its importance to Machine Learning, see Section 6.1"
  },
  {
    "objectID": "w06/slides.html#definition",
    "href": "w06/slides.html#definition",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "Definition",
    "text": "Definition\n\nFor a discrete RV \\(X\\):\n\n\\[\n\\expect{X} = \\sum_{x \\in \\mathcal{R}_X}x P(x)\n\\]\n\nFor a continuous RV \\(X\\):\n\n\\[\n\\expect{X} = \\int_{-\\infty}^{\\infty}xf(x)dx\n\\]\n\n\nRemember that \\(\\mathcal{R}_X\\) is the support of the random variable \\(X\\). If \\(X\\) is discrete, this is just \\(\\mathcal{R}_X = \\{x \\in \\mathbb{R} \\given P(X = x) &gt; 0\\}\\). If \\(X\\) is continuous, we can almost always* use the similar definition \\(\\mathcal{R}_X = \\{x \\in \\mathbb{R} \\given f_X(x) &gt; 0\\}\\), remembering that \\(f_X(x) \\neq P(X = x)\\)!!! See Section 6.2 for the scarier definition that works for all continuous RVs."
  },
  {
    "objectID": "w06/slides.html#important-properties",
    "href": "w06/slides.html#important-properties",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "Important Properties",
    "text": "Important Properties\n\n\nFor RVs \\(X\\), \\(Y\\), and \\(a, b \\in \\mathbb{R}\\):\n\n\n\n\n\n\nLinear\n\n\\[\n\\expect{aX} = a\\expect{X}\n\\]\n\n\n\n\nAdditive\n\n\\[\n\\expect{X + Y} = \\expect{X} + \\expect{Y}\n\\]\n\n\n\n\nAffine1\n\n\\[\n\\expect{aX + b} = a\\expect{X} + b\n\\]\n\n\n\n\nLOTUS:\n\n\\[\n\\expect{g(X)} = g(x)f(x)dx\n\\]\n\nNot Multiplicative:\n\n\\[\n\\expect{X \\cdot Y} = \\expect{X} \\cdot \\expect{Y} \\iff X \\perp Y\n\\]\n\nReally these should be called affine functions, but this property is usually just known as “linearity”, so for the sake of being able to google it I’m calling it “Linear” here as well, for now\n\nMathematically, it’s somewhat important to call \\(aX + b\\) an “affine transformation”, not a linear transformation. In practice, everyone calls this “linear”, so I’ll try to use both (for sake of Googling!). The reason it matters will come up when we discuss Variance!"
  },
  {
    "objectID": "w06/slides.html#variance-motivation",
    "href": "w06/slides.html#variance-motivation",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "Variance: Motivation",
    "text": "Variance: Motivation\n\nWe’ve now got a “measure of central tendency”, the expectation \\(\\expect{X}\\), with some nice properties. We can use it to produce point estimates.\nNow, how do we describe and communicate the spread of the data in a dataset? Similarly, how can we describe our uncertainty about a point estimate?\nLet’s try to develop a function, \\(\\text{Spread}\\), that takes in a set of values and computes how spread out they are\n(Hint: we can use the arithmetic mean, but apply it to differences between points rather than points themselves)"
  },
  {
    "objectID": "w06/slides.html#first-attempt",
    "href": "w06/slides.html#first-attempt",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "First Attempt",
    "text": "First Attempt\n\nWhat properties should \\(\\text{Spread}(\\cdot)\\) have?\n\nShould be \\(0\\) if every data point is identical, then increase as they spread apart\n\nHow about: average difference between each point and the overall (arithmetic) mean? \\[\n\\text{Spread}(X) = M_1(X - \\overline{X}) = \\frac{(x_1 - \\overline{X}) + (x_2 - \\overline{X}) + \\cdots + (x_n - \\overline{X})}{n}\n\\]\n\n\n\n\n\nCode\nlibrary(latex2exp)\nN &lt;- 10\nx &lt;- seq(1,N)\ny &lt;- rnorm(N, 0, 10)\nmean_y &lt;- mean(y)\nspread &lt;- y - mean_y\ndf &lt;- tibble(x=x, y=y, spread=spread)\nggplot(df, aes(x=x, y=y)) +\n  geom_hline(aes(yintercept=mean_y, linetype=\"dashed\"), color=\"purple\", size=g_linesize) +\n  geom_segment(aes(xend=x, yend=mean_y, color=ifelse(y&gt;0,\"Positive\",\"Negative\")), size=g_linesize) +\n  geom_point(size=g_pointsize) +\n  scale_linetype_manual(element_blank(), values=c(\"dashed\"=\"dashed\"), labels=c(\"dashed\"=unname(TeX(c(\"$M_1(X)$\"))))) +\n  dsan_theme(\"half\") +\n  scale_color_manual(\"Spread\", values=c(\"Positive\"=cbPalette[3],\"Negative\"=cbPalette[6]), labels=c(\"Positive\"=\"Positive\",\"Negative\"=\"Negative\")) +\n  scale_x_continuous(breaks=seq(0,10,2)) +\n  #remove_legend_title() +\n  theme(legend.spacing.y=unit(0.1,\"mm\")) +\n  labs(\n    title=paste0(N, \" Randomly-Generated Points, N(0,10)\"),\n    x=\"Index\",\n    y=\"Value\"\n  )\n\n\n\n\n\n\n\n\n\n\nThe result? To ten decimal places:\n\n\nCode\nspread_fmt &lt;- sprintf(\"%0.10f\", mean(df$spread))\nwriteLines(spread_fmt)\n\n\n0.0000000000\n\n\n😞 What happened?"
  },
  {
    "objectID": "w06/slides.html#avoiding-cancellation",
    "href": "w06/slides.html#avoiding-cancellation",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "Avoiding Cancellation",
    "text": "Avoiding Cancellation\n\nHow do we avoid positive deviations and negative deviations cancelling out?\nTwo options\n\nAbsolute value \\(|X - \\overline{X}|\\)\nSquared error \\(\\left( X - \\overline{X} \\right)^2\\)…\n\nGhost of calculus past: which is differentiable everywhere?1\n\n\n\n\n\nCode\n# Could use facet_grid() here, but it doesn't work too nicely with stat_function() :(\nggplot(data.frame(x=c(-4,4)), aes(x=x)) +\n  stat_function(fun=~ .x^2, linewidth = g_linewidth) +\n  dsan_theme(\"quarter\") +\n  labs(\n    title=\"f(x) = x^2\",\n    y=\"f(x)\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Could use facet_grid() here, but it doesn't work too nicely with stat_function() :(\nggplot(data.frame(x=c(-4,4)), aes(x=x)) +\n  stat_function(fun=~ abs(.x), linewidth=g_linewidth) +\n  dsan_theme(\"quarter\") +\n  labs(\n    title=\"f(x) = |x|\",\n    y=\"f(x)\"\n  )\n\n\n\n\n\n\n\n\n\n\n\nFor why differentiability matters a lot for modern Machine Learning, see the Backpropagation algorithm."
  },
  {
    "objectID": "w06/slides.html#weve-arrived-at-variance",
    "href": "w06/slides.html#weve-arrived-at-variance",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "We’ve Arrived at Variance!",
    "text": "We’ve Arrived at Variance!\n\\[\n\\Var{X} = \\bigexpect{ \\left(X - \\expect{X}\\right)^2 }\n\\]\n\nAnd, we can apply what we know about \\(\\expect{X}\\) to derive:\n\n\\[\n\\begin{align*}\n\\Var{X} &= \\bigexpect{ \\left(X - \\expect{X}\\right)^2 } = \\bigexpect{ X^2 - 2X\\expect{X} + \\left( \\expect{X} \\right)^2 } \\\\\n&= \\expect{X^2} - \\expect{2 X\\expect{X}} + \\left( \\expect{X} \\right)^2 \\\\\n&= \\expect{X^2} - 2\\expect{X}\\expect{X} + \\left(\\expect{X}\\right)^2 \\\\\n&= \\expect{X^2} - \\left( \\expect{X} \\right)^2 \\; \\; \\green{\\small{\\text{ (we'll need this in a minute)}}}\n\\end{align*}\n\\]\n\n\nWhy does \\(\\expect{2X\\expect{X}} = 2\\expect{X}\\expect{X}\\)? Remember: \\(X\\) is an RV, but \\(\\expect{X}\\) is a number!"
  },
  {
    "objectID": "w06/slides.html#standard-deviation",
    "href": "w06/slides.html#standard-deviation",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "Standard Deviation",
    "text": "Standard Deviation\n\nWhen we squared the deviations, we lost the units of our datapoints!\nTo see spread, but in the same units as the original data, let’s just undo the squaring!\n\n\\[\n\\text{SD}[X] = \\sqrt{\\Var{X}}\n\\]\n\nBut, computers don’t care about the unit of this measure (just minimizing it). No reason to do this additional step if humans aren’t looking at the results!"
  },
  {
    "objectID": "w06/slides.html#properties-of-variance",
    "href": "w06/slides.html#properties-of-variance",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "Properties of Variance",
    "text": "Properties of Variance\n\nRecall that Expectation was an affine function:\n\n\\[\n\\mathbb{E}[aX + b] = a\\mathbb{E}[X] + b\n\\]\n\nVariance has a similar property, but is called homogeneous of degree 2, which means\n\n\\[\n\\Var{aX + b} = a^2\\Var{X} \\; \\underbrace{\\phantom{+ b}}_{\\mathclap{\\text{(Something missing?)}}}\n\\]\n\n\nNote that since the expected value function is linear, it is also homogeneous, of degree 1, even though the \\(b\\) term doesn’t “disappear” like it does in the variance equation!"
  },
  {
    "objectID": "w06/slides.html#what-happened-to-the-b-term",
    "href": "w06/slides.html#what-happened-to-the-b-term",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "What Happened to the \\(b\\) Term?",
    "text": "What Happened to the \\(b\\) Term?\nMathematically:\n\\[\n\\begin{align*}\n\\Var{aX + b} \\definedas \\; &\\mathbb{E}[(aX + b - \\mathbb{E}[aX + b])^2] \\\\\n\\definedalign \\; &\\expect{(aX \\color{orange}{+ b} - a\\expect{X} \\color{orange}{- b})^2} \\\\\n\\definedalign \\; &\\expect{a^2X^2 - 2a^2\\expectsq{X} + a^2\\expectsq{X}} \\\\\n\\definedalign \\; &a^2 \\expect{X^2 - \\expectsq{X}} = a^2(\\expect{X^2} - \\expectsq{X})b \\\\\n\\definedas \\; & a^2\\Var{X}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w06/slides.html#what-happened-to-the-b-term-1",
    "href": "w06/slides.html#what-happened-to-the-b-term-1",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "What Happened to the \\(b\\) Term?",
    "text": "What Happened to the \\(b\\) Term?\n\nVisually (Assuming \\(X \\sim \\mathcal{N}(0,1)\\))\n\n\n\nCode\npdf_alpha &lt;- 0.333\nconst_variance &lt;- 0.25\ndnorm_center &lt;- function(x) dnorm(x, 0, const_variance)\ndnorm_p1 &lt;- function(x) dnorm(x, 1, const_variance)\ndnorm_m3 &lt;- function(x) dnorm(x, -3, const_variance)\nggplot(data.frame(x = c(-4, 2)), aes(x = x)) +\n    # X - 3\n    stat_function(aes(color=cbPalette[1]), fun = dnorm_m3, size=g_linesize) +\n    geom_area(stat = \"function\", fun = dnorm_m3, fill = cbPalette[3], xlim = c(-4, 2), alpha=pdf_alpha) +\n    # X + 1\n    stat_function(aes(color=cbPalette[2]), fun = dnorm_p1, size=g_linesize) +\n    geom_area(stat = \"function\", fun = dnorm_p1, fill = cbPalette[2], xlim = c(-4, 2), alpha=pdf_alpha) +\n    # X\n    stat_function(aes(color=cbPalette[3]), fun = dnorm_center, size = g_linesize) +\n    geom_area(stat = \"function\", fun = dnorm_center, fill = cbPalette[1], xlim = c(-4, 2), alpha=pdf_alpha) +\n    # Scales\n    scale_color_manual(\"RV\", values=c(cbPalette[1], cbPalette[2], cbPalette[3]), labels=c(\"X\", \"X + 1\", \"X - 3\")) +\n    geom_segment(x=0, y=0, xend=0, yend=dnorm_center(0), size = g_linesize, color=cbPalette[1]) +\n    geom_segment(x=1, y=0, xend=1, yend=dnorm_p1(1), size = g_linesize, color=cbPalette[2]) +\n    geom_segment(x=-3, y=0, xend=-3, yend=dnorm_m3(-3), size = g_linesize, color=cbPalette[3]) +\n    dsan_theme(\"quarter\") +\n    theme(\n      title = element_text(size=20)\n    ) +\n    labs(\n        title = \"Normal Distributions with Shifted Means\",\n        y = \"f(x)\"\n    )\n\n\n\n\n\n\n\n\n\n\\[\n\\begin{align*}\n\\expect{{\\color{lightblue}X + 1}} = \\expect{{\\color{orange}X}} + 1, \\; \\; \\Var{{\\color{lightblue}X + 1}} = \\Var{{\\color{orange}X}} \\\\\n\\expect{{\\color{green}X - 3}} = \\expect{{\\color{orange}X}} - 3, \\; \\; \\Var{{\\color{green}X - 3}} = \\Var{{\\color{orange}X}}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w06/slides.html#generalizing-from-expectation-and-variance",
    "href": "w06/slides.html#generalizing-from-expectation-and-variance",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "Generalizing from Expectation and Variance",
    "text": "Generalizing from Expectation and Variance\n\nIt turns out that, expectation and variance are just two “levels” of a hierarchy of information about a distribution!\nIn calculus: knowing \\(f(x)\\) is sufficient information for us to subsequently figure out \\(f'(x)\\), \\(f''(x)\\), …\nIn probability/statistics: knowing \\(M_X(t)\\) is sufficient information for us to figure out \\(\\expect{X}\\), \\(\\Var{X}\\), …"
  },
  {
    "objectID": "w06/slides.html#not-a-metaphor",
    "href": "w06/slides.html#not-a-metaphor",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "Not a Metaphor!",
    "text": "Not a Metaphor!\n\nThis calculus \\(\\leftrightarrow\\) statistics connection is not a metaphor: differentiating \\(M_X(t)\\) literally gives us \\(\\expect{X}\\), \\(\\Var{X}\\), …\nLet’s look at MGF for \\(X \\sim \\text{Bern}(\\param{p})\\), and try to derive \\(\\expect{X}\\)1.\n\n\\[\n\\begin{align*}\nM_X(t) &= (1 - p) + pe^t \\\\\nM'_X(t) &= pe^t,\\text{ and }\\expect{X} = M'_X(0) = \\green{p} \\; ✅\n\\end{align*}\n\\]\n\n\\(\\Var{X}\\)?\n\n\\[\n\\begin{align*}\nM''_{X}(t) &= pe^t,\\text{ and }\\expect{X^2} = M''_X(0) = p \\\\\n\\Var{X} &\\definedas{} \\expect{X^2} - (\\expect{X})^2 = p - p^2 = \\green{p(1-p)} \\; ✅\n\\end{align*}\n\\]\nRecall that, for a Bernoulli-distributed random variable \\(X\\), \\(\\expect{X} = p\\)"
  },
  {
    "objectID": "w06/slides.html#mgf-in-econometrics",
    "href": "w06/slides.html#mgf-in-econometrics",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "MGF in Econometrics",
    "text": "MGF in Econometrics\n\n\n\nOpen in new window →\n\n\n\nIn case it doesn’t load: (hansen_large_1982?) has 17,253 citations as of 2023-05-21"
  },
  {
    "objectID": "w06/slides.html#beware",
    "href": "w06/slides.html#beware",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "BEWARE ☠️",
    "text": "BEWARE ☠️\nAs we saw last week (the Dreaded Cauchy Distribution):\n\nNot all random variables have moment-generating functions.\nWorse yet, not all random variables have well-defined variances\nWorse yet, not all random variables have well-defined means\n(This happens in non-contrived cases!)"
  },
  {
    "objectID": "w06/slides.html#multivariate-distributions-w02",
    "href": "w06/slides.html#multivariate-distributions-w02",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "Multivariate Distributions (W02)",
    "text": "Multivariate Distributions (W02)\n\nThe bivariate normal distribution represents the distribution of two normally-distributed RVs \\(\\mathbf{X} = [\\begin{smallmatrix} X_1 & X_2\\end{smallmatrix}]\\), which may or may not be correlated:\n\n\n\\[\n\\mathbf{X} = \\begin{bmatrix}X_1 \\\\ X_2\\end{bmatrix}, \\; \\boldsymbol{\\mu} =\n%\\begin{bmatrix}\\mu_1 \\\\ \\mu_2\\end{bmatrix}\n\\begin{bmatrix}\\smash{\\overbrace{\\mu_1}^{\\mathbb{E}[X_1]}} \\\\ \\smash{\\underbrace{\\mu_2}_{\\mathbb{E}[X_2]}}\\end{bmatrix}\n, \\; \\mathbf{\\Sigma} = \\begin{bmatrix}\\smash{\\overbrace{\\sigma_1^2}^{\\text{Var}[X_1]}} & \\smash{\\overbrace{\\rho\\sigma_1\\sigma_2}^{\\text{Cov}[X_1,X_2]}} \\\\ \\smash{\\underbrace{\\rho\\sigma_2\\sigma_1}_{\\text{Cov}[X_2,X_1]}} & \\smash{\\underbrace{\\sigma_2^2}_{\\text{Var}[X_2]}}\\end{bmatrix}\n% \\begin{bmatrix}\\sigma_1^2 & \\rho\\sigma_1\\sigma_2 \\\\ \\rho\\sigma_2\\sigma_1 & \\sigma_2^2 \\end{bmatrix}\n% = \\begin{bmatrix}\\text{Var}[X_1] & \\text{Cov}[X_1,X_2] \\\\ \\text{Cov}[X_2,X_1] & \\text{Var}[X_2] \\end{bmatrix}\n\\]\n\n\nBy squishing all this information intro matrices, we can specify the parameters of multivariate-normally-distributed vectors of RVs similarly to how we specify single-dimensional normally-distributed RVs:\n\n\n\\[\n\\begin{align*}\n\\overbrace{X}^{\\mathclap{\\text{scalar}}} &\\sim \\mathcal{N}\\phantom{_k}(\\overbrace{\\mu}^{\\text{scalar}}, \\overbrace{\\sigma}^{\\text{scalar}}) \\tag{Univariate} \\\\\n\\underbrace{\\mathbf{X}}_{\\text{vector}} &\\sim \\boldsymbol{\\mathcal{N}}_k(\\smash{\\underbrace{\\boldsymbol{\\mu}}_{\\text{vector}}}, \\underbrace{\\mathbf{\\Sigma}}_{\\text{matrix}}) \\tag{Multivariate}\n\\end{align*}\n\\]\n\n\nNote: In the future I’ll use the notation \\(\\mathbf{X}_{[a \\times b]}\\) to denote the dimensions of the vectors/matrices, like \\(\\mathbf{X}_{[k \\times 1]} \\sim \\boldsymbol{\\mathcal{N}}_k(\\boldsymbol{\\mu}_{[k \\times 1]}, \\mathbf{\\Sigma}_{[k \\times k]})\\)"
  },
  {
    "objectID": "w06/slides.html#visualizing-3d-distributions-projection",
    "href": "w06/slides.html#visualizing-3d-distributions-projection",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "Visualizing 3D Distributions: Projection",
    "text": "Visualizing 3D Distributions: Projection\n\nSince most of our intuitions about plots come from 2D plots, it is extremely useful to be able to take a 3D plot like this and imagine “projecting” it down into different 2D plots:\n\n\nAdapted (and corrected!) from LaTeX code in this StackExchange thread"
  },
  {
    "objectID": "w06/slides.html#visualizing-3d-distributions-contours",
    "href": "w06/slides.html#visualizing-3d-distributions-contours",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "Visualizing 3D Distributions: Contours",
    "text": "Visualizing 3D Distributions: Contours\n\nFrom Prof. Hickman’s slides!"
  },
  {
    "objectID": "w06/slides.html#visualizing-3d-distributions-contours-1",
    "href": "w06/slides.html#visualizing-3d-distributions-contours-1",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "Visualizing 3D Distributions: Contours",
    "text": "Visualizing 3D Distributions: Contours\n\nAlso from Prof. Hickman’s slides!"
  },
  {
    "objectID": "w06/slides.html#bivariate-distributions",
    "href": "w06/slides.html#bivariate-distributions",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "Bivariate Distributions",
    "text": "Bivariate Distributions\nDeGroot and Schervish (2013, 118) | DSPS Sec. 3.4 \n\nWe generalize the concept of the distribution of a random variable to the joint distribution of two random variables.\nIn doing so, we introduce the joint pmf for two discrete random variables, the joint pdf for two continuous variables, and the joint CDF for any two random variables."
  },
  {
    "objectID": "w06/slides.html#sec-hadamard",
    "href": "w06/slides.html#sec-hadamard",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "Appendix A: The Hadamard Product",
    "text": "Appendix A: The Hadamard Product\n\n\n\nUsed in nearly all neural NLP algorithms, as the basis of LSTM (see LSTM equations on the right)\nThe subscripts for the harmonic mean \\(M_{-1}\\), geometric mean \\(M_0\\), and arithmetic mean \\(M_1\\) come from the definition of the generalized mean:\n\n\\[\nM_p(V) = \\left( \\frac{1}{n} \\sum_{i=1}^n v_i^p \\right)^{1/p}\n\\]\n\n\\[\n\\begin{align*}\nf_t &= \\sigma(W_f [h_{t - 1}, x_t] + b_f) \\\\\ni_t &= \\sigma(W_i [h_{t - 1}, x_t] + b_i) \\\\\n\\tilde{C}_t &= \\tanh(W_C [h_{t - 1}, x_t] + b_C) \\\\\nC_t &= f_t \\odot C_{t - 1} + i_t \\odot \\tilde{C}_t \\\\\no_t &= \\sigma(W_o [h_{t - 1}, x_t] + b_o) \\\\\nh_t &= o_t \\odot \\tanh(C_t) \\\\\n\\hat{y} &= \\text{softmax}(W_y h_t + b_y)\n\\end{align*}\n\\]\n\n\n\nIf you’re a dork like me, you can read about generalized means, Fréchet means, or Stata’s trimmean function, all of which bring together seemingly-unrelated functions used throughout Machine Learning!"
  },
  {
    "objectID": "w06/slides.html#sec-continuous-support",
    "href": "w06/slides.html#sec-continuous-support",
    "title": "Week 6: Continuous Distributions, Moments, Covariance",
    "section": "Appendix B: Continuous RV Support",
    "text": "Appendix B: Continuous RV Support\nIn most cases, for continuous RVs, the definition\n\\[\n\\mathcal{R}_X = \\{x \\in \\mathsf{Domain}(f_X) \\given f_X(x) &gt; 0\\}\n\\]\nworks fine. But, to fully capture all possible continuous RVs, the following formal definition is necessary:\n\\[\n\\mathcal{R}_X = \\left\\{x \\in \\mathbb{R} \\given \\forall r &gt; 0 \\left[ f_X(B(x,r)) &gt; 0 \\right] \\right\\},\n\\]\nwhere \\(B(x,r)\\) is a “band”1 around \\(x\\) with radius \\(r\\).\n\n\n\nDSAN 5100-03 Week 6: Distributions, Moments, Covariance\n\n\n\nDeGroot, Morris H., and Mark J. Schervish. 2013. Probability and Statistics. Pearson Education.\n\n\n\nFor a full explanation, see this StackExchange discussion.\nIn one dimension, this would be an interval; in two dimensions, a circle; in three dimensions, a sphere; etc."
  },
  {
    "objectID": "w09/notes.html",
    "href": "w09/notes.html",
    "title": "Statistical Inference",
    "section": "",
    "text": "Modified from Dr. Purna Gamage ANLY-511 slides\n\n\n\nLarge Random Samples (Chapter 6)\n\n\nLaw of Large Numbers\nThe Central Limit Theorem\n\n\nEstimation\n\n\nMaximum Likelihood Estimators\nMethod of Moments\nUnbiased Estimators\nEfficiency\n\n\n\n\n\n\n\n\n\nThe law of large numbers, in probability and statistics, states that as a sample size grows, its mean gets closer to the average of the whole population.\nIn the 16th century, mathematician Gerolama Cardano recognized the Law of Large Numbers but never proved it.\nIn 1713, Swiss mathematician Jakob Bernoulli proved this theorem in his book, Ars Conjectandi.\nIt was later refined by other noted mathematicians, such as Pafnuty Chebyshev, founder of the St. Petersburg mathematical school. https://www.investopedia.com/terms/l/lawoflargenumbers.asp\n\n\n\n\n\n\nStatistical convergence involves the tendency of a sequence of random variables to stabilize in distribution as the sample size increases, indicating a likelihood of approaching a limiting behavior in a probabilistic sense rather than pointwise certainty.\n\n\nGood visual resource: https://seeing-theory.brown.edu/basic-probability/index.html#section1\n\n\n\n“The Law of Large Numbers has nothing whatever to do with growth. What it actually says is that as a large number of samples of a random variable are taken from a population, the mean of the samples approaches the expected value of the population. In other (and simplified) terms, the larger your sample the better your estimate of the actual value… the basis of all sampling, polling, and inferential statistics…\n“So what do we call the principle that the growth rate of things tends to slow as they get larger? The idea is kind of obvious, which may be why it doesn’t have a name [so] I propose we call it the logistic principle.”\n\nSteve Wildstrom (via Techpinions, highlights courtesy of Annotote)\n\n\n\n\n\nVehicle Automation\n\nAI development for self-driving vehicles takes the law of large numbers quite literally, and runs with it (pun intended). Tesla for example, parses and collates data from countless Tesla car users, “using billions of miles to train neural networks”.\nIn this example, car mileage data is averaged to plot out and optimize paths and driving policies. Recorded video and images are repeatedly analyzed by the AI, so that it eventually predicts visual elements with a reliable rate of probability. Even data involving the driving decisions of other cars on the road, is averaged to help the AI make better predictions of what other drivers are most likely to do in the near future.\n\nhttps://www.analyticssteps.com/blogs/how-tesla-making-use-artificial-intelligence-its-operations\nModel Y Unveil: Elon Musk\nhttps://www.youtube.com/watch?v=Tb_Wn6K0uVs&feature=emb_logo\nTesla has taken excellent use of AI and Big Data for expanding its customer base. The firm has made use of existing customer databases for its data analytics using it to comprehend customer requirements and regularly updating their systems accordingly\nhttps://medium.com/kambria-network/the-importance-of-the-law-of-large-numbers-in-ai-ea55d8af21cf\n\n\n\nOther notable demonstrations of the law of large numbers in \\(\\mathrm{AI}\\) that are potential game changers, such as deep learning-based weather prediction and the ever-improving gambling AI, are also bound to shape the future of our world in some way, and could take us to directions we have yet to even begin to consider. As one Google Translate engineer put it, “when you go from 10,000 training examples to 10 billion training examples, it all starts to work. Data trumps everything.” Garry Kasparov, yes the man defeated in chess by the AI Deep_Blue, mentions this quote from his book Deep Thinking: Where Machine Intelligence Ends and Human Creativity Begins. This one sentence sums up succinctly why the law of large numbers is inevitably intertwined with AI.\nhttps://medium.com/kambria-network/the-importance-of-the-law-of-large-numbers-in-ai-ea55d8af21cf\n\n\n\nThe average of a random sample of i.i.d. random variables is called their sample mean.\nThe sample mean is useful for summarizing the information in a random sample in much the same way that the mean of a probability distribution summarizes the information in the distribution.\nIn this section, we present some results that illustrate the connection between the sample mean and the expected value of the individual random variables that comprise the random sample.\nFun Interactive Viz:\nhttps://seeing-theory.brown.edu/basic-probability/index.html#section1\n\n\n\nIn Definition 5.6.3, we defined the sample mean of \\(n\\) random variables \\(X_1, \\ldots, X_n\\) to be their average, \\[\n\\bar{X}_n=\\frac{1}{n}\\left(X_1+\\cdots+X_n\\right) .\n\\] The mean and the variance of \\(\\bar{X}_n\\) are easily computed.\n\n\n\nMean and Variance of the Sample Mean. Let \\(X_1, \\ldots, X_n\\) be a random sample fron a distribution with mean \\(\\mu\\) and variance \\(\\sigma^2\\). Let \\(\\bar{X}_n\\) be the sample mean. The \\(E\\left(\\bar{X}_n\\right)=\\mu\\) and \\(\\operatorname{Var}\\left(\\bar{X}_n\\right)=\\sigma^2 / n\\). Proof It follows from Theorems 4.2.1 and 4.2.4 that \\[\nE\\left(\\bar{X}_n\\right)=\\frac{1}{n} \\sum_{i=1}^n E\\left(X_i\\right)=\\frac{1}{n} \\cdot n \\mu=\\mu .\n\\] Furthermore, since \\(X_1, \\ldots, X_n\\) are independent, Theorems 4.3.4 and 4.3.5 say that \\[\n\\begin{aligned}\n\\operatorname{Var}\\left(\\bar{X}_n\\right) & =\\frac{1}{n^2} \\operatorname{Var}\\left(\\sum_{i=1}^n X_i\\right) \\\\\n& =\\frac{1}{n^2} \\sum_{i=1}^n \\operatorname{Var}\\left(X_i\\right)=\\frac{1}{n^2} \\cdot n \\sigma^2=\\frac{\\sigma^2}{n}\n\\end{aligned}\n\\]\n\n\n\nConvergence in Probability. A sequence \\(Z_1, Z_2, \\ldots\\) of random variables converges to \\(b\\) in probability if for every number \\(\\varepsilon&gt;0\\), \\[\n\\lim _{n \\rightarrow \\infty} \\operatorname{Pr}\\left(\\left|Z_n-b\\right|&lt;\\varepsilon\\right)=1 .\n\\] This property is denoted by \\[\nZ_n \\stackrel{p}{\\longrightarrow} b,\n\\] and is sometimes stated simply as \\(Z_n\\) converges to \\(b\\) in probability.\nIn other words, \\(Z_n\\) converges to \\(b\\) in probability if the probability that \\(Z_n\\) lies in each given interval around \\(b\\), no matter how small this interval may be, approaches 1 as \\(n \\rightarrow \\infty\\).\n\n\n\nLet \\(S_n=\\frac{1}{n} \\sum_{j=1}^n X_j\\) be the sample mean of the first \\(n\\) observations. if you have a sample of independent and identically distributed random variables, as the sample size grows larger, the sample mean will tend toward the population mean. \\[\nP\\left(\\left|S_n-\\mu\\right|&gt;\\epsilon\\right) \\rightarrow 0 \\quad \\text { for any } \\quad \\epsilon&gt;0\n\\] - This is called “convergence in probability”. - The probability of seeing the event \\(\\left|S_n-\\mu\\right|&gt;\\epsilon\\) becomes very small as \\(n\\) becomes large. - \\(\\quad\\) Box plot, histograms of the \\(S_n\\) etc. all become closer and closer to the constant \\(\\mu\\). - This is a statement about individual observations: Eventually most \\(S_n\\) are close to \\(\\mu\\).\n\n\n\n(Weak Law of Large Numbers) Let \\(X_1, X_2, \\ldots, X_n\\) be a sequence of mutually independent and identically distributed random variables each of which has a finite mean \\(E\\left[X_k\\right]=\\mu_X&lt;\\infty, k=1,2, \\ldots, n\\). Let \\(S_n\\) be the linear sum of the \\(n\\) random variables; that is, \\[\nS_n=X_1+X_2+\\cdots+X_n\n\\] Then for any \\(\\varepsilon&gt;0\\), \\[\n\\lim _{n \\rightarrow \\infty} P\\left[\\left|\\frac{S_n}{n}-\\mu_X\\right| \\geq \\varepsilon\\right] \\rightarrow 0\n\\] Alternatively, \\[\n\\lim _{n \\rightarrow \\infty} P\\left[\\left|\\frac{S_n}{n}-\\mu_X\\right|&lt;\\varepsilon\\right] \\rightarrow 1\n\\] Proof: By definition, \\[\n\\begin{gathered}\nS_n=X_1+X_2+\\cdots+X_n \\\\\n\\bar{S}_n=\\frac{S_n}{n}=\\frac{X_1+X_2+\\cdots+X_n}{n}=\\frac{n \\mu_X}{n}=\\mu_X \\\\\n\\operatorname{Var}\\left(\\bar{S}_n\\right)=\\operatorname{Var}\\left\\{\\frac{X_1+X_2+\\cdots+X_n}{n}\\right\\} \\\\\n=\\frac{1}{n^2}\\left\\{\\operatorname{Var}\\left(X_1\\right)+\\operatorname{Var}\\left(X_2\\right)+\\cdots+\\operatorname{Var}\\left(X_n\\right)\\right\\}=\\frac{n \\sigma_X^2}{n^2}\n\\end{gathered}\n\\] https://www.sciencedirect.com/book/9780128008522/fundamentals-of-applied-probability-and-random-processes\n\n\n\n(Strong Law of Large Numbers) Let \\(X_1, X_2, \\ldots, X_n\\) be a sequence of mutually independent and identically distributed random variables each of which has a finite mean \\(E\\left[X_k\\right]=\\mu_X&lt;\\infty, k=1,2, \\ldots, n\\). Let \\(S_n\\) be the linear sum of the \\(n\\) random variables; that is, \\[\nS_n=X_1+X_2+\\cdots+X_n\n\\] Then for any \\(\\varepsilon&gt;0\\), \\[\nP\\left[\\lim _{n \\rightarrow \\infty}\\left|\\bar{S}_n-\\mu_X\\right|&gt;\\varepsilon\\right]=0\n\\] where \\(\\bar{S}_n=S_n / n\\). An alternativ statement of the law is \\[\nP\\left[\\lim _{n \\rightarrow \\infty}\\left|\\bar{S}_n-\\mu_X\\right| \\leq \\varepsilon\\right]=1\n\\] https://www.sciencedirect.com/book/9780128008522/fundamentals-of-applied-probability-and-random-processes\n\n\n\nThe weak law of large numbers essentially states that for any nonzero specified margin, no matter how small, there is a high probability that the average of a sufficiently large number of observations will be close to the expected value within the margin. That is, \\[\n\\lim _{n \\rightarrow \\infty} \\bar{S}_n \\rightarrow \\mu_X\n\\] Alternatively, the arithmetic average \\(\\bar{S}_n\\) of a sequence of independent observations of a random variable \\(X\\) converges with probability \\(I\\) to the expected value \\(\\mu_X\\) of \\(X\\). Thus, the weak law is a convergence statement about a sequence of probabilities; it states that the sequence of random variables \\(\\left\\{\\bar{S}_n\\right\\}\\) converges in probability to the population mean \\(\\mu_X\\) as \\(n\\) becomes very large.\nThe strong law of large numbers states that with probability 1 the sequence of sample means \\(\\bar{S}_n\\) converges to a constant value \\(\\mu_x\\), which is the population mean of the random variables, as \\(n\\) becomes very large. This validates the relative-frequency definition of probability.\nhttps://www.sciencedirect.com/book/9780128008522/fundamentals-of-applied-probability-and-random-processes\n\n\n\n\\(S_n \\rightarrow \\mu \\quad\\) with probability 1\n\nThis is called “almost sure convergence. The probability that \\(S_n\\) does not converge to 0 is zero.\nThis is also a statement about individual observations: Eventually practically every \\(S_n\\) is close to \\(\\mu\\).\n\n\n\n\nStrong Law of Large Number The strong law of large numbers states that with probability 1 the sequence of sample means \\(S^{-} n\\) converges to a constant value \\(\\mu \\mathrm{X}\\), which is the population mean of the random variables, as \\(n\\) becomes very large. From: Fundamentals of Applied Probability and Random Processes (Second Edition), 2014\nWeak Law of Large Number The weak law of large numbers essentially states that for any nonzero specified margin, no matter how small, there is a high probability that the average of a sufficiently large number of observations will be close to the expected value within the margin. From: Fundamentals of Applied Probability and Random Processes (Second Edition), 2014\nhttps://www.sciencedirect.com/topics/mathematics/strong-law-of-large-number\nhttps://www.sciencedirect.com/topics/mathematics/weak-law-of-large-number#:~:text=6.9%20Laws%20of%20Large%20Numbers&text=One%20law%20is%20called%20the,variables%20behaves%20in%20the%20limit.\n\n\n\nLaw of Large Numbers. Suppose that \\(X_1, \\ldots, X_n\\) form a random sample from a distribution for which the mean is \\(\\mu\\) and for which the variance is finite. Let \\(\\bar{X}_n\\) denote the sample mean. Then \\[\n\\bar{X}_n \\stackrel{p}{\\longrightarrow} \\mu \\text {. }\n\\]"
  },
  {
    "objectID": "w09/notes.html#what-are-we-covering-today",
    "href": "w09/notes.html#what-are-we-covering-today",
    "title": "Statistical Inference",
    "section": "",
    "text": "Large Random Samples (Chapter 6)\n\n\nLaw of Large Numbers\nThe Central Limit Theorem\n\n\nEstimation\n\n\nMaximum Likelihood Estimators\nMethod of Moments\nUnbiased Estimators\nEfficiency"
  },
  {
    "objectID": "w09/notes.html#what-is-the-law-of-large-numbers",
    "href": "w09/notes.html#what-is-the-law-of-large-numbers",
    "title": "Statistical Inference",
    "section": "",
    "text": "The law of large numbers, in probability and statistics, states that as a sample size grows, its mean gets closer to the average of the whole population.\nIn the 16th century, mathematician Gerolama Cardano recognized the Law of Large Numbers but never proved it.\nIn 1713, Swiss mathematician Jakob Bernoulli proved this theorem in his book, Ars Conjectandi.\nIt was later refined by other noted mathematicians, such as Pafnuty Chebyshev, founder of the St. Petersburg mathematical school. https://www.investopedia.com/terms/l/lawoflargenumbers.asp"
  },
  {
    "objectID": "w09/notes.html#statistical-convergence",
    "href": "w09/notes.html#statistical-convergence",
    "title": "Statistical Inference",
    "section": "",
    "text": "Statistical convergence involves the tendency of a sequence of random variables to stabilize in distribution as the sample size increases, indicating a likelihood of approaching a limiting behavior in a probabilistic sense rather than pointwise certainty.\n\n\nGood visual resource: https://seeing-theory.brown.edu/basic-probability/index.html#section1"
  },
  {
    "objectID": "w09/notes.html#quote",
    "href": "w09/notes.html#quote",
    "title": "Statistical Inference",
    "section": "",
    "text": "“The Law of Large Numbers has nothing whatever to do with growth. What it actually says is that as a large number of samples of a random variable are taken from a population, the mean of the samples approaches the expected value of the population. In other (and simplified) terms, the larger your sample the better your estimate of the actual value… the basis of all sampling, polling, and inferential statistics…\n“So what do we call the principle that the growth rate of things tends to slow as they get larger? The idea is kind of obvious, which may be why it doesn’t have a name [so] I propose we call it the logistic principle.”\n\nSteve Wildstrom (via Techpinions, highlights courtesy of Annotote)"
  },
  {
    "objectID": "w09/notes.html#applications-of-the-law-of-large-numbers",
    "href": "w09/notes.html#applications-of-the-law-of-large-numbers",
    "title": "Statistical Inference",
    "section": "",
    "text": "Vehicle Automation\n\nAI development for self-driving vehicles takes the law of large numbers quite literally, and runs with it (pun intended). Tesla for example, parses and collates data from countless Tesla car users, “using billions of miles to train neural networks”.\nIn this example, car mileage data is averaged to plot out and optimize paths and driving policies. Recorded video and images are repeatedly analyzed by the AI, so that it eventually predicts visual elements with a reliable rate of probability. Even data involving the driving decisions of other cars on the road, is averaged to help the AI make better predictions of what other drivers are most likely to do in the near future.\n\nhttps://www.analyticssteps.com/blogs/how-tesla-making-use-artificial-intelligence-its-operations\nModel Y Unveil: Elon Musk\nhttps://www.youtube.com/watch?v=Tb_Wn6K0uVs&feature=emb_logo\nTesla has taken excellent use of AI and Big Data for expanding its customer base. The firm has made use of existing customer databases for its data analytics using it to comprehend customer requirements and regularly updating their systems accordingly\nhttps://medium.com/kambria-network/the-importance-of-the-law-of-large-numbers-in-ai-ea55d8af21cf"
  },
  {
    "objectID": "w09/notes.html#applications-of-the-law-of-large-numbers-1",
    "href": "w09/notes.html#applications-of-the-law-of-large-numbers-1",
    "title": "Statistical Inference",
    "section": "",
    "text": "Other notable demonstrations of the law of large numbers in \\(\\mathrm{AI}\\) that are potential game changers, such as deep learning-based weather prediction and the ever-improving gambling AI, are also bound to shape the future of our world in some way, and could take us to directions we have yet to even begin to consider. As one Google Translate engineer put it, “when you go from 10,000 training examples to 10 billion training examples, it all starts to work. Data trumps everything.” Garry Kasparov, yes the man defeated in chess by the AI Deep_Blue, mentions this quote from his book Deep Thinking: Where Machine Intelligence Ends and Human Creativity Begins. This one sentence sums up succinctly why the law of large numbers is inevitably intertwined with AI.\nhttps://medium.com/kambria-network/the-importance-of-the-law-of-large-numbers-in-ai-ea55d8af21cf"
  },
  {
    "objectID": "w09/notes.html#the-law-of-large-numbers",
    "href": "w09/notes.html#the-law-of-large-numbers",
    "title": "Statistical Inference",
    "section": "",
    "text": "The average of a random sample of i.i.d. random variables is called their sample mean.\nThe sample mean is useful for summarizing the information in a random sample in much the same way that the mean of a probability distribution summarizes the information in the distribution.\nIn this section, we present some results that illustrate the connection between the sample mean and the expected value of the individual random variables that comprise the random sample.\nFun Interactive Viz:\nhttps://seeing-theory.brown.edu/basic-probability/index.html#section1"
  },
  {
    "objectID": "w09/notes.html#properties-of-the-sample-mean",
    "href": "w09/notes.html#properties-of-the-sample-mean",
    "title": "Statistical Inference",
    "section": "",
    "text": "In Definition 5.6.3, we defined the sample mean of \\(n\\) random variables \\(X_1, \\ldots, X_n\\) to be their average, \\[\n\\bar{X}_n=\\frac{1}{n}\\left(X_1+\\cdots+X_n\\right) .\n\\] The mean and the variance of \\(\\bar{X}_n\\) are easily computed."
  },
  {
    "objectID": "w09/notes.html#properties-of-the-sample-mean-1",
    "href": "w09/notes.html#properties-of-the-sample-mean-1",
    "title": "Statistical Inference",
    "section": "",
    "text": "Mean and Variance of the Sample Mean. Let \\(X_1, \\ldots, X_n\\) be a random sample fron a distribution with mean \\(\\mu\\) and variance \\(\\sigma^2\\). Let \\(\\bar{X}_n\\) be the sample mean. The \\(E\\left(\\bar{X}_n\\right)=\\mu\\) and \\(\\operatorname{Var}\\left(\\bar{X}_n\\right)=\\sigma^2 / n\\). Proof It follows from Theorems 4.2.1 and 4.2.4 that \\[\nE\\left(\\bar{X}_n\\right)=\\frac{1}{n} \\sum_{i=1}^n E\\left(X_i\\right)=\\frac{1}{n} \\cdot n \\mu=\\mu .\n\\] Furthermore, since \\(X_1, \\ldots, X_n\\) are independent, Theorems 4.3.4 and 4.3.5 say that \\[\n\\begin{aligned}\n\\operatorname{Var}\\left(\\bar{X}_n\\right) & =\\frac{1}{n^2} \\operatorname{Var}\\left(\\sum_{i=1}^n X_i\\right) \\\\\n& =\\frac{1}{n^2} \\sum_{i=1}^n \\operatorname{Var}\\left(X_i\\right)=\\frac{1}{n^2} \\cdot n \\sigma^2=\\frac{\\sigma^2}{n}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "w09/notes.html#extra-notes-converges-in-probability",
    "href": "w09/notes.html#extra-notes-converges-in-probability",
    "title": "Statistical Inference",
    "section": "",
    "text": "Convergence in Probability. A sequence \\(Z_1, Z_2, \\ldots\\) of random variables converges to \\(b\\) in probability if for every number \\(\\varepsilon&gt;0\\), \\[\n\\lim _{n \\rightarrow \\infty} \\operatorname{Pr}\\left(\\left|Z_n-b\\right|&lt;\\varepsilon\\right)=1 .\n\\] This property is denoted by \\[\nZ_n \\stackrel{p}{\\longrightarrow} b,\n\\] and is sometimes stated simply as \\(Z_n\\) converges to \\(b\\) in probability.\nIn other words, \\(Z_n\\) converges to \\(b\\) in probability if the probability that \\(Z_n\\) lies in each given interval around \\(b\\), no matter how small this interval may be, approaches 1 as \\(n \\rightarrow \\infty\\)."
  },
  {
    "objectID": "w09/notes.html#extra-notes-convergence-in-probability",
    "href": "w09/notes.html#extra-notes-convergence-in-probability",
    "title": "Statistical Inference",
    "section": "",
    "text": "Let \\(S_n=\\frac{1}{n} \\sum_{j=1}^n X_j\\) be the sample mean of the first \\(n\\) observations. if you have a sample of independent and identically distributed random variables, as the sample size grows larger, the sample mean will tend toward the population mean. \\[\nP\\left(\\left|S_n-\\mu\\right|&gt;\\epsilon\\right) \\rightarrow 0 \\quad \\text { for any } \\quad \\epsilon&gt;0\n\\] - This is called “convergence in probability”. - The probability of seeing the event \\(\\left|S_n-\\mu\\right|&gt;\\epsilon\\) becomes very small as \\(n\\) becomes large. - \\(\\quad\\) Box plot, histograms of the \\(S_n\\) etc. all become closer and closer to the constant \\(\\mu\\). - This is a statement about individual observations: Eventually most \\(S_n\\) are close to \\(\\mu\\)."
  },
  {
    "objectID": "w09/notes.html#extra-notes-weak-law-of-large-numbers",
    "href": "w09/notes.html#extra-notes-weak-law-of-large-numbers",
    "title": "Statistical Inference",
    "section": "",
    "text": "(Weak Law of Large Numbers) Let \\(X_1, X_2, \\ldots, X_n\\) be a sequence of mutually independent and identically distributed random variables each of which has a finite mean \\(E\\left[X_k\\right]=\\mu_X&lt;\\infty, k=1,2, \\ldots, n\\). Let \\(S_n\\) be the linear sum of the \\(n\\) random variables; that is, \\[\nS_n=X_1+X_2+\\cdots+X_n\n\\] Then for any \\(\\varepsilon&gt;0\\), \\[\n\\lim _{n \\rightarrow \\infty} P\\left[\\left|\\frac{S_n}{n}-\\mu_X\\right| \\geq \\varepsilon\\right] \\rightarrow 0\n\\] Alternatively, \\[\n\\lim _{n \\rightarrow \\infty} P\\left[\\left|\\frac{S_n}{n}-\\mu_X\\right|&lt;\\varepsilon\\right] \\rightarrow 1\n\\] Proof: By definition, \\[\n\\begin{gathered}\nS_n=X_1+X_2+\\cdots+X_n \\\\\n\\bar{S}_n=\\frac{S_n}{n}=\\frac{X_1+X_2+\\cdots+X_n}{n}=\\frac{n \\mu_X}{n}=\\mu_X \\\\\n\\operatorname{Var}\\left(\\bar{S}_n\\right)=\\operatorname{Var}\\left\\{\\frac{X_1+X_2+\\cdots+X_n}{n}\\right\\} \\\\\n=\\frac{1}{n^2}\\left\\{\\operatorname{Var}\\left(X_1\\right)+\\operatorname{Var}\\left(X_2\\right)+\\cdots+\\operatorname{Var}\\left(X_n\\right)\\right\\}=\\frac{n \\sigma_X^2}{n^2}\n\\end{gathered}\n\\] https://www.sciencedirect.com/book/9780128008522/fundamentals-of-applied-probability-and-random-processes"
  },
  {
    "objectID": "w09/notes.html#extra-notes-strong-law-of-large-numbers",
    "href": "w09/notes.html#extra-notes-strong-law-of-large-numbers",
    "title": "Statistical Inference",
    "section": "",
    "text": "(Strong Law of Large Numbers) Let \\(X_1, X_2, \\ldots, X_n\\) be a sequence of mutually independent and identically distributed random variables each of which has a finite mean \\(E\\left[X_k\\right]=\\mu_X&lt;\\infty, k=1,2, \\ldots, n\\). Let \\(S_n\\) be the linear sum of the \\(n\\) random variables; that is, \\[\nS_n=X_1+X_2+\\cdots+X_n\n\\] Then for any \\(\\varepsilon&gt;0\\), \\[\nP\\left[\\lim _{n \\rightarrow \\infty}\\left|\\bar{S}_n-\\mu_X\\right|&gt;\\varepsilon\\right]=0\n\\] where \\(\\bar{S}_n=S_n / n\\). An alternativ statement of the law is \\[\nP\\left[\\lim _{n \\rightarrow \\infty}\\left|\\bar{S}_n-\\mu_X\\right| \\leq \\varepsilon\\right]=1\n\\] https://www.sciencedirect.com/book/9780128008522/fundamentals-of-applied-probability-and-random-processes"
  },
  {
    "objectID": "w09/notes.html#extra-notes-wlln-slln",
    "href": "w09/notes.html#extra-notes-wlln-slln",
    "title": "Statistical Inference",
    "section": "",
    "text": "The weak law of large numbers essentially states that for any nonzero specified margin, no matter how small, there is a high probability that the average of a sufficiently large number of observations will be close to the expected value within the margin. That is, \\[\n\\lim _{n \\rightarrow \\infty} \\bar{S}_n \\rightarrow \\mu_X\n\\] Alternatively, the arithmetic average \\(\\bar{S}_n\\) of a sequence of independent observations of a random variable \\(X\\) converges with probability \\(I\\) to the expected value \\(\\mu_X\\) of \\(X\\). Thus, the weak law is a convergence statement about a sequence of probabilities; it states that the sequence of random variables \\(\\left\\{\\bar{S}_n\\right\\}\\) converges in probability to the population mean \\(\\mu_X\\) as \\(n\\) becomes very large.\nThe strong law of large numbers states that with probability 1 the sequence of sample means \\(\\bar{S}_n\\) converges to a constant value \\(\\mu_x\\), which is the population mean of the random variables, as \\(n\\) becomes very large. This validates the relative-frequency definition of probability.\nhttps://www.sciencedirect.com/book/9780128008522/fundamentals-of-applied-probability-and-random-processes"
  },
  {
    "objectID": "w09/notes.html#extra-notes-strong-law-of-large-numbers-1",
    "href": "w09/notes.html#extra-notes-strong-law-of-large-numbers-1",
    "title": "Statistical Inference",
    "section": "",
    "text": "\\(S_n \\rightarrow \\mu \\quad\\) with probability 1\n\nThis is called “almost sure convergence. The probability that \\(S_n\\) does not converge to 0 is zero.\nThis is also a statement about individual observations: Eventually practically every \\(S_n\\) is close to \\(\\mu\\)."
  },
  {
    "objectID": "w09/notes.html#summary",
    "href": "w09/notes.html#summary",
    "title": "Statistical Inference",
    "section": "",
    "text": "Strong Law of Large Number The strong law of large numbers states that with probability 1 the sequence of sample means \\(S^{-} n\\) converges to a constant value \\(\\mu \\mathrm{X}\\), which is the population mean of the random variables, as \\(n\\) becomes very large. From: Fundamentals of Applied Probability and Random Processes (Second Edition), 2014\nWeak Law of Large Number The weak law of large numbers essentially states that for any nonzero specified margin, no matter how small, there is a high probability that the average of a sufficiently large number of observations will be close to the expected value within the margin. From: Fundamentals of Applied Probability and Random Processes (Second Edition), 2014\nhttps://www.sciencedirect.com/topics/mathematics/strong-law-of-large-number\nhttps://www.sciencedirect.com/topics/mathematics/weak-law-of-large-number#:~:text=6.9%20Laws%20of%20Large%20Numbers&text=One%20law%20is%20called%20the,variables%20behaves%20in%20the%20limit."
  },
  {
    "objectID": "w09/notes.html#law-of-large-numbers",
    "href": "w09/notes.html#law-of-large-numbers",
    "title": "Statistical Inference",
    "section": "",
    "text": "Law of Large Numbers. Suppose that \\(X_1, \\ldots, X_n\\) form a random sample from a distribution for which the mean is \\(\\mu\\) and for which the variance is finite. Let \\(\\bar{X}_n\\) denote the sample mean. Then \\[\n\\bar{X}_n \\stackrel{p}{\\longrightarrow} \\mu \\text {. }\n\\]"
  },
  {
    "objectID": "w09/notes.html#motivation",
    "href": "w09/notes.html#motivation",
    "title": "Statistical Inference",
    "section": "Motivation",
    "text": "Motivation\nThe Central Limit Theorem states that, regardless of the original distribution, the sum (or average) of a sufficiently large number of independent and identically distributed random variables will converge to a normal distribution."
  },
  {
    "objectID": "w09/notes.html#visualization",
    "href": "w09/notes.html#visualization",
    "title": "Statistical Inference",
    "section": "Visualization",
    "text": "Visualization\nGood Interactive Viz: https://seeing-theory.brown.edu/probability-distributions/index.html#section3"
  },
  {
    "objectID": "w09/notes.html#statement",
    "href": "w09/notes.html#statement",
    "title": "Statistical Inference",
    "section": "Statement",
    "text": "Statement\nThe central limit theorem states the distribution of sample means should be approximately normal.\nCentral Limit Theorem (Lindeberg and Lévy). If the random variables \\(X_1, \\ldots, X_n\\) form a random sample of size \\(n\\) from a given distribution with mean \\(\\mu\\) and variance \\(\\sigma^2\\) \\(\\left(0&lt;\\sigma^2&lt;\\infty\\right)\\), then for each fixed number \\(x\\), \\[\n\\lim _{n \\rightarrow \\infty} \\operatorname{Pr}\\left[\\frac{\\bar{X}_n-\\mu}{\\sigma / n^{1 / 2}} \\leq x\\right]=\\Phi(x),\n\\] where \\(\\Phi\\) denotes the c.d.f. of the standard normal distribution."
  },
  {
    "objectID": "w09/notes.html#clt",
    "href": "w09/notes.html#clt",
    "title": "Statistical Inference",
    "section": "CLT",
    "text": "CLT\nLet \\(S_n=\\frac{1}{n} \\sum_{j=1}^n X_j\\) be the sample mean of the first \\(n\\) observations. For large \\(n\\) \\[\n\\sqrt{n} \\frac{S_n-\\mu}{\\sigma} \\sim N(0,1) \\quad \\text { approximately }\n\\] The distribution of \\(\\sqrt{n} \\frac{S_n-\\mu}{\\sigma}\\) is close to \\(N(0,1)\\) for large \\(n\\). Formally, \\[\nP\\left(a \\leq \\sqrt{n} \\frac{S_n-\\mu}{\\sigma} \\leq b\\right) \\rightarrow P(a \\leq Z \\leq b)\n\\] as \\(n \\rightarrow \\infty\\), for any \\(a, b\\), where \\(Z \\sim N(0,1)\\). - Box plot, histograms, etc. all become closer and closer to the constant \\(\\mu\\) and also become more bell-shaped. - \\(\\quad\\) qqnorm() plots become straight lines. - \\(\\quad\\) This is exact if the \\(X_i\\) already have normal distributions."
  },
  {
    "objectID": "w09/notes.html#extra-notes-convergence-in-distribution",
    "href": "w09/notes.html#extra-notes-convergence-in-distribution",
    "title": "Statistical Inference",
    "section": "Extra Notes: Convergence in Distribution",
    "text": "Extra Notes: Convergence in Distribution\n\nThis is called convergence in distribution. We can say something about the probability distribution of the \\(S_n\\) as \\(n\\) becomes large.\nIt’s not a statement about individual observations.\nBut it is a stronger (more precise) statement that the Law of Large Numbers."
  },
  {
    "objectID": "w09/notes.html#clt-1",
    "href": "w09/notes.html#clt-1",
    "title": "Statistical Inference",
    "section": "CLT",
    "text": "CLT\n\nThe sampling distribution of the sample means approaches a normal distribution as the sample size gets larger - no matter what the shape of the population distribution.\nIf you sample batches of data from any distribution and take the mean of each batch. Then the distribution of the means is going to resemble a Gaussian distribution. (Same goes for taking the sum)"
  },
  {
    "objectID": "w09/notes.html#example",
    "href": "w09/notes.html#example",
    "title": "Statistical Inference",
    "section": "Example",
    "text": "Example"
  },
  {
    "objectID": "w09/notes.html#clt-2",
    "href": "w09/notes.html#clt-2",
    "title": "Statistical Inference",
    "section": "CLT",
    "text": "CLT\n\nNo matter what is the population distribution is, by CLT for large samples, sample mean will follow a normal distribution."
  },
  {
    "objectID": "w09/notes.html#clt-applications",
    "href": "w09/notes.html#clt-applications",
    "title": "Statistical Inference",
    "section": "CLT Applications",
    "text": "CLT Applications"
  },
  {
    "objectID": "w09/notes.html#motivating-example",
    "href": "w09/notes.html#motivating-example",
    "title": "Statistical Inference",
    "section": "Motivating example",
    "text": "Motivating example"
  },
  {
    "objectID": "w09/notes.html#example-1",
    "href": "w09/notes.html#example-1",
    "title": "Statistical Inference",
    "section": "Example",
    "text": "Example\n\nPossible samples and sample means of samples of size 2"
  },
  {
    "objectID": "w09/notes.html#summary-1",
    "href": "w09/notes.html#summary-1",
    "title": "Statistical Inference",
    "section": "Summary",
    "text": "Summary\nWe all understand intuitively that the average of many measurements of the same unknown quantity tends to give a better estimate than a single measurement. Intuitively, this is because the random error of each measurement cancels out in the average. In these notes we will make this intuition precise in two ways: the law of large numbers (LoLN) and the central limit theorem (CLT).\nBriefly, both the law of large numbers and central limit theorem are about many independent samples from same distribution. The LoLN tells us two things: 1. The average of many independent samples is (with high probability) close to the mean of the underlying distribution. 2. This density histogram of many independent samples is (with high probability) close to the graph of the density of the underlying distribution.\nhttps://ocw.mit.edu/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/readings/ MIT18_05S14_Reading6b.pdf\n\nLoLN: As \\(n\\) grows, the probability that \\(X_n\\) is close to \\(\\mu\\) goes to 1 .\nCLT: As \\(n\\) grows, the distribution of \\(\\bar{X}_n\\) converges to the normal distribution \\(N\\left(\\mu, \\sigma^2 / n\\right)\\). Before giving a more formal statement of the LoLN, let’s unpack its meaning through a concrete example (we’ll return to the CLT later on)."
  },
  {
    "objectID": "w09/notes.html#sample",
    "href": "w09/notes.html#sample",
    "title": "Statistical Inference",
    "section": "Sample",
    "text": "Sample\n\nA good sample must be….\nRepresentative of the population,\nBig enough to draw conclusions from, which in statistics is a sample size greater or equal to 30 .\nPicked at random, so you’re not biased towards certain characteristics in the population.\nAlso number of samples taken should represent the Population."
  },
  {
    "objectID": "w09/notes.html#sums-of-normally-distributed-random-variables",
    "href": "w09/notes.html#sums-of-normally-distributed-random-variables",
    "title": "Statistical Inference",
    "section": "Sums of Normally Distributed Random Variables",
    "text": "Sums of Normally Distributed Random Variables\n\nSuppose \\(X_1, X_2\\) are independent and \\(X_1 \\sim N\\left(\\mu_1, \\sigma_1^2\\right), X_2 \\sim N\\left(\\mu_2, \\sigma_2^2\\right)\\). Then \\[\nX_1+X_2 \\sim N\\left(\\mu_1+\\mu_2, \\sigma_1^2+\\sigma_2^2\\right)\n\\] l.e. \\(\\operatorname{Var}\\left(X_1+X_2\\right)=\\sigma_1^2+\\sigma_2^2\\).\nThis generalizes to sums of several independent normally distributed random variable.\nSuppose \\(X_1, \\ldots, X_n\\) are identically \\(N\\left(\\mu . \\sigma^2\\right)\\) distributed. Then\n\n\\[\n\\begin{aligned}\n\\frac{X_j-\\mu}{\\sigma} & \\sim N(0,1) \\\\\n\\sum_{j=1}^n X_j & \\sim N\\left(n \\mu, n \\sigma^2\\right) \\\\\nS_n & \\sim N\\left(\\mu, \\frac{\\sigma^2}{n}\\right) \\\\\n\\sqrt{n} \\frac{S_n-\\mu}{\\sigma} & \\sim N(0,1)\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "w09/notes.html#example-1-1",
    "href": "w09/notes.html#example-1-1",
    "title": "Statistical Inference",
    "section": "Example-1",
    "text": "Example-1\nSAT Math scores of a group of Science & Engineering majors had a normal distribution with mean 609 and SD 80. We will randomly select \\(\\mathbf{1 0}\\) students from these majors.\n\nWhat is the sampling distribution of the sample average?\n\nSince the population has a Normal distribution and we took a simple random sample, \\(\\bar{y}\\) has a normal distribution (regardless of the sample size).\n\nShape: normal\nMean: \\(\\mu=609\\)\nSD: \\(\\sigma_{\\bar{y}}=\\frac{\\sigma}{\\sqrt{n}}=\\frac{80}{\\sqrt{10}}=25.298\\)\n\n\nHow often would this average be more than 630 ?\n\n\\[\n\\begin{gathered}\nz=\\frac{\\bar{y}-\\mu}{\\sigma / \\sqrt{n}}=\\frac{630-609}{25.298}=0.83 \\\\\nP(Z&gt;0.83)=1-0.7967=0.2033\n\\end{gathered}\n\\]"
  },
  {
    "objectID": "w09/notes.html#example-2",
    "href": "w09/notes.html#example-2",
    "title": "Statistical Inference",
    "section": "Example-2",
    "text": "Example-2\nLet \\(X_1, X_2, \\ldots, X_9 \\sim \\operatorname{iidN}\\left(7,3^2\\right)\\) and let \\(Y_1, Y_2, \\ldots, Y_{12} \\sim \\operatorname{iidN}\\left(10,5^2\\right)\\). Let \\(W=\\bar{X}-\\bar{Y}\\) be the difference of the sample means. This is similar to the homework problem but not the same. I. Find the exact sampling distribution of \\(W\\) approximately. Solution \\(\\bar{X}\\) has a mean 7 and variance \\(9 / 9=1\\). \\(\\bar{Y}\\) has a mean 10 and variance \\(25 / 12=\\). By the CLT (Which applies already for normal distribution) we have a normal distribution. Therefore \\(W\\) has a normal distribution with mean \\(\\mu=7-10=-3, \\sigma^2=1+25 / 12\\)"
  },
  {
    "objectID": "w09/notes.html#statistical-inference-1",
    "href": "w09/notes.html#statistical-inference-1",
    "title": "Statistical Inference",
    "section": "Statistical Inference",
    "text": "Statistical Inference\n\nWhat would we say is the probability that a future patient will respond successfully to treatment after we observe the results from a collection of other patients?\nThis is the kind of question that statistical inference is designed to address.\nIn general, statistical inference consists of making probabilistic statements about unknown quantities.\nFor example, we can compute means, variances, quantiles, probabilities, and some other quantities yet to be introduced concerning unobserved random variables and unknown parameters of distributions.\nOur goal will be to say what we have learned about the unknown quantities after observing some data that we believe contain relevant information."
  },
  {
    "objectID": "w09/notes.html#statistical-inference-2",
    "href": "w09/notes.html#statistical-inference-2",
    "title": "Statistical Inference",
    "section": "Statistical Inference",
    "text": "Statistical Inference\nHere are some other examples of questions that statistical inference can try to answer.\n\nWhat can we say about whether a machine is functioning properly after we observe some of its output?\nIn a civil lawsuit, what can we say about whether there was discrimination after observing how different ethnic groups were treated?\n\nThe methods of statistical inference, which we shall develop to address these questions, are built upon the theory of probability covered in the earlier chapters of this text."
  },
  {
    "objectID": "w09/notes.html#definition",
    "href": "w09/notes.html#definition",
    "title": "Statistical Inference",
    "section": "Definition",
    "text": "Definition\nStatistical Inference. A statistical inference is a procedure that produces a probabilistic statement about some or all parts of a statistical model.\nBy a “probabilistic statement” we mean a statement that makes use of any of the concepts of probability theory that were discussed earlier in the text or are yet to be discussed later in the text. Some examples include a mean, a conditional mean, a quantile, a variance, a conditional distribution for a random variable given another, the probability of an event, a conditional probability of an event given something, and so on. In Example 7.1.1, here are some examples of statistical inferences that one might wish to make: - Produce a random variable \\(Y\\) (a function of \\(\\left.X_1, \\ldots, X_m\\right)\\) such that \\(\\operatorname{Pr}(Y \\geq\\) \\(\\theta \\mid \\theta)=0.9\\). - Produce a random variable \\(Y\\) that we expect to be close to \\(\\theta\\). - Compute how likely it is that the average of the next 10 lifetimes, \\(\\frac{1}{10} \\sum_{i=m+1}^{m+10} X_i\\), is at least 2. - Say something about how confident we are that \\(\\theta \\leq 0.4\\) after observing \\(X_1, \\ldots\\), \\(X_m\\).\nAll of these types of inference and others will be discussed in more detail later in this book."
  },
  {
    "objectID": "w09/notes.html#statistical-decision-problems",
    "href": "w09/notes.html#statistical-decision-problems",
    "title": "Statistical Inference",
    "section": "Statistical Decision Problems",
    "text": "Statistical Decision Problems\nIn many statistical inference problems, after the experimental data have been analyzed, we must choose a decision from some available class of decisions with the property that the consequences of each available decision depend on the unknown value of some parameter. - For example, we might have to estimate the unknown failure rate \\(\\theta\\) of our electronic components when the consequences depend on how close our estimate is to the correct value \\(\\theta\\). - As another example, we might have to decide whether the unknown proportion \\(P\\) of patients in the imipramine group (Example 7.1.3) is larger or smaller than some specified constant when the consequences depend on where \\(P\\) lies relative to the constant. - This last type of inference is closely related to hypothesis testing, the subject of Chapter 9."
  },
  {
    "objectID": "w09/notes.html#experimental-design",
    "href": "w09/notes.html#experimental-design",
    "title": "Statistical Inference",
    "section": "Experimental Design",
    "text": "Experimental Design\nIn some statistical inference problems, we have some control over the type or the amount of experimental data that will be collected. - For example, consider an experiment to determine the mean tensile strength of a certain type of alloy as a function of the pressure and temperature at which the alloy is produced. - Within the limits of certain budgetary and time constraints, it may be possible for the experimenter to choose the levels of pressure and temperature at which experimental specimens of the alloy are to be produced, and also to specify the number of specimens to be produced at each of these levels. - Such a problem, in which the experimenter can choose (at least to some extent) the particular experiment that is to be carried out, is called a problem of experimental design. - Of course, the design of an experiment and the statistical analysis of the experimental data are closely related. - One cannot design an effective experiment without considering the subsequent statistical analysis that is to be carried out on the data that will be obtained. - And one cannot carry out a meaningful statistical analysis of experimental data without considering the particular type of experiment from which the data were derived."
  },
  {
    "objectID": "w09/notes.html#other-inferences",
    "href": "w09/notes.html#other-inferences",
    "title": "Statistical Inference",
    "section": "Other Inferences",
    "text": "Other Inferences\n\nThe general classes of problems described above, as well as the more specific examples that appeared earlier, are intended as illustrations of types of statistical inferences that we will be able to perform with the theory and methods introduced in this text.\nThe range of possible models, inferences, and methods that can arise when data are observed in real research problems far exceeds what we can introduce here.\nIt is hoped that gaining an understanding of the problems that we can cover here will give you an appreciation for what needs to be done when a more challenging statistical problem arises."
  },
  {
    "objectID": "w09/notes.html#statistical-model",
    "href": "w09/notes.html#statistical-model",
    "title": "Statistical Inference",
    "section": "Statistical Model",
    "text": "Statistical Model\nStatistical Model. A statistical model consists of an identification of random variables of interest (both observable and only hypothetically observable), a specification of a joint distribution or a family of possible joint distributions for the observable random variables, the identification of any parameters of those distributions that are assumed unknown and possibly hypothetically observable, and (if desired) a specification for a (joint) distribution for the unknown parameter(s). When we treat the unknown parameter(s) \\(\\theta\\) as random, then the joint distribution of the observable random variables indexed by \\(\\theta\\) is understood as the conditional distribution of the observable random variables given \\(\\theta\\).\n Source: DeGroot and Schervish, Definition 7.1.1"
  },
  {
    "objectID": "w09/notes.html#parameterparameter-space",
    "href": "w09/notes.html#parameterparameter-space",
    "title": "Statistical Inference",
    "section": "Parameter/Parameter space",
    "text": "Parameter/Parameter space\n\nParameter/Parameter space. In a problem of statistical inference, a characteristic or combination of characteristics that determine the joint distribution for the random variables of interest is called a parameter of the distribution. The set \\(\\Omega\\) of all possible values of a parameter \\(\\theta\\) or of a vector of parameters \\(\\left(\\theta_1, \\ldots, \\theta_k\\right)\\) is called the parameter space.\nAll of the families of distributions introduced earlier (and to be introduced later) in this book have parameters that are included in the names of the individual members of the family. For example, the family of binomial distributions has parameters that we called \\(n\\) and \\(p\\), the family of normal distributions is parameterized by the mean \\(\\mu\\) and variance \\(\\sigma^2\\) of each distribution, the family of uniform distributions on intervals is parameterized by the endpoints of the intervals, the family of exponential distributions is parameterized by the rate parameter \\(\\theta\\), and so on.\n\n\n Source: DeGroot and Schervish, Definition 7.1.3"
  },
  {
    "objectID": "w09/notes.html#example-3",
    "href": "w09/notes.html#example-3",
    "title": "Statistical Inference",
    "section": "Example",
    "text": "Example\nA Clinical Trial. Suppose that 40 patients are going to be given a treatment for a condition and that we will observe for each patient whether or not they recover from the condition. We are most likely also intersted in a large collection of additional patients besides the 40 to be observed. To be specific, for each patient \\(i=1,2\\), let \\(X_i=1\\) if patient \\(i\\) recovers, and let \\(X_i=0\\) if not. As a collection of possible distributions for \\(X_1, X_2, \\ldots\\), we could choose to say that the \\(X_i\\) are i.i.d. having the Bernoulli distribution with parameter \\(p\\) for \\(0 \\leq p \\leq 1\\). In this case, the parameter \\(p\\) is known to lie in the closed interval \\([0,1]\\), and this interval could be taken as the parameter space. Notice also that the law of large numbers (Theorem 6.2.4) says that \\(p\\) is the limit as \\(n\\) goes to infinity of the proportion of the first \\(n\\) patients who recover."
  },
  {
    "objectID": "w09/notes.html#statistic",
    "href": "w09/notes.html#statistic",
    "title": "Statistical Inference",
    "section": "Statistic",
    "text": "Statistic\nStatistic. Suppose that the observable random variables of interest are \\(X_1, \\ldots, X_n\\). Let \\(r\\) be an arbitrary real-valued function of \\(n\\) real variables. Then the random variable \\(T=r\\left(X_1, \\ldots, X_n\\right)\\) is called a statistic.\n Source: DeGroot and Schervish, Definition 7.1.4"
  },
  {
    "objectID": "w09/notes.html#maximum-likelihood-estimation-mle",
    "href": "w09/notes.html#maximum-likelihood-estimation-mle",
    "title": "Statistical Inference",
    "section": "Maximum Likelihood Estimation (MLE)",
    "text": "Maximum Likelihood Estimation (MLE)"
  },
  {
    "objectID": "w09/notes.html#overview",
    "href": "w09/notes.html#overview",
    "title": "Statistical Inference",
    "section": "Overview",
    "text": "Overview\n\nObjective: Estimate parameters that maximize the likelihood of observed data.\nAssumption: Data follows a certain distribution.\nProcess: Find parameter values that make the observed data most probable.\nMethod: Maximize the likelihood function.\nProperties: Asymptotically efficient and consistent.\nOutput: Point estimates for model parameters."
  },
  {
    "objectID": "w09/notes.html#recall-joint-probability-density-function",
    "href": "w09/notes.html#recall-joint-probability-density-function",
    "title": "Statistical Inference",
    "section": "Recall: Joint probability density function",
    "text": "Recall: Joint probability density function\n\nGiven a random variable \\(X\\) with probability mass / density function \\(f(x \\mid \\theta)\\), where \\(\\theta\\) is some parameter.\nDistribution of \\(n\\) independent observations \\(X_1, \\ldots, X_n\\) : Joint pdf / pmf \\[\nf_{\\text {joint }}\\left(x_1, \\ldots, x_n \\mid \\theta\\right)=f\\left(x_1 \\mid \\theta\\right) \\cdots f\\left(x_n \\mid \\theta\\right)\n\\]\nProbability Theory: Assume that \\(\\theta\\) is given and the \\(x_i\\) are variables (have not yet been observed).\nExample: Exponential distribution"
  },
  {
    "objectID": "w09/notes.html#likelihood-function",
    "href": "w09/notes.html#likelihood-function",
    "title": "Statistical Inference",
    "section": "Likelihood Function",
    "text": "Likelihood Function\nLet the random variables \\(X_1, \\ldots, X_n\\) form a random sample from a discrete distribution or a continuous distribution for which the p.f. or the p.d.f. is \\(f(x \\mid \\theta)\\), where the parameter \\(\\theta\\) belongs to some parameter space \\(\\Omega\\). Here, \\(\\theta\\) can be either a real-valued parameter or a vector. For every observed vector \\(\\boldsymbol{x}=\\left(x_1, \\ldots, x_n\\right)\\) in the sample, the value of the joint p.f. or joint p.d.f. will, as usual, be denoted by \\(f_n(\\boldsymbol{x} \\mid \\theta)\\). Because of its importance in this section, we repeat Definition 7.2.3.\nLikelihood Function. When the joint p.d.f. or the joint p.f. \\(f_n(\\boldsymbol{x} \\mid \\theta)\\) of the observations in a random sample is regarded as a function of \\(\\theta\\) for given values of \\(x_1, \\ldots, x_n\\), it is called the likelihood function.\n Source: DeGroot and Schervish, Definition 7.5.1"
  },
  {
    "objectID": "w09/notes.html#likelihood-function-1",
    "href": "w09/notes.html#likelihood-function-1",
    "title": "Statistical Inference",
    "section": "Likelihood function",
    "text": "Likelihood function\nGiven a random variable \\(X\\) with probability mass / density function \\(f(x \\mid \\theta)\\), where \\(\\theta\\) is some parameter. Assume a sample of \\(n\\) independent observations \\(X=x_1, \\ldots, X=x_n\\) is given. Likelihood function \\[\nL\\left(\\theta \\mid x_1, \\ldots, x_n\\right)=f\\left(x_1 \\mid \\theta\\right) \\cdots f\\left(x_n \\mid \\theta\\right)\n\\] This is the same as the joint probability density/mass function. Assume now that the \\(x_i\\) are given (have been observed) and \\(\\theta\\) is unknown."
  },
  {
    "objectID": "w09/notes.html#visualization-1",
    "href": "w09/notes.html#visualization-1",
    "title": "Statistical Inference",
    "section": "Visualization",
    "text": "Visualization\nIn statistics, the likelihood function has a very precise definition: \\[\nL(\\theta \\mid x)=P(x \\mid \\theta)\n\\] The concept of likelihood plays a fundamental role in both Bayesian and frequentist statistics.\n\nGood Interactive Viz:https://seeing-theory.brown.edu/bayesian-inference/index.html#section2"
  },
  {
    "objectID": "w09/notes.html#mle",
    "href": "w09/notes.html#mle",
    "title": "Statistical Inference",
    "section": "MLE",
    "text": "MLE\n\n Source: https://www.youtube.com/watch?v=XepXtl9YKwc"
  },
  {
    "objectID": "w09/notes.html#example-poisson-distribution",
    "href": "w09/notes.html#example-poisson-distribution",
    "title": "Statistical Inference",
    "section": "Example: Poisson distribution",
    "text": "Example: Poisson distribution\n\nDiscrete distribution on \\(\\{0,1,2, \\ldots\\}\\), parameter \\(\\lambda=\\) intensity\nThe pmf is \\(f(x \\mid \\lambda)=e^{-\\lambda} \\frac{\\lambda^x}{x !}\\) for \\(x=0,1,2, \\ldots\\)\nThe joint pmf of \\(n\\) independent observations is \\[\n\\begin{aligned}\nf_{\\text {joint }}\\left(x_1, \\ldots, x_n \\mid \\lambda\\right) & =e^{-n \\lambda} \\frac{\\lambda^{x_1}}{x_{1} !} \\ldots \\frac{\\lambda^{x_n}}{x_{n} !} \\\\\n& =e^{-n \\lambda} \\frac{\\lambda^{x_1+x_2+\\cdots+x_n}}{x_{1} ! x_{2} ! \\ldots x_{n} !} \\\\\n& =L\\left(\\lambda \\mid x_1, \\ldots, x_n\\right)\n\\end{aligned}\n\\]\nThis is also the likelihood function.\nThree parts: \\(e^{-n \\lambda}\\) depends only on \\(\\lambda\\), the \\(x_i\\) ! depend only on the data, the term \\(\\lambda^{x_1+x_2+\\cdots+x_n}\\) depends both on \\(\\lambda\\) and the data."
  },
  {
    "objectID": "w09/notes.html#example-exponential-distribution",
    "href": "w09/notes.html#example-exponential-distribution",
    "title": "Statistical Inference",
    "section": "Example: Exponential distribution",
    "text": "Example: Exponential distribution\n\nContinuous distribution on \\([0, \\infty)\\), parameter \\(\\lambda=\\) rate\nThe pdf is \\(f(x \\mid \\lambda)=\\lambda e^{-\\lambda x}\\) for \\(x \\geq 0\\)\nThe joint pdf of \\(n\\) independent observations is\n\n\\[\n\\begin{aligned}\nf_{\\text {joint }}\\left(x_1, \\ldots, x_n \\mid \\lambda\\right) & =\\lambda^n e^{-\\lambda x_1} \\ldots \\lambda e^{-\\lambda x_n} \\\\\n& =\\lambda^n e^{-\\lambda x_1-\\lambda x_2-\\ldots \\lambda x_n} \\\\\n& =\\lambda^n e^{-\\lambda \\sum_i x_i} \\\\\n& =L\\left(\\lambda \\mid x_1, \\ldots, x_n\\right)\n\\end{aligned}\n\\]\n\nThis is also the likelihood function.\nTwo parts: A term depending only on \\(\\lambda\\) and another term depending on \\(\\lambda\\) and the data, specifically \\(\\sum_i x_i\\)."
  },
  {
    "objectID": "w09/notes.html#calculation",
    "href": "w09/notes.html#calculation",
    "title": "Statistical Inference",
    "section": "Calculation",
    "text": "Calculation"
  },
  {
    "objectID": "w09/notes.html#example-bernoulli-distribution",
    "href": "w09/notes.html#example-bernoulli-distribution",
    "title": "Statistical Inference",
    "section": "Example: Bernoulli distribution",
    "text": "Example: Bernoulli distribution\nDiscrete distribution on \\(\\{0,1\\}\\), parameter \\(p=\\) success probability Pmf: \\(f(x \\mid p)=p^x(1-p)^{1-x}=\\left\\{\\begin{array}{ll}1-p & (x=0) \\\\ p & (x=1)\\end{array} \\quad\\right.\\) for \\(x=0,1\\) The joint pmf of \\(n\\) independent observations is \\[\n\\begin{aligned}\nf_{\\text {joint }}\\left(x_1, \\ldots, x_n \\mid p\\right) & =\\prod_{i=1}^n p^{x_i}(1-p)^{1-x_i} \\\\\n& =p^{\\sum_{i=1}^n x_i}(1-p)^{\\sum_{i=1}^n\\left(1-x_i\\right)} \\\\\n& =p^{\\sum_i x_i}(1-p)^{n-\\sum_i x_i} \\\\\n& =(1-p)^n\\left(\\frac{p}{1-p}\\right)^{\\sum_i x_i}=L\\left(p \\mid x_1, \\ldots, x_n\\right)\n\\end{aligned}\n\\] This is also the likelihood function."
  },
  {
    "objectID": "w09/notes.html#exponential-families",
    "href": "w09/notes.html#exponential-families",
    "title": "Statistical Inference",
    "section": "Exponential Families",
    "text": "Exponential Families\nIn all these cases, the likelihood function for a sample \\(\\mathbf{x}=\\left(x_1, \\ldots, x_n\\right)\\) has two or three parts:\n\na function \\(g(\\mathbf{x})\\) that depends on the sample (could be 1)\na function \\(h(\\theta)\\) that depends on \\(\\theta\\) but not on the sample\na term that depends on the sample and on \\(\\theta\\) that has a special exponential form.\n\nThese are examples of exponential families of distributions (well studied in statistics)."
  },
  {
    "objectID": "w09/notes.html#example-cauchy-distribution",
    "href": "w09/notes.html#example-cauchy-distribution",
    "title": "Statistical Inference",
    "section": "Example: Cauchy Distribution",
    "text": "Example: Cauchy Distribution\nContinuous distribution on \\((-\\infty, \\infty)\\), location parameter \\(\\theta\\) The pdf is \\(f(x \\mid \\theta)=\\frac{1}{\\pi\\left((x-\\theta)^2+1\\right)}\\) The joint pdf of \\(n\\) independent observations is \\[\nf_{\\text {joint }}\\left(x_1, \\ldots, x_n \\mid \\theta\\right)=\\frac{1}{\\pi^n} \\prod_{i=1}^n \\frac{1}{\\left.\\left(x_i-\\theta\\right)^2+1\\right)}\n\\] This is also the likelihood function. Not clear how to simplify this! This is not an exponential family."
  },
  {
    "objectID": "w09/notes.html#likelihood-function-2",
    "href": "w09/notes.html#likelihood-function-2",
    "title": "Statistical Inference",
    "section": "Likelihood function",
    "text": "Likelihood function\nThe part of the likelihood function that connects the data and the parameter often depends only on a statistic \\(T(\\mathbf{x})\\). Exponential distribution: \\[\nL\\left(\\lambda \\mid x_1, \\ldots, x_n\\right)=\\lambda^n e^{-\\lambda x_1-\\lambda x_2 \\cdots-\\lambda x_n}\n\\] depends only on \\(T(\\mathbf{x})=x_1+\\cdots+x_n=n \\bar{x}\\). Poisson distribution: \\[\nL\\left(\\lambda \\mid x_1, \\ldots, x_n\\right)=e^{-n \\lambda} \\frac{\\lambda^{x_1+x_2+\\cdots+x_n}}{x_{1} ! x_{2} ! \\ldots x_{n} !}\n\\] The term connecting the data and \\(\\lambda\\) depends only on \\(T(\\mathbf{x})=x_1+\\cdots+x_n\\)."
  },
  {
    "objectID": "w09/notes.html#likelihood-function-for-normal-distribution",
    "href": "w09/notes.html#likelihood-function-for-normal-distribution",
    "title": "Statistical Inference",
    "section": "Likelihood function for normal distribution",
    "text": "Likelihood function for normal distribution\nTwo parameters: Mean \\(\\mu\\) and standard deviation \\(\\sigma\\). Probability density: \\[\nf(x \\mid \\mu, \\sigma)=\\frac{1}{\\sqrt{2 \\pi} \\sigma} e^{-\\frac{(x-\\mu)^2}{2 \\sigma^2}}\n\\] Likelihood function: \\[\n\\begin{aligned}\nL\\left(\\mu, \\sigma \\mid x_1, \\ldots, x_n\\right) & =\\frac{1}{(\\sqrt{2 \\pi})^n \\sigma^n} \\prod_{i=1}^n e^{-\\frac{\\left(x_i-\\mu\\right)^2}{2 \\sigma^2}} \\\\\n& =\\frac{1}{(\\sqrt{2 \\pi})^n \\sigma^n} e^{-\\sum_{i=1}^n \\frac{\\left(x_i-\\mu\\right)^2}{2 \\sigma^2}}\n\\end{aligned}\n\\] The data and the parameters \\(\\mu\\) and \\(\\sigma\\) are connected through \\(T_1(\\mathbf{x})=\\sum_i x_i\\) and \\(T_2(\\mathbf{x})=\\sum_i x_i^2\\)."
  },
  {
    "objectID": "w09/notes.html#log-likelihood",
    "href": "w09/notes.html#log-likelihood",
    "title": "Statistical Inference",
    "section": "Log Likelihood",
    "text": "Log Likelihood\n\nTake the logarithm of the likelihood function.\n\nPoisson distribution \\[\n\\log L=-n \\lambda+\\left(\\sum_i x_i\\right) \\log \\lambda-\\sum_i \\log x_{i} !\n\\] Exponential distribution \\[\n\\log L=n \\log \\lambda-\\lambda\\left(\\sum_i x_i\\right)\n\\] Bernoulli distribution \\[\n\\log L=\\log p\\left(\\sum_i x_i\\right)+\\log (1-p)\\left(n-\\sum_i x_i\\right)\n\\]"
  },
  {
    "objectID": "w09/notes.html#calculation-1",
    "href": "w09/notes.html#calculation-1",
    "title": "Statistical Inference",
    "section": "Calculation",
    "text": "Calculation"
  },
  {
    "objectID": "w09/notes.html#maximum-likelihood",
    "href": "w09/notes.html#maximum-likelihood",
    "title": "Statistical Inference",
    "section": "Maximum likelihood",
    "text": "Maximum likelihood\nWe need to find a value of \\(\\theta\\) for which the probability density \\(f_n(\\boldsymbol{x} \\mid \\theta)\\) is large and to use this value as an estimate of \\(\\boldsymbol{\\theta}\\). For each possible observed vector \\(x\\), we are led by this reasoning to consider a value of \\(\\theta\\) for which the likelihood function \\(f_n(\\boldsymbol{x} \\mid \\theta)\\) is a maximum and to use this value as an estimate of \\(\\theta\\). This concept is formalized in the following definition."
  },
  {
    "objectID": "w09/notes.html#maximum-likelihood-estimate",
    "href": "w09/notes.html#maximum-likelihood-estimate",
    "title": "Statistical Inference",
    "section": "Maximum Likelihood Estimate",
    "text": "Maximum Likelihood Estimate\n\nMaximum Likelihood Estimator/Estimate. For each possible observed vector \\(\\boldsymbol{x}\\), let \\(\\delta(\\boldsymbol{x}) \\in \\Omega\\) denote a value of \\(\\theta \\in \\Omega\\) for which the likelihood function \\(f_n(\\boldsymbol{x} \\mid \\theta)\\) is a maximum, and let \\(\\hat{\\theta}=\\delta(\\boldsymbol{X})\\) be the estimator of \\(\\theta\\) defined in this way.\nThe estimator \\(\\hat{\\theta}\\) is called a maximum likelihood estimator of \\(\\theta\\). After \\(\\boldsymbol{X}=\\boldsymbol{x}\\) is observed, the value \\(\\delta(\\boldsymbol{x})\\) is called a maximum likelihood estimate of \\(\\theta\\).\n\n Source: DeGroot and Schervish, Definition 7.5.2"
  },
  {
    "objectID": "w09/notes.html#arg-max-function",
    "href": "w09/notes.html#arg-max-function",
    "title": "Statistical Inference",
    "section": "Arg-max function",
    "text": "Arg-max function\n\nThe argmax function identifies the argument that maximizes a given function.\nIn mathematical terms, it finds the input value that yields the maximum output of the function.\nIt is crucial for optimization problems and statistical estimation.\n\nIn mathematics, the arguments of the maxima (abbreviated arg max or argmax) are the points, or elements, of the domain of some function at which the function values are maximized.[note 1] In contrast to global maxima, which refers to the largest outputs of a function, arg max refers to the inputs, or arguments, at which the function outputs are as large as possible."
  },
  {
    "objectID": "w09/notes.html#maximum-likelihood-1",
    "href": "w09/notes.html#maximum-likelihood-1",
    "title": "Statistical Inference",
    "section": "Maximum Likelihood",
    "text": "Maximum Likelihood\n*Observe the graphs of the likelihood functions. Where are the maxima? Maximum Likelihood Estimation Estimate the unknown parameter \\(\\theta\\) by using the maximum of the likelihood function, \\[\n\\hat{\\theta}_{M L E}=\\operatorname{argmax}_\\theta L\\left(\\theta \\mid x_1, \\ldots, x_n\\right)\n\\] Equivalently we can try to maximize the log likelihood. Use Optimization Theory to work out the maximum or to compute it numerically."
  },
  {
    "objectID": "w09/notes.html#example-exponential-distribution-1",
    "href": "w09/notes.html#example-exponential-distribution-1",
    "title": "Statistical Inference",
    "section": "Example: Exponential Distribution",
    "text": "Example: Exponential Distribution\nGiven a sample of size \\(n\\) and \\(\\sum_i x_i\\), the log likelihood is \\[\n\\log L(\\lambda)=n \\log \\lambda-\\lambda \\cdot \\sum_i x_i=n \\log \\lambda-\\lambda n \\bar{x}\n\\] Differentiate wrt. \\(\\lambda\\) : \\[\n\\frac{d}{d \\lambda} \\log L(\\lambda)=\\frac{n}{\\lambda}-n \\bar{x}\n\\] Set this \\(=0\\) and solve for \\(\\lambda\\). Calculus shows that this is the maximum, the maximum likelihood estimate of \\(\\lambda\\). \\[\n\\hat{\\lambda}_{M L E}=\\frac{1}{\\bar{x}}\n\\]"
  },
  {
    "objectID": "w09/notes.html#examples-of-mles",
    "href": "w09/notes.html#examples-of-mles",
    "title": "Statistical Inference",
    "section": "Examples of MLEs",
    "text": "Examples of MLEs\n\nPoisson distribution: \\(\\hat{\\lambda}_{M L E}=\\bar{x}\\)\nExponential distribution: \\(\\hat{\\lambda}_{M L E}=\\frac{1}{\\bar{x}}\\)\nBernoulli distribution: \\(\\hat{p}_{M L E}=\\bar{x}\\)\nTheoretical justification of intuitive choices\nShows how to reduce data\nGeneral method"
  },
  {
    "objectID": "w09/notes.html#normal-distribution",
    "href": "w09/notes.html#normal-distribution",
    "title": "Statistical Inference",
    "section": "Normal Distribution",
    "text": "Normal Distribution\nConsider normal distribution \\(N\\left(\\mu, \\sigma^2\\right)\\). The likelihood function depends on two parameters, namely \\(\\mu\\) and \\(\\sigma^2\\). \\[\n\\begin{aligned}\nL\\left(\\mu, \\sigma \\mid x_1, \\ldots, x_n\\right) & =\\frac{1}{(\\sqrt{2 \\pi})^n \\sigma^n} \\prod_{i=1}^n e^{-\\frac{\\left(x_i-\\mu\\right)^2}{2 \\sigma^2}} \\\\\n& =\\frac{1}{(\\sqrt{2 \\pi})^n \\sigma^n} e^{-\\sum_{i=1}^n \\frac{\\left(x_i-\\mu\\right)^2}{2 \\sigma^2}}\n\\end{aligned}\n\\] Need calculus of several variables to minimize. Maximum likelihood estimates: \\[\n\\hat{\\mu}_{M L E}=\\bar{x}, \\quad \\hat{\\sigma}^2 M L E=\\frac{1}{n} \\sum_{i=1}^n\\left(x_i-\\bar{x}\\right)^2\n\\]"
  },
  {
    "objectID": "w09/notes.html#uniform-distribution",
    "href": "w09/notes.html#uniform-distribution",
    "title": "Statistical Inference",
    "section": "Uniform Distribution",
    "text": "Uniform Distribution\nConsider uniform distribution on \\((0, a)\\) where \\(a\\) is unknown. Likelihood function depends on \\(a\\). \\[\nL\\left(a \\mid x_1, \\ldots, x_n\\right)= \\begin{cases}\\frac{1}{a^n} & \\left(0 \\leq x_1, x_2, \\ldots, x_n \\leq a\\right) \\\\ 0 & \\text { otherwise }\\end{cases}\n\\] Given a sample, we should pick the smallest a such that the first condition is true, since this will maximize the likelihood. Maximum likelihood estimates: \\[\n\\hat{a}_{M L E}=\\max _i x_i\n\\] Does this make sense? This is always biased - why?"
  },
  {
    "objectID": "w09/notes.html#example-logistic-regression",
    "href": "w09/notes.html#example-logistic-regression",
    "title": "Statistical Inference",
    "section": "Example: Logistic Regression",
    "text": "Example: Logistic Regression\n12.2.1 Likelihood Function for Logistic Regression Because logistic regression predicts probabilities, rather than just classes, we can fit it using likelihood. For each training data-point, we have a vector of features, \\(x_i\\), and an observed class, \\(y_i\\). The probability of that class was either \\(p\\), if \\(y_i=1\\), or \\(1-p\\), if \\(y_i=0\\). The likelihood is then \\[\nL\\left(\\beta_0, \\beta\\right)=\\prod_{i=1}^n p\\left(x_i\\right)^{y_i}\\left(1-p\\left(x_i\\right)^{1-y_i}\\right.\n\\]\nReference: http://www.stat.cmu.edu/~cshalizi/uADA/12/lectures/ch12.pdf"
  },
  {
    "objectID": "w09/notes.html#example-logistic-regression-1",
    "href": "w09/notes.html#example-logistic-regression-1",
    "title": "Statistical Inference",
    "section": "Example: Logistic Regression",
    "text": "Example: Logistic Regression\n(I could substitute in the actual equation for \\(p\\), but things will be clearer in a moment if I don’t.) The log-likelihood turns products into sums: \\[\n\\begin{aligned}\n\\ell\\left(\\beta_0, \\beta\\right) & =\\sum_{i=1}^n y_i \\log p\\left(x_i\\right)+\\left(1-y_i\\right) \\log 1-p\\left(x_i\\right) \\\\\n& =\\sum_{i=1}^n \\log 1-p\\left(x_i\\right)+\\sum_{i=1}^n y_i \\log \\frac{p\\left(x_i\\right)}{1-p\\left(x_i\\right)} \\\\\n& =\\sum_{i=1}^n \\log 1-p\\left(x_i\\right)+\\sum_{i=1}^n y_i\\left(\\beta_0+x_i \\cdot \\beta\\right) \\\\\n& =\\sum_{i=1}^n-\\log 1+e^{\\beta_0+x_i \\cdot \\beta}+\\sum_{i=1}^n y_i\\left(\\beta_0+x_i \\cdot \\beta\\right)\n\\end{aligned}\n\\] where in the next-to-last step we finally use equation 12.4. Reference: http://www.stat.cmu.edu/ cshalizi/uADA/12/lectures/ch12.pdf"
  },
  {
    "objectID": "w09/notes.html#example-logistic-regression-2",
    "href": "w09/notes.html#example-logistic-regression-2",
    "title": "Statistical Inference",
    "section": "Example: Logistic Regression",
    "text": "Example: Logistic Regression\nTypically, to find the maximum likelihood estimates we’d differentiate the log likelihood with respect to the parameters, set the derivatives equal to zero, and solve. To start that, take the derivative with respect to one component of \\(\\beta\\), say \\(\\beta_j\\). \\[\n\\begin{aligned}\n\\frac{\\partial \\ell}{\\partial \\beta_j} & =-\\sum_{i=1}^n \\frac{1}{1+e^{\\beta_0+x_i \\cdot \\beta}} e^{\\beta_0+x_i \\cdot \\beta} x_{i j}+\\sum_{i=1}^n y_i x_{i j} \\\\\n& =\\sum_{i=1}^n\\left(y_i-p\\left(x_i ; \\beta_0, \\beta\\right)\\right) x_{i j}\n\\end{aligned}\n\\] We are not going to be able to set this to zero and solve exactly. (That’s a transcendental equation, and there is no closed-form solution.) We can however approximately solve it numerically."
  },
  {
    "objectID": "w09/notes.html#notes",
    "href": "w09/notes.html#notes",
    "title": "Statistical Inference",
    "section": "Notes",
    "text": "Notes\nIt should be noted that in some problems, for certain observed vectors \\(\\boldsymbol{x}\\), the maximum value of \\(f_n(\\boldsymbol{x} \\mid \\theta)\\) may not actually be attained for any point \\(\\theta \\in \\Omega\\). In such a case, an M.L.E. of \\(\\theta\\) does not exist. For certain other observed vectors \\(\\boldsymbol{x}\\), the maximum value of \\(f_n(\\boldsymbol{x} \\mid \\theta)\\) may actually be attained at more than one point in the space \\(\\Omega\\). In such a case, the M.L.E. is not uniquely defined, and any one of these points can be chosen as the value of the estimator \\(\\hat{\\theta}\\). In many practical problems, however, the M.L.E. exists and is uniquely defined.\n# Method of Moments (MOM)"
  },
  {
    "objectID": "w09/notes.html#overview-1",
    "href": "w09/notes.html#overview-1",
    "title": "Statistical Inference",
    "section": "Overview",
    "text": "Overview\n\nThe method of moments is an intuitive method for estimating parameters when other, more attractive, methods may be too difficult\n\nMethod of Moments. Assume that \\(X_1, \\ldots, X_n\\) form a random sample from a distribution that is indexed by a \\(k\\)-dimensional parameter \\(\\theta\\) and that has at least \\(k\\) finite moments. For \\(j=1, \\ldots, k\\), let \\(\\mu_j(\\theta)=E\\left(X_1^j \\mid \\theta\\right)\\). Suppose that the function \\(\\mu(\\theta)=\\left(\\mu_1(\\theta), \\ldots, \\mu_k(\\theta)\\right)\\) is a one-to-one function of \\(\\theta\\). Let \\(M\\left(\\mu_1, \\ldots, \\mu_k\\right)\\) denote the inverse function, that is, for all \\(\\theta\\), \\[\n\\theta=M\\left(\\mu_1(\\theta), \\ldots, \\mu_k(\\theta)\\right) \\text {. }\n\\] Define the sample moments by \\(m_j=\\frac{1}{n} \\sum_{i=1}^n X_i^j\\) for \\(j=1, \\ldots, k\\). The method of moments estimator of \\(\\theta\\) is \\(M\\left(m_1, \\ldots, m_j\\right)\\).\nThe usual way of implementing the method of moments is to set up the \\(k\\) equations \\(m_j=\\mu_j(\\theta)\\) and then solve for \\(\\theta\\).\n Source: DeGroot and Schervish, Definition 7.6.3"
  },
  {
    "objectID": "w09/notes.html#method-of-moments-estimation",
    "href": "w09/notes.html#method-of-moments-estimation",
    "title": "Statistical Inference",
    "section": "Method of Moments Estimation",
    "text": "Method of Moments Estimation\nGiven a random variable \\(X\\) whose distribution depends on a parameter \\(\\theta\\). To estimate \\(\\theta\\),\n\nExpress a moment \\(\\mathcal{E}(X)\\) or \\(\\mathcal{E}\\left(X^2\\right)\\) or … in terms of \\(\\theta\\), e.g. \\(\\mathcal{E}(X)=H(\\theta)\\)\nEstimate this moment from the sample\nSolve the equation relating the moment and the parameter, e.g. solve \\(\\bar{x}=H(\\hat{\\theta})\\) for \\(\\hat{\\theta}\\).\n\nSimilar to a plug-in estimation\nAvoids calculus or likelihood functions, only algebra is needed"
  },
  {
    "objectID": "w09/notes.html#example-uniform-distribution",
    "href": "w09/notes.html#example-uniform-distribution",
    "title": "Statistical Inference",
    "section": "Example: Uniform Distribution",
    "text": "Example: Uniform Distribution\nConsider uniform distribution on \\((0, a)\\) where \\(a\\) is unknown. Then \\(E(X)=\\frac{a}{2}\\). Given a sample, compute the sample mean. Then use the method of moments: \\[\nE(X)=\\frac{a}{2} \\text { becomes } \\quad \\bar{x}=\\frac{\\hat{a}}{2} \\Rightarrow \\hat{a}=2 \\bar{x}\n\\] Method of moments estimate: \\[\n\\hat{a}_{M o M}=2 \\bar{x}\n\\] This is not biased. Does this make sense?"
  },
  {
    "objectID": "w09/notes.html#example-beta-distribution",
    "href": "w09/notes.html#example-beta-distribution",
    "title": "Statistical Inference",
    "section": "Example: Beta Distribution",
    "text": "Example: Beta Distribution\nContinuous distribution on \\((0,1)\\), parameters \\(\\alpha, \\beta&gt;0\\) The pdf is \\[\nf(x \\mid \\alpha, \\beta)=\\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha) \\Gamma(\\beta)} x^{\\alpha-1}(1-x)^{\\beta-1}\n\\] for \\(0&lt;x&lt;1\\) Likelihood function is complicated. Calculus minimization is challenging, due to \\(\\Gamma\\) function."
  },
  {
    "objectID": "w09/notes.html#estimation-using-method-of-moments",
    "href": "w09/notes.html#estimation-using-method-of-moments",
    "title": "Statistical Inference",
    "section": "Estimation using Method of Moments",
    "text": "Estimation using Method of Moments\nKnown for the beta distribution: \\[\n\\mathcal{E}(X)=\\frac{\\alpha}{\\alpha+\\beta}, \\quad \\operatorname{var}(X)=\\frac{\\alpha \\beta}{(\\alpha+\\beta)^2(\\alpha+\\beta+1)}\n\\] This is equivalent to formulae for the moments \\(\\mathcal{E}(X)\\) and \\(\\mathcal{E}\\left(X^2\\right)\\), since \\(\\mathcal{E}\\left(X^2\\right)=\\operatorname{var}(X)+\\mathcal{E}(X)^2\\).\nMoM approach: Use sample mean \\(\\bar{x}\\) and sample variance \\(\\bar{v}\\). Solve the equations \\[\n\\bar{x}=\\frac{\\alpha}{\\alpha+\\beta}, \\quad \\bar{v}=\\frac{\\alpha \\beta}{(\\alpha+\\beta)^2(\\alpha+\\beta+1)}\n\\]"
  },
  {
    "objectID": "w09/notes.html#resulting-estimators",
    "href": "w09/notes.html#resulting-estimators",
    "title": "Statistical Inference",
    "section": "Resulting Estimators",
    "text": "Resulting Estimators\n\nAfter some algebra … \\[\n\\begin{aligned}\n& \\hat{\\alpha}=\\bar{x}\\left(\\frac{\\bar{x}(1-\\bar{x})}{\\bar{v}}-1\\right) \\\\\n& \\hat{\\beta}=(1-\\bar{x})\\left(\\frac{\\bar{x}(1-\\bar{x})}{\\bar{v}}-1\\right)\n\\end{aligned}\n\\]\nWhat if \\(\\bar{v}&gt;\\bar{x}(1-\\bar{x})\\) ? The estimates then are negative! R packages such as EnvStats uses a numerical method to maximize the likelihood."
  },
  {
    "objectID": "w09/notes.html#bias-and-variance",
    "href": "w09/notes.html#bias-and-variance",
    "title": "Statistical Inference",
    "section": "Bias and Variance",
    "text": "Bias and Variance"
  },
  {
    "objectID": "w09/notes.html#bias-and-variance-1",
    "href": "w09/notes.html#bias-and-variance-1",
    "title": "Statistical Inference",
    "section": "Bias and Variance",
    "text": "Bias and Variance\nBias is systematic error, variance is random error. Bias can sometimes be estimated and corrected, variance can only be estimated. Formal Definition Suppose \\(\\hat{\\theta}\\) is an estimator (based on a random sample) for \\(\\theta\\). The bias is defined as \\[\n\\operatorname{bias}(\\hat{\\theta})=\\mathcal{E}(\\hat{\\theta})-\\theta\n\\] Theoretical evaluation and simulation approach may both be possible."
  },
  {
    "objectID": "w09/notes.html#unbiased-estimator",
    "href": "w09/notes.html#unbiased-estimator",
    "title": "Statistical Inference",
    "section": "Unbiased Estimator",
    "text": "Unbiased Estimator\nLet \\(\\delta\\) be an estimator of a function \\(g\\) of a parameter \\(\\theta\\). We say that \\(\\delta\\) is unbiased if \\(E_\\theta[\\delta(\\boldsymbol{X})]=g(\\theta)\\) for all values of \\(\\theta\\). This section provides several examples of unbiased estimators.\nLet \\(\\boldsymbol{X}=\\left(X_1, \\ldots, X_n\\right)\\) be a random sample from a distribution that involves a parameter (or parameter vector) \\(\\theta\\) whose value is unknown. Suppose that we wish to estimate a function \\(g(\\theta)\\) of the parameter. In a problem of this type, it is desirable to use an estimator \\(\\delta(\\boldsymbol{X})\\) that, with high probability, will be close to \\(g(\\theta)\\). In other words,"
  },
  {
    "objectID": "w09/notes.html#unbiased-estimator-1",
    "href": "w09/notes.html#unbiased-estimator-1",
    "title": "Statistical Inference",
    "section": "Unbiased Estimator",
    "text": "Unbiased Estimator\nit is desirable to use an estimator \\(\\delta\\) whose distribution changes with the value of \\(\\theta\\) in such a way that no matter what the true value of \\(\\theta\\) is, the probability distribution of \\(\\delta\\) is concentrated around \\(g(\\theta)\\). For example, suppose that \\(\\boldsymbol{X}=\\left(X_1, \\ldots, X_n\\right)\\) form a random sample from a normal distribution for which the mean \\(\\theta\\) is unknown and the variance is 1 . In this case, the M.L.E. of \\(\\theta\\) is the sample mean \\(\\bar{X}_n\\). The estimator \\(\\bar{X}_n\\) is a reasonably good estimator of \\(\\theta\\) because its distribution is the normal distribution with mean \\(\\theta\\) and variance \\(1 / n\\). This distribution is concentrated around the unknown value of \\(\\theta\\), no matter how large or how small \\(\\theta\\) is."
  },
  {
    "objectID": "w09/notes.html#unbiased-estimator-2",
    "href": "w09/notes.html#unbiased-estimator-2",
    "title": "Statistical Inference",
    "section": "Unbiased Estimator",
    "text": "Unbiased Estimator\nUnbiased Estimator/Bias. An estimator \\(\\delta(\\boldsymbol{X})\\) is an unbiased estimator of a function \\(g(\\theta)\\) of the parameter \\(\\theta\\) if \\(E_\\theta[\\delta(\\boldsymbol{X})]=g(\\theta)\\) for every possible value of \\(\\theta\\). An estimator that is not unbiased is called a biased estimator. The difference between the expectation of an estimator and \\(g(\\theta)\\) is called the bias of the estimator. That is, the bias of \\(\\delta\\) as an estimator of \\(g(\\theta)\\) is \\(E_\\theta[\\delta(\\boldsymbol{X})]-g(\\theta)\\), and \\(\\delta\\) is unbiased if and only if the bias is 0 for all \\(\\theta\\).\nIn the case of a sample from a normal distribution with unknown mean \\(\\theta, \\bar{X}_n\\) is an unbiased estimator of \\(\\theta\\) because \\(E_\\theta\\left(\\bar{X}_n\\right)=\\theta\\) for \\(-\\infty&lt;\\theta&lt;\\infty\\)\n Source: DeGroot and Schervish, Definition 8.7.1"
  },
  {
    "objectID": "w09/notes.html#example-poisson-distribution-1",
    "href": "w09/notes.html#example-poisson-distribution-1",
    "title": "Statistical Inference",
    "section": "Example: Poisson Distribution",
    "text": "Example: Poisson Distribution\n\nThe maximum likelihood estimator for \\(\\lambda\\) is the sample mean, \\(\\hat{\\lambda}=\\bar{X}\\). We know that \\[\n\\mathcal{E}\\left(X_i\\right)=\\lambda \\Longrightarrow \\mathcal{E}(\\bar{X})=\\lambda .\n\\]\nTherefore,\n\n\\[\n\\mathcal{E}(\\hat{\\lambda})-\\lambda=0\n\\]\n\nThis estimator is unbiased."
  },
  {
    "objectID": "w09/notes.html#exponential-distribution",
    "href": "w09/notes.html#exponential-distribution",
    "title": "Statistical Inference",
    "section": "Exponential Distribution",
    "text": "Exponential Distribution\nThe maximum likelihood estimator for \\(\\lambda\\) is \\(\\hat{\\lambda}=\\frac{1}{\\bar{\\chi}}\\). We know that \\[\n\\mathcal{E}\\left(X_i\\right)=\\frac{1}{\\lambda} \\Longrightarrow \\mathcal{E}(\\bar{X})=\\frac{1}{\\lambda} .\n\\] But one can show that \\[\n\\mathcal{E}(\\hat{\\lambda})=\\mathcal{E}\\left(\\frac{1}{\\bar{X}}\\right)=\\frac{n}{n-1} \\lambda .\n\\] Can also assess and correct the bias with a simulation (“parametric bootstrap”)."
  },
  {
    "objectID": "w09/notes.html#calculation-1-1",
    "href": "w09/notes.html#calculation-1-1",
    "title": "Statistical Inference",
    "section": "Calculation-1",
    "text": "Calculation-1"
  },
  {
    "objectID": "w09/notes.html#calculation-2",
    "href": "w09/notes.html#calculation-2",
    "title": "Statistical Inference",
    "section": "Calculation-2",
    "text": "Calculation-2"
  },
  {
    "objectID": "w09/notes.html#unbiased-estimation-of-the-variance",
    "href": "w09/notes.html#unbiased-estimation-of-the-variance",
    "title": "Statistical Inference",
    "section": "Unbiased Estimation of the Variance",
    "text": "Unbiased Estimation of the Variance\nSampling from a General Distribution. Let \\(\\boldsymbol{X}=\\left(X_1, \\ldots, X_n\\right)\\) be a random sample from a distribution that depends on a parameter (or parameter vector) \\(\\theta\\). Assume that the variance of the distribution is finite. Define \\(g(\\theta)=\\operatorname{Var}_\\theta\\left(X_1\\right)\\). The following statistic is an unbiased estimator of the variance \\(g(\\theta)\\) :\n\\[\n\\hat{\\sigma}_1^2=\\frac{1}{n-1} \\sum_{i=1}^n\\left(X_i-\\bar{X}_n\\right)^2\n\\]\n Source: DeGroot and Schervish, Theorem 8.7.1"
  },
  {
    "objectID": "w09/notes.html#example-4",
    "href": "w09/notes.html#example-4",
    "title": "Statistical Inference",
    "section": "Example",
    "text": "Example\nSampling from a Specific Family of Distributions When it can be assumed that \\(X_1, \\ldots, X_n\\) form a random sample from a specific family of distributions, such as the family of Poisson distributions, it will generally be desirable to consider not only \\(\\hat{\\sigma}_1^2\\) but also other unbiased estimators of the variance.\nSample from a Poisson Distribution. Suppose that we observe a random sample from the Poisson distribution for which the mean \\(\\theta\\) is unknown. We have already seen that \\(\\bar{X}_n\\) will be an unbiased estimator of the mean \\(\\theta\\). Moreover, since the variance of a Poisson distribution is also equal to \\(\\theta\\), it follows that \\(\\bar{X}_n\\) is also an unbiased estimator of the variance. In this example, therefore, both \\(\\bar{X}_n\\) and \\(\\hat{\\sigma}_1^2\\) are unbiased estimators of the unknown variance \\(\\theta\\). Furthermore, any combination of \\(\\bar{X}_n\\) and \\(\\hat{\\sigma}_1^2\\) having the form \\(\\alpha \\bar{X}_n+(1-\\alpha) \\hat{\\sigma}_1^2\\), where \\(\\alpha\\) is a given constant \\((-\\infty&lt;\\alpha&lt;\\infty)\\), will also be an unbiased estimator of \\(\\theta\\) because its expectation will be \\[\nE\\left[\\alpha \\bar{X}_n+(1-\\alpha) \\hat{\\sigma}_1^2\\right]=\\alpha E\\left(\\bar{X}_n\\right)+(1-\\alpha) E\\left(\\hat{\\sigma}_1^2\\right)=\\alpha \\theta+(1-\\alpha) \\theta=\\theta\n\\] Other unbiased estimators of \\(\\theta\\) can also be constructed."
  },
  {
    "objectID": "w09/notes.html#mean-square-error",
    "href": "w09/notes.html#mean-square-error",
    "title": "Statistical Inference",
    "section": "Mean Square Error",
    "text": "Mean Square Error\nCombine variance and bias to assess quality of an estimator: MSE\nFor an estimator \\(\\hat{\\theta}\\), \\[\n\\operatorname{MSE}(\\hat{\\theta})=\\mathcal{E}\\left((\\hat{\\theta}-\\theta)^2\\right)=\\operatorname{var}(\\hat{\\theta})+\\operatorname{bias}(\\hat{\\theta})^2\n\\]"
  },
  {
    "objectID": "w09/notes.html#mse",
    "href": "w09/notes.html#mse",
    "title": "Statistical Inference",
    "section": "MSE",
    "text": "MSE\nProposition 6.4 MSE \\([\\hat{\\theta}]=\\operatorname{Var}[\\hat{\\theta}]+\\operatorname{Bias}[\\hat{\\theta}]^2\\). Proof \\[\n\\begin{aligned}\n\\operatorname{MSE}[\\hat{\\theta}] & =\\mathrm{E}\\left[(\\hat{\\theta}-\\theta)^2\\right] \\\\\n& =\\mathrm{E}\\left[(\\hat{\\theta}-\\mathrm{E}[\\hat{\\theta}]+\\mathrm{E}[\\hat{\\theta}]-\\theta)^2\\right] \\\\\n& =\\mathrm{E}\\left[((\\hat{\\theta}-\\mathrm{E}[\\hat{\\theta}])+(\\mathrm{E}[\\hat{\\theta}]-\\theta))^2\\right] \\\\\n& =\\mathrm{E}\\left[(\\hat{\\theta}-\\mathrm{E}[\\hat{\\theta}])^2\\right]+2 \\mathrm{E}[\\hat{\\theta}-\\mathrm{E}[\\hat{\\theta}]](\\mathrm{E}[\\hat{\\theta}]-\\theta)+(\\mathrm{E}[\\hat{\\theta}]-\\theta)^2 \\\\\n& =\\operatorname{Var}[\\hat{\\theta}]+(\\operatorname{Bias}[\\hat{\\theta}])^2\n\\end{aligned}\n\\] Also, if \\(\\hat{\\theta}\\) is unbiased, then \\(\\operatorname{MSE}[\\theta]=\\operatorname{Var}[\\hat{\\theta}]\\). So, the unbiased estimator \\(\\hat{\\theta}_1\\) of \\(\\theta\\) is more efficient than the unbiased estimator \\(\\hat{\\theta}_2\\) if and only if \\(\\operatorname{MSE}\\left[\\hat{\\theta}_1\\right]&lt;\\operatorname{MSE}\\left[\\hat{\\theta}_2\\right]\\)."
  },
  {
    "objectID": "w09/notes.html#mse-1",
    "href": "w09/notes.html#mse-1",
    "title": "Statistical Inference",
    "section": "MSE",
    "text": "MSE\nDefinition. Let \\(T\\) be an estimator for a parameter \\(\\theta\\). The mean squared error of \\(T\\) is the number \\(\\operatorname{MSE}(T)=\\mathrm{E}\\left[(T-\\theta)^2\\right]\\). According to this criterion, an estimator \\(T_1\\) performs better than an estimator \\(T_2\\) if \\(\\operatorname{MSE}\\left(T_1\\right)&lt;\\operatorname{MSE}\\left(T_2\\right)\\). Note that \\[\n\\begin{aligned}\n\\operatorname{MSE}(T) & =\\mathrm{E}\\left[(T-\\theta)^2\\right] \\\\\n& =\\mathrm{E}\\left[(T-\\mathrm{E}[T]+\\mathrm{E}[T]-\\theta)^2\\right] \\\\\n& =\\mathrm{E}\\left[(T-\\mathrm{E}[T])^2\\right]+2 \\mathrm{E}[T-\\mathrm{E}[T]](\\mathrm{E}[T]-\\theta)+(\\mathrm{E}[T]-\\theta)^2 \\\\\n& =\\operatorname{Var}(T)+(\\mathrm{E}[T]-\\theta)^2 .\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "w09/notes.html#efficiency",
    "href": "w09/notes.html#efficiency",
    "title": "Statistical Inference",
    "section": "Efficiency",
    "text": "Efficiency\nEFFICIENCY. Let \\(T_1\\) and \\(T_2\\) be two unbiased estimators for the same parameter \\(\\theta\\). Then estimator \\(T_2\\) is called more efficient than estimator \\(T_1\\) if \\(\\operatorname{Var}\\left(T_2\\right)&lt;\\operatorname{Var}\\left(T_1\\right)\\), irrespective of the value of \\(\\theta\\)."
  },
  {
    "objectID": "w09/notes.html#note",
    "href": "w09/notes.html#note",
    "title": "Statistical Inference",
    "section": "Note",
    "text": "Note\nSo the MSE of \\(T\\) turns out to be the variance of \\(T\\) plus the square of the bias of \\(T\\). In particular, when \\(T\\) is unbiased, the MSE of \\(T\\) is just the variance of \\(T\\). This means that we already used mean squared errors to compare the estimators \\(T_1\\) and \\(T_2\\) in the previous section. We extend the notion of efficiency by saying that estimator \\(T_2\\) is more efficient than estimator \\(T_1\\) (for the same parameter of interest), if the MSE of \\(T_2\\) is smaller than the MSE of \\(T_1\\)."
  },
  {
    "objectID": "w09/notes.html#efficiency-1",
    "href": "w09/notes.html#efficiency-1",
    "title": "Statistical Inference",
    "section": "Efficiency",
    "text": "Efficiency\n\nGiven two estimators \\(\\hat{\\theta}_1, \\hat{\\theta}_2\\) for the same parameter. If both are unbiased, the one with smaller variance is better (“more efficient”).\nRelative Efficiency of \\(\\hat{\\theta}_1\\) wrt. \\(\\hat{\\theta}_2\\)\nAssuming \\(\\mathcal{E}\\left(\\hat{\\theta}_1\\right)=\\mathcal{E}\\left(\\hat{\\theta}_2\\right)=\\theta\\), this is defined as \\[\nE=\\operatorname{var}\\left(\\hat{\\theta}_2\\right) / \\operatorname{var}\\left(\\hat{\\theta}_1\\right)\n\\]\nIf \\(\\hat{\\theta}_2\\) is used instead of \\(\\hat{\\theta}_1\\), the sample size must be increased by a factor \\(E\\) to get the same accuracy."
  },
  {
    "objectID": "w09/notes.html#example-mean-and-median",
    "href": "w09/notes.html#example-mean-and-median",
    "title": "Statistical Inference",
    "section": "Example: Mean and Median",
    "text": "Example: Mean and Median\n\nConsider data from a normal distribution, \\(N(\\mu, 1)\\). Can estimate \\(\\mu\\) in two ways from a sample \\(x=\\left(x_1, \\ldots, x_n\\right)\\) : \\[\n\\hat{\\mu}_1=\\bar{x}, \\quad \\hat{\\mu}_2=\\operatorname{median}(x)\n\\]\nWhat is the relative efficiency?"
  },
  {
    "objectID": "w09/notes.html#example-5",
    "href": "w09/notes.html#example-5",
    "title": "Statistical Inference",
    "section": "Example",
    "text": "Example\nExercise 6.4 #28 in Chihara/Hesterberg. 28. Let \\(\\hat{\\theta}_1\\) and \\(\\hat{\\theta}_2\\) be two estimators of \\(\\theta\\) with \\(\\mathrm{E}\\left[\\hat{\\theta}_1\\right]=0.9 \\theta\\) and \\(\\mathrm{E}\\left[\\hat{\\theta}_2\\right]=1.2 \\theta\\). Also, suppose \\(\\operatorname{Var}\\left[\\hat{\\theta}_1\\right]=3\\) and \\(\\operatorname{Var}\\left[\\hat{\\theta}_2\\right]=2\\). Find two unbiased estimators of \\(\\theta\\) and determine which one is more efficient. Solution Set \\(\\tilde{\\theta}_1=\\frac{\\hat{\\theta}_1}{0.9}\\) and \\(\\tilde{\\theta}_2=\\frac{\\hat{\\theta}_2}{1.2}\\). Then \\(E\\left(\\tilde{\\theta}_1\\right)=\\frac{0.9}{0.9} \\theta=\\theta\\) and similarly \\(E\\left(\\tilde{\\theta}_2\\right)=\\theta\\), so both are unbiased. Also, \\(\\operatorname{Var}\\left(\\tilde{\\theta}_1\\right)=\\frac{3}{0.9^2} \\approx 3.76\\) and \\(\\operatorname{Var}\\left(\\tilde{\\theta}_2\\right)=\\frac{2}{1.2^2} \\approx 1.39\\), so \\(\\tilde{\\theta}_2\\) is more efficient."
  },
  {
    "objectID": "w09/notes.html#calculation-3",
    "href": "w09/notes.html#calculation-3",
    "title": "Statistical Inference",
    "section": "Calculation",
    "text": "Calculation"
  },
  {
    "objectID": "w09/notes.html#bias-variance-trade-off---a-look-ahead",
    "href": "w09/notes.html#bias-variance-trade-off---a-look-ahead",
    "title": "Statistical Inference",
    "section": "Bias-Variance Trade Off - a look ahead",
    "text": "Bias-Variance Trade Off - a look ahead\nConsider \\(M S E^2=\\) bias \\(^2+\\) var . More complex models (with more parameters) tend to have less bias (are more flexible) and more variance (are more susceptible to noise)."
  },
  {
    "objectID": "w09/slides.html#what-are-we-covering-today",
    "href": "w09/slides.html#what-are-we-covering-today",
    "title": "Week 9: Statistical Inference",
    "section": "What are we covering today?",
    "text": "What are we covering today?\n\nLarge Random Samples (Chapter 6)\n\n\nLaw of Large Numbers\nThe Central Limit Theorem\n\n\nEstimation\n\n\nMaximum Likelihood Estimators\nMethod of Moments\nUnbiased Estimators\nEfficiency"
  },
  {
    "objectID": "w09/slides.html#large-random-samples",
    "href": "w09/slides.html#large-random-samples",
    "title": "Week 9: Statistical Inference",
    "section": "Large Random Samples",
    "text": "Large Random Samples"
  },
  {
    "objectID": "w09/slides.html#what-is-the-law-of-large-numbers",
    "href": "w09/slides.html#what-is-the-law-of-large-numbers",
    "title": "Week 9: Statistical Inference",
    "section": "What Is the Law of Large Numbers?",
    "text": "What Is the Law of Large Numbers?\n\nThe law of large numbers, in probability and statistics, states that as a sample size grows, its mean gets closer to the average of the whole population.\nIn the 16th century, mathematician Gerolama Cardano recognized the Law of Large Numbers but never proved it.\nIn 1713, Swiss mathematician Jakob Bernoulli proved this theorem in his book, Ars Conjectandi.\nIt was later refined by other noted mathematicians, such as Pafnuty Chebyshev, founder of the St. Petersburg mathematical school. https://www.investopedia.com/terms/l/lawoflargenumbers.asp"
  },
  {
    "objectID": "w09/slides.html#statistical-convergence",
    "href": "w09/slides.html#statistical-convergence",
    "title": "Week 9: Statistical Inference",
    "section": "Statistical convergence",
    "text": "Statistical convergence\n\nStatistical convergence involves the tendency of a sequence of random variables to stabilize in distribution as the sample size increases, indicating a likelihood of approaching a limiting behavior in a probabilistic sense rather than pointwise certainty.\n\n\nGood visual resource: https://seeing-theory.brown.edu/basic-probability/index.html#section1"
  },
  {
    "objectID": "w09/slides.html#quote",
    "href": "w09/slides.html#quote",
    "title": "Week 9: Statistical Inference",
    "section": "Quote",
    "text": "Quote\n“The Law of Large Numbers has nothing whatever to do with growth. What it actually says is that as a large number of samples of a random variable are taken from a population, the mean of the samples approaches the expected value of the population. In other (and simplified) terms, the larger your sample the better your estimate of the actual value… the basis of all sampling, polling, and inferential statistics…\n“So what do we call the principle that the growth rate of things tends to slow as they get larger? The idea is kind of obvious, which may be why it doesn’t have a name [so] I propose we call it the logistic principle.”\n\nSteve Wildstrom (via Techpinions, highlights courtesy of Annotote)"
  },
  {
    "objectID": "w09/slides.html#applications-of-the-law-of-large-numbers",
    "href": "w09/slides.html#applications-of-the-law-of-large-numbers",
    "title": "Week 9: Statistical Inference",
    "section": "Applications of the Law of Large Numbers",
    "text": "Applications of the Law of Large Numbers\n\nVehicle Automation\n\nAI development for self-driving vehicles takes the law of large numbers quite literally, and runs with it (pun intended). Tesla for example, parses and collates data from countless Tesla car users, “using billions of miles to train neural networks”.\nIn this example, car mileage data is averaged to plot out and optimize paths and driving policies. Recorded video and images are repeatedly analyzed by the AI, so that it eventually predicts visual elements with a reliable rate of probability. Even data involving the driving decisions of other cars on the road, is averaged to help the AI make better predictions of what other drivers are most likely to do in the near future.\n\nhttps://www.analyticssteps.com/blogs/how-tesla-making-use-artificial-intelligence-its-operations\nModel Y Unveil: Elon Musk\nhttps://www.youtube.com/watch?v=Tb_Wn6K0uVs&feature=emb_logo\nTesla has taken excellent use of AI and Big Data for expanding its customer base. The firm has made use of existing customer databases for its data analytics using it to comprehend customer requirements and regularly updating their systems accordingly\nhttps://medium.com/kambria-network/the-importance-of-the-law-of-large-numbers-in-ai-ea55d8af21cf"
  },
  {
    "objectID": "w09/slides.html#applications-of-the-law-of-large-numbers-1",
    "href": "w09/slides.html#applications-of-the-law-of-large-numbers-1",
    "title": "Week 9: Statistical Inference",
    "section": "Applications of the Law of Large Numbers",
    "text": "Applications of the Law of Large Numbers\nOther notable demonstrations of the law of large numbers in \\(\\mathrm{AI}\\) that are potential game changers, such as deep learning-based weather prediction and the ever-improving gambling AI, are also bound to shape the future of our world in some way, and could take us to directions we have yet to even begin to consider. As one Google Translate engineer put it, “when you go from 10,000 training examples to 10 billion training examples, it all starts to work. Data trumps everything.” Garry Kasparov, yes the man defeated in chess by the AI Deep_Blue, mentions this quote from his book Deep Thinking: Where Machine Intelligence Ends and Human Creativity Begins. This one sentence sums up succinctly why the law of large numbers is inevitably intertwined with AI.\nhttps://medium.com/kambria-network/the-importance-of-the-law-of-large-numbers-in-ai-ea55d8af21cf"
  },
  {
    "objectID": "w09/slides.html#the-law-of-large-numbers",
    "href": "w09/slides.html#the-law-of-large-numbers",
    "title": "Week 9: Statistical Inference",
    "section": "The Law of Large Numbers",
    "text": "The Law of Large Numbers\nThe average of a random sample of i.i.d. random variables is called their sample mean.\nThe sample mean is useful for summarizing the information in a random sample in much the same way that the mean of a probability distribution summarizes the information in the distribution.\nIn this section, we present some results that illustrate the connection between the sample mean and the expected value of the individual random variables that comprise the random sample.\nFun Interactive Viz:\nhttps://seeing-theory.brown.edu/basic-probability/index.html#section1"
  },
  {
    "objectID": "w09/slides.html#properties-of-the-sample-mean",
    "href": "w09/slides.html#properties-of-the-sample-mean",
    "title": "Week 9: Statistical Inference",
    "section": "Properties of the Sample Mean",
    "text": "Properties of the Sample Mean\nIn Definition 5.6.3, we defined the sample mean of \\(n\\) random variables \\(X_1, \\ldots, X_n\\) to be their average, \\[\n\\bar{X}_n=\\frac{1}{n}\\left(X_1+\\cdots+X_n\\right) .\n\\] The mean and the variance of \\(\\bar{X}_n\\) are easily computed."
  },
  {
    "objectID": "w09/slides.html#properties-of-the-sample-mean-1",
    "href": "w09/slides.html#properties-of-the-sample-mean-1",
    "title": "Week 9: Statistical Inference",
    "section": "Properties of the Sample Mean",
    "text": "Properties of the Sample Mean\nMean and Variance of the Sample Mean. Let \\(X_1, \\ldots, X_n\\) be a random sample fron a distribution with mean \\(\\mu\\) and variance \\(\\sigma^2\\). Let \\(\\bar{X}_n\\) be the sample mean. The \\(E\\left(\\bar{X}_n\\right)=\\mu\\) and \\(\\operatorname{Var}\\left(\\bar{X}_n\\right)=\\sigma^2 / n\\). Proof It follows from Theorems 4.2.1 and 4.2.4 that \\[\nE\\left(\\bar{X}_n\\right)=\\frac{1}{n} \\sum_{i=1}^n E\\left(X_i\\right)=\\frac{1}{n} \\cdot n \\mu=\\mu .\n\\] Furthermore, since \\(X_1, \\ldots, X_n\\) are independent, Theorems 4.3.4 and 4.3.5 say that \\[\n\\begin{aligned}\n\\operatorname{Var}\\left(\\bar{X}_n\\right) & =\\frac{1}{n^2} \\operatorname{Var}\\left(\\sum_{i=1}^n X_i\\right) \\\\\n& =\\frac{1}{n^2} \\sum_{i=1}^n \\operatorname{Var}\\left(X_i\\right)=\\frac{1}{n^2} \\cdot n \\sigma^2=\\frac{\\sigma^2}{n}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "w09/slides.html#extra-notes-converges-in-probability",
    "href": "w09/slides.html#extra-notes-converges-in-probability",
    "title": "Week 9: Statistical Inference",
    "section": "Extra Notes: Converges in Probability",
    "text": "Extra Notes: Converges in Probability\nConvergence in Probability. A sequence \\(Z_1, Z_2, \\ldots\\) of random variables converges to \\(b\\) in probability if for every number \\(\\varepsilon&gt;0\\), \\[\n\\lim _{n \\rightarrow \\infty} \\operatorname{Pr}\\left(\\left|Z_n-b\\right|&lt;\\varepsilon\\right)=1 .\n\\] This property is denoted by \\[\nZ_n \\stackrel{p}{\\longrightarrow} b,\n\\] and is sometimes stated simply as \\(Z_n\\) converges to \\(b\\) in probability.\nIn other words, \\(Z_n\\) converges to \\(b\\) in probability if the probability that \\(Z_n\\) lies in each given interval around \\(b\\), no matter how small this interval may be, approaches 1 as \\(n \\rightarrow \\infty\\)."
  },
  {
    "objectID": "w09/slides.html#extra-notes-convergence-in-probability",
    "href": "w09/slides.html#extra-notes-convergence-in-probability",
    "title": "Week 9: Statistical Inference",
    "section": "Extra Notes: Convergence in probability",
    "text": "Extra Notes: Convergence in probability\nLet \\(S_n=\\frac{1}{n} \\sum_{j=1}^n X_j\\) be the sample mean of the first \\(n\\) observations. if you have a sample of independent and identically distributed random variables, as the sample size grows larger, the sample mean will tend toward the population mean. \\[\nP\\left(\\left|S_n-\\mu\\right|&gt;\\epsilon\\right) \\rightarrow 0 \\quad \\text { for any } \\quad \\epsilon&gt;0\n\\] - This is called “convergence in probability”. - The probability of seeing the event \\(\\left|S_n-\\mu\\right|&gt;\\epsilon\\) becomes very small as \\(n\\) becomes large. - \\(\\quad\\) Box plot, histograms of the \\(S_n\\) etc. all become closer and closer to the constant \\(\\mu\\). - This is a statement about individual observations: Eventually most \\(S_n\\) are close to \\(\\mu\\)."
  },
  {
    "objectID": "w09/slides.html#extra-notes-weak-law-of-large-numbers",
    "href": "w09/slides.html#extra-notes-weak-law-of-large-numbers",
    "title": "Week 9: Statistical Inference",
    "section": "Extra Notes: Weak Law of Large Numbers",
    "text": "Extra Notes: Weak Law of Large Numbers\n(Weak Law of Large Numbers) Let \\(X_1, X_2, \\ldots, X_n\\) be a sequence of mutually independent and identically distributed random variables each of which has a finite mean \\(E\\left[X_k\\right]=\\mu_X&lt;\\infty, k=1,2, \\ldots, n\\). Let \\(S_n\\) be the linear sum of the \\(n\\) random variables; that is, \\[\nS_n=X_1+X_2+\\cdots+X_n\n\\] Then for any \\(\\varepsilon&gt;0\\), \\[\n\\lim _{n \\rightarrow \\infty} P\\left[\\left|\\frac{S_n}{n}-\\mu_X\\right| \\geq \\varepsilon\\right] \\rightarrow 0\n\\] Alternatively, \\[\n\\lim _{n \\rightarrow \\infty} P\\left[\\left|\\frac{S_n}{n}-\\mu_X\\right|&lt;\\varepsilon\\right] \\rightarrow 1\n\\] Proof: By definition, \\[\n\\begin{gathered}\nS_n=X_1+X_2+\\cdots+X_n \\\\\n\\bar{S}_n=\\frac{S_n}{n}=\\frac{X_1+X_2+\\cdots+X_n}{n}=\\frac{n \\mu_X}{n}=\\mu_X \\\\\n\\operatorname{Var}\\left(\\bar{S}_n\\right)=\\operatorname{Var}\\left\\{\\frac{X_1+X_2+\\cdots+X_n}{n}\\right\\} \\\\\n=\\frac{1}{n^2}\\left\\{\\operatorname{Var}\\left(X_1\\right)+\\operatorname{Var}\\left(X_2\\right)+\\cdots+\\operatorname{Var}\\left(X_n\\right)\\right\\}=\\frac{n \\sigma_X^2}{n^2}\n\\end{gathered}\n\\] https://www.sciencedirect.com/book/9780128008522/fundamentals-of-applied-probability-and-random-processes"
  },
  {
    "objectID": "w09/slides.html#extra-notes-strong-law-of-large-numbers",
    "href": "w09/slides.html#extra-notes-strong-law-of-large-numbers",
    "title": "Week 9: Statistical Inference",
    "section": "Extra Notes: Strong Law of Large Numbers",
    "text": "Extra Notes: Strong Law of Large Numbers\n(Strong Law of Large Numbers) Let \\(X_1, X_2, \\ldots, X_n\\) be a sequence of mutually independent and identically distributed random variables each of which has a finite mean \\(E\\left[X_k\\right]=\\mu_X&lt;\\infty, k=1,2, \\ldots, n\\). Let \\(S_n\\) be the linear sum of the \\(n\\) random variables; that is, \\[\nS_n=X_1+X_2+\\cdots+X_n\n\\] Then for any \\(\\varepsilon&gt;0\\), \\[\nP\\left[\\lim _{n \\rightarrow \\infty}\\left|\\bar{S}_n-\\mu_X\\right|&gt;\\varepsilon\\right]=0\n\\] where \\(\\bar{S}_n=S_n / n\\). An alternativ statement of the law is \\[\nP\\left[\\lim _{n \\rightarrow \\infty}\\left|\\bar{S}_n-\\mu_X\\right| \\leq \\varepsilon\\right]=1\n\\] https://www.sciencedirect.com/book/9780128008522/fundamentals-of-applied-probability-and-random-processes"
  },
  {
    "objectID": "w09/slides.html#extra-notes-wlln-slln",
    "href": "w09/slides.html#extra-notes-wlln-slln",
    "title": "Week 9: Statistical Inference",
    "section": "Extra Notes: WLLN & SLLN",
    "text": "Extra Notes: WLLN & SLLN\nThe weak law of large numbers essentially states that for any nonzero specified margin, no matter how small, there is a high probability that the average of a sufficiently large number of observations will be close to the expected value within the margin. That is, \\[\n\\lim _{n \\rightarrow \\infty} \\bar{S}_n \\rightarrow \\mu_X\n\\] Alternatively, the arithmetic average \\(\\bar{S}_n\\) of a sequence of independent observations of a random variable \\(X\\) converges with probability \\(I\\) to the expected value \\(\\mu_X\\) of \\(X\\). Thus, the weak law is a convergence statement about a sequence of probabilities; it states that the sequence of random variables \\(\\left\\{\\bar{S}_n\\right\\}\\) converges in probability to the population mean \\(\\mu_X\\) as \\(n\\) becomes very large.\nThe strong law of large numbers states that with probability 1 the sequence of sample means \\(\\bar{S}_n\\) converges to a constant value \\(\\mu_x\\), which is the population mean of the random variables, as \\(n\\) becomes very large. This validates the relative-frequency definition of probability.\nhttps://www.sciencedirect.com/book/9780128008522/fundamentals-of-applied-probability-and-random-processes"
  },
  {
    "objectID": "w09/slides.html#extra-notes-strong-law-of-large-numbers-1",
    "href": "w09/slides.html#extra-notes-strong-law-of-large-numbers-1",
    "title": "Week 9: Statistical Inference",
    "section": "Extra Notes: Strong Law of large numbers",
    "text": "Extra Notes: Strong Law of large numbers\n\\(S_n \\rightarrow \\mu \\quad\\) with probability 1\n\nThis is called “almost sure convergence. The probability that \\(S_n\\) does not converge to 0 is zero.\nThis is also a statement about individual observations: Eventually practically every \\(S_n\\) is close to \\(\\mu\\)."
  },
  {
    "objectID": "w09/slides.html#summary",
    "href": "w09/slides.html#summary",
    "title": "Week 9: Statistical Inference",
    "section": "Summary",
    "text": "Summary\nStrong Law of Large Number The strong law of large numbers states that with probability 1 the sequence of sample means \\(S^{-} n\\) converges to a constant value \\(\\mu \\mathrm{X}\\), which is the population mean of the random variables, as \\(n\\) becomes very large. From: Fundamentals of Applied Probability and Random Processes (Second Edition), 2014\nWeak Law of Large Number The weak law of large numbers essentially states that for any nonzero specified margin, no matter how small, there is a high probability that the average of a sufficiently large number of observations will be close to the expected value within the margin. From: Fundamentals of Applied Probability and Random Processes (Second Edition), 2014\nhttps://www.sciencedirect.com/topics/mathematics/strong-law-of-large-number\nhttps://www.sciencedirect.com/topics/mathematics/weak-law-of-large-number#:~:text=6.9%20Laws%20of%20Large%20Numbers&text=One%20law%20is%20called%20the,variables%20behaves%20in%20the%20limit."
  },
  {
    "objectID": "w09/slides.html#law-of-large-numbers",
    "href": "w09/slides.html#law-of-large-numbers",
    "title": "Week 9: Statistical Inference",
    "section": "Law of Large Numbers",
    "text": "Law of Large Numbers"
  },
  {
    "objectID": "w09/slides.html#motivation",
    "href": "w09/slides.html#motivation",
    "title": "Week 9: Statistical Inference",
    "section": "Motivation",
    "text": "Motivation\nThe Central Limit Theorem states that, regardless of the original distribution, the sum (or average) of a sufficiently large number of independent and identically distributed random variables will converge to a normal distribution."
  },
  {
    "objectID": "w09/slides.html#visualization",
    "href": "w09/slides.html#visualization",
    "title": "Week 9: Statistical Inference",
    "section": "Visualization",
    "text": "Visualization\nGood Interactive Viz: https://seeing-theory.brown.edu/probability-distributions/index.html#section3"
  },
  {
    "objectID": "w09/slides.html#statement",
    "href": "w09/slides.html#statement",
    "title": "Week 9: Statistical Inference",
    "section": "Statement",
    "text": "Statement\nThe central limit theorem states the distribution of sample means should be approximately normal.\nCentral Limit Theorem (Lindeberg and Lévy). If the random variables \\(X_1, \\ldots, X_n\\) form a random sample of size \\(n\\) from a given distribution with mean \\(\\mu\\) and variance \\(\\sigma^2\\) \\(\\left(0&lt;\\sigma^2&lt;\\infty\\right)\\), then for each fixed number \\(x\\), \\[\n\\lim _{n \\rightarrow \\infty} \\operatorname{Pr}\\left[\\frac{\\bar{X}_n-\\mu}{\\sigma / n^{1 / 2}} \\leq x\\right]=\\Phi(x),\n\\] where \\(\\Phi\\) denotes the c.d.f. of the standard normal distribution."
  },
  {
    "objectID": "w09/slides.html#clt",
    "href": "w09/slides.html#clt",
    "title": "Week 9: Statistical Inference",
    "section": "CLT",
    "text": "CLT\nLet \\(S_n=\\frac{1}{n} \\sum_{j=1}^n X_j\\) be the sample mean of the first \\(n\\) observations. For large \\(n\\) \\[\n\\sqrt{n} \\frac{S_n-\\mu}{\\sigma} \\sim N(0,1) \\quad \\text { approximately }\n\\] The distribution of \\(\\sqrt{n} \\frac{S_n-\\mu}{\\sigma}\\) is close to \\(N(0,1)\\) for large \\(n\\). Formally, \\[\nP\\left(a \\leq \\sqrt{n} \\frac{S_n-\\mu}{\\sigma} \\leq b\\right) \\rightarrow P(a \\leq Z \\leq b)\n\\] as \\(n \\rightarrow \\infty\\), for any \\(a, b\\), where \\(Z \\sim N(0,1)\\). - Box plot, histograms, etc. all become closer and closer to the constant \\(\\mu\\) and also become more bell-shaped. - \\(\\quad\\) qqnorm() plots become straight lines. - \\(\\quad\\) This is exact if the \\(X_i\\) already have normal distributions."
  },
  {
    "objectID": "w09/slides.html#extra-notes-convergence-in-distribution",
    "href": "w09/slides.html#extra-notes-convergence-in-distribution",
    "title": "Week 9: Statistical Inference",
    "section": "Extra Notes: Convergence in Distribution",
    "text": "Extra Notes: Convergence in Distribution\n\nThis is called convergence in distribution. We can say something about the probability distribution of the \\(S_n\\) as \\(n\\) becomes large.\nIt’s not a statement about individual observations.\nBut it is a stronger (more precise) statement that the Law of Large Numbers."
  },
  {
    "objectID": "w09/slides.html#clt-1",
    "href": "w09/slides.html#clt-1",
    "title": "Week 9: Statistical Inference",
    "section": "CLT",
    "text": "CLT\n\nThe sampling distribution of the sample means approaches a normal distribution as the sample size gets larger - no matter what the shape of the population distribution.\nIf you sample batches of data from any distribution and take the mean of each batch. Then the distribution of the means is going to resemble a Gaussian distribution. (Same goes for taking the sum)"
  },
  {
    "objectID": "w09/slides.html#example",
    "href": "w09/slides.html#example",
    "title": "Week 9: Statistical Inference",
    "section": "Example",
    "text": "Example"
  },
  {
    "objectID": "w09/slides.html#clt-2",
    "href": "w09/slides.html#clt-2",
    "title": "Week 9: Statistical Inference",
    "section": "CLT",
    "text": "CLT\n\nNo matter what is the population distribution is, by CLT for large samples, sample mean will follow a normal distribution."
  },
  {
    "objectID": "w09/slides.html#clt-applications",
    "href": "w09/slides.html#clt-applications",
    "title": "Week 9: Statistical Inference",
    "section": "CLT Applications",
    "text": "CLT Applications"
  },
  {
    "objectID": "w09/slides.html#motivating-example",
    "href": "w09/slides.html#motivating-example",
    "title": "Week 9: Statistical Inference",
    "section": "Motivating example",
    "text": "Motivating example"
  },
  {
    "objectID": "w09/slides.html#example-1",
    "href": "w09/slides.html#example-1",
    "title": "Week 9: Statistical Inference",
    "section": "Example",
    "text": "Example\n\nPossible samples and sample means of samples of size 2"
  },
  {
    "objectID": "w09/slides.html#summary-1",
    "href": "w09/slides.html#summary-1",
    "title": "Week 9: Statistical Inference",
    "section": "Summary",
    "text": "Summary\nWe all understand intuitively that the average of many measurements of the same unknown quantity tends to give a better estimate than a single measurement. Intuitively, this is because the random error of each measurement cancels out in the average. In these notes we will make this intuition precise in two ways: the law of large numbers (LoLN) and the central limit theorem (CLT).\nBriefly, both the law of large numbers and central limit theorem are about many independent samples from same distribution. The LoLN tells us two things: 1. The average of many independent samples is (with high probability) close to the mean of the underlying distribution. 2. This density histogram of many independent samples is (with high probability) close to the graph of the density of the underlying distribution.\nhttps://ocw.mit.edu/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/readings/ MIT18_05S14_Reading6b.pdf\n\nLoLN: As \\(n\\) grows, the probability that \\(X_n\\) is close to \\(\\mu\\) goes to 1 .\nCLT: As \\(n\\) grows, the distribution of \\(\\bar{X}_n\\) converges to the normal distribution \\(N\\left(\\mu, \\sigma^2 / n\\right)\\). Before giving a more formal statement of the LoLN, let’s unpack its meaning through a concrete example (we’ll return to the CLT later on)."
  },
  {
    "objectID": "w09/slides.html#sample",
    "href": "w09/slides.html#sample",
    "title": "Week 9: Statistical Inference",
    "section": "Sample",
    "text": "Sample\n\nA good sample must be….\nRepresentative of the population,\nBig enough to draw conclusions from, which in statistics is a sample size greater or equal to 30 .\nPicked at random, so you’re not biased towards certain characteristics in the population.\nAlso number of samples taken should represent the Population."
  },
  {
    "objectID": "w09/slides.html#sums-of-normally-distributed-random-variables",
    "href": "w09/slides.html#sums-of-normally-distributed-random-variables",
    "title": "Week 9: Statistical Inference",
    "section": "Sums of Normally Distributed Random Variables",
    "text": "Sums of Normally Distributed Random Variables\n\nSuppose \\(X_1, X_2\\) are independent and \\(X_1 \\sim N\\left(\\mu_1, \\sigma_1^2\\right), X_2 \\sim N\\left(\\mu_2, \\sigma_2^2\\right)\\). Then \\[\nX_1+X_2 \\sim N\\left(\\mu_1+\\mu_2, \\sigma_1^2+\\sigma_2^2\\right)\n\\] l.e. \\(\\operatorname{Var}\\left(X_1+X_2\\right)=\\sigma_1^2+\\sigma_2^2\\).\nThis generalizes to sums of several independent normally distributed random variable.\nSuppose \\(X_1, \\ldots, X_n\\) are identically \\(N\\left(\\mu . \\sigma^2\\right)\\) distributed. Then\n\n\\[\n\\begin{aligned}\n\\frac{X_j-\\mu}{\\sigma} & \\sim N(0,1) \\\\\n\\sum_{j=1}^n X_j & \\sim N\\left(n \\mu, n \\sigma^2\\right) \\\\\nS_n & \\sim N\\left(\\mu, \\frac{\\sigma^2}{n}\\right) \\\\\n\\sqrt{n} \\frac{S_n-\\mu}{\\sigma} & \\sim N(0,1)\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "w09/slides.html#example-1-1",
    "href": "w09/slides.html#example-1-1",
    "title": "Week 9: Statistical Inference",
    "section": "Example-1",
    "text": "Example-1\nSAT Math scores of a group of Science & Engineering majors had a normal distribution with mean 609 and SD 80. We will randomly select \\(\\mathbf{1 0}\\) students from these majors.\n\nWhat is the sampling distribution of the sample average?\n\nSince the population has a Normal distribution and we took a simple random sample, \\(\\bar{y}\\) has a normal distribution (regardless of the sample size).\n\nShape: normal\nMean: \\(\\mu=609\\)\nSD: \\(\\sigma_{\\bar{y}}=\\frac{\\sigma}{\\sqrt{n}}=\\frac{80}{\\sqrt{10}}=25.298\\)\n\n\nHow often would this average be more than 630 ?\n\n\\[\n\\begin{gathered}\nz=\\frac{\\bar{y}-\\mu}{\\sigma / \\sqrt{n}}=\\frac{630-609}{25.298}=0.83 \\\\\nP(Z&gt;0.83)=1-0.7967=0.2033\n\\end{gathered}\n\\]"
  },
  {
    "objectID": "w09/slides.html#example-2",
    "href": "w09/slides.html#example-2",
    "title": "Week 9: Statistical Inference",
    "section": "Example-2",
    "text": "Example-2\nLet \\(X_1, X_2, \\ldots, X_9 \\sim \\operatorname{iidN}\\left(7,3^2\\right)\\) and let \\(Y_1, Y_2, \\ldots, Y_{12} \\sim \\operatorname{iidN}\\left(10,5^2\\right)\\). Let \\(W=\\bar{X}-\\bar{Y}\\) be the difference of the sample means. This is similar to the homework problem but not the same. I. Find the exact sampling distribution of \\(W\\) approximately. Solution \\(\\bar{X}\\) has a mean 7 and variance \\(9 / 9=1\\). \\(\\bar{Y}\\) has a mean 10 and variance \\(25 / 12=\\). By the CLT (Which applies already for normal distribution) we have a normal distribution. Therefore \\(W\\) has a normal distribution with mean \\(\\mu=7-10=-3, \\sigma^2=1+25 / 12\\)"
  },
  {
    "objectID": "w09/slides.html#statistical-inference-1",
    "href": "w09/slides.html#statistical-inference-1",
    "title": "Week 9: Statistical Inference",
    "section": "Statistical Inference",
    "text": "Statistical Inference\n\nWhat would we say is the probability that a future patient will respond successfully to treatment after we observe the results from a collection of other patients?\nThis is the kind of question that statistical inference is designed to address.\nIn general, statistical inference consists of making probabilistic statements about unknown quantities.\nFor example, we can compute means, variances, quantiles, probabilities, and some other quantities yet to be introduced concerning unobserved random variables and unknown parameters of distributions.\nOur goal will be to say what we have learned about the unknown quantities after observing some data that we believe contain relevant information."
  },
  {
    "objectID": "w09/slides.html#statistical-inference-2",
    "href": "w09/slides.html#statistical-inference-2",
    "title": "Week 9: Statistical Inference",
    "section": "Statistical Inference",
    "text": "Statistical Inference\nHere are some other examples of questions that statistical inference can try to answer.\n\nWhat can we say about whether a machine is functioning properly after we observe some of its output?\nIn a civil lawsuit, what can we say about whether there was discrimination after observing how different ethnic groups were treated?\n\nThe methods of statistical inference, which we shall develop to address these questions, are built upon the theory of probability covered in the earlier chapters of this text."
  },
  {
    "objectID": "w09/slides.html#definition",
    "href": "w09/slides.html#definition",
    "title": "Week 9: Statistical Inference",
    "section": "Definition",
    "text": "Definition\nStatistical Inference. A statistical inference is a procedure that produces a probabilistic statement about some or all parts of a statistical model.\nBy a “probabilistic statement” we mean a statement that makes use of any of the concepts of probability theory that were discussed earlier in the text or are yet to be discussed later in the text. Some examples include a mean, a conditional mean, a quantile, a variance, a conditional distribution for a random variable given another, the probability of an event, a conditional probability of an event given something, and so on. In Example 7.1.1, here are some examples of statistical inferences that one might wish to make: - Produce a random variable \\(Y\\) (a function of \\(\\left.X_1, \\ldots, X_m\\right)\\) such that \\(\\operatorname{Pr}(Y \\geq\\) \\(\\theta \\mid \\theta)=0.9\\). - Produce a random variable \\(Y\\) that we expect to be close to \\(\\theta\\). - Compute how likely it is that the average of the next 10 lifetimes, \\(\\frac{1}{10} \\sum_{i=m+1}^{m+10} X_i\\), is at least 2. - Say something about how confident we are that \\(\\theta \\leq 0.4\\) after observing \\(X_1, \\ldots\\), \\(X_m\\).\nAll of these types of inference and others will be discussed in more detail later in this book."
  },
  {
    "objectID": "w09/slides.html#statistical-decision-problems",
    "href": "w09/slides.html#statistical-decision-problems",
    "title": "Week 9: Statistical Inference",
    "section": "Statistical Decision Problems",
    "text": "Statistical Decision Problems\nIn many statistical inference problems, after the experimental data have been analyzed, we must choose a decision from some available class of decisions with the property that the consequences of each available decision depend on the unknown value of some parameter. - For example, we might have to estimate the unknown failure rate \\(\\theta\\) of our electronic components when the consequences depend on how close our estimate is to the correct value \\(\\theta\\). - As another example, we might have to decide whether the unknown proportion \\(P\\) of patients in the imipramine group (Example 7.1.3) is larger or smaller than some specified constant when the consequences depend on where \\(P\\) lies relative to the constant. - This last type of inference is closely related to hypothesis testing, the subject of Chapter 9."
  },
  {
    "objectID": "w09/slides.html#experimental-design",
    "href": "w09/slides.html#experimental-design",
    "title": "Week 9: Statistical Inference",
    "section": "Experimental Design",
    "text": "Experimental Design\nIn some statistical inference problems, we have some control over the type or the amount of experimental data that will be collected. - For example, consider an experiment to determine the mean tensile strength of a certain type of alloy as a function of the pressure and temperature at which the alloy is produced. - Within the limits of certain budgetary and time constraints, it may be possible for the experimenter to choose the levels of pressure and temperature at which experimental specimens of the alloy are to be produced, and also to specify the number of specimens to be produced at each of these levels. - Such a problem, in which the experimenter can choose (at least to some extent) the particular experiment that is to be carried out, is called a problem of experimental design. - Of course, the design of an experiment and the statistical analysis of the experimental data are closely related. - One cannot design an effective experiment without considering the subsequent statistical analysis that is to be carried out on the data that will be obtained. - And one cannot carry out a meaningful statistical analysis of experimental data without considering the particular type of experiment from which the data were derived."
  },
  {
    "objectID": "w09/slides.html#other-inferences",
    "href": "w09/slides.html#other-inferences",
    "title": "Week 9: Statistical Inference",
    "section": "Other Inferences",
    "text": "Other Inferences\n\nThe general classes of problems described above, as well as the more specific examples that appeared earlier, are intended as illustrations of types of statistical inferences that we will be able to perform with the theory and methods introduced in this text.\nThe range of possible models, inferences, and methods that can arise when data are observed in real research problems far exceeds what we can introduce here.\nIt is hoped that gaining an understanding of the problems that we can cover here will give you an appreciation for what needs to be done when a more challenging statistical problem arises."
  },
  {
    "objectID": "w09/slides.html#statistical-model",
    "href": "w09/slides.html#statistical-model",
    "title": "Week 9: Statistical Inference",
    "section": "Statistical Model",
    "text": "Statistical Model\nStatistical Model. A statistical model consists of an identification of random variables of interest (both observable and only hypothetically observable), a specification of a joint distribution or a family of possible joint distributions for the observable random variables, the identification of any parameters of those distributions that are assumed unknown and possibly hypothetically observable, and (if desired) a specification for a (joint) distribution for the unknown parameter(s). When we treat the unknown parameter(s) \\(\\theta\\) as random, then the joint distribution of the observable random variables indexed by \\(\\theta\\) is understood as the conditional distribution of the observable random variables given \\(\\theta\\).\n Source: DeGroot and Schervish, Definition 7.1.1"
  },
  {
    "objectID": "w09/slides.html#parameterparameter-space",
    "href": "w09/slides.html#parameterparameter-space",
    "title": "Week 9: Statistical Inference",
    "section": "Parameter/Parameter space",
    "text": "Parameter/Parameter space\n\nParameter/Parameter space. In a problem of statistical inference, a characteristic or combination of characteristics that determine the joint distribution for the random variables of interest is called a parameter of the distribution. The set \\(\\Omega\\) of all possible values of a parameter \\(\\theta\\) or of a vector of parameters \\(\\left(\\theta_1, \\ldots, \\theta_k\\right)\\) is called the parameter space.\nAll of the families of distributions introduced earlier (and to be introduced later) in this book have parameters that are included in the names of the individual members of the family. For example, the family of binomial distributions has parameters that we called \\(n\\) and \\(p\\), the family of normal distributions is parameterized by the mean \\(\\mu\\) and variance \\(\\sigma^2\\) of each distribution, the family of uniform distributions on intervals is parameterized by the endpoints of the intervals, the family of exponential distributions is parameterized by the rate parameter \\(\\theta\\), and so on.\n\n\n Source: DeGroot and Schervish, Definition 7.1.3"
  },
  {
    "objectID": "w09/slides.html#example-3",
    "href": "w09/slides.html#example-3",
    "title": "Week 9: Statistical Inference",
    "section": "Example",
    "text": "Example\nA Clinical Trial. Suppose that 40 patients are going to be given a treatment for a condition and that we will observe for each patient whether or not they recover from the condition. We are most likely also intersted in a large collection of additional patients besides the 40 to be observed. To be specific, for each patient \\(i=1,2\\), let \\(X_i=1\\) if patient \\(i\\) recovers, and let \\(X_i=0\\) if not. As a collection of possible distributions for \\(X_1, X_2, \\ldots\\), we could choose to say that the \\(X_i\\) are i.i.d. having the Bernoulli distribution with parameter \\(p\\) for \\(0 \\leq p \\leq 1\\). In this case, the parameter \\(p\\) is known to lie in the closed interval \\([0,1]\\), and this interval could be taken as the parameter space. Notice also that the law of large numbers (Theorem 6.2.4) says that \\(p\\) is the limit as \\(n\\) goes to infinity of the proportion of the first \\(n\\) patients who recover."
  },
  {
    "objectID": "w09/slides.html#statistic",
    "href": "w09/slides.html#statistic",
    "title": "Week 9: Statistical Inference",
    "section": "Statistic",
    "text": "Statistic\nStatistic. Suppose that the observable random variables of interest are \\(X_1, \\ldots, X_n\\). Let \\(r\\) be an arbitrary real-valued function of \\(n\\) real variables. Then the random variable \\(T=r\\left(X_1, \\ldots, X_n\\right)\\) is called a statistic.\n Source: DeGroot and Schervish, Definition 7.1.4"
  },
  {
    "objectID": "w09/slides.html#maximum-likelihood-estimation-mle",
    "href": "w09/slides.html#maximum-likelihood-estimation-mle",
    "title": "Week 9: Statistical Inference",
    "section": "Maximum Likelihood Estimation (MLE)",
    "text": "Maximum Likelihood Estimation (MLE)"
  },
  {
    "objectID": "w09/slides.html#overview",
    "href": "w09/slides.html#overview",
    "title": "Week 9: Statistical Inference",
    "section": "Overview",
    "text": "Overview\n\nObjective: Estimate parameters that maximize the likelihood of observed data.\nAssumption: Data follows a certain distribution.\nProcess: Find parameter values that make the observed data most probable.\nMethod: Maximize the likelihood function.\nProperties: Asymptotically efficient and consistent.\nOutput: Point estimates for model parameters."
  },
  {
    "objectID": "w09/slides.html#recall-joint-probability-density-function",
    "href": "w09/slides.html#recall-joint-probability-density-function",
    "title": "Week 9: Statistical Inference",
    "section": "Recall: Joint probability density function",
    "text": "Recall: Joint probability density function\n\nGiven a random variable \\(X\\) with probability mass / density function \\(f(x \\mid \\theta)\\), where \\(\\theta\\) is some parameter.\nDistribution of \\(n\\) independent observations \\(X_1, \\ldots, X_n\\) : Joint pdf / pmf \\[\nf_{\\text {joint }}\\left(x_1, \\ldots, x_n \\mid \\theta\\right)=f\\left(x_1 \\mid \\theta\\right) \\cdots f\\left(x_n \\mid \\theta\\right)\n\\]\nProbability Theory: Assume that \\(\\theta\\) is given and the \\(x_i\\) are variables (have not yet been observed).\nExample: Exponential distribution"
  },
  {
    "objectID": "w09/slides.html#likelihood-function",
    "href": "w09/slides.html#likelihood-function",
    "title": "Week 9: Statistical Inference",
    "section": "Likelihood Function",
    "text": "Likelihood Function\nLet the random variables \\(X_1, \\ldots, X_n\\) form a random sample from a discrete distribution or a continuous distribution for which the p.f. or the p.d.f. is \\(f(x \\mid \\theta)\\), where the parameter \\(\\theta\\) belongs to some parameter space \\(\\Omega\\). Here, \\(\\theta\\) can be either a real-valued parameter or a vector. For every observed vector \\(\\boldsymbol{x}=\\left(x_1, \\ldots, x_n\\right)\\) in the sample, the value of the joint p.f. or joint p.d.f. will, as usual, be denoted by \\(f_n(\\boldsymbol{x} \\mid \\theta)\\). Because of its importance in this section, we repeat Definition 7.2.3.\nLikelihood Function. When the joint p.d.f. or the joint p.f. \\(f_n(\\boldsymbol{x} \\mid \\theta)\\) of the observations in a random sample is regarded as a function of \\(\\theta\\) for given values of \\(x_1, \\ldots, x_n\\), it is called the likelihood function.\n Source: DeGroot and Schervish, Definition 7.5.1"
  },
  {
    "objectID": "w09/slides.html#likelihood-function-1",
    "href": "w09/slides.html#likelihood-function-1",
    "title": "Week 9: Statistical Inference",
    "section": "Likelihood function",
    "text": "Likelihood function\nGiven a random variable \\(X\\) with probability mass / density function \\(f(x \\mid \\theta)\\), where \\(\\theta\\) is some parameter. Assume a sample of \\(n\\) independent observations \\(X=x_1, \\ldots, X=x_n\\) is given. Likelihood function \\[\nL\\left(\\theta \\mid x_1, \\ldots, x_n\\right)=f\\left(x_1 \\mid \\theta\\right) \\cdots f\\left(x_n \\mid \\theta\\right)\n\\] This is the same as the joint probability density/mass function. Assume now that the \\(x_i\\) are given (have been observed) and \\(\\theta\\) is unknown."
  },
  {
    "objectID": "w09/slides.html#visualization-1",
    "href": "w09/slides.html#visualization-1",
    "title": "Week 9: Statistical Inference",
    "section": "Visualization",
    "text": "Visualization\nIn statistics, the likelihood function has a very precise definition: \\[\nL(\\theta \\mid x)=P(x \\mid \\theta)\n\\] The concept of likelihood plays a fundamental role in both Bayesian and frequentist statistics.\n\nGood Interactive Viz:https://seeing-theory.brown.edu/bayesian-inference/index.html#section2"
  },
  {
    "objectID": "w09/slides.html#mle",
    "href": "w09/slides.html#mle",
    "title": "Week 9: Statistical Inference",
    "section": "MLE",
    "text": "MLE\n\n Source: https://www.youtube.com/watch?v=XepXtl9YKwc"
  },
  {
    "objectID": "w09/slides.html#example-poisson-distribution",
    "href": "w09/slides.html#example-poisson-distribution",
    "title": "Week 9: Statistical Inference",
    "section": "Example: Poisson distribution",
    "text": "Example: Poisson distribution\n\nDiscrete distribution on \\(\\{0,1,2, \\ldots\\}\\), parameter \\(\\lambda=\\) intensity\nThe pmf is \\(f(x \\mid \\lambda)=e^{-\\lambda} \\frac{\\lambda^x}{x !}\\) for \\(x=0,1,2, \\ldots\\)\nThe joint pmf of \\(n\\) independent observations is \\[\n\\begin{aligned}\nf_{\\text {joint }}\\left(x_1, \\ldots, x_n \\mid \\lambda\\right) & =e^{-n \\lambda} \\frac{\\lambda^{x_1}}{x_{1} !} \\ldots \\frac{\\lambda^{x_n}}{x_{n} !} \\\\\n& =e^{-n \\lambda} \\frac{\\lambda^{x_1+x_2+\\cdots+x_n}}{x_{1} ! x_{2} ! \\ldots x_{n} !} \\\\\n& =L\\left(\\lambda \\mid x_1, \\ldots, x_n\\right)\n\\end{aligned}\n\\]\nThis is also the likelihood function.\nThree parts: \\(e^{-n \\lambda}\\) depends only on \\(\\lambda\\), the \\(x_i\\) ! depend only on the data, the term \\(\\lambda^{x_1+x_2+\\cdots+x_n}\\) depends both on \\(\\lambda\\) and the data."
  },
  {
    "objectID": "w09/slides.html#example-exponential-distribution",
    "href": "w09/slides.html#example-exponential-distribution",
    "title": "Week 9: Statistical Inference",
    "section": "Example: Exponential distribution",
    "text": "Example: Exponential distribution\n\nContinuous distribution on \\([0, \\infty)\\), parameter \\(\\lambda=\\) rate\nThe pdf is \\(f(x \\mid \\lambda)=\\lambda e^{-\\lambda x}\\) for \\(x \\geq 0\\)\nThe joint pdf of \\(n\\) independent observations is\n\n\\[\n\\begin{aligned}\nf_{\\text {joint }}\\left(x_1, \\ldots, x_n \\mid \\lambda\\right) & =\\lambda^n e^{-\\lambda x_1} \\ldots \\lambda e^{-\\lambda x_n} \\\\\n& =\\lambda^n e^{-\\lambda x_1-\\lambda x_2-\\ldots \\lambda x_n} \\\\\n& =\\lambda^n e^{-\\lambda \\sum_i x_i} \\\\\n& =L\\left(\\lambda \\mid x_1, \\ldots, x_n\\right)\n\\end{aligned}\n\\]\n\nThis is also the likelihood function.\nTwo parts: A term depending only on \\(\\lambda\\) and another term depending on \\(\\lambda\\) and the data, specifically \\(\\sum_i x_i\\)."
  },
  {
    "objectID": "w09/slides.html#calculation",
    "href": "w09/slides.html#calculation",
    "title": "Week 9: Statistical Inference",
    "section": "Calculation",
    "text": "Calculation"
  },
  {
    "objectID": "w09/slides.html#example-bernoulli-distribution",
    "href": "w09/slides.html#example-bernoulli-distribution",
    "title": "Week 9: Statistical Inference",
    "section": "Example: Bernoulli distribution",
    "text": "Example: Bernoulli distribution\nDiscrete distribution on \\(\\{0,1\\}\\), parameter \\(p=\\) success probability Pmf: \\(f(x \\mid p)=p^x(1-p)^{1-x}=\\left\\{\\begin{array}{ll}1-p & (x=0) \\\\ p & (x=1)\\end{array} \\quad\\right.\\) for \\(x=0,1\\) The joint pmf of \\(n\\) independent observations is \\[\n\\begin{aligned}\nf_{\\text {joint }}\\left(x_1, \\ldots, x_n \\mid p\\right) & =\\prod_{i=1}^n p^{x_i}(1-p)^{1-x_i} \\\\\n& =p^{\\sum_{i=1}^n x_i}(1-p)^{\\sum_{i=1}^n\\left(1-x_i\\right)} \\\\\n& =p^{\\sum_i x_i}(1-p)^{n-\\sum_i x_i} \\\\\n& =(1-p)^n\\left(\\frac{p}{1-p}\\right)^{\\sum_i x_i}=L\\left(p \\mid x_1, \\ldots, x_n\\right)\n\\end{aligned}\n\\] This is also the likelihood function."
  },
  {
    "objectID": "w09/slides.html#exponential-families",
    "href": "w09/slides.html#exponential-families",
    "title": "Week 9: Statistical Inference",
    "section": "Exponential Families",
    "text": "Exponential Families\nIn all these cases, the likelihood function for a sample \\(\\mathbf{x}=\\left(x_1, \\ldots, x_n\\right)\\) has two or three parts:\n\na function \\(g(\\mathbf{x})\\) that depends on the sample (could be 1)\na function \\(h(\\theta)\\) that depends on \\(\\theta\\) but not on the sample\na term that depends on the sample and on \\(\\theta\\) that has a special exponential form.\n\nThese are examples of exponential families of distributions (well studied in statistics)."
  },
  {
    "objectID": "w09/slides.html#example-cauchy-distribution",
    "href": "w09/slides.html#example-cauchy-distribution",
    "title": "Week 9: Statistical Inference",
    "section": "Example: Cauchy Distribution",
    "text": "Example: Cauchy Distribution\nContinuous distribution on \\((-\\infty, \\infty)\\), location parameter \\(\\theta\\) The pdf is \\(f(x \\mid \\theta)=\\frac{1}{\\pi\\left((x-\\theta)^2+1\\right)}\\) The joint pdf of \\(n\\) independent observations is \\[\nf_{\\text {joint }}\\left(x_1, \\ldots, x_n \\mid \\theta\\right)=\\frac{1}{\\pi^n} \\prod_{i=1}^n \\frac{1}{\\left.\\left(x_i-\\theta\\right)^2+1\\right)}\n\\] This is also the likelihood function. Not clear how to simplify this! This is not an exponential family."
  },
  {
    "objectID": "w09/slides.html#likelihood-function-2",
    "href": "w09/slides.html#likelihood-function-2",
    "title": "Week 9: Statistical Inference",
    "section": "Likelihood function",
    "text": "Likelihood function\nThe part of the likelihood function that connects the data and the parameter often depends only on a statistic \\(T(\\mathbf{x})\\). Exponential distribution: \\[\nL\\left(\\lambda \\mid x_1, \\ldots, x_n\\right)=\\lambda^n e^{-\\lambda x_1-\\lambda x_2 \\cdots-\\lambda x_n}\n\\] depends only on \\(T(\\mathbf{x})=x_1+\\cdots+x_n=n \\bar{x}\\). Poisson distribution: \\[\nL\\left(\\lambda \\mid x_1, \\ldots, x_n\\right)=e^{-n \\lambda} \\frac{\\lambda^{x_1+x_2+\\cdots+x_n}}{x_{1} ! x_{2} ! \\ldots x_{n} !}\n\\] The term connecting the data and \\(\\lambda\\) depends only on \\(T(\\mathbf{x})=x_1+\\cdots+x_n\\)."
  },
  {
    "objectID": "w09/slides.html#likelihood-function-for-normal-distribution",
    "href": "w09/slides.html#likelihood-function-for-normal-distribution",
    "title": "Week 9: Statistical Inference",
    "section": "Likelihood function for normal distribution",
    "text": "Likelihood function for normal distribution\nTwo parameters: Mean \\(\\mu\\) and standard deviation \\(\\sigma\\). Probability density: \\[\nf(x \\mid \\mu, \\sigma)=\\frac{1}{\\sqrt{2 \\pi} \\sigma} e^{-\\frac{(x-\\mu)^2}{2 \\sigma^2}}\n\\] Likelihood function: \\[\n\\begin{aligned}\nL\\left(\\mu, \\sigma \\mid x_1, \\ldots, x_n\\right) & =\\frac{1}{(\\sqrt{2 \\pi})^n \\sigma^n} \\prod_{i=1}^n e^{-\\frac{\\left(x_i-\\mu\\right)^2}{2 \\sigma^2}} \\\\\n& =\\frac{1}{(\\sqrt{2 \\pi})^n \\sigma^n} e^{-\\sum_{i=1}^n \\frac{\\left(x_i-\\mu\\right)^2}{2 \\sigma^2}}\n\\end{aligned}\n\\] The data and the parameters \\(\\mu\\) and \\(\\sigma\\) are connected through \\(T_1(\\mathbf{x})=\\sum_i x_i\\) and \\(T_2(\\mathbf{x})=\\sum_i x_i^2\\)."
  },
  {
    "objectID": "w09/slides.html#log-likelihood",
    "href": "w09/slides.html#log-likelihood",
    "title": "Week 9: Statistical Inference",
    "section": "Log Likelihood",
    "text": "Log Likelihood\n\nTake the logarithm of the likelihood function.\n\nPoisson distribution \\[\n\\log L=-n \\lambda+\\left(\\sum_i x_i\\right) \\log \\lambda-\\sum_i \\log x_{i} !\n\\] Exponential distribution \\[\n\\log L=n \\log \\lambda-\\lambda\\left(\\sum_i x_i\\right)\n\\] Bernoulli distribution \\[\n\\log L=\\log p\\left(\\sum_i x_i\\right)+\\log (1-p)\\left(n-\\sum_i x_i\\right)\n\\]"
  },
  {
    "objectID": "w09/slides.html#calculation-1",
    "href": "w09/slides.html#calculation-1",
    "title": "Week 9: Statistical Inference",
    "section": "Calculation",
    "text": "Calculation"
  },
  {
    "objectID": "w09/slides.html#maximum-likelihood",
    "href": "w09/slides.html#maximum-likelihood",
    "title": "Week 9: Statistical Inference",
    "section": "Maximum likelihood",
    "text": "Maximum likelihood\nWe need to find a value of \\(\\theta\\) for which the probability density \\(f_n(\\boldsymbol{x} \\mid \\theta)\\) is large and to use this value as an estimate of \\(\\boldsymbol{\\theta}\\). For each possible observed vector \\(x\\), we are led by this reasoning to consider a value of \\(\\theta\\) for which the likelihood function \\(f_n(\\boldsymbol{x} \\mid \\theta)\\) is a maximum and to use this value as an estimate of \\(\\theta\\). This concept is formalized in the following definition."
  },
  {
    "objectID": "w09/slides.html#maximum-likelihood-estimate",
    "href": "w09/slides.html#maximum-likelihood-estimate",
    "title": "Week 9: Statistical Inference",
    "section": "Maximum Likelihood Estimate",
    "text": "Maximum Likelihood Estimate\n\nMaximum Likelihood Estimator/Estimate. For each possible observed vector \\(\\boldsymbol{x}\\), let \\(\\delta(\\boldsymbol{x}) \\in \\Omega\\) denote a value of \\(\\theta \\in \\Omega\\) for which the likelihood function \\(f_n(\\boldsymbol{x} \\mid \\theta)\\) is a maximum, and let \\(\\hat{\\theta}=\\delta(\\boldsymbol{X})\\) be the estimator of \\(\\theta\\) defined in this way.\nThe estimator \\(\\hat{\\theta}\\) is called a maximum likelihood estimator of \\(\\theta\\). After \\(\\boldsymbol{X}=\\boldsymbol{x}\\) is observed, the value \\(\\delta(\\boldsymbol{x})\\) is called a maximum likelihood estimate of \\(\\theta\\).\n\n Source: DeGroot and Schervish, Definition 7.5.2"
  },
  {
    "objectID": "w09/slides.html#arg-max-function",
    "href": "w09/slides.html#arg-max-function",
    "title": "Week 9: Statistical Inference",
    "section": "Arg-max function",
    "text": "Arg-max function\n\nThe argmax function identifies the argument that maximizes a given function.\nIn mathematical terms, it finds the input value that yields the maximum output of the function.\nIt is crucial for optimization problems and statistical estimation.\n\nIn mathematics, the arguments of the maxima (abbreviated arg max or argmax) are the points, or elements, of the domain of some function at which the function values are maximized.[note 1] In contrast to global maxima, which refers to the largest outputs of a function, arg max refers to the inputs, or arguments, at which the function outputs are as large as possible."
  },
  {
    "objectID": "w09/slides.html#maximum-likelihood-1",
    "href": "w09/slides.html#maximum-likelihood-1",
    "title": "Week 9: Statistical Inference",
    "section": "Maximum Likelihood",
    "text": "Maximum Likelihood\n*Observe the graphs of the likelihood functions. Where are the maxima? Maximum Likelihood Estimation Estimate the unknown parameter \\(\\theta\\) by using the maximum of the likelihood function, \\[\n\\hat{\\theta}_{M L E}=\\operatorname{argmax}_\\theta L\\left(\\theta \\mid x_1, \\ldots, x_n\\right)\n\\] Equivalently we can try to maximize the log likelihood. Use Optimization Theory to work out the maximum or to compute it numerically."
  },
  {
    "objectID": "w09/slides.html#example-exponential-distribution-1",
    "href": "w09/slides.html#example-exponential-distribution-1",
    "title": "Week 9: Statistical Inference",
    "section": "Example: Exponential Distribution",
    "text": "Example: Exponential Distribution\nGiven a sample of size \\(n\\) and \\(\\sum_i x_i\\), the log likelihood is \\[\n\\log L(\\lambda)=n \\log \\lambda-\\lambda \\cdot \\sum_i x_i=n \\log \\lambda-\\lambda n \\bar{x}\n\\] Differentiate wrt. \\(\\lambda\\) : \\[\n\\frac{d}{d \\lambda} \\log L(\\lambda)=\\frac{n}{\\lambda}-n \\bar{x}\n\\] Set this \\(=0\\) and solve for \\(\\lambda\\). Calculus shows that this is the maximum, the maximum likelihood estimate of \\(\\lambda\\). \\[\n\\hat{\\lambda}_{M L E}=\\frac{1}{\\bar{x}}\n\\]"
  },
  {
    "objectID": "w09/slides.html#examples-of-mles",
    "href": "w09/slides.html#examples-of-mles",
    "title": "Week 9: Statistical Inference",
    "section": "Examples of MLEs",
    "text": "Examples of MLEs\n\nPoisson distribution: \\(\\hat{\\lambda}_{M L E}=\\bar{x}\\)\nExponential distribution: \\(\\hat{\\lambda}_{M L E}=\\frac{1}{\\bar{x}}\\)\nBernoulli distribution: \\(\\hat{p}_{M L E}=\\bar{x}\\)\nTheoretical justification of intuitive choices\nShows how to reduce data\nGeneral method"
  },
  {
    "objectID": "w09/slides.html#normal-distribution",
    "href": "w09/slides.html#normal-distribution",
    "title": "Week 9: Statistical Inference",
    "section": "Normal Distribution",
    "text": "Normal Distribution\nConsider normal distribution \\(N\\left(\\mu, \\sigma^2\\right)\\). The likelihood function depends on two parameters, namely \\(\\mu\\) and \\(\\sigma^2\\). \\[\n\\begin{aligned}\nL\\left(\\mu, \\sigma \\mid x_1, \\ldots, x_n\\right) & =\\frac{1}{(\\sqrt{2 \\pi})^n \\sigma^n} \\prod_{i=1}^n e^{-\\frac{\\left(x_i-\\mu\\right)^2}{2 \\sigma^2}} \\\\\n& =\\frac{1}{(\\sqrt{2 \\pi})^n \\sigma^n} e^{-\\sum_{i=1}^n \\frac{\\left(x_i-\\mu\\right)^2}{2 \\sigma^2}}\n\\end{aligned}\n\\] Need calculus of several variables to minimize. Maximum likelihood estimates: \\[\n\\hat{\\mu}_{M L E}=\\bar{x}, \\quad \\hat{\\sigma}^2 M L E=\\frac{1}{n} \\sum_{i=1}^n\\left(x_i-\\bar{x}\\right)^2\n\\]"
  },
  {
    "objectID": "w09/slides.html#uniform-distribution",
    "href": "w09/slides.html#uniform-distribution",
    "title": "Week 9: Statistical Inference",
    "section": "Uniform Distribution",
    "text": "Uniform Distribution\nConsider uniform distribution on \\((0, a)\\) where \\(a\\) is unknown. Likelihood function depends on \\(a\\). \\[\nL\\left(a \\mid x_1, \\ldots, x_n\\right)= \\begin{cases}\\frac{1}{a^n} & \\left(0 \\leq x_1, x_2, \\ldots, x_n \\leq a\\right) \\\\ 0 & \\text { otherwise }\\end{cases}\n\\] Given a sample, we should pick the smallest a such that the first condition is true, since this will maximize the likelihood. Maximum likelihood estimates: \\[\n\\hat{a}_{M L E}=\\max _i x_i\n\\] Does this make sense? This is always biased - why?"
  },
  {
    "objectID": "w09/slides.html#example-logistic-regression",
    "href": "w09/slides.html#example-logistic-regression",
    "title": "Week 9: Statistical Inference",
    "section": "Example: Logistic Regression",
    "text": "Example: Logistic Regression\n12.2.1 Likelihood Function for Logistic Regression Because logistic regression predicts probabilities, rather than just classes, we can fit it using likelihood. For each training data-point, we have a vector of features, \\(x_i\\), and an observed class, \\(y_i\\). The probability of that class was either \\(p\\), if \\(y_i=1\\), or \\(1-p\\), if \\(y_i=0\\). The likelihood is then \\[\nL\\left(\\beta_0, \\beta\\right)=\\prod_{i=1}^n p\\left(x_i\\right)^{y_i}\\left(1-p\\left(x_i\\right)^{1-y_i}\\right.\n\\]\nReference: http://www.stat.cmu.edu/~cshalizi/uADA/12/lectures/ch12.pdf"
  },
  {
    "objectID": "w09/slides.html#example-logistic-regression-1",
    "href": "w09/slides.html#example-logistic-regression-1",
    "title": "Week 9: Statistical Inference",
    "section": "Example: Logistic Regression",
    "text": "Example: Logistic Regression\n(I could substitute in the actual equation for \\(p\\), but things will be clearer in a moment if I don’t.) The log-likelihood turns products into sums: \\[\n\\begin{aligned}\n\\ell\\left(\\beta_0, \\beta\\right) & =\\sum_{i=1}^n y_i \\log p\\left(x_i\\right)+\\left(1-y_i\\right) \\log 1-p\\left(x_i\\right) \\\\\n& =\\sum_{i=1}^n \\log 1-p\\left(x_i\\right)+\\sum_{i=1}^n y_i \\log \\frac{p\\left(x_i\\right)}{1-p\\left(x_i\\right)} \\\\\n& =\\sum_{i=1}^n \\log 1-p\\left(x_i\\right)+\\sum_{i=1}^n y_i\\left(\\beta_0+x_i \\cdot \\beta\\right) \\\\\n& =\\sum_{i=1}^n-\\log 1+e^{\\beta_0+x_i \\cdot \\beta}+\\sum_{i=1}^n y_i\\left(\\beta_0+x_i \\cdot \\beta\\right)\n\\end{aligned}\n\\] where in the next-to-last step we finally use equation 12.4. Reference: http://www.stat.cmu.edu/ cshalizi/uADA/12/lectures/ch12.pdf"
  },
  {
    "objectID": "w09/slides.html#example-logistic-regression-2",
    "href": "w09/slides.html#example-logistic-regression-2",
    "title": "Week 9: Statistical Inference",
    "section": "Example: Logistic Regression",
    "text": "Example: Logistic Regression\nTypically, to find the maximum likelihood estimates we’d differentiate the log likelihood with respect to the parameters, set the derivatives equal to zero, and solve. To start that, take the derivative with respect to one component of \\(\\beta\\), say \\(\\beta_j\\). \\[\n\\begin{aligned}\n\\frac{\\partial \\ell}{\\partial \\beta_j} & =-\\sum_{i=1}^n \\frac{1}{1+e^{\\beta_0+x_i \\cdot \\beta}} e^{\\beta_0+x_i \\cdot \\beta} x_{i j}+\\sum_{i=1}^n y_i x_{i j} \\\\\n& =\\sum_{i=1}^n\\left(y_i-p\\left(x_i ; \\beta_0, \\beta\\right)\\right) x_{i j}\n\\end{aligned}\n\\] We are not going to be able to set this to zero and solve exactly. (That’s a transcendental equation, and there is no closed-form solution.) We can however approximately solve it numerically."
  },
  {
    "objectID": "w09/slides.html#notes",
    "href": "w09/slides.html#notes",
    "title": "Week 9: Statistical Inference",
    "section": "Notes",
    "text": "Notes\nIt should be noted that in some problems, for certain observed vectors \\(\\boldsymbol{x}\\), the maximum value of \\(f_n(\\boldsymbol{x} \\mid \\theta)\\) may not actually be attained for any point \\(\\theta \\in \\Omega\\). In such a case, an M.L.E. of \\(\\theta\\) does not exist. For certain other observed vectors \\(\\boldsymbol{x}\\), the maximum value of \\(f_n(\\boldsymbol{x} \\mid \\theta)\\) may actually be attained at more than one point in the space \\(\\Omega\\). In such a case, the M.L.E. is not uniquely defined, and any one of these points can be chosen as the value of the estimator \\(\\hat{\\theta}\\). In many practical problems, however, the M.L.E. exists and is uniquely defined.\n# Method of Moments (MOM)"
  },
  {
    "objectID": "w09/slides.html#overview-1",
    "href": "w09/slides.html#overview-1",
    "title": "Week 9: Statistical Inference",
    "section": "Overview",
    "text": "Overview\n\nThe method of moments is an intuitive method for estimating parameters when other, more attractive, methods may be too difficult\n\nMethod of Moments. Assume that \\(X_1, \\ldots, X_n\\) form a random sample from a distribution that is indexed by a \\(k\\)-dimensional parameter \\(\\theta\\) and that has at least \\(k\\) finite moments. For \\(j=1, \\ldots, k\\), let \\(\\mu_j(\\theta)=E\\left(X_1^j \\mid \\theta\\right)\\). Suppose that the function \\(\\mu(\\theta)=\\left(\\mu_1(\\theta), \\ldots, \\mu_k(\\theta)\\right)\\) is a one-to-one function of \\(\\theta\\). Let \\(M\\left(\\mu_1, \\ldots, \\mu_k\\right)\\) denote the inverse function, that is, for all \\(\\theta\\), \\[\n\\theta=M\\left(\\mu_1(\\theta), \\ldots, \\mu_k(\\theta)\\right) \\text {. }\n\\] Define the sample moments by \\(m_j=\\frac{1}{n} \\sum_{i=1}^n X_i^j\\) for \\(j=1, \\ldots, k\\). The method of moments estimator of \\(\\theta\\) is \\(M\\left(m_1, \\ldots, m_j\\right)\\).\nThe usual way of implementing the method of moments is to set up the \\(k\\) equations \\(m_j=\\mu_j(\\theta)\\) and then solve for \\(\\theta\\).\n Source: DeGroot and Schervish, Definition 7.6.3"
  },
  {
    "objectID": "w09/slides.html#method-of-moments-estimation",
    "href": "w09/slides.html#method-of-moments-estimation",
    "title": "Week 9: Statistical Inference",
    "section": "Method of Moments Estimation",
    "text": "Method of Moments Estimation\nGiven a random variable \\(X\\) whose distribution depends on a parameter \\(\\theta\\). To estimate \\(\\theta\\),\n\nExpress a moment \\(\\mathcal{E}(X)\\) or \\(\\mathcal{E}\\left(X^2\\right)\\) or … in terms of \\(\\theta\\), e.g. \\(\\mathcal{E}(X)=H(\\theta)\\)\nEstimate this moment from the sample\nSolve the equation relating the moment and the parameter, e.g. solve \\(\\bar{x}=H(\\hat{\\theta})\\) for \\(\\hat{\\theta}\\).\n\nSimilar to a plug-in estimation\nAvoids calculus or likelihood functions, only algebra is needed"
  },
  {
    "objectID": "w09/slides.html#example-uniform-distribution",
    "href": "w09/slides.html#example-uniform-distribution",
    "title": "Week 9: Statistical Inference",
    "section": "Example: Uniform Distribution",
    "text": "Example: Uniform Distribution\nConsider uniform distribution on \\((0, a)\\) where \\(a\\) is unknown. Then \\(E(X)=\\frac{a}{2}\\). Given a sample, compute the sample mean. Then use the method of moments: \\[\nE(X)=\\frac{a}{2} \\text { becomes } \\quad \\bar{x}=\\frac{\\hat{a}}{2} \\Rightarrow \\hat{a}=2 \\bar{x}\n\\] Method of moments estimate: \\[\n\\hat{a}_{M o M}=2 \\bar{x}\n\\] This is not biased. Does this make sense?"
  },
  {
    "objectID": "w09/slides.html#example-beta-distribution",
    "href": "w09/slides.html#example-beta-distribution",
    "title": "Week 9: Statistical Inference",
    "section": "Example: Beta Distribution",
    "text": "Example: Beta Distribution\nContinuous distribution on \\((0,1)\\), parameters \\(\\alpha, \\beta&gt;0\\) The pdf is \\[\nf(x \\mid \\alpha, \\beta)=\\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha) \\Gamma(\\beta)} x^{\\alpha-1}(1-x)^{\\beta-1}\n\\] for \\(0&lt;x&lt;1\\) Likelihood function is complicated. Calculus minimization is challenging, due to \\(\\Gamma\\) function."
  },
  {
    "objectID": "w09/slides.html#estimation-using-method-of-moments",
    "href": "w09/slides.html#estimation-using-method-of-moments",
    "title": "Week 9: Statistical Inference",
    "section": "Estimation using Method of Moments",
    "text": "Estimation using Method of Moments\nKnown for the beta distribution: \\[\n\\mathcal{E}(X)=\\frac{\\alpha}{\\alpha+\\beta}, \\quad \\operatorname{var}(X)=\\frac{\\alpha \\beta}{(\\alpha+\\beta)^2(\\alpha+\\beta+1)}\n\\] This is equivalent to formulae for the moments \\(\\mathcal{E}(X)\\) and \\(\\mathcal{E}\\left(X^2\\right)\\), since \\(\\mathcal{E}\\left(X^2\\right)=\\operatorname{var}(X)+\\mathcal{E}(X)^2\\).\nMoM approach: Use sample mean \\(\\bar{x}\\) and sample variance \\(\\bar{v}\\). Solve the equations \\[\n\\bar{x}=\\frac{\\alpha}{\\alpha+\\beta}, \\quad \\bar{v}=\\frac{\\alpha \\beta}{(\\alpha+\\beta)^2(\\alpha+\\beta+1)}\n\\]"
  },
  {
    "objectID": "w09/slides.html#resulting-estimators",
    "href": "w09/slides.html#resulting-estimators",
    "title": "Week 9: Statistical Inference",
    "section": "Resulting Estimators",
    "text": "Resulting Estimators\n\nAfter some algebra … \\[\n\\begin{aligned}\n& \\hat{\\alpha}=\\bar{x}\\left(\\frac{\\bar{x}(1-\\bar{x})}{\\bar{v}}-1\\right) \\\\\n& \\hat{\\beta}=(1-\\bar{x})\\left(\\frac{\\bar{x}(1-\\bar{x})}{\\bar{v}}-1\\right)\n\\end{aligned}\n\\]\nWhat if \\(\\bar{v}&gt;\\bar{x}(1-\\bar{x})\\) ? The estimates then are negative! R packages such as EnvStats uses a numerical method to maximize the likelihood."
  },
  {
    "objectID": "w09/slides.html#bias-and-variance",
    "href": "w09/slides.html#bias-and-variance",
    "title": "Week 9: Statistical Inference",
    "section": "Bias and Variance",
    "text": "Bias and Variance"
  },
  {
    "objectID": "w09/slides.html#bias-and-variance-1",
    "href": "w09/slides.html#bias-and-variance-1",
    "title": "Week 9: Statistical Inference",
    "section": "Bias and Variance",
    "text": "Bias and Variance\nBias is systematic error, variance is random error. Bias can sometimes be estimated and corrected, variance can only be estimated. Formal Definition Suppose \\(\\hat{\\theta}\\) is an estimator (based on a random sample) for \\(\\theta\\). The bias is defined as \\[\n\\operatorname{bias}(\\hat{\\theta})=\\mathcal{E}(\\hat{\\theta})-\\theta\n\\] Theoretical evaluation and simulation approach may both be possible."
  },
  {
    "objectID": "w09/slides.html#unbiased-estimator",
    "href": "w09/slides.html#unbiased-estimator",
    "title": "Week 9: Statistical Inference",
    "section": "Unbiased Estimator",
    "text": "Unbiased Estimator\nLet \\(\\delta\\) be an estimator of a function \\(g\\) of a parameter \\(\\theta\\). We say that \\(\\delta\\) is unbiased if \\(E_\\theta[\\delta(\\boldsymbol{X})]=g(\\theta)\\) for all values of \\(\\theta\\). This section provides several examples of unbiased estimators.\nLet \\(\\boldsymbol{X}=\\left(X_1, \\ldots, X_n\\right)\\) be a random sample from a distribution that involves a parameter (or parameter vector) \\(\\theta\\) whose value is unknown. Suppose that we wish to estimate a function \\(g(\\theta)\\) of the parameter. In a problem of this type, it is desirable to use an estimator \\(\\delta(\\boldsymbol{X})\\) that, with high probability, will be close to \\(g(\\theta)\\). In other words,"
  },
  {
    "objectID": "w09/slides.html#unbiased-estimator-1",
    "href": "w09/slides.html#unbiased-estimator-1",
    "title": "Week 9: Statistical Inference",
    "section": "Unbiased Estimator",
    "text": "Unbiased Estimator\nit is desirable to use an estimator \\(\\delta\\) whose distribution changes with the value of \\(\\theta\\) in such a way that no matter what the true value of \\(\\theta\\) is, the probability distribution of \\(\\delta\\) is concentrated around \\(g(\\theta)\\). For example, suppose that \\(\\boldsymbol{X}=\\left(X_1, \\ldots, X_n\\right)\\) form a random sample from a normal distribution for which the mean \\(\\theta\\) is unknown and the variance is 1 . In this case, the M.L.E. of \\(\\theta\\) is the sample mean \\(\\bar{X}_n\\). The estimator \\(\\bar{X}_n\\) is a reasonably good estimator of \\(\\theta\\) because its distribution is the normal distribution with mean \\(\\theta\\) and variance \\(1 / n\\). This distribution is concentrated around the unknown value of \\(\\theta\\), no matter how large or how small \\(\\theta\\) is."
  },
  {
    "objectID": "w09/slides.html#unbiased-estimator-2",
    "href": "w09/slides.html#unbiased-estimator-2",
    "title": "Week 9: Statistical Inference",
    "section": "Unbiased Estimator",
    "text": "Unbiased Estimator\nUnbiased Estimator/Bias. An estimator \\(\\delta(\\boldsymbol{X})\\) is an unbiased estimator of a function \\(g(\\theta)\\) of the parameter \\(\\theta\\) if \\(E_\\theta[\\delta(\\boldsymbol{X})]=g(\\theta)\\) for every possible value of \\(\\theta\\). An estimator that is not unbiased is called a biased estimator. The difference between the expectation of an estimator and \\(g(\\theta)\\) is called the bias of the estimator. That is, the bias of \\(\\delta\\) as an estimator of \\(g(\\theta)\\) is \\(E_\\theta[\\delta(\\boldsymbol{X})]-g(\\theta)\\), and \\(\\delta\\) is unbiased if and only if the bias is 0 for all \\(\\theta\\).\nIn the case of a sample from a normal distribution with unknown mean \\(\\theta, \\bar{X}_n\\) is an unbiased estimator of \\(\\theta\\) because \\(E_\\theta\\left(\\bar{X}_n\\right)=\\theta\\) for \\(-\\infty&lt;\\theta&lt;\\infty\\)\n Source: DeGroot and Schervish, Definition 8.7.1"
  },
  {
    "objectID": "w09/slides.html#example-poisson-distribution-1",
    "href": "w09/slides.html#example-poisson-distribution-1",
    "title": "Week 9: Statistical Inference",
    "section": "Example: Poisson Distribution",
    "text": "Example: Poisson Distribution\n\nThe maximum likelihood estimator for \\(\\lambda\\) is the sample mean, \\(\\hat{\\lambda}=\\bar{X}\\). We know that \\[\n\\mathcal{E}\\left(X_i\\right)=\\lambda \\Longrightarrow \\mathcal{E}(\\bar{X})=\\lambda .\n\\]\nTherefore,\n\n\\[\n\\mathcal{E}(\\hat{\\lambda})-\\lambda=0\n\\]\n\nThis estimator is unbiased."
  },
  {
    "objectID": "w09/slides.html#exponential-distribution",
    "href": "w09/slides.html#exponential-distribution",
    "title": "Week 9: Statistical Inference",
    "section": "Exponential Distribution",
    "text": "Exponential Distribution\nThe maximum likelihood estimator for \\(\\lambda\\) is \\(\\hat{\\lambda}=\\frac{1}{\\bar{\\chi}}\\). We know that \\[\n\\mathcal{E}\\left(X_i\\right)=\\frac{1}{\\lambda} \\Longrightarrow \\mathcal{E}(\\bar{X})=\\frac{1}{\\lambda} .\n\\] But one can show that \\[\n\\mathcal{E}(\\hat{\\lambda})=\\mathcal{E}\\left(\\frac{1}{\\bar{X}}\\right)=\\frac{n}{n-1} \\lambda .\n\\] Can also assess and correct the bias with a simulation (“parametric bootstrap”)."
  },
  {
    "objectID": "w09/slides.html#calculation-1-1",
    "href": "w09/slides.html#calculation-1-1",
    "title": "Week 9: Statistical Inference",
    "section": "Calculation-1",
    "text": "Calculation-1"
  },
  {
    "objectID": "w09/slides.html#calculation-2",
    "href": "w09/slides.html#calculation-2",
    "title": "Week 9: Statistical Inference",
    "section": "Calculation-2",
    "text": "Calculation-2"
  },
  {
    "objectID": "w09/slides.html#unbiased-estimation-of-the-variance",
    "href": "w09/slides.html#unbiased-estimation-of-the-variance",
    "title": "Week 9: Statistical Inference",
    "section": "Unbiased Estimation of the Variance",
    "text": "Unbiased Estimation of the Variance\nSampling from a General Distribution. Let \\(\\boldsymbol{X}=\\left(X_1, \\ldots, X_n\\right)\\) be a random sample from a distribution that depends on a parameter (or parameter vector) \\(\\theta\\). Assume that the variance of the distribution is finite. Define \\(g(\\theta)=\\operatorname{Var}_\\theta\\left(X_1\\right)\\). The following statistic is an unbiased estimator of the variance \\(g(\\theta)\\) :\n\\[\n\\hat{\\sigma}_1^2=\\frac{1}{n-1} \\sum_{i=1}^n\\left(X_i-\\bar{X}_n\\right)^2\n\\]\n Source: DeGroot and Schervish, Theorem 8.7.1"
  },
  {
    "objectID": "w09/slides.html#example-4",
    "href": "w09/slides.html#example-4",
    "title": "Week 9: Statistical Inference",
    "section": "Example",
    "text": "Example\nSampling from a Specific Family of Distributions When it can be assumed that \\(X_1, \\ldots, X_n\\) form a random sample from a specific family of distributions, such as the family of Poisson distributions, it will generally be desirable to consider not only \\(\\hat{\\sigma}_1^2\\) but also other unbiased estimators of the variance.\nSample from a Poisson Distribution. Suppose that we observe a random sample from the Poisson distribution for which the mean \\(\\theta\\) is unknown. We have already seen that \\(\\bar{X}_n\\) will be an unbiased estimator of the mean \\(\\theta\\). Moreover, since the variance of a Poisson distribution is also equal to \\(\\theta\\), it follows that \\(\\bar{X}_n\\) is also an unbiased estimator of the variance. In this example, therefore, both \\(\\bar{X}_n\\) and \\(\\hat{\\sigma}_1^2\\) are unbiased estimators of the unknown variance \\(\\theta\\). Furthermore, any combination of \\(\\bar{X}_n\\) and \\(\\hat{\\sigma}_1^2\\) having the form \\(\\alpha \\bar{X}_n+(1-\\alpha) \\hat{\\sigma}_1^2\\), where \\(\\alpha\\) is a given constant \\((-\\infty&lt;\\alpha&lt;\\infty)\\), will also be an unbiased estimator of \\(\\theta\\) because its expectation will be \\[\nE\\left[\\alpha \\bar{X}_n+(1-\\alpha) \\hat{\\sigma}_1^2\\right]=\\alpha E\\left(\\bar{X}_n\\right)+(1-\\alpha) E\\left(\\hat{\\sigma}_1^2\\right)=\\alpha \\theta+(1-\\alpha) \\theta=\\theta\n\\] Other unbiased estimators of \\(\\theta\\) can also be constructed."
  },
  {
    "objectID": "w09/slides.html#mean-square-error",
    "href": "w09/slides.html#mean-square-error",
    "title": "Week 9: Statistical Inference",
    "section": "Mean Square Error",
    "text": "Mean Square Error\nCombine variance and bias to assess quality of an estimator: MSE\nFor an estimator \\(\\hat{\\theta}\\), \\[\n\\operatorname{MSE}(\\hat{\\theta})=\\mathcal{E}\\left((\\hat{\\theta}-\\theta)^2\\right)=\\operatorname{var}(\\hat{\\theta})+\\operatorname{bias}(\\hat{\\theta})^2\n\\]"
  },
  {
    "objectID": "w09/slides.html#mse",
    "href": "w09/slides.html#mse",
    "title": "Week 9: Statistical Inference",
    "section": "MSE",
    "text": "MSE\nProposition 6.4 MSE \\([\\hat{\\theta}]=\\operatorname{Var}[\\hat{\\theta}]+\\operatorname{Bias}[\\hat{\\theta}]^2\\). Proof \\[\n\\begin{aligned}\n\\operatorname{MSE}[\\hat{\\theta}] & =\\mathrm{E}\\left[(\\hat{\\theta}-\\theta)^2\\right] \\\\\n& =\\mathrm{E}\\left[(\\hat{\\theta}-\\mathrm{E}[\\hat{\\theta}]+\\mathrm{E}[\\hat{\\theta}]-\\theta)^2\\right] \\\\\n& =\\mathrm{E}\\left[((\\hat{\\theta}-\\mathrm{E}[\\hat{\\theta}])+(\\mathrm{E}[\\hat{\\theta}]-\\theta))^2\\right] \\\\\n& =\\mathrm{E}\\left[(\\hat{\\theta}-\\mathrm{E}[\\hat{\\theta}])^2\\right]+2 \\mathrm{E}[\\hat{\\theta}-\\mathrm{E}[\\hat{\\theta}]](\\mathrm{E}[\\hat{\\theta}]-\\theta)+(\\mathrm{E}[\\hat{\\theta}]-\\theta)^2 \\\\\n& =\\operatorname{Var}[\\hat{\\theta}]+(\\operatorname{Bias}[\\hat{\\theta}])^2\n\\end{aligned}\n\\] Also, if \\(\\hat{\\theta}\\) is unbiased, then \\(\\operatorname{MSE}[\\theta]=\\operatorname{Var}[\\hat{\\theta}]\\). So, the unbiased estimator \\(\\hat{\\theta}_1\\) of \\(\\theta\\) is more efficient than the unbiased estimator \\(\\hat{\\theta}_2\\) if and only if \\(\\operatorname{MSE}\\left[\\hat{\\theta}_1\\right]&lt;\\operatorname{MSE}\\left[\\hat{\\theta}_2\\right]\\)."
  },
  {
    "objectID": "w09/slides.html#mse-1",
    "href": "w09/slides.html#mse-1",
    "title": "Week 9: Statistical Inference",
    "section": "MSE",
    "text": "MSE\nDefinition. Let \\(T\\) be an estimator for a parameter \\(\\theta\\). The mean squared error of \\(T\\) is the number \\(\\operatorname{MSE}(T)=\\mathrm{E}\\left[(T-\\theta)^2\\right]\\). According to this criterion, an estimator \\(T_1\\) performs better than an estimator \\(T_2\\) if \\(\\operatorname{MSE}\\left(T_1\\right)&lt;\\operatorname{MSE}\\left(T_2\\right)\\). Note that \\[\n\\begin{aligned}\n\\operatorname{MSE}(T) & =\\mathrm{E}\\left[(T-\\theta)^2\\right] \\\\\n& =\\mathrm{E}\\left[(T-\\mathrm{E}[T]+\\mathrm{E}[T]-\\theta)^2\\right] \\\\\n& =\\mathrm{E}\\left[(T-\\mathrm{E}[T])^2\\right]+2 \\mathrm{E}[T-\\mathrm{E}[T]](\\mathrm{E}[T]-\\theta)+(\\mathrm{E}[T]-\\theta)^2 \\\\\n& =\\operatorname{Var}(T)+(\\mathrm{E}[T]-\\theta)^2 .\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "w09/slides.html#efficiency",
    "href": "w09/slides.html#efficiency",
    "title": "Week 9: Statistical Inference",
    "section": "Efficiency",
    "text": "Efficiency\nEFFICIENCY. Let \\(T_1\\) and \\(T_2\\) be two unbiased estimators for the same parameter \\(\\theta\\). Then estimator \\(T_2\\) is called more efficient than estimator \\(T_1\\) if \\(\\operatorname{Var}\\left(T_2\\right)&lt;\\operatorname{Var}\\left(T_1\\right)\\), irrespective of the value of \\(\\theta\\)."
  },
  {
    "objectID": "w09/slides.html#note",
    "href": "w09/slides.html#note",
    "title": "Week 9: Statistical Inference",
    "section": "Note",
    "text": "Note\nSo the MSE of \\(T\\) turns out to be the variance of \\(T\\) plus the square of the bias of \\(T\\). In particular, when \\(T\\) is unbiased, the MSE of \\(T\\) is just the variance of \\(T\\). This means that we already used mean squared errors to compare the estimators \\(T_1\\) and \\(T_2\\) in the previous section. We extend the notion of efficiency by saying that estimator \\(T_2\\) is more efficient than estimator \\(T_1\\) (for the same parameter of interest), if the MSE of \\(T_2\\) is smaller than the MSE of \\(T_1\\)."
  },
  {
    "objectID": "w09/slides.html#efficiency-1",
    "href": "w09/slides.html#efficiency-1",
    "title": "Week 9: Statistical Inference",
    "section": "Efficiency",
    "text": "Efficiency\n\nGiven two estimators \\(\\hat{\\theta}_1, \\hat{\\theta}_2\\) for the same parameter. If both are unbiased, the one with smaller variance is better (“more efficient”).\nRelative Efficiency of \\(\\hat{\\theta}_1\\) wrt. \\(\\hat{\\theta}_2\\)\nAssuming \\(\\mathcal{E}\\left(\\hat{\\theta}_1\\right)=\\mathcal{E}\\left(\\hat{\\theta}_2\\right)=\\theta\\), this is defined as \\[\nE=\\operatorname{var}\\left(\\hat{\\theta}_2\\right) / \\operatorname{var}\\left(\\hat{\\theta}_1\\right)\n\\]\nIf \\(\\hat{\\theta}_2\\) is used instead of \\(\\hat{\\theta}_1\\), the sample size must be increased by a factor \\(E\\) to get the same accuracy."
  },
  {
    "objectID": "w09/slides.html#example-mean-and-median",
    "href": "w09/slides.html#example-mean-and-median",
    "title": "Week 9: Statistical Inference",
    "section": "Example: Mean and Median",
    "text": "Example: Mean and Median\n\nConsider data from a normal distribution, \\(N(\\mu, 1)\\). Can estimate \\(\\mu\\) in two ways from a sample \\(x=\\left(x_1, \\ldots, x_n\\right)\\) : \\[\n\\hat{\\mu}_1=\\bar{x}, \\quad \\hat{\\mu}_2=\\operatorname{median}(x)\n\\]\nWhat is the relative efficiency?"
  },
  {
    "objectID": "w09/slides.html#example-5",
    "href": "w09/slides.html#example-5",
    "title": "Week 9: Statistical Inference",
    "section": "Example",
    "text": "Example\nExercise 6.4 #28 in Chihara/Hesterberg. 28. Let \\(\\hat{\\theta}_1\\) and \\(\\hat{\\theta}_2\\) be two estimators of \\(\\theta\\) with \\(\\mathrm{E}\\left[\\hat{\\theta}_1\\right]=0.9 \\theta\\) and \\(\\mathrm{E}\\left[\\hat{\\theta}_2\\right]=1.2 \\theta\\). Also, suppose \\(\\operatorname{Var}\\left[\\hat{\\theta}_1\\right]=3\\) and \\(\\operatorname{Var}\\left[\\hat{\\theta}_2\\right]=2\\). Find two unbiased estimators of \\(\\theta\\) and determine which one is more efficient. Solution Set \\(\\tilde{\\theta}_1=\\frac{\\hat{\\theta}_1}{0.9}\\) and \\(\\tilde{\\theta}_2=\\frac{\\hat{\\theta}_2}{1.2}\\). Then \\(E\\left(\\tilde{\\theta}_1\\right)=\\frac{0.9}{0.9} \\theta=\\theta\\) and similarly \\(E\\left(\\tilde{\\theta}_2\\right)=\\theta\\), so both are unbiased. Also, \\(\\operatorname{Var}\\left(\\tilde{\\theta}_1\\right)=\\frac{3}{0.9^2} \\approx 3.76\\) and \\(\\operatorname{Var}\\left(\\tilde{\\theta}_2\\right)=\\frac{2}{1.2^2} \\approx 1.39\\), so \\(\\tilde{\\theta}_2\\) is more efficient."
  },
  {
    "objectID": "w09/slides.html#calculation-3",
    "href": "w09/slides.html#calculation-3",
    "title": "Week 9: Statistical Inference",
    "section": "Calculation",
    "text": "Calculation"
  },
  {
    "objectID": "w09/slides.html#bias-variance-trade-off---a-look-ahead",
    "href": "w09/slides.html#bias-variance-trade-off---a-look-ahead",
    "title": "Week 9: Statistical Inference",
    "section": "Bias-Variance Trade Off - a look ahead",
    "text": "Bias-Variance Trade Off - a look ahead\nConsider \\(M S E^2=\\) bias \\(^2+\\) var . More complex models (with more parameters) tend to have less bias (are more flexible) and more variance (are more susceptible to noise).\n\n\n\nDSAN 5100-03 Week 9: Statistical Inference"
  },
  {
    "objectID": "w09/slides.html#statistical-inference",
    "href": "w09/slides.html#statistical-inference",
    "title": "Week 9: Statistical Inference",
    "section": "Statistical Inference",
    "text": "Statistical Inference\n\nMoving from understanding probability to getting things done using probability!\nEverything up to this point: understanding the “rules” of stochastic processes\nNow: Using what we know to allow us to draw inferences about populations without having to carry out a census"
  },
  {
    "objectID": "w09/slides.html#large-random-samples-1",
    "href": "w09/slides.html#large-random-samples-1",
    "title": "Week 9: Statistical Inference",
    "section": "Large Random Samples",
    "text": "Large Random Samples"
  },
  {
    "objectID": "w09/slides.html#samples-vs.-populations",
    "href": "w09/slides.html#samples-vs.-populations",
    "title": "Week 9: Statistical Inference",
    "section": "Samples vs. Populations",
    "text": "Samples vs. Populations\n\nSample = The data you have\nPopulation = The thing you want to learn about, by looking at the sample\nLike “success” vs. “failure” in Bernoulli trials, no exact definition of what counts as sample vs. population\nWhat we call the “sample” and the “population” is vocabulary there to help us know what to do"
  },
  {
    "objectID": "w09/slides.html#inference",
    "href": "w09/slides.html#inference",
    "title": "Week 9: Statistical Inference",
    "section": "Inference",
    "text": "Inference\nWhat are we doing when we do science?\n\n\n\nScience in General\n\n\n\nCode\ndigraph grid\n{\n    graph [\n        overlap=true,\n        scale=0.2,\n        newrank=true\n    ]\n    nodesep=1.0\n    ranksep=1.0\n    rankdir=\"LR\"\n    nodedir=\"LR\"\n    scale=0.2\n    node [\n        style=\"filled\",\n        color=black,\n        fillcolor=lightblue\n    ]\n    \n    subgraph cluster_01 {\n        label=\"\\\"Nature\\\"\";\n        Obs[label=\"Thing(s) we can see\"];\n        Und[label=\"Underlying processes\",fillcolor=white]\n        \n    }\n    {\n    Und -&gt; Model[dir=back,style=dashed];\n    Model -&gt; Obs[style=dashed];\n    }\n    {\n        rank=source;\n        Und -&gt; Obs [constraint=false];\n    }\n    \n    subgraph cluster_02 {\n        label=\"\\\"Science\\\"\"\n        Model[style=dashed];\n    }\n}\n\n\n\n\n\n\n\ngrid\n\n \n\ncluster_02\n\n “Science”  \n\ncluster_01\n\n “Nature”   \n\nObs\n\n Thing(s) we can see   \n\nUnd\n\n Underlying processes   \n\nUnd-&gt;Obs\n\n    \n\nModel\n\n Model   \n\nUnd-&gt;Model\n\n    \n\nModel-&gt;Obs\n\n   \n\n\n\n\n\n\n\nExample: Newton\n\n\n\nCode\ndigraph grid\n{\n    graph [\n        overlap=true,\n        scale=0.2,\n        newrank=true\n    ]\n    nodesep=1.0\n    ranksep=1.0\n    rankdir=\"LR\"\n    nodedir=\"LR\"\n    scale=0.2\n    node [\n        style=\"filled\",\n        color=black,\n        fillcolor=lightblue\n    ]\n  subgraph cluster_04 {\n    label=&lt;&lt;U&gt;Woolsthorpe Manor&lt;/U&gt;&gt;;\n    URL=\"https://en.wikipedia.org/wiki/Woolsthorpe_Manor\"\n    target=\"_blank\"\n    Tree[label=&lt;&lt;U&gt;Falling Apple&lt;/U&gt;&gt;,URL=\"https://www.popularmechanics.com/science/a5259/4343234/\",target=\"_blank\"];\n    Physics[label=&lt;&lt;U&gt;Particle Interactions&lt;/U&gt;&gt;,URL=\"https://en.wikipedia.org/wiki/Fundamental_interaction\",target=\"_blank\",fillcolor=white];\n  }\n  subgraph cluster_03 {\n    label=\"Isaac Newton\"\n    Newton[label=\"Newton's Laws\",style=dashed,fillcolor=white]\n  }\n  Newton -&gt; Tree [style=dashed];\n  {\n        rank=source;\n        Physics -&gt; Tree [constraint=false];\n    }\n  Physics -&gt; Newton[dir=back,style=dashed]\n}\n\n\n\n\n\n\n\ngrid\n\n \n\ncluster_04\n\n  Woolsthorpe Manor    \n\ncluster_03\n\n Isaac Newton   \n\nTree\n\n  Falling Apple     \n\nPhysics\n\n  Particle Interactions     \n\nPhysics-&gt;Tree\n\n    \n\nNewton\n\n Newton’s Laws   \n\nPhysics-&gt;Newton\n\n    \n\nNewton-&gt;Tree\n\n   \n\n\n\n\n\n\n\n\n\nRemember that the filled-in nodes represent things we can observe, while the non-filled nodes represent things we have to infer from the observable data."
  },
  {
    "objectID": "w09/slides.html#examples-abound",
    "href": "w09/slides.html#examples-abound",
    "title": "Week 9: Statistical Inference",
    "section": "Examples Abound!",
    "text": "Examples Abound!\n\n\n\nDarwinian Evolution\n\n\n\nCode\ndigraph grid\n{\n    graph [\n        overlap=true,\n        scale=0.2,\n        newrank=true\n    ]\n    nodesep=1.0\n    ranksep=1.0\n    rankdir=\"LR\"\n    nodedir=\"LR\"\n    scale=0.2\n    node [\n        style=\"filled\",\n        color=black,\n        fillcolor=lightblue\n    ]\n  subgraph cluster_04 {\n    label=\"Galápagos Islands\";\n    Tree[label=&lt;&lt;U&gt;Finches&lt;/U&gt;&gt;,URL=\"https://en.wikipedia.org/wiki/Darwin%27s_finches\",target=\"_blank\"];\n    Physics[label=\"Natural selection\",fillcolor=white];\n  }\n  subgraph cluster_03 {\n    label=\"Charles Darwin\"\n    Newton[label=\"Theory of Evolution\",style=dashed,fillcolor=white]\n  }\n  Newton -&gt; Tree [style=dashed];\n  {\n        rank=source;\n        Physics -&gt; Tree [constraint=false];\n    }\n  Physics -&gt; Newton[dir=back,style=dashed]\n}\n\n\n\n\n\n\n\ngrid\n\n \n\ncluster_03\n\n Charles Darwin  \n\ncluster_04\n\n Galápagos Islands   \n\nTree\n\n  Finches     \n\nPhysics\n\n Natural selection   \n\nPhysics-&gt;Tree\n\n    \n\nNewton\n\n Theory of Evolution   \n\nPhysics-&gt;Newton\n\n    \n\nNewton-&gt;Tree\n\n   \n\n\n\n\n\n\n\nEuclidean Geometry\n\n\n\nCode\ndigraph grid\n{\n    graph [\n        overlap=true,\n        scale=0.2,\n        newrank=true\n    ]\n    nodesep=1.0\n    ranksep=1.0\n    rankdir=\"LR\"\n    nodedir=\"LR\"\n    scale=0.2\n    node [\n        style=\"filled\",\n        color=black,\n        fillcolor=lightblue\n    ]\n  subgraph cluster_04 {\n    label=&lt;&lt;U&gt;Alexandria&lt;/U&gt;&gt;;\n    href=\"https://www.britannica.com/biography/Euclid-Greek-mathematician\";\n    target=\"_blank\";\n    Actual[label=\"Actual Triangles\"];\n    Platonic[label=\"Platonic Ideal Triangle\",fillcolor=white];\n  }\n  subgraph cluster_03 {\n    label=\"Euclid\"\n    Euclid[label=\"Euclidean Geometry\",style=dashed,fillcolor=white]\n  }\n  Euclid -&gt; Actual [style=dashed];\n  {\n        rank=source;\n        Platonic -&gt; Actual [constraint=false];\n    }\n  Platonic -&gt; Euclid[dir=back,style=dashed]\n}\n\n\n\n\n\n\n\ngrid\n\n \n\ncluster_04\n\n  Alexandria    \n\ncluster_03\n\n Euclid   \n\nActual\n\n Actual Triangles   \n\nPlatonic\n\n Platonic Ideal Triangle   \n\nPlatonic-&gt;Actual\n\n    \n\nEuclid\n\n Euclidean Geometry   \n\nPlatonic-&gt;Euclid\n\n    \n\nEuclid-&gt;Actual"
  },
  {
    "objectID": "w09/slides.html#zooming-in-on-euclid",
    "href": "w09/slides.html#zooming-in-on-euclid",
    "title": "Week 9: Statistical Inference",
    "section": "Zooming in on Euclid",
    "text": "Zooming in on Euclid\n\n\nObservations\n\n\n\n\n\n\nSource: Emily Pierce\n\n\n\n\n\n\n\nSource: Wikimedia\n\n\n\n\n\n\n\n\nInteractive visualization from UNC Archaeology\n\n\n\n\n\n→\n\n\n\nInference\n\n\n\n13th-Century Arabic Elements, from Sotheby’s\n\n\n\n\n\n\nFor an absolutely beautiful visual presentation of Elements see here"
  },
  {
    "objectID": "w09/slides.html#inference-in-the-diagram",
    "href": "w09/slides.html#inference-in-the-diagram",
    "title": "Week 9: Statistical Inference",
    "section": "Inference in the Diagram",
    "text": "Inference in the Diagram\n\n\nCode\ndigraph grid\n{\n    graph [\n        overlap=true,\n        scale=0.2,\n        newrank=true\n    ]\n    nodesep=1.0\n    ranksep=1.0\n    rankdir=\"LR\"\n    nodedir=\"LR\"\n    scale=0.2\n    node [\n        style=\"filled\",\n        color=black,\n        fillcolor=lightblue\n    ]\n  subgraph cluster_04 {\n    label=&lt;&lt;U&gt;Alexandria&lt;/U&gt;&gt;;\n    href=\"https://www.britannica.com/biography/Euclid-Greek-mathematician\";\n    target=\"_blank\";\n    Actual[label=\"Actual Triangles\"];\n    Platonic[label=\"Platonic Ideal Triangle\",fillcolor=white];\n  }\n  subgraph cluster_03 {\n    label=\"Euclid\"\n    Euclid[label=\"Euclidean Geometry\",style=dashed,fillcolor=white]\n  }\n  Actual -&gt; Euclid [style=solid,label=\"Observe\"];\n  {\n        rank=source;\n        Platonic -&gt; Actual[\n        //label=\"What goes here? \",\n        constraint=false,\n        //labeldistance=10.0,\n        xlabel=&lt;&lt;B&gt;What goes here? &lt;/B&gt;&gt;,\n        dir=both,\n        style=dashed\n      ];\n    }\n  Platonic -&gt; Euclid[dir=back,style=solid,label=\"Infer\"]\n}\n\n\n\n\n\n\n\ngrid\n\n \n\ncluster_04\n\n  Alexandria    \n\ncluster_03\n\n Euclid   \n\nActual\n\n Actual Triangles   \n\nEuclid\n\n Euclidean Geometry   \n\nActual-&gt;Euclid\n\n  Observe   \n\nPlatonic\n\n Platonic Ideal Triangle   \n\nPlatonic-&gt;Actual\n\n   What goes here?    \n\nPlatonic-&gt;Euclid\n\n  Infer"
  },
  {
    "objectID": "w09/slides.html#completing-the-cycle",
    "href": "w09/slides.html#completing-the-cycle",
    "title": "Week 9: Statistical Inference",
    "section": "Completing the Cycle",
    "text": "Completing the Cycle\n\n\nCode\ndigraph grid\n{\n    graph [\n        overlap=true,\n        scale=0.2,\n        newrank=true\n    ]\n    nodesep=1.0\n    ranksep=1.0\n    rankdir=\"LR\"\n    nodedir=\"LR\"\n    scale=0.2\n    node [\n        style=\"filled\",\n        color=black,\n        fillcolor=lightblue\n    ]\n  subgraph cluster_04 {\n    margin=28;\n    label=&lt;&lt;U&gt;Alexandria&lt;/U&gt;&gt;;\n    href=\"https://www.britannica.com/biography/Euclid-Greek-mathematician\";\n    target=\"_blank\";\n    Actual[label=\"Actual Triangles\"];\n    Platonic[label=\"Platonic Ideal Triangle\",fillcolor=white];\n  }\n  subgraph cluster_03 {\n    label=\"Euclid\"\n    Euclid[label=\"Euclidean Geometry\",style=dashed,fillcolor=white]\n  }\n  Actual -&gt; Euclid [style=solid,label=&lt;&lt;B&gt;Observe&lt;/B&gt;&gt;];\n  {\n        rank=source;\n        Platonic -&gt; Actual[\n        //label=\"What goes here? \",\n        constraint=false,\n        //labeldistance=10.0,\n        xlabel=&lt;&lt;B&gt;Hypothesis Testing! &lt;/B&gt;&gt;,\n        dir=both,\n        style=dashed\n      ];\n    }\n  Platonic -&gt; Euclid[dir=back,style=solid,label=&lt;&lt;B&gt;Infer&lt;/B&gt;&gt;]\n}\n\n\n\n\n\n\n\ngrid\n\n \n\ncluster_04\n\n  Alexandria    \n\ncluster_03\n\n Euclid   \n\nActual\n\n Actual Triangles   \n\nEuclid\n\n Euclidean Geometry   \n\nActual-&gt;Euclid\n\n  Observe   \n\nPlatonic\n\n Platonic Ideal Triangle   \n\nPlatonic-&gt;Actual\n\n   Hypothesis Testing!    \n\nPlatonic-&gt;Euclid\n\n  Infer"
  },
  {
    "objectID": "w09/slides.html#our-case",
    "href": "w09/slides.html#our-case",
    "title": "Week 9: Statistical Inference",
    "section": "Our Case",
    "text": "Our Case\n\n\nCode\ndigraph grid\n{\n    graph [\n        overlap=true,\n        scale=0.2,\n        newrank=true\n    ]\n    nodesep=1.0\n    ranksep=1.0\n    rankdir=\"LR\"\n    nodedir=\"LR\"\n    scale=0.2\n    node [\n        style=\"filled\",\n        color=black,\n        fillcolor=lightblue\n    ]\n  subgraph cluster_04 {\n    label=\"The World\";\n    margin=32;\n    Sample[label=\"Sample\"];\n    Population[label=\"Population\",fillcolor=white];\n  }\n  subgraph cluster_03 {\n    label=\"Us\"\n    Stats[label=\"Statistics\",style=dashed,fillcolor=white]\n  }\n  Stats -&gt; Sample [style=solid,dir=back,label=&lt;&lt;B&gt;Observe&lt;/B&gt;&gt;];\n  {\n        rank=source;\n        Population -&gt; Sample [\n        constraint=false,\n        //style=\"invis\",\n        //dir=both\n        xlabel=&lt;&lt;B&gt;Take Sample &lt;/B&gt;&gt;\n      ];\n    }\n  Population -&gt; Stats[label=&lt;&lt;B&gt;Infer&lt;/B&gt;&gt;,dir=back,style=solid]\n}\n\n\n\n\n\n\n\ngrid\n\n \n\ncluster_03\n\n Us  \n\ncluster_04\n\n The World   \n\nSample\n\n Sample   \n\nPopulation\n\n Population   \n\nPopulation-&gt;Sample\n\n  Take Sample    \n\nStats\n\n Statistics   \n\nPopulation-&gt;Stats\n\n  Infer   \n\nStats-&gt;Sample\n\n  Observe  \n\n\n\n\n\n\n\nIf you’re wondering, “what happened to Hypothesis Testing?”, don’t worry, we’ll dive back into that over the next 2 weeks!"
  },
  {
    "objectID": "w09/slides.html#stability-out-of-randomness",
    "href": "w09/slides.html#stability-out-of-randomness",
    "title": "Week 9: Statistical Inference",
    "section": "Stability out of Randomness",
    "text": "Stability out of Randomness\n\n\\(X\\) = result of coin flip\nRemembering that \\(X\\) is a random variable, so it maps outcomes to numbers: \\(X(\\)\\() = 0\\), \\(X(\\)\\() = 1\\)\nWe have no idea what the result of some single coin flip will be, yet we can be sure that the mean of many trials will converge to the expected value of \\(0.5\\)!\n\n\n\nTo check that you understand: what value would the mean of many dice rolls converge to?"
  },
  {
    "objectID": "w09/slides.html#interactive-visualization",
    "href": "w09/slides.html#interactive-visualization",
    "title": "Week 9: Statistical Inference",
    "section": "Interactive Visualization",
    "text": "Interactive Visualization"
  },
  {
    "objectID": "w09/slides.html#how-many-is-many",
    "href": "w09/slides.html#how-many-is-many",
    "title": "Week 9: Statistical Inference",
    "section": "How Many is “Many”?",
    "text": "How Many is “Many”?\n\n\nCode\nlibrary(ggplot2)\nlibrary(tibble)\nlibrary(dplyr)\nn_vals &lt;- c(ceiling(sqrt(10)), 10, ceiling(10*sqrt(10)), 100, ceiling(100*sqrt(10)), 1000, ceiling(1000*sqrt(10)), 10000, ceiling(10000*sqrt(10)), 100000)\nheads_data &lt;- c()\ntotal_data &lt;- c()\nfor (n in n_vals) {\n  coin_flips &lt;- rbinom(n, 1, 0.5)\n  num_heads &lt;- sum(coin_flips)\n  heads_data &lt;- c(heads_data, num_heads)\n  num_flipped &lt;- length(coin_flips)\n  total_data &lt;- c(total_data, num_flipped)\n}\nresults &lt;- tibble(n = n_vals, heads=heads_data, total=total_data)\nresults &lt;- results %&gt;% mutate(head_prop = heads / total)\n#results\nggplot(results, aes(x=n, y=head_prop)) +\n  geom_hline(aes(yintercept=0.5, linetype='dashed'), color=cbPalette[2]) +\n  geom_line(aes(color='black'), fill=cbPalette[1], linewidth=g_linewidth, color=cbPalette[1]) +\n  geom_point(aes(color='black'), size=g_pointsize*0.9) +\n  scale_color_manual(\"\", values=c(\"black\",\"purple\"), labels=c(\"Mean of n samples\",\"Expected Value\")) +\n  scale_linetype_manual(\"\", values=\"dashed\", labels=\"Expected Value\") +\n  scale_fill_manual(\"\", values=cbPalette[1], labels=\"95% CI\") +\n  #scale_linetype_manual('type', values=c('dashed', 'solid'), labels=c(\"Expected Value\", \"Sample Mean\")) +\n  #scale_color_manual('color', values=c(cbPalette[1], 'black'), labels=c('Expected Value', 'Sample Mean')) +\n  dsan_theme(\"full\") +\n  theme(\n      legend.title = element_blank(),\n      legend.spacing.y = unit(0, \"mm\")\n  ) +\n      labs(\n          title = \"Estimates of Population Mean for Increasing Sample Sizes\",\n          x = \"n (Sample Size)\",\n          y = \"Sample Mean\"\n      ) +\n  scale_x_log10(breaks = c(10, 100, 1000, 10000, 100000), labels = c(\"10\", \"100\", \"1000\", \"10000\", \"100000\"))"
  },
  {
    "objectID": "w09/slides.html#central-limit-theorem",
    "href": "w09/slides.html#central-limit-theorem",
    "title": "Week 9: Statistical Inference",
    "section": "Central Limit Theorem",
    "text": "Central Limit Theorem\n\nWe’ll never actually reach \\(n = \\infty\\), so we zoom in on how close our sample-based estimate gets to the true value\nCentral Limit Theorem says: these “closeness” values are normally distributed!\nLLN guarantees that \\(X_n \\eqeventual \\mu\\)\nCLT tells us what the gap \\(X_n - \\mu\\) looks like"
  },
  {
    "objectID": "w09/slides.html#formal-clt",
    "href": "w09/slides.html#formal-clt",
    "title": "Week 9: Statistical Inference",
    "section": "Formal CLT",
    "text": "Formal CLT\n\nSampled observations: \\(\\mathbf{X} = \\{X_1, \\ldots, X_n\\}\\)\n\\(\\expect{X_i} = \\mu, \\Var{X_i} = \\sigma^2 &lt; \\infty\\)\n\\(\\overline{X}_n \\definedas M_1(\\mathbf{X}) = \\frac{X_1 + \\cdots + X_n}{n}\\)\n\n\\[\n\\frac{\\overline{X}_n - \\mu}{\\sigma / \\sqrt{n}} \\overset{\\text{asymp}}{\\sim} \\mathcal{N}(0,1)\n\\]"
  },
  {
    "objectID": "w09/slides.html#when-is-mathcaln0-1-a-good-approximation",
    "href": "w09/slides.html#when-is-mathcaln0-1-a-good-approximation",
    "title": "Week 9: Statistical Inference",
    "section": "When is \\(\\mathcal{N}(0, 1)\\) a “good” approximation?",
    "text": "When is \\(\\mathcal{N}(0, 1)\\) a “good” approximation?\n\n\n\n\nCode\n# Prepare data for all plots\nmax_n &lt;- 10000\nnum_reps &lt;- 1000\nall_rolls &lt;- replicate(\n  num_reps,\n  sample(1:6, size = max_n, replace = TRUE, prob = rep(1 / 6, 6))\n)\ngen_clt_plot &lt;- function(n) {\n  exp_val &lt;- 3.5\n  sigma &lt;- sqrt(35/12)\n  denom &lt;- sigma / sqrt(n)\n  # Get the slice of all_rolls for this n\n  n_rolls &lt;- all_rolls[1:n,]\n  sample_means &lt;- colMeans(n_rolls)\n  norm_gaps &lt;- (sample_means - exp_val) / denom\n  n_df &lt;- tibble(norm_gap=norm_gaps)\n  #if (n == 5) {\n  #  print(sample_means)\n  #  print(n_df)\n  #}\n  ggplot(n_df, aes(x = norm_gap)) +\n  geom_histogram(aes(y = after_stat(density)), binwidth = 1/2) +\n  #geom_density() +\n  stat_function(fun=dnorm, size=g_linesize) +\n  dsan_theme(\"quarter\") +\n  labs(\n    title = paste0(\"n = \",n),\n    x = \"Normalized Sample Gap\"\n  )\n}\n\n\n\n\nCode\ngen_clt_plot(2)\n\n\n\n\n\n\n\n\n\n\n\nCode\ngen_clt_plot(4)\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ngen_clt_plot(5)\n\n\n\n\n\n\n\n\n\n\n\nCode\ngen_clt_plot(10000)"
  },
  {
    "objectID": "w09/slides.html#q-q-plots",
    "href": "w09/slides.html#q-q-plots",
    "title": "Week 9: Statistical Inference",
    "section": "Q-Q Plots",
    "text": "Q-Q Plots\n\n\n\n\nCode\ngen_qq &lt;- function(n) {\n  n_rolls &lt;- all_rolls[1:n,]\n  sample_means &lt;- colMeans(n_rolls)\n  qq_df &lt;- tibble(smean = sample_means)\n  qq_plot &lt;- ggplot(qq_df, aes(sample = smean)) +\n  stat_qq() + stat_qq_line() +\n  dsan_theme(\"quarter\") +\n  labs(\n    title = paste0(\"n = \",n)\n  )\n  return(qq_plot)\n}\ngen_qq(5)\n\n\n\n\n\n\n\n\n\n\n\nCode\ngen_qq(1000)\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ngen_qq(100)\n\n\n\n\n\n\n\n\n\n\n\nCode\ngen_qq(10000)"
  },
  {
    "objectID": "w09/slides.html#maximum-likelihood-estimation",
    "href": "w09/slides.html#maximum-likelihood-estimation",
    "title": "Week 9: Statistical Inference",
    "section": "Maximum Likelihood Estimation",
    "text": "Maximum Likelihood Estimation\n\nRecall: when we develop a model \\(\\mathcal{M}\\), we’re working with\n\n\\[\nP_{\\mathcal{M}}(\\underbrace{x_1, \\ldots, x_n}_{\\text{Observed Data}} \\mid \\underbrace{\\theta}_{\\text{Model Parameters}})\n\\]\n\nWhen we view this as a function of \\(\\theta\\), given the observed data, we call it the likelihood function \\(\\mathcal{L}_{\\mathcal{M}}(\\theta \\mid x_1, \\ldots, x_n)\\)\nRead this as “the likelihood that our model \\(\\mathcal{M}\\), with parameters \\(\\theta\\), produced the data \\(x_1, \\ldots, x_n\\)”"
  },
  {
    "objectID": "w09/slides.html#intuition-generative-models",
    "href": "w09/slides.html#intuition-generative-models",
    "title": "Week 9: Statistical Inference",
    "section": "Intuition: Generative Models",
    "text": "Intuition: Generative Models\n\nA given choice of model parameters \\(\\theta\\) can be used to generate simulated datapoints!\nSimple example: \\(X \\sim \\text{Bern}(p)\\). Just one parameter, \\(\\theta = \\{p\\}\\)\nWe observe 10 coin flips: 8 heads, 2 tails. Of all the Bernoulli distributions (parameterized by \\(p\\)), which is most likely to generate this data?"
  },
  {
    "objectID": "w09/slides.html#section",
    "href": "w09/slides.html#section",
    "title": "Week 9: Statistical Inference",
    "section": "",
    "text": "Given a choice of \\(\\theta\\), we can generate as many simulated datasets as we want (in this case, 10 datasets for each \\(\\theta\\) value), then compute likelihood of producing 8 heads, 2 tails\n\n\nCode\nlibrary(tibble)\nlibrary(ggplot2)\nlibrary(dplyr)\nset.seed(1948)\nobs_heads &lt;- 8\nnum_flips &lt;- 10\nnum_reps &lt;- 10\ntheta_vals &lt;- c(0.01, 0.2, 0.4, 0.6, 0.8, 0.99)\nobs_matches &lt;- c()\nfor (i in 1:length(theta_vals)) {\n  theta &lt;- theta_vals[i]\n  theta_str &lt;- sprintf(\"%.2f\", theta)\n  #print(theta_str)\n  sim_data &lt;- replicate(\n    num_reps,\n    rbinom(num_flips, 1, theta)\n  )\n  #print(sim_data)\n  #data_str &lt;- paste0(sim_data, collapse=\", \")\n  num_heads &lt;- colSums(sim_data)\n  #print(num_heads)\n  num_matches &lt;- sum(num_heads == obs_heads)\n  obs_matches &lt;- c(obs_matches, num_matches)\n  #print(num_matches)\n  #print(num_heads)\n  num_tails &lt;- num_flips - num_heads\n  #print(num_tails)\n  data_strs &lt;- paste0(\"[\",num_heads,\" heads, \",num_tails,\" tails]\")\n  data_str &lt;- paste0(data_strs, collapse=\", \")\n  #writeLines(paste0(\"p = \",theta_str,\": \",data_str))\n}\n#print(obs_matches)\nresult_df &lt;- tibble(theta=as.character(theta_vals), num_matches=obs_matches)\nresult_df &lt;- result_df %&gt;% mutate(prop_matches = obs_matches / num_reps)\n\n\n\n\nCode\nggplot(result_df, aes(x=theta, y=prop_matches)) +\n  geom_bar(stat = 'identity', fill=cbPalette[1]) +\n  dsan_theme(\"full\") +\n  labs(\n    title = \"Likelihood of data (8 heads, 2 tails) given theta value\",\n    y = \"Proportion of times (8,2) generated\"\n  )\n\n\n\n(Among these vals) \\(p = 0.8\\) is maximum likelihood estimate\n\n\nCode\n# for (i in 1:length(theta_vals)) {\n#   cur_theta &lt;- theta_vals[i]\n#   print(cur_theta)\n#   cur_results &lt;- results[[i]]\n#   print(cur_results)\n#   num_matches &lt;- cur_results == 8\n#   writeLines(paste0(\"p = \",cur_theta,\": our dataset was produced \",num_matches,\" times\"))\n# }"
  },
  {
    "objectID": "w09/slides.html#mle-in-the-real-world",
    "href": "w09/slides.html#mle-in-the-real-world",
    "title": "Week 9: Statistical Inference",
    "section": "MLE in the Real World",
    "text": "MLE in the Real World\nPrev example may feel silly, since we could just mathematically solve for the optimal \\(p\\) value…\n\\[\n\\begin{align*}\np^* &\\overset{\\phantom{x_i\\text{ indep}}}{=} \\argmax_{\\theta} \\mathcal{L}(x_1, \\ldots, x_n \\mid p) \\\\\n&\\overset{x_i\\text{ indep}}{=} \\argmax_{\\theta} \\mathcal{L}(x_1 \\mid p)\\mathcal{L}(x_2 \\mid p) \\cdots \\mathcal{L}(x_n \\mid p)\n\\end{align*}\n\\]\n\nWhat are the individual \\(\\mathcal{L}(x_i \\mid p)\\) terms?\nHow do we maximize the product \\(\\mathcal{L}(x_1 \\mid p) \\cdots \\mathcal{L}(x_n \\mid p)\\)?\n\n\nTime for some Math Magic…"
  },
  {
    "objectID": "w09/slides.html#math-magic-1",
    "href": "w09/slides.html#math-magic-1",
    "title": "Week 9: Statistical Inference",
    "section": "Math Magic 1",
    "text": "Math Magic 1\n\nWhat are the individual \\(P(x_i \\mid p)\\) terms?\n\n\\(X \\sim \\text{Bern}(p)\\), so\n\\[\n\\begin{align*}\nP(X = x_i \\mid p) &= \\begin{cases}1 - p & x_i = 0 \\\\ p & x_i = 1\\end{cases} \\leftarrow \\genfrac{}{}{0pt}{}{\\text{ Non-differentiable}}{😭} \\\\\n&\\overset{\\text{math}}{\\underset{\\text{magic}}{=}} (1-p)^{1-x_i}p^{x_i} \\leftarrow \\text{ Differentiable! 😲}\n\\end{align*}\n\\]\nWhy do we need it to be differentiable? Stay tuned…"
  },
  {
    "objectID": "w09/slides.html#math-magic-2",
    "href": "w09/slides.html#math-magic-2",
    "title": "Week 9: Statistical Inference",
    "section": "Math Magic 2",
    "text": "Math Magic 2\nRemember calculus!\n\\[\np^* = \\argmax_p f(p) \\implies f'(p^*) = 0\n\\]\nSo, to maximize likelihood function, we need to find its derivative1, set it equal to 0, and solve:\n\\[\n\\begin{align*}\n&\\frac{d}{dp}\\mathcal{L}(x \\mid p) = 0 \\iff \\\\\n&\\frac{d}{dp}\\left[\\mathcal{L}(x_1 \\mid p)\\mathcal{L}(x_2 \\mid p)\\cdots \\mathcal{L}(x_n \\mid p)\\right] = 0\n\\end{align*}\n\\]\nThis is why we used math magic to make \\(P(x_i \\mid \\theta)\\) differentiable, in the previous slide!"
  },
  {
    "objectID": "w09/slides.html#obstacle-products-vs.-sums",
    "href": "w09/slides.html#obstacle-products-vs.-sums",
    "title": "Week 9: Statistical Inference",
    "section": "Obstacle: Products vs. Sums",
    "text": "Obstacle: Products vs. Sums\n\nFinding \\(\\frac{d}{dp}\\left[ \\mathcal{L}(x_1)\\mathcal{L}(x_2)\\cdots \\mathcal{L}(x_n)\\right]\\) is a doozy, even with just \\(n = 2\\) datapoints:\n\n\\[\n\\begin{align*}\n&\\frac{d}{dp}\\left[ \\mathcal{L}(x_1)\\mathcal{L}(x_2) \\right] = \\left( \\frac{d}{dp}\\mathcal{L}(x_1)\\right) \\cdot \\mathcal{L}(x_2) + \\mathcal{L}(x_1)\\cdot \\left( \\frac{d}{dp}\\mathcal{L}(x_2) \\right) \\\\\n&= (1-p)^{-x_1}p^{x_1-1}(x_1-p)\\cdot (1-p)^{1-x_2}p^{x_2} \\\\\n&+ (1-p)^{1-x_1}p^{x_1} \\cdot (1-p)^{-x_2}p^{x_2-1}(x_2 - p)\n%&= \\frac{d}{d\\theta}\\left[ (1-p)^{1-x_1}p^{x_1}(1-p)^{1-x_2}p^{x_2} \\right]\n\\end{align*}\n\\]\n\nComplicating factor: \\(\\mathcal{L}(x_i)\\) terms are all multiplied together, forcing us to use product rule: \\(\\frac{d}{d\\theta}\\left[P(x_1)P(x_2)\\right] = \\left(\\frac{d}{d\\theta}P(x_1)\\right)\\cdot P(x_2) + P(x_1)\\cdot \\left(\\frac{d}{d\\theta}P(x_2)\\right)\\)\nIf we had terms that were added rather than multiplied, we’d have a much easier time: \\(\\frac{d}{d\\theta}\\left[ \\mathcal{L}(x_1) + \\mathcal{L}(x_2)\\right] = \\frac{d}{d\\theta}P(x_1) + \\frac{d}{d\\theta} P(x_2)\\)1\nSo, what math operation do we know that turns multiplications into additions?\n\n\nWe achieve this simplification because the derivative operator is linear: \\(\\frac{d}{dx}\\left[ f(x) + g(x) \\right] = \\frac{d}{dx}f(x) + \\frac{d}{dx}g(x)\\)"
  },
  {
    "objectID": "w09/slides.html#math-magic-3-log-likelihood",
    "href": "w09/slides.html#math-magic-3-log-likelihood",
    "title": "Week 9: Statistical Inference",
    "section": "Math Magic 3: Log-Likelihood",
    "text": "Math Magic 3: Log-Likelihood\n\\[\n\\log(a\\cdot b) = \\log(a) + \\log(b)\n\\]\nBingo! So, can we maximize \\(\\ell(x_i) = \\log(\\mathcal{L}(x_i))\\) rather than \\(\\mathcal{L}(x_i)\\)? Bingo again! Because logarithms are monotonic,\n\\[\nx^* = \\argmax_x \\left[ \\log\\left(f(x)\\right) \\right] \\iff x^* = \\argmax_x \\left[ f(x) \\right]\n\\]\nSo, we can just solve\n\\[\np^* = \\argmax_p \\left[ \\ell(x_1, \\ldots, x_n)\\right]\n\\]"
  },
  {
    "objectID": "w09/slides.html#section-1",
    "href": "w09/slides.html#section-1",
    "title": "Week 9: Statistical Inference",
    "section": "",
    "text": "Our problem simplifies to figuring out\n\\[\n\\begin{align*}\n\\frac{d}{dp}\\left[ \\log \\left( \\mathcal{L}(x_1)\\cdots \\mathcal{L}(x_n) \\right) \\right] &= \\frac{d}{dp}\\left[ \\log \\mathcal{L}(x_1) + \\log\\mathcal{L}(x_2) + \\cdots + \\log\\mathcal{L}(x_n) \\right] \\\\\n&= \\frac{d}{dp}\\left[ \\ell(x_1) + \\ell(x_2) + \\cdots + \\ell(x_n) \\right] = \\frac{d}{dp}\\left[ \\sum_{i=1}^n \\ell(x_i)\\right]\n\\end{align*}\n\\]\nBut since the derivative is a linear operator, \\(\\frac{d}{dp}\\left[ \\sum_{i=1}^n \\ell(x_i) \\right] = \\sum_{i=1}^n \\frac{d}{dp}\\left[ \\ell(x_i) \\right]\\), so we just have to compute \\(\\frac{d}{dp}\\ell(x_i)\\)! No product rule required (though we still need chain rule):\n\\[\n\\begin{align*}\n\\frac{d}{dp}\\left[ \\ell(x_i) \\right] &= \\frac{d}{dp}\\left[ \\log((1-p)^{1-x_i}p^{x_i}) \\right] = \\frac{d}{dp}\\left[(1-x_i)\\log(1-p) + x_i\\log(p)\\right] \\\\\n&= (1-x_i)\\frac{d}{dp}\\log(1-p) + x_i\\frac{d}{dp}\\log(p) = -\\frac{1-x_i}{1-p} + \\frac{x_i}{p} \\\\\n&= \\frac{p - x_i}{(p-1)p}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w09/slides.html#section-2",
    "href": "w09/slides.html#section-2",
    "title": "Week 9: Statistical Inference",
    "section": "",
    "text": "Now that we know \\(\\frac{d}{dp}\\ell(x_i)\\), we set our log-likelihood equation equal to zero to find the likelihood-maximizing \\(p\\) value, \\(p^*\\):\n\\[\n\\begin{align*}\n&\\sum_{i=1}^n\\frac{d}{dp}\\ell(x_i) = 0 \\iff \\sum_{i=1}^n \\frac{p^* - x_i}{(p^*-1)p^*} = 0 \\\\\n&\\iff -\\frac{1}{(p^*-1)p^*}\\sum_{i=1}^nx_i - np^* = 0 \\\\\n&\\iff \\sum_{i=1}^nx_i = np^* \\iff \\boxed{p^* = \\frac{\\sum_{i=1}^nx_i}{n}}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w09/slides.html#mle-intuition",
    "href": "w09/slides.html#mle-intuition",
    "title": "Week 9: Statistical Inference",
    "section": "MLE Intuition",
    "text": "MLE Intuition\n\\[\np^* = \\frac{\\sum_{i=1}^nx_i}{n} = \\frac{\\sum_{i=1}^n \\mathbf{1}[x_i = 1]}{n} \\genfrac{}{}{0pt}{}{\\leftarrow \\text{\\# Heads}}{\\leftarrow \\text{\\# Flips }}\n\\]\n\nMLE almost always matches intuition! Example: given data \\(x_1, \\ldots, x_n\\), what Normal distribution best fits this data?\nSame as asking: what parameter settings for \\(\\mathcal{N}(\\mu, \\sigma^2)\\) are most likely to produce \\(x_1, \\ldots, x_n\\)? The answer:\n\n\\[\n\\mu^* = \\frac{\\sum_{i=1}^n x_i}{n} \\; \\; \\; \\sigma^2_* = \\frac{\\sum_{i=1}^n (x_i-\\mu^*)^2}{n}\n\\]"
  },
  {
    "objectID": "w09/slides.html#the-dark-side-of-mle",
    "href": "w09/slides.html#the-dark-side-of-mle",
    "title": "Week 9: Statistical Inference",
    "section": "The Dark Side of MLE",
    "text": "The Dark Side of MLE\n\nSometimes steers us in the wrong direction!\nConsider values from previous slide, as estimators for population \\(\\mu\\) and \\(\\sigma^2\\): \\(\\mu^*\\) unbiased if \\(\\expect{\\mu^*} = \\mu\\):\n\n\\[\n\\begin{align*}\n\\expect{\\mu^*} &= \\bigexpect{\\frac{\\sum_{i=1}^nx_i}{n}} = \\frac{1}{n}\\sum_{i=1}^n\\expect{x_i} \\\\\n&= \\frac{1}{n}\\sum_{i=1}^n\\mu = \\frac{n\\mu}{n} = \\mu \\; ✅\n\\end{align*}\n\\]\n\nSo far so good. How about \\(\\sigma^2_*\\)?"
  },
  {
    "objectID": "w09/slides.html#mle-as-biased-estimator",
    "href": "w09/slides.html#mle-as-biased-estimator",
    "title": "Week 9: Statistical Inference",
    "section": "MLE as Biased Estimator",
    "text": "MLE as Biased Estimator\n\nBefore we think about \\(\\expect{\\sigma^2_*}\\), let’s rewrite \\(\\sigma^2_*\\):\n\n\\[\n\\begin{align*}\n\\sigma^2_* &= \\frac{1}{n}\\sum_{i=1}^n(x_i - \\mu^*)^2 = \\frac{1}{n}\\sum_{i=1}^n \\left( x_i^2 - 2 \\mu^* x_i + (\\mu^*)^2 \\right) \\\\\n&= \\frac{1}{n}\\sum_{i=1}^nx_i^2 - 2\\mu^*\\underbrace{\\frac{\\sum_{i=1}^nx_i}{n}}_{\\mu^*} + (\\mu^*)^2 = \\frac{1}{n}\\sum_{i=1}^nx_i^2 - (\\mu^*)^2 \\\\\n&= \\frac{1}{n}\\sum_{i=1}^nx_i^2 - (\\mu^*)^2\n\\end{align*}\n\\]\n\nNow we’re ready to compute \\(\\expect{\\sigma^2_*}\\)!"
  },
  {
    "objectID": "w09/slides.html#section-3",
    "href": "w09/slides.html#section-3",
    "title": "Week 9: Statistical Inference",
    "section": "",
    "text": "\\[\n\\begin{align*}\n\\expect{\\sigma^2_*} &= \\bigexpect{\\frac{1}{n}\\sum_{i=1}^nx_i^2 - (\\mu^*)^2} = \\frac{1}{n}\\sum_{i=1}^n \\expect{x_i^2} - \\expect{(\\mu^*)^2}\n\\end{align*}\n\\]\n\nWhat do we know about \\(\\expect{x_i^2}\\)?\nRemember the (alternate) definition of variance: \\(\\Var{X} = \\expect{X^2} - \\left(\\expect{X}\\right)^2\\). Then\n\n\\[\n\\expect{X^2} = \\Var{X} + \\left(\\expect{X}\\right)^2\n\\]\nSo let’s plug in the right side when we see \\(\\expect{X^2}\\) or \\(\\expect{(\\mu^*)^2}\\):\n\\[\n\\begin{align*}\n\\frac{1}{n}\\sum_{i=1}^n \\expect{x_i^2} - \\expect{(\\mu^*)^2} &= \\frac{1}{n}\\sum_{i=1}^n\\left(\\Var{X} + \\left(\\expect{X}\\right)^2\\right) - \\expect{(\\mu^*)^2} \\\\\n&= (\\sigma^2 + \\mu^2) - \\left(\\Var{\\mu^*} + \\left(\\expect{\\mu^*}\\right)^2\\right)\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w09/slides.html#section-4",
    "href": "w09/slides.html#section-4",
    "title": "Week 9: Statistical Inference",
    "section": "",
    "text": "Almost there! We know that \\(\\expect{\\mu^*} = \\mu\\), but what is \\(\\Var{\\mu^*}\\)? Remember that \\(\\Var{aX} = a^2\\Var{X}\\)!\n\n\\[\n\\Var{\\mu^*} = \\bigVar{\\frac{1}{n}\\sum_{i=1}^nx_i} = \\frac{1}{n^2}\\sum_{i=1}^n\\Var{x_i} = \\frac{n\\sigma^2}{n^2} = \\frac{\\sigma^2}{n}\n\\]\nAnd we plug back in to get:\n\\[\n\\begin{align*}\n\\expect{\\sigma^2_*} &= \\sigma^2 + \\mu^2 - \\Var{\\mu^*} - \\left(\\expect{\\mu^*}\\right)^2 \\\\\n&= \\sigma^2 + \\mu^2 - \\frac{\\sigma^2}{n} - \\mu^2 = \\sigma^2 - \\frac{\\sigma^2}{n} \\\\\n&= \\frac{n\\sigma^2 - \\sigma^2}{n} = \\frac{\\sigma^2(n-1)}{n} \\\\\n&= \\color{red}{\\left(\\frac{n-1}{n}\\right)\\sigma^2} \\neq \\sigma^2 \\; 💀\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w09/slides.html#why-does-this-happen-handwaving",
    "href": "w09/slides.html#why-does-this-happen-handwaving",
    "title": "Week 9: Statistical Inference",
    "section": "Why Does This Happen?: Handwaving",
    "text": "Why Does This Happen?: Handwaving\n\nLong story short, we underpredict the population variance because we already used some of the data to compute \\(\\mu^*\\)!\nThis is where the heuristic of degrees of freedom comes in:\n\nWhen computing an estimate \\(e\\), \\(df(e) = n - k_e\\)\n\\(k_e =\\) number of other estimates used to calculate \\(e\\)!"
  },
  {
    "objectID": "w09/slides.html#handwavy-intuition",
    "href": "w09/slides.html#handwavy-intuition",
    "title": "Week 9: Statistical Inference",
    "section": "Handwavy Intuition",
    "text": "Handwavy Intuition\n\nConsider \\(X_1, X_2 \\sim \\mathcal{N}(0,1)\\): \\(\\mu = 0\\), \\(\\sigma^2 = 1\\).\n\n\\[\n\\expect{\\mu^*} = \\bigexpect{\\frac{X_1 + X_2}{2}} = \\frac{1}{2}\\left(\\expect{X_1} + \\expect{X_2}\\right) = 0 = \\mu \\; ✅\n\\]\n\\[\n\\begin{align*}\n\\expect{\\sigma^2_*} &= \\frac{1}{2}\\bigexpect{(X_1 - \\mu^*)^2 + (X_2 - \\mu^*)^2} \\\\\n&= \\frac{1}{2}\\bigexpect{\\left(X_1^2 + \\mu^2_* -2\\mu^*X_1\\right) + \\left(X_2^2 + \\mu^2_* - 2X_2\\mu^*\\right)} \\\\\n&= \\frac{1}{2}\\expect{X_1^2 + X_2^2 + 2\\mu_*^2 - 2\\mu^*X_1 - 2\\mu^*X_2} \\\\\n&= \\frac{1}{2}\\left(\\expect{X_1^2} + \\expect{X_2^2} + 2\\expect{\\mu_*^2} - 2\\expect{\\mu^*X_1} - 2\\expect{\\mu^*X_2}\\right) \\\\\n&\\implies \\boxed{\\expect{\\sigma^2_*} = \\frac{1}{2}\\sigma^2}\n\\end{align*}\n\\]\n\nWe’re off by \\(\\frac{1}{2}\\)! What to do?"
  },
  {
    "objectID": "w09/slides.html#handwavy-solution",
    "href": "w09/slides.html#handwavy-solution",
    "title": "Week 9: Statistical Inference",
    "section": "Handwavy Solution",
    "text": "Handwavy Solution\n\nWe can account for degrees of freedom, correcting the MLE by a factor of \\(\\frac{n}{df(e^*)}\\)!\n\n\\(e^\\circledast = \\frac{n}{df(e^*)}e^*\\)\n\nEx: Since \\(\\expect{\\sigma_*^2} = \\frac{n-1}{n}\\sigma^2\\), we can instead use \\(\\sigma^2_\\circledast = \\frac{n}{n-1}\\sigma^2_*\\). This gives us:\n\n\\[\n\\expect{\\sigma^2_\\circledast} = \\bigexpect{\\frac{n}{n-1}\\sigma^2_*} = \\frac{n}{n-1}\\frac{n-1}{n}\\sigma^2 = \\color{green}{\\sigma^2} \\; ✅\n\\]"
  },
  {
    "objectID": "w09/slides.html#st-century-solution",
    "href": "w09/slides.html#st-century-solution",
    "title": "Week 9: Statistical Inference",
    "section": "21st-Century Solution",
    "text": "21st-Century Solution\n\nBe Bayesian, use priors on parameters (creating hyperparameters)!\nPretend we know \\(\\sigma^2\\), but want to find the “best” value of \\(\\mu\\):\n\n\\[\n\\begin{array}{rlccc}\nX_1, X_2 \\overset{iid}{\\sim} \\mathcal{N}( &\\hspace{-5mm}\\mu\\hspace{0.5mm}, &\\hspace{-8mm}\\overbrace{\\sigma^2}^{\\large\\text{known}}\\hspace{-2mm}) & & \\\\\n&\\hspace{-4mm}\\downarrow & ~ &\\hspace{-10mm}{\\small\\text{estimate}} & \\hspace{-6mm} & \\hspace{-8mm}{\\small\\text{uncertainty}} \\\\[-5mm]\n&\\hspace{-5mm}\\mu &\\hspace{-5mm}\\sim \\mathcal{N}&\\hspace{-7mm}(\\overbrace{m}&\\hspace{-12mm}, &\\hspace{-16mm}\\overbrace{s})\n\\end{array}\n\\]"
  },
  {
    "objectID": "w09/slides.html#section-5",
    "href": "w09/slides.html#section-5",
    "title": "Week 9: Statistical Inference",
    "section": "",
    "text": "Let’s consider the estimate of \\(\\mu\\) from a single datapoint \\(X_i\\). MLE just gives us \\(\\mu^* = X_i\\). How about MAP estimate?\n\n\\[\n\\lik\\left(X_i, \\mu, m, s\\right) \\overset{\\text{factors}}{\\underset{\\text{into}}{=}} P(X_i \\mid \\mu)P(\\mu \\mid m, s)P(m, s)\n\\]\n\nRemembering the pdf of the Normal distribution, we have:\n\n\\[\n\\lik\\left(X_i, \\mu, m, s\\right) = \\frac{1}{\\sigma\\sqrt{2\\pi}}\\exp\\left[-\\frac{(X_i-\\mu)^2}{2\\sigma^2}\\right]\\frac{1}{s\\sqrt{2\\pi}}\\exp\\left[-\\frac{(\\mu - m)^2}{2s^2}\\right]\n\\]\n\nThen, remembering that we can maximize the log-likelihood rather than the likelihood:\n\n\\[\n\\ell(X_i, \\mu, m, s) = \\log\\left[\\frac{1}{\\sigma\\sqrt{2\\pi}}\\right] - \\frac{(X_i-\\mu)^2}{2\\sigma^2} + \\log\\left[\\frac{1}{s\\sqrt{2\\pi}}\\right] - \\frac{(\\mu - m)^2}{2s^2}\n\\]"
  },
  {
    "objectID": "w09/slides.html#section-6",
    "href": "w09/slides.html#section-6",
    "title": "Week 9: Statistical Inference",
    "section": "",
    "text": "Taking the derivative gives us:\n\n\\[\n\\begin{align*}\n\\frac{\\partial\\ell}{\\partial \\mu} &= \\frac{\\partial}{\\partial\\mu}\\left[ {\\color{red}\\cancel{\\color{black}\\log\\left[\\frac{1}{\\sigma\\sqrt{2\\pi}}\\right]}} - \\frac{(X_i-\\mu)^2}{2\\sigma^2} + {\\color{red}\\cancel{\\color{black}\\log\\left[\\frac{1}{s\\sqrt{2\\pi}}\\right]}} - \\frac{(\\mu - m)^2}{2s^2}\\right] \\\\\n&= - \\frac{1}{2\\sigma^2}\\cdot\\frac{\\partial}{\\partial\\mu}\\left[{\\color{red}\\cancel{\\color{black}X_i^2}} + \\mu^2 - 2X_i\\mu\\right] - \\frac{1}{2s^2}\\cdot\\frac{\\partial}{\\partial\\mu}\\left[\\mu^2 + {\\color{red}\\cancel{\\color{black}m^2}} - 2\\mu m\\right] \\\\\n&= -\\frac{1}{2\\sigma^2}\\cdot (2\\mu -2X_i) - \\frac{1}{2s^2}\\cdot (2\\mu - 2m) = \\frac{X_i-\\mu}{\\sigma^2} + \\frac{m - \\mu}{s^2}\n\\end{align*}\n\\]\n\nAnd we set equal to zero and solve to obtain the MAP estimate:\n\n\\[\n\\begin{align*}\n&\\frac{X_i - \\mu^*}{\\sigma^2} + \\frac{m - \\mu^*}{s^2} = 0 \\iff \\frac{\\mu^*}{\\sigma^2} + \\frac{\\mu^*}{s^2} = \\frac{X_i}{\\sigma^2} + \\frac{m}{s^2} \\iff \\\\\n&\\frac{s^2\\mu^* + \\sigma^2\\mu^*}{\\sigma^2s^2} = \\frac{s^2X_i + \\sigma^2m}{\\sigma^2s^2} \\iff \\mu^*(s^2+\\sigma^2) = s^2X_i + \\sigma^2m \\\\\n&\\iff \\boxed{\\mu^* = \\left(\\frac{s^2}{s^2 + \\sigma^2}\\right)X_i + \\left(\\frac{\\sigma^2}{s^2 + \\sigma^2}\\right)m}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w09/slides.html#the-takeaway",
    "href": "w09/slides.html#the-takeaway",
    "title": "Week 9: Statistical Inference",
    "section": "The Takeaway",
    "text": "The Takeaway\n\nBayesian approach allows new evidence to be weighed against existing evidence, with statistically principled way to derive these weights:\n\n\\[\n\\begin{array}{ccccc}\nP_{\\text{post}}(\\mathcal{H}) &\\hspace{-6mm}\\propto &\\hspace{-6mm} P(X \\mid \\mathcal{H}) &\\hspace{-6mm} \\times &\\hspace{-6mm} P_{\\text{pre}}(\\mathcal{H}) \\\\\n\\text{Posterior} &\\hspace{-6mm}\\propto &\\hspace{-6mm}\\text{Evidence} &\\hspace{-6mm} \\times &\\hspace{-6mm} \\text{Prior}\n\\end{array}\n\\]"
  },
  {
    "objectID": "w09/slides.html#next-week",
    "href": "w09/slides.html#next-week",
    "title": "Week 9: Statistical Inference",
    "section": "Next Week",
    "text": "Next Week\n\nBootstrap Sampling"
  },
  {
    "objectID": "w09/slides.html#appendix-1-derivation-of-expectmu_2",
    "href": "w09/slides.html#appendix-1-derivation-of-expectmu_2",
    "title": "Week 9: Statistical Inference",
    "section": "Appendix 1: Derivation of \\(\\expect{\\mu_*^2}\\)",
    "text": "Appendix 1: Derivation of \\(\\expect{\\mu_*^2}\\)\n\\[\n\\begin{align*}\n\\expect{\\mu_*^2} &= \\bigexpect{\\left(\\frac{X_1 + X_2}{2}\\right)^2} = \\frac{1}{4}\\expect{(X_1+X_2)^2} \\\\\n&= \\frac{1}{4}\\expect{X_1^2 + X_2^2 + 2X_1X_2} = \\frac{1}{4}\\left(\\expect{X_1^2} + \\expect{X_2^2} + 2\\expect{X_1X_2}\\right) \\\\\n&= \\frac{1}{4}\\left(\\Var{X_1} + \\expect{X_1}^2 + \\Var{X_2} + \\expect{X_2}^2 + 2\\expect{X_1X_2}\\right) \\\\\n&= \\frac{1}{4}\\left(2\\sigma^2 + 2\\mu^2 + 2\\expect{X_1X_2}\\right) \\\\\n&= \\frac{1}{2}\\left(\\sigma^2 + \\mu^2 + \\expect{X_1X_2}\\right) \\overset{iid}{=} \\frac{1}{2}\\left(\\sigma^2 + \\mu^2 + \\mu^2\\right) \\\\\n&\\implies \\boxed{\\expect{\\mu^2_*} = \\mu^2 + \\frac{\\sigma^2}{2}} \\; \\; \\left(\\therefore \\; \\expect{\\mu_*^2} \\neq \\mu^2 \\right)\n\\end{align*}\n\\]"
  },
  {
    "objectID": "w09/slides.html#appendix-2-derivation-of-expectmux_i",
    "href": "w09/slides.html#appendix-2-derivation-of-expectmux_i",
    "title": "Week 9: Statistical Inference",
    "section": "Appendix 2: Derivation of \\(\\expect{\\mu^*X_i}\\)",
    "text": "Appendix 2: Derivation of \\(\\expect{\\mu^*X_i}\\)\n\\[\n\\begin{align*}\n\\expect{\\mu^*X_1} &= \\bigexpect{\\left(\\frac{X_1 + X_2}{2}\\right)X_1} = \\frac{1}{2}\\expect{X_1^2 + X_1X_2} \\\\\n&= \\frac{1}{2}\\expect{X_1^2} + \\frac{1}{2}\\expect{X_1X_2} = \\frac{1}{2}\\left(\\sigma^2 + \\mu^2\\right) + \\frac{1}{2}\\mu^2 \\\\\n&\\implies \\expect{\\mu^*X_1} = \\mu^2 + \\frac{\\sigma^2}{2}\n\\end{align*}\n\\]\nAnd since \\(X_1\\) was chosen without loss of generality,\n\\[\n\\boxed{\\expect{\\mu^*X_i} = \\mu^2 + \\frac{\\sigma^2}{2}}\n\\]"
  },
  {
    "objectID": "w09/slides.html#appendix-3-derivation-of-expectsigma2_",
    "href": "w09/slides.html#appendix-3-derivation-of-expectsigma2_",
    "title": "Week 9: Statistical Inference",
    "section": "Appendix 3: Derivation of \\(\\expect{\\sigma^2_*}\\)",
    "text": "Appendix 3: Derivation of \\(\\expect{\\sigma^2_*}\\)\n\\[\n\\begin{align*}\n\\expect{\\sigma^2_*} &= \\frac{1}{2}\\bigexpect{(X_1 - \\mu^*)^2 + (X_2 - \\mu^*)^2} \\\\\n&= \\frac{1}{2}\\bigexpect{\\left(X_1^2 + \\mu^2_* -2\\mu^*X_1\\right) + \\left(X_2^2 + \\mu^2_* - 2X_2\\mu^*\\right)} \\\\\n&= \\frac{1}{2}\\expect{X_1^2 + X_2^2 + 2\\mu_*^2 - 2\\mu^*X_1 - 2\\mu^*X_2} \\\\\n&= \\frac{1}{2}\\left(\\expect{X_1^2} + \\expect{X_2^2} + 2\\expect{\\mu_*^2} - 2\\expect{\\mu^*X_1} - 2\\expect{\\mu^*X_2}\\right) \\\\\n&= \\frac{1}{2}\\left( 2\\sigma^2 + 2\\mu^2 + 2\\left(\\mu^2 + \\frac{\\sigma^2}{2}\\right) - 2\\left(\\mu^2 + s/2\\right) - 2\\left(\\mu^2 + s/2\\right) \\right) \\\\\n&= \\sigma^2 + \\mu^2 + \\mu^2 + \\frac{\\sigma^2}{2} - \\mu^2 - \\frac{\\sigma^2}{2} - \\mu^2 - \\frac{\\sigma^2}{2} = \\sigma^2 - \\frac{\\sigma^2}{2} \\\\\n&\\implies \\boxed{\\expect{\\sigma^2_*} = \\frac{1}{2}\\sigma^2}\n\\end{align*}\n\\]\n\n\nDSAN 5100-03 Week 9: Statistical Inference"
  },
  {
    "objectID": "w09/slides.html#law-of-large-numbers-1",
    "href": "w09/slides.html#law-of-large-numbers-1",
    "title": "Week 9: Statistical Inference",
    "section": "Law of Large Numbers",
    "text": "Law of Large Numbers\nSuppose that \\(X_1, \\ldots, X_n\\) form a random sample from a distribution for which the mean is \\(\\mu\\) and for which the variance is finite. Let \\(\\bar{X}_n\\) denote the sample mean. Then \\[\n\\bar{X}_n \\stackrel{p}{\\longrightarrow} \\mu \\text {. }\n\\]"
  }
]