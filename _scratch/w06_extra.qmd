
## Example: Discrete Joint Distributions

**Theater Patrons**: Suppose that a sample of 10 people is selected at random from a theater with 200 patrons. One random variable of interest might be the number $X$ of **people in the same sample who are over 60 years of age**, and another random variable might be the number $Y$ of **people in the sample who live more than 25 miles away from the theater**.

* For each ordered pair $(x,y)$ with $x = 0, \ldots, 10$ and $y = 0, \ldots, 10$, we might wish to compute $\Pr((X,Y) = (x,y))$, the **probability** that there are $x$ people in the sample who are **over 60 years of age** and there are $y$ people in the sample who **live more than 25 miles away from the theater**.

## Discrete Joint distributions

::: {.callout-tip icon=false title="Definition: Discrete Joint Distribution (DeGroot and Schervish)"}

Let $X$ and $Y$ be random variables, and consider the ordered pair $(X,Y)$. If there are only finitely or at most countably many different possible values $(x,y)$ for the pair $(X,Y)$, then we say that $X$ and $Y$ have a *discrete joint distribution*.

:::

::: {.callout-tip icon=false title="Theorem 3.4.1 (DeGroot and Schervish)"}

Suppose that two random variables $X$ and $Y$ each have a discrete distribution. Then $X$ and $Y$ have a discrete joint distribution.

:::

## Joint Probability Function

::: {.callout-tip icon=false title="Definition: Joint Probability Function PF (DeGroot and Schervish)"}

The **joint probability function**, or the **joint PF**, of $X$ and $Y$ is definted as the function $f$ such that for every point $(x,y)$ in the $xy$-plane,

$$
f(x,y) = \Pr(X = x\text{ and }Y = y).
$$

:::

::: {.callout-tip icon=false title="Theorem 3.4.2 (DeGroot and Schervish)"}

Let $X$ and $Y$ have a discrete joint distribution. If $(x,y)$ is not one of the possible values of the pair $(X,Y)$, then $f(x,y) = 0$. Also,

$$
\sum_{(x,y) \in \Omega_X \times \Omega_Y}f(x,y) = 1.
$$

Finally, for each set $C$ of ordered pairs,

$$
\Pr\left[(X,Y) \in C\right] = \sum_{(x,y) \in C}f(x,y).
$$

:::

## Example

::: {.callout-tip icon=false title="Example: Specifying a Discrete Joint Distribution by a Table of Probabilities (DeGroot and Schervish)"}

In a certain suburban area, each household reported the number of cars and the number of television sets that they owned. Let $X$ stand for the number of cars owned by a randomly-selected household in this area. Let $Y$ stand for the number of television sets owned by that same randomly-selected household. In this case, $X$ takes only the values $1$, $2$, and $3$; $Y$ takes only the values $1$, $2$, $3$, and $4$; and the joint PF $f$ of $X$ and $Y$ is as specified in Table 3.2

::: columns
::: {.column width="50%"}

<table style="table-layout: fixed; width: 100% !important;">
<tr>
    <td></td>
    <td colspan="4" align="center">$y$</td>
</tr>
<tr>
    <td> $x$ </td>
    <td align="center">1</td>
    <td align="center">2</td>
    <td align="center">3</td>
    <td align="center">4</td>
</tr>
<tr>
    <td>1</td>
    <td>0.1</td>
    <td>0.0</td>
    <td>0.1</td>
    <td>0.0</td>
</tr>
<tr>
    <td>2</td>
    <td>0.3</td>
    <td>0.0</td>
    <td>0.1</td>
    <td>0.2</td>
</tr>
<tr>
    <td>3</td>
    <td>0.0</td>
    <td>0.2</td>
    <td>0.0</td>
    <td>0.0</td>
</tr>
</table>

:::
::: {.column width="50%"}

![](images/joint_pf_diagram.png)

:::
:::

:::

## Example

* The joint PF is sketched on the previous slide. We shall determine the probability that the randomly-selected household owns at least two of both cars and televisions. In symbols, this is $\Pr(X \geq 2\text{ and }Y \geq 2)$.

* By summing $f(x,y)$ over all values of $x \geq 2$ and $y \geq 2$, we obtain the value

$$
\Pr(X \geq 2\text{ and }Y \geq 2) = f(2,2) + f(2,3) + f(2,4) + f(3,2) + f(3,3) + f(3,4) = 0.5.
$$

* Next, we shall determine the probability that the randomly-selected household owns exactly one car, namely $\Pr(X = 1)$. By summing the probabilities in the first row of the table, we otain the value

$$
\Pr(X = 1) = \sum_{y = 1}^4 f(1,y) = 0.2.
$$

## Continuous Joint Distributions

::: {.callout-tip icon=false title="Definition: Continuous Joint Distribution (DeGroot and Schervish)"}

Two random variables $X$ and $Y$ have a **continuous joint distribution** if there exists a nonnegative function $f$ defined over the entire $xy$-plane such that for every subset $C$ of the plane,

$$
\Pr\left[(X,Y) \in C\right] = \int_C\int f(x,y)dxdy.
$$

:::

::: {.callout-tip icon=false title="Theorem 3.4.3 (DeGroot and Schervish)"}

A joint PDF must satisfy the following two conditions:

$$
f(x,y) \geq 0\text{ for }-\infty < x < \infty\text{ and }-\infty < y < \infty,
$$

and

$$
\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}f(x,y)dxdy = 1.
$$

:::

## Continuous joint distribution

::: {.callout-tip icon=false title="Theorem 3.4.4 (DeGroot and Schervish)"}

For every continuous joint distribution on the $xy$-plane, the following two statements hold:

i. Every individual point, and every infinite sequence of points, in the $xy$-plane has probability $0$.
ii. Let $f$ be a continuous function of one real variable defined on a (possibly unbounded) interval $(a,b)$. The sets $\{(x,y) : y = f(x), a < x < b\}$ and $\{(x,y) : x = f(y), a < y < b\}$ have probability $0$.

:::

## Example

* Let $(U,V)$ be independent random variables, each with uniform distribution on $(0,1)$.
* The joint density is

$$
f_{UV}(u, v) = \begin{cases}
1 &\text{for }(0 < u, v < 1) \\
0 &\text{otherwise.}
\end{cases}
$$

* Let $X = \min\{U,V\}$ and $Y = \max\{U,V\}$. One can show that the joint density of $(X,Y)$ is

$$
f_{XY}(x,y) = \begin{cases}
2 &\text{for }(0 < x \leq y < 1) \\
0 &\text{otherwise.}
\end{cases}
$$

## Example: Uniform on a triangle

* Suppose $(X,Y)$ is uniformly distributed over the region $\{(x,y) : 0 < x < y < 1\}$.
* **Problem 1**: Find the **joint density** of $(X,Y)$.
    * **Solution**: By the assumption, $f(x,y) = c$ for $0 < x < y < 1$ and $0$ elsewhere. Because the triangle has area $\frac{1}{2}$, $c = 2$.
* **Problem 2**: Find the **marginal densities** $f_X(x)$ and $f_Y(y)$.

## Example

::: {.callout-tip icon=false title="Example: Determining a Joint PDF by Geometric Methods (DeGroot and Schervish)"}

Suppose that a point $(X,Y)$ is selected at random from inside the circle $x^2 + y^2 \leq 9$. We shall determine the joint PDF of $X$ and $Y$.

The support of $(X,Y)$ is the set $S$ of points on and inside the circle $x^2 + y^2 \leq 9$. The statement that the point $(X,Y)$ is selected at random from inside the circle is interpreted to mean that the joint PDF of $X$ and $Y$ is constant over $S$ and is $0$ outside $S$. Thus,

$$
f(x,y) = \begin{cases}
c &\text{for }(x,y) \in S, \\
0 &\text{otherwise.}
\end{cases}
$$

We must have

$$
\int_S\int f(x,y)dxdy = c \cdot \text{(area of }S\text{)} = 1.
$$

Since the area of the circle $S$ is $9\pi$, the value of the constant $c$ must be $\frac{1}{9\pi}$.

:::

## Example

![An example of a joint PDF](images/ds-fig-3-11.png){#fig-3-11}

An example of the graph of a joint PDF is presented in @fig-3-11. The total volume beneath the surface $z = f(x,y)$ and above the $xy$-plane must be $1$. The probability that the pair $(X,Y)$ will belong to the rectangle $C$ is equal to the volume of the solid figure with base $A$ shown in @fig-3-11. The top of this solid figure is formed by the surface $z = f(x,y)$.

## Bivariate Cumulative Distribution Functions (CDFs)

::: {.callout-tip icon=false title="Definition 34.6: Joint Distribution Function/CDF (DeGroot and Schervish)"}

The **joint distribution function** or **joint cumulative distribution function (joint CDF)** of two random variables $X$ and $Y$ is defined as the function $F$ such that for all values of $x$ and $y$ ($-\infty < x < \infty$ and $-\infty < y < \infty$),

$$
F(x,y) = \Pr(X \leq x\text{ and }Y \leq y).
$$

:::

## Bivariate Normal distributions

::: {.callout-tip icon=false title="Theorem 5.10.1 (DeGroot and Schervish)"}

Suppose that $Z_1$ and $Z_2$ are independent random variables, each of which has the standard normal distribution. Let $\mu_1$, $\mu_2$, $\sigma_1$, $\sigma_2$, and $\rho$ be constants such that $-\infty < mu_i < \infty$ ($i = 1, 2$), $\sigma_i > 0$ ($i = 1,2$), and $-1 < \rho < 1$. Define two new random variables $X_1$ and $X_2$ as follows:

$$
\begin{align*}
X_1 &= \sigma_1Z_1 + \mu_1, \\
X_2 &= \sigma_2\left[\rho Z_1 + (1-\rho^2)^{1/2}Z_2 \right] + \mu_2.
\end{align*}
$$

The joint PDF of $X_1$ and $X_2$ is

$$
\begin{align*}
f(x_1, x_2) &= \frac{1}{2\pi(1-\rho^2)^{1/2}\sigma_1 \sigma_2} \exp\left\{ -\frac{1}{2(1-\rho^2)} \left[ \left( \frac{x_1 - \mu_1}{\sigma_1} \right)^2 \right. \right. \\
&\phantom{=} \left. \left. -2\rho \left(\frac{x_1 - \mu_1}{\sigma_1}\right) \left( \frac{x_2 - \mu_2}{\sigma_2} \right) + \left(\frac{x_2 - \mu_2}{\sigma_2}\right)^2 \right] \right\}
\end{align*}
$$

:::