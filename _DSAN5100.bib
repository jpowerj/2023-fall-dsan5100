@book{agnesi_analytical_1801,
  title = {Analytical {{Institutions}} in {{Four Books}}: {{Originally Written}} in {{Italian}}},
  shorttitle = {Analytical {{Institutions}} in {{Four Books}}},
  author = {Agnesi, Maria Gaetana},
  year = {1801},
  publisher = {{Taylor and Wilks}},
  googlebooks = {o54AAAAAMAAJ},
  langid = {english}
}

@book{collins_golem_1993,
  title = {The {{Golem}}: {{What You Should Know About Science}}},
  shorttitle = {The {{Golem}}},
  author = {Collins, Harry M. and Pinch, Trevor},
  year = {1993},
  publisher = {{Cambridge University Press}},
  abstract = {Harry Collins and Trevor Pinch liken science to the Golem, a creature from Jewish mythology, powerful yet potentially dangerous, a gentle, helpful creature that may yet run amok at any moment. Through a series of intriguing case studies the authors debunk the traditional view that science is the straightforward result of competent theorisation, observation and experimentation. The very well-received first edition generated much debate, reflected in a substantial new Afterword in this second edition, which seeks to place the book in what have become known as 'the science wars'.},
  isbn = {978-1-107-39449-0},
  langid = {english}
}

@book{degroot_probability_2013,
  title = {Probability and {{Statistics}}},
  author = {DeGroot, Morris H. and Schervish, Mark J.},
  year = {2013},
  publisher = {{Pearson Education}},
  abstract = {The revision of this well-respected text presents a balanced approach of the classical and Bayesian methods and now includes a chapter on simulation (including Markov chain Monte Carlo and the Bootstrap), coverage of residual analysis in linear models, and many examples using real data. Probability \& Statistics, Fourth Edition, was written for a one- or two-semester probability and statistics course. This course is offered primarily at four-year institutions and taken mostly by sophomore and junior level students majoring in mathematics or statistics. Calculus is a prerequisite, and a familiarity with the concepts and elementary properties of vectors and matrices is a plus.},
  googlebooks = {hIPkngEACAAJ},
  isbn = {978-1-292-02504-9},
  langid = {english}
}

@book{gardner_colossal_2001,
  title = {Colossal {{Book}} of {{Mathematics}}: {{Classic Puzzles Paradoxes And Problems}}},
  shorttitle = {Colossal {{Book}} of {{Mathematics}}},
  author = {Gardner, Martin},
  year = {2001},
  publisher = {{W. W. Norton \& Company}},
  abstract = {No amateur or math authority can be without this ultimate compendium from America's best-loved mathematical expert.Whether discussing hexaflexagons or number theory, Klein bottles or the essence of "nothing," Martin Gardner has single-handedly created the field of "recreational mathematics." The Colossal Book of Mathematics collects together Gardner's most popular pieces from his legendary "Mathematical Games" column, which ran in Scientific American for twenty-five years. Gardner's array of absorbing puzzles and mind-twisting paradoxes opens mathematics up to the world at large, inspiring people to see past numbers and formulas and experience the application of mathematical principles to the mysterious world around them. With articles on topics ranging from simple algebra to the twisting surfaces of Mobius strips, from an endless game of Bulgarian solitaire to the unreachable dream of time travel, this volume comprises a substantial and definitive monument to Gardner's influence on mathematics, science, and culture.  In its twelve sections, The Colossal Book of Math explores a wide range of areas, each startlingly illuminated by Gardner's incisive expertise. Beginning with seemingly simple topics, Gardner expertly guides us through complicated and wondrous worlds: by way of basic algebra we contemplate the mesmerizing, often hilarious, linguistic and numerical possibilities of palindromes; using simple geometry, he dissects the principles of symmetry upon which the renowned mathematical artist M. C. Escher constructs his unique, dizzying universe. Gardner, like few thinkers today, melds a rigorous scientific skepticism with a profound artistic and imaginative impulse. His stunning exploration of "The Church of the Fourth Dimension," for example, bridges the disparate worlds of religion and science by brilliantly imagining the spatial possibility of God's presence in the world as a fourth dimension, at once "everywhere and nowhere."  With boundless wisdom and his trademark wit, Gardner allows the reader to further engage challenging topics like probability and game theory which have plagued clever gamblers, and famous mathematicians, for centuries. Whether debunking Pascal's wager with basic probability, making visual music with fractals, or uncoiling a "knotted doughnut" with introductory topology, Gardner continuously displays his fierce intelligence and gentle humor. His articles confront both the comfortingly mundane\textemdash "Generalized Ticktacktoe" and "Sprouts and Brussel Sprouts"\textemdash and the quakingly abstract\textemdash "Hexaflexagons," "Nothing," and "Everything." He navigates these staggeringly obscure topics with a deft intelligence and, with addendums and suggested reading lists, he informs these classic articles with new insight.  Admired by scientists and mathematicians, writers and readers alike, Gardner's vast knowledge and burning curiosity reveal themselves on every page. The culmination of a lifelong devotion to the wonders of mathematics, The Colossal Book of Mathematics is the largest and most comprehensive math book ever assembled by Gardner and remains an indispensable volume for the amateur and expert alike.},
  googlebooks = {orz0SDEakpYC},
  isbn = {978-0-393-02023-6},
  langid = {english}
}

@book{hastie_elements_2013,
  title = {The {{Elements}} of {{Statistical Learning}}: {{Data Mining}}, {{Inference}}, and {{Prediction}}},
  shorttitle = {The {{Elements}} of {{Statistical Learning}}},
  author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
  year = {2013},
  month = nov,
  publisher = {{Springer Science \& Business Media}},
  abstract = {During the past decade there has been an explosion in computation and information technology. With it have come vast amounts of data in a variety of fields such as medicine, biology, finance, and marketing. The challenge of understanding these data has led to the development of new tools in the field of statistics, and spawned new areas such as data mining, machine learning, and bioinformatics. Many of these tools have common underpinnings but are often expressed with different terminology. This book describes the important ideas in these areas in a common conceptual framework. While the approach is statistical, the emphasis is on concepts rather than mathematics. Many examples are given, with a liberal use of color graphics. It is a valuable resource for statisticians and anyone interested in data mining in science or industry. The book's coverage is broad, from supervised learning (prediction) to unsupervised learning. The many topics include neural networks, support vector machines, classification trees and boosting---the first comprehensive treatment of this topic in any book. This major new edition features many topics not covered in the original, including graphical models, random forests, ensemble methods, least angle regression \& path algorithms for the lasso, non-negative matrix factorization, and spectral clustering. There is also a chapter on methods for ``wide'' data (p bigger than n), including multiple testing and false discovery rates. Trevor Hastie, Robert Tibshirani, and Jerome Friedman are professors of statistics at Stanford University. They are prominent researchers in this area: Hastie and Tibshirani developed generalized additive models and wrote a popular book of that title. Hastie co-developed much of the statistical modeling software and environment in R/S-PLUS and invented principal curves and surfaces. Tibshirani proposed the lasso and is co-author of the very successful An Introduction to the Bootstrap. Friedman is the co-inventor of many data-mining tools including CART, MARS, projection pursuit and gradient boosting.},
  googlebooks = {yPfZBwAAQBAJ},
  isbn = {978-0-387-21606-5},
  langid = {english},
  keywords = {Computers / Artificial Intelligence / General,Computers / Database Administration \& Management,Computers / Mathematical \& Statistical Software,Mathematics / Discrete Mathematics,Mathematics / Probability \& Statistics / General,Mathematics / Probability \& Statistics / Stochastic Processes,Science / Life Sciences / Biology,Science / Life Sciences / General}
}

@book{mcelreath_statistical_2020,
  title = {Statistical {{Rethinking}}: {{A Bayesian Course}} with {{Examples}} in {{R}} and {{STAN}}},
  shorttitle = {Statistical {{Rethinking}}},
  author = {McElreath, Richard},
  year = {2020},
  month = mar,
  publisher = {{CRC Press}},
  abstract = {Statistical Rethinking: A Bayesian Course with Examples in R and Stan builds your knowledge of and confidence in making inferences from data. Reflecting the need for scripting in today's model-based statistics, the book pushes you to perform step-by-step calculations that are usually automated. This unique computational approach ensures that you understand enough of the details to make reasonable choices and interpretations in your own modeling work.  The text presents causal inference and generalized linear multilevel models from a simple Bayesian perspective that builds on information theory and maximum entropy. The core material ranges from the basics of regression to advanced multilevel models. It also presents measurement error, missing data, and Gaussian process models for spatial and phylogenetic confounding.  The second edition emphasizes the directed acyclic graph (DAG) approach to causal inference, integrating DAGs into many examples. The new edition also contains new material on the design of prior distributions, splines, ordered categorical predictors, social relations models, cross-validation, importance sampling, instrumental variables, and Hamiltonian Monte Carlo. It ends with an entirely new chapter that goes beyond generalized linear modeling, showing how domain-specific scientific models can be built into statistical analyses.  Features   Integrates working code into the main text   Illustrates concepts through worked data analysis examples   Emphasizes understanding assumptions and how assumptions are reflected in code   Offers more detailed explanations of the mathematics in optional sections   Presents examples of using the dagitty R package to analyze causal graphs   Provides the rethinking R package on the author's website and on GitHub},
  googlebooks = {FuLWDwAAQBAJ},
  isbn = {978-0-429-64231-9},
  langid = {english},
  keywords = {Mathematics / General,Mathematics / Probability \& Statistics / General,Science / Life Sciences / Biological Diversity}
}

@article{tharwat_parameter_2019,
  title = {Parameter Investigation of Support Vector Machine Classifier with Kernel Functions},
  author = {Tharwat, Alaa},
  year = {2019},
  month = dec,
  journal = {Knowledge and Information Systems},
  volume = {61},
  number = {3},
  pages = {1269--1302},
  issn = {0219-3116},
  doi = {10.1007/s10115-019-01335-4},
  urldate = {2023-10-19},
  abstract = {Support vector machine (SVM) is one of the well-known learning algorithms for classification and regression problems. SVM parameters such as kernel parameters and penalty parameter have a great influence on the complexity and performance of predicting models. Hence, the model selection in SVM involves the penalty parameter and kernel parameters. However, these parameters are usually selected and used as a black box, without understanding the internal details. In this paper, the behavior of the SVM classifier is analyzed when these parameters take different values. This analysis consists of illustrative examples, visualization, and mathematical and geometrical interpretations with the aim of providing the basics of kernel functions with SVM and to show how it works to serve as a comprehensive source for researchers who are interested in this field. This paper starts by highlighting the definition and underlying principles of SVM in details. Moreover, different kernel functions are introduced and the impact of each parameter in these kernel functions is explained from different perspectives.},
  langid = {english},
  file = {/Users/jpj/Zotero/storage/BX3VQ6AH/Tharwat - 2019 - Parameter investigation of support vector machine .pdf}
}
